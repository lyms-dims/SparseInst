[11/22 05:41:26] detectron2 INFO: Rank of current process: 0. World size: 1
[11/22 05:41:27] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]
numpy                            2.2.6
detectron2                       0.6 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\detectron2
Compiler                         MSVC 195035718
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.9.1+cu126 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  True
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4060 (arch=8.9)
Driver version                   572.42
CUDA_HOME                        None - invalid!
Pillow                           12.0.0
torchvision                      0.24.1+cu126 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torchvision
torchvision arch flags           C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 194234444
  - Intel(R) oneAPI Math Kernel Library Version 2025.3-Product Build 20251007 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.7.1 (Git Hash 8d263e693366ef8db40acc569cc7d8edf644556d)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.6
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 91.0.2  (built against CUDA 12.9)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, COMMIT_SHA=5811a8d7da873dd699ff6687092c225caffcf1bb, CUDA_VERSION=12.6, CUDNN_VERSION=9.10.2, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/pytorch/.ci/pytorch/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, USE_XCCL=OFF, USE_XPU=OFF, 

[11/22 05:41:27] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sparse_inst_r50_giam_crack.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:49153', opts=['SOLVER.STEPS', '(10000,)', 'SOLVER.IMS_PER_BATCH', '8', 'SOLVER.BASE_LR', '0.00005', 'SOLVER.AMP.ENABLED', 'True', 'INPUT.MIN_SIZE_TRAIN', '(512,)', 'INPUT.MIN_SIZE_TEST', '512', 'OUTPUT_DIR', 'output/crack_model_turbo'])
[11/22 05:41:27] detectron2 INFO: Contents of args.config_file=configs/sparse_inst_r50_giam_crack.yaml:
# Configuration for SparseInst with ResNet-50 backbone for crack detection
# Based on sparse_inst_r50_giam.yaml but adapted for single-class crack detection

_BASE_: "Base-SparseInst.yaml"

MODEL:
  WEIGHTS: "pretrained_models/R-50.pkl"
  SPARSE_INST:
    DECODER:
      NUM_CLASSES: 1  # Only one class: crack
      NUM_MASKS: 100  # Maximum number of instances to detect

DATASETS:
  # Update these names after registering your dataset
  # Example: ("deepcracks_train",)
  TRAIN: ("deepcracks_train",)
  TEST: ("deepcracks_val",)

SOLVER:
  IMS_PER_BATCH: 16  # Reduced from 64 for smaller datasets, adjust based on GPU memory
  BASE_LR: 0.0001  # Slightly higher learning rate for fine-tuning
  STEPS: (10000, 15000)  # Adjust based on your dataset size
  MAX_ITER: 15000  # Adjust based on your dataset size
  WEIGHT_DECAY: 0.05
  # For smaller datasets, you might want to reduce learning rate schedule
  # STEPS: (5000, 10000)
  # MAX_ITER: 15000

INPUT:
  MIN_SIZE_TRAIN: (416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 853
  MIN_SIZE_TEST: 640
  MAX_SIZE_TEST: 853
  FORMAT: "RGB"
  MASK_FORMAT: "bitmask"

TEST:
  EVAL_PERIOD: 1000  # Evaluate every 1000 iterations

DATALOADER:
  NUM_WORKERS: 4  # Adjust based on your system

OUTPUT_DIR: "output/sparse_inst_r50_giam_crack"


[11/22 05:41:27] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - deepcracks_val
  TRAIN:
  - deepcracks_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: RGB
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 853
  MAX_SIZE_TRAIN: 853
  MIN_SIZE_TEST: 512
  MIN_SIZE_TRAIN:
  - 512
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_backbone
  CSPNET:
    NAME: darknet53
    NORM: ''
    OUT_FEATURES:
    - csp1
    - csp2
    - csp3
    - csp4
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: SparseInst
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  PVT:
    LINEAR: false
    NAME: b1
    OUT_FEATURES:
    - p2
    - p3
    - p4
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SPARSE_INST:
    CLS_THRESHOLD: 0.005
    DATASET_MAPPER: SparseInstDatasetMapper
    DECODER:
      GROUPS: 4
      INST:
        CONVS: 4
        DIM: 256
      KERNEL_DIM: 128
      MASK:
        CONVS: 4
        DIM: 256
      NAME: GroupIAMDecoder
      NUM_CLASSES: 1
      NUM_MASKS: 100
      OUTPUT_IAM: false
      SCALE_FACTOR: 2.0
    ENCODER:
      IN_FEATURES:
      - res3
      - res4
      - res5
      NAME: InstanceContextEncoder
      NORM: ''
      NUM_CHANNELS: 256
    LOSS:
      CLASS_WEIGHT: 2.0
      ITEMS:
      - labels
      - masks
      MASK_DICE_WEIGHT: 2.0
      MASK_PIXEL_WEIGHT: 5.0
      NAME: SparseInstCriterion
      OBJECTNESS_WEIGHT: 1.0
    MASK_THRESHOLD: 0.45
    MATCHER:
      ALPHA: 0.8
      BETA: 0.2
      NAME: SparseInstMatcher
    MAX_DETECTIONS: 100
  WEIGHTS: pretrained_models/R-50.pkl
OUTPUT_DIR: output/crack_model_turbo
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  AMSGRAD: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 15000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 10000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/22 05:41:27] detectron2 INFO: Full config saved to output/crack_model_turbo\config.yaml
[11/22 05:41:27] d2.utils.env INFO: Using a generated random seed 27099265
[11/22 05:41:27] d2.engine.defaults INFO: Model:
SparseInst(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (encoder): InstanceContextEncoder(
    (fpn_laterals): ModuleList(
      (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (fpn_outputs): ModuleList(
      (0-2): 3 x Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (ppm): PyramidPoolingModule(
      (stages): ModuleList(
        (0): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(2, 2))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(3, 3))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(6, 6))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (bottleneck): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (fusion): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
  )
  (decoder): GroupIAMDecoder(
    (inst_branch): GroupInstanceBranch(
      (inst_convs): Sequential(
        (0): Conv2d(258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU(inplace=True)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU(inplace=True)
      )
      (iam_conv): Conv2d(256, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)
      (fc): Linear(in_features=1024, out_features=1024, bias=True)
      (cls_score): Linear(in_features=1024, out_features=1, bias=True)
      (mask_kernel): Linear(in_features=1024, out_features=128, bias=True)
      (objectness): Linear(in_features=1024, out_features=1, bias=True)
    )
    (mask_branch): MaskBranch(
      (mask_convs): Sequential(
        (0): Conv2d(258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU(inplace=True)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU(inplace=True)
      )
      (projection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (criterion): SparseInstCriterion(
    (matcher): SparseInstMatcher()
  )
)
[11/22 05:41:27] sparseinst.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(512,), max_size=853, sample_style='choice')]
[11/22 05:41:27] d2.data.datasets.coco INFO: Loaded 382 images in COCO format from datasets/DeepCrack/annotations/train.json
[11/22 05:41:27] d2.data.build INFO: Removed 0 images with no usable annotations. 382 images left.
[11/22 05:41:27] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   crack    | 1250         |
|            |              |[0m
[11/22 05:41:27] d2.data.build INFO: Using training sampler TrainingSampler
[11/22 05:41:27] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 05:41:27] d2.data.common INFO: Serializing 382 elements to byte tensors and concatenating them all ...
[11/22 05:41:27] d2.data.common INFO: Serialized dataset takes 0.66 MiB
[11/22 05:41:27] d2.data.build INFO: Making batched data loader with batch_size=8
[11/22 05:41:27] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from pretrained_models/R-50.pkl ...
[11/22 05:41:27] fvcore.common.checkpoint INFO: [Checkpointer] Loading from pretrained_models/R-50.pkl ...
[11/22 05:41:27] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[11/22 05:41:27] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone - Total num: 54
[11/22 05:41:27] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mdecoder.inst_branch.cls_score.{bias, weight}[0m
[34mdecoder.inst_branch.fc.{bias, weight}[0m
[34mdecoder.inst_branch.iam_conv.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.0.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.2.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.4.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.6.{bias, weight}[0m
[34mdecoder.inst_branch.mask_kernel.{bias, weight}[0m
[34mdecoder.inst_branch.objectness.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.0.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.2.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.4.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.6.{bias, weight}[0m
[34mdecoder.mask_branch.projection.{bias, weight}[0m
[34mencoder.fpn_laterals.0.{bias, weight}[0m
[34mencoder.fpn_laterals.1.{bias, weight}[0m
[34mencoder.fpn_laterals.2.{bias, weight}[0m
[34mencoder.fpn_outputs.0.{bias, weight}[0m
[34mencoder.fpn_outputs.1.{bias, weight}[0m
[34mencoder.fpn_outputs.2.{bias, weight}[0m
[34mencoder.fusion.{bias, weight}[0m
[34mencoder.ppm.bottleneck.{bias, weight}[0m
[34mencoder.ppm.stages.0.1.{bias, weight}[0m
[34mencoder.ppm.stages.1.1.{bias, weight}[0m
[34mencoder.ppm.stages.2.1.{bias, weight}[0m
[34mencoder.ppm.stages.3.1.{bias, weight}[0m
[11/22 05:41:27] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[11/22 05:41:27] d2.engine.train_loop INFO: Starting training from iteration 0
[11/22 05:41:38] d2.utils.events INFO:  eta: 1:15:42  iter: 19  total_loss: 133.5  loss_ce: 1.76  loss_objectness: 0.9206  loss_dice: 1.959  loss_mask: 128.9    time: 0.3075  last_time: 0.3061  data_time: 0.2108  last_data_time: 0.0044   lr: 9.9905e-07  max_mem: 2549M
[11/22 05:41:45] d2.utils.events INFO:  eta: 1:15:51  iter: 39  total_loss: 6.919  loss_ce: 1.85  loss_objectness: 0.9693  loss_dice: 1.996  loss_mask: 2.068    time: 0.3065  last_time: 0.3063  data_time: 0.0047  last_data_time: 0.0052   lr: 1.998e-06  max_mem: 2549M
[11/22 05:41:51] d2.utils.events INFO:  eta: 1:15:38  iter: 59  total_loss: 6.928  loss_ce: 1.861  loss_objectness: 0.9194  loss_dice: 2  loss_mask: 2.168    time: 0.3055  last_time: 0.3028  data_time: 0.0047  last_data_time: 0.0045   lr: 2.997e-06  max_mem: 2555M
[11/22 05:41:57] d2.utils.events INFO:  eta: 1:15:44  iter: 79  total_loss: 6.075  loss_ce: 1.833  loss_objectness: 0.8105  loss_dice: 2  loss_mask: 1.44    time: 0.3058  last_time: 0.3103  data_time: 0.0049  last_data_time: 0.0049   lr: 3.9961e-06  max_mem: 2556M
[11/22 05:42:03] d2.utils.events INFO:  eta: 1:15:36  iter: 99  total_loss: 5.515  loss_ce: 1.778  loss_objectness: 0.661  loss_dice: 1.999  loss_mask: 1.041    time: 0.3054  last_time: 0.3052  data_time: 0.0047  last_data_time: 0.0045   lr: 4.9951e-06  max_mem: 2556M
[11/22 05:42:09] d2.utils.events INFO:  eta: 1:15:29  iter: 119  total_loss: 4.787  loss_ce: 1.709  loss_objectness: 0.5381  loss_dice: 1.923  loss_mask: 0.747    time: 0.3053  last_time: 0.3048  data_time: 0.0047  last_data_time: 0.0055   lr: 5.9941e-06  max_mem: 2556M
[11/22 05:42:15] d2.utils.events INFO:  eta: 1:15:19  iter: 139  total_loss: 4.363  loss_ce: 1.539  loss_objectness: 0.4219  loss_dice: 1.859  loss_mask: 0.4782    time: 0.3051  last_time: 0.3047  data_time: 0.0046  last_data_time: 0.0045   lr: 6.993e-06  max_mem: 2557M
[11/22 05:42:21] d2.utils.events INFO:  eta: 1:15:16  iter: 159  total_loss: 3.91  loss_ce: 1.304  loss_objectness: 0.3519  loss_dice: 1.821  loss_mask: 0.4703    time: 0.3054  last_time: 0.3033  data_time: 0.0054  last_data_time: 0.0046   lr: 7.9921e-06  max_mem: 2557M
[11/22 05:42:28] d2.utils.events INFO:  eta: 1:15:16  iter: 179  total_loss: 3.521  loss_ce: 1.015  loss_objectness: 0.3015  loss_dice: 1.793  loss_mask: 0.3925    time: 0.3062  last_time: 0.3095  data_time: 0.0056  last_data_time: 0.0055   lr: 8.9911e-06  max_mem: 2557M
[11/22 05:42:34] d2.utils.events INFO:  eta: 1:15:14  iter: 199  total_loss: 3.185  loss_ce: 0.8562  loss_objectness: 0.286  loss_dice: 1.714  loss_mask: 0.3363    time: 0.3067  last_time: 0.3042  data_time: 0.0053  last_data_time: 0.0040   lr: 9.99e-06  max_mem: 2557M
[11/22 05:42:40] d2.utils.events INFO:  eta: 1:15:09  iter: 219  total_loss: 3.119  loss_ce: 0.8456  loss_objectness: 0.3062  loss_dice: 1.672  loss_mask: 0.2891    time: 0.3068  last_time: 0.3070  data_time: 0.0048  last_data_time: 0.0048   lr: 1.0989e-05  max_mem: 2557M
[11/22 05:42:46] d2.utils.events INFO:  eta: 1:15:09  iter: 239  total_loss: 3.05  loss_ce: 0.8119  loss_objectness: 0.2988  loss_dice: 1.671  loss_mask: 0.2722    time: 0.3072  last_time: 0.3068  data_time: 0.0052  last_data_time: 0.0050   lr: 1.1988e-05  max_mem: 2557M
[11/22 05:42:52] d2.utils.events INFO:  eta: 1:14:59  iter: 259  total_loss: 3.022  loss_ce: 0.8045  loss_objectness: 0.3176  loss_dice: 1.635  loss_mask: 0.2442    time: 0.3069  last_time: 0.3091  data_time: 0.0052  last_data_time: 0.0053   lr: 1.2987e-05  max_mem: 2557M
[11/22 05:42:58] d2.utils.events INFO:  eta: 1:14:47  iter: 279  total_loss: 2.94  loss_ce: 0.7798  loss_objectness: 0.3338  loss_dice: 1.607  loss_mask: 0.2199    time: 0.3067  last_time: 0.3008  data_time: 0.0051  last_data_time: 0.0044   lr: 1.3986e-05  max_mem: 2557M
[11/22 05:43:04] d2.utils.events INFO:  eta: 1:14:41  iter: 299  total_loss: 2.895  loss_ce: 0.7493  loss_objectness: 0.3476  loss_dice: 1.596  loss_mask: 0.2178    time: 0.3066  last_time: 0.3038  data_time: 0.0054  last_data_time: 0.0063   lr: 1.4985e-05  max_mem: 2557M
[11/22 05:43:11] d2.utils.events INFO:  eta: 1:14:40  iter: 319  total_loss: 2.858  loss_ce: 0.7078  loss_objectness: 0.3621  loss_dice: 1.544  loss_mask: 0.2122    time: 0.3070  last_time: 0.3468  data_time: 0.0058  last_data_time: 0.0087   lr: 1.5984e-05  max_mem: 2557M
[11/22 05:43:17] d2.utils.events INFO:  eta: 1:14:36  iter: 339  total_loss: 2.765  loss_ce: 0.641  loss_objectness: 0.4101  loss_dice: 1.472  loss_mask: 0.2474    time: 0.3073  last_time: 0.3071  data_time: 0.0057  last_data_time: 0.0060   lr: 1.6983e-05  max_mem: 2557M
[11/22 05:43:23] d2.utils.events INFO:  eta: 1:14:33  iter: 359  total_loss: 2.638  loss_ce: 0.5666  loss_objectness: 0.409  loss_dice: 1.458  loss_mask: 0.1972    time: 0.3078  last_time: 0.3194  data_time: 0.0059  last_data_time: 0.0063   lr: 1.7982e-05  max_mem: 2557M
[11/22 05:43:30] d2.utils.events INFO:  eta: 1:14:31  iter: 379  total_loss: 2.609  loss_ce: 0.5575  loss_objectness: 0.3872  loss_dice: 1.489  loss_mask: 0.2079    time: 0.3081  last_time: 0.3442  data_time: 0.0057  last_data_time: 0.0045   lr: 1.8981e-05  max_mem: 2557M
[11/22 05:43:34] d2.engine.hooks INFO: Overall training speed: 392 iterations in 0:02:00 (0.3084 s / it)
[11/22 05:43:34] d2.engine.hooks INFO: Total training time: 0:02:01 (0:00:00 on hooks)
[11/22 05:43:34] d2.utils.events INFO:  eta: 1:14:25  iter: 394  total_loss: 2.599  loss_ce: 0.5378  loss_objectness: 0.3816  loss_dice: 1.495  loss_mask: 0.2118    time: 0.3080  last_time: 0.3063  data_time: 0.0049  last_data_time: 0.0047   lr: 1.968e-05  max_mem: 2557M
[11/22 05:44:19] detectron2 INFO: Rank of current process: 0. World size: 1
[11/22 05:44:19] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]
numpy                            2.2.6
detectron2                       0.6 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\detectron2
Compiler                         MSVC 195035718
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.9.1+cu126 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  True
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4060 (arch=8.9)
Driver version                   572.42
CUDA_HOME                        None - invalid!
Pillow                           12.0.0
torchvision                      0.24.1+cu126 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torchvision
torchvision arch flags           C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 194234444
  - Intel(R) oneAPI Math Kernel Library Version 2025.3-Product Build 20251007 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.7.1 (Git Hash 8d263e693366ef8db40acc569cc7d8edf644556d)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.6
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 91.0.2  (built against CUDA 12.9)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, COMMIT_SHA=5811a8d7da873dd699ff6687092c225caffcf1bb, CUDA_VERSION=12.6, CUDNN_VERSION=9.10.2, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/pytorch/.ci/pytorch/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, USE_XCCL=OFF, USE_XPU=OFF, 

[11/22 05:44:19] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sparse_inst_r50_giam_crack.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:49153', opts=['SOLVER.STEPS', '(10000,)', 'SOLVER.IMS_PER_BATCH', '8', 'SOLVER.BASE_LR', '0.00005', 'SOLVER.AMP.ENABLED', 'True', 'INPUT.MIN_SIZE_TRAIN', '(512,)', 'INPUT.MIN_SIZE_TEST', '512', 'OUTPUT_DIR', 'output/crack_model_turbo'])
[11/22 05:44:19] detectron2 INFO: Contents of args.config_file=configs/sparse_inst_r50_giam_crack.yaml:
# Configuration for SparseInst with ResNet-50 backbone for crack detection
# Based on sparse_inst_r50_giam.yaml but adapted for single-class crack detection

_BASE_: "Base-SparseInst.yaml"

MODEL:
  WEIGHTS: "pretrained_models/R-50.pkl"
  SPARSE_INST:
    DECODER:
      NUM_CLASSES: 1  # Only one class: crack
      NUM_MASKS: 100  # Maximum number of instances to detect

DATASETS:
  # Update these names after registering your dataset
  # Example: ("deepcracks_train",)
  TRAIN: ("deepcracks_train",)
  TEST: ("deepcracks_val",)

SOLVER:
  IMS_PER_BATCH: 16  # Reduced from 64 for smaller datasets, adjust based on GPU memory
  BASE_LR: 0.0001  # Slightly higher learning rate for fine-tuning
  STEPS: (10000, 15000)  # Adjust based on your dataset size
  MAX_ITER: 15000  # Adjust based on your dataset size
  WEIGHT_DECAY: 0.05
  # For smaller datasets, you might want to reduce learning rate schedule
  # STEPS: (5000, 10000)
  # MAX_ITER: 15000

INPUT:
  MIN_SIZE_TRAIN: (416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 853
  MIN_SIZE_TEST: 640
  MAX_SIZE_TEST: 853
  FORMAT: "RGB"
  MASK_FORMAT: "bitmask"

TEST:
  EVAL_PERIOD: 1000  # Evaluate every 1000 iterations

DATALOADER:
  NUM_WORKERS: 4  # Adjust based on your system

OUTPUT_DIR: "output/sparse_inst_r50_giam_crack"


[11/22 05:44:19] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - deepcracks_val
  TRAIN:
  - deepcracks_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: RGB
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 853
  MAX_SIZE_TRAIN: 853
  MIN_SIZE_TEST: 512
  MIN_SIZE_TRAIN:
  - 512
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_backbone
  CSPNET:
    NAME: darknet53
    NORM: ''
    OUT_FEATURES:
    - csp1
    - csp2
    - csp3
    - csp4
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: SparseInst
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  PVT:
    LINEAR: false
    NAME: b1
    OUT_FEATURES:
    - p2
    - p3
    - p4
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SPARSE_INST:
    CLS_THRESHOLD: 0.005
    DATASET_MAPPER: SparseInstDatasetMapper
    DECODER:
      GROUPS: 4
      INST:
        CONVS: 4
        DIM: 256
      KERNEL_DIM: 128
      MASK:
        CONVS: 4
        DIM: 256
      NAME: GroupIAMDecoder
      NUM_CLASSES: 1
      NUM_MASKS: 100
      OUTPUT_IAM: false
      SCALE_FACTOR: 2.0
    ENCODER:
      IN_FEATURES:
      - res3
      - res4
      - res5
      NAME: InstanceContextEncoder
      NORM: ''
      NUM_CHANNELS: 256
    LOSS:
      CLASS_WEIGHT: 2.0
      ITEMS:
      - labels
      - masks
      MASK_DICE_WEIGHT: 2.0
      MASK_PIXEL_WEIGHT: 5.0
      NAME: SparseInstCriterion
      OBJECTNESS_WEIGHT: 1.0
    MASK_THRESHOLD: 0.45
    MATCHER:
      ALPHA: 0.8
      BETA: 0.2
      NAME: SparseInstMatcher
    MAX_DETECTIONS: 100
  WEIGHTS: pretrained_models/R-50.pkl
OUTPUT_DIR: output/crack_model_turbo
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  AMSGRAD: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 15000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 10000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/22 05:44:19] detectron2 INFO: Full config saved to output/crack_model_turbo\config.yaml
[11/22 05:44:19] d2.utils.env INFO: Using a generated random seed 19511011
[11/22 05:44:19] d2.engine.defaults INFO: Model:
SparseInst(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (encoder): InstanceContextEncoder(
    (fpn_laterals): ModuleList(
      (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (fpn_outputs): ModuleList(
      (0-2): 3 x Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (ppm): PyramidPoolingModule(
      (stages): ModuleList(
        (0): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(2, 2))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(3, 3))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(6, 6))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (bottleneck): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (fusion): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
  )
  (decoder): GroupIAMDecoder(
    (inst_branch): GroupInstanceBranch(
      (inst_convs): Sequential(
        (0): Conv2d(258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU(inplace=True)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU(inplace=True)
      )
      (iam_conv): Conv2d(256, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)
      (fc): Linear(in_features=1024, out_features=1024, bias=True)
      (cls_score): Linear(in_features=1024, out_features=1, bias=True)
      (mask_kernel): Linear(in_features=1024, out_features=128, bias=True)
      (objectness): Linear(in_features=1024, out_features=1, bias=True)
    )
    (mask_branch): MaskBranch(
      (mask_convs): Sequential(
        (0): Conv2d(258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU(inplace=True)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU(inplace=True)
      )
      (projection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (criterion): SparseInstCriterion(
    (matcher): SparseInstMatcher()
  )
)
[11/22 05:44:19] sparseinst.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(512,), max_size=853, sample_style='choice')]
[11/22 05:44:19] d2.data.datasets.coco INFO: Loaded 382 images in COCO format from datasets/DeepCrack/annotations/train.json
[11/22 05:44:19] d2.data.build INFO: Removed 0 images with no usable annotations. 382 images left.
[11/22 05:44:19] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   crack    | 1250         |
|            |              |[0m
[11/22 05:44:19] d2.data.build INFO: Using training sampler TrainingSampler
[11/22 05:44:19] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 05:44:19] d2.data.common INFO: Serializing 382 elements to byte tensors and concatenating them all ...
[11/22 05:44:19] d2.data.common INFO: Serialized dataset takes 0.66 MiB
[11/22 05:44:19] d2.data.build INFO: Making batched data loader with batch_size=8
[11/22 05:44:19] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from pretrained_models/R-50.pkl ...
[11/22 05:44:19] fvcore.common.checkpoint INFO: [Checkpointer] Loading from pretrained_models/R-50.pkl ...
[11/22 05:44:19] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[11/22 05:44:19] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone - Total num: 54
[11/22 05:44:20] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mdecoder.inst_branch.cls_score.{bias, weight}[0m
[34mdecoder.inst_branch.fc.{bias, weight}[0m
[34mdecoder.inst_branch.iam_conv.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.0.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.2.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.4.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.6.{bias, weight}[0m
[34mdecoder.inst_branch.mask_kernel.{bias, weight}[0m
[34mdecoder.inst_branch.objectness.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.0.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.2.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.4.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.6.{bias, weight}[0m
[34mdecoder.mask_branch.projection.{bias, weight}[0m
[34mencoder.fpn_laterals.0.{bias, weight}[0m
[34mencoder.fpn_laterals.1.{bias, weight}[0m
[34mencoder.fpn_laterals.2.{bias, weight}[0m
[34mencoder.fpn_outputs.0.{bias, weight}[0m
[34mencoder.fpn_outputs.1.{bias, weight}[0m
[34mencoder.fpn_outputs.2.{bias, weight}[0m
[34mencoder.fusion.{bias, weight}[0m
[34mencoder.ppm.bottleneck.{bias, weight}[0m
[34mencoder.ppm.stages.0.1.{bias, weight}[0m
[34mencoder.ppm.stages.1.1.{bias, weight}[0m
[34mencoder.ppm.stages.2.1.{bias, weight}[0m
[34mencoder.ppm.stages.3.1.{bias, weight}[0m
[11/22 05:44:20] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[11/22 05:44:20] d2.engine.train_loop INFO: Starting training from iteration 0
[11/22 05:44:31] d2.utils.events INFO:  eta: 1:15:59  iter: 19  total_loss: 6.448  loss_ce: 2.53  loss_objectness: 0.8736  loss_dice: 1.964  loss_mask: 1.076    time: 0.3151  last_time: 0.3076  data_time: 0.2110  last_data_time: 0.0052   lr: 9.9905e-07  max_mem: 2544M
[11/22 05:44:37] d2.utils.events INFO:  eta: 1:15:22  iter: 39  total_loss: 5.353  loss_ce: 2.449  loss_objectness: 0.5672  loss_dice: 1.876  loss_mask: 0.5177    time: 0.3083  last_time: 0.3074  data_time: 0.0048  last_data_time: 0.0050   lr: 1.998e-06  max_mem: 2544M
[11/22 05:44:43] d2.utils.events INFO:  eta: 1:15:14  iter: 59  total_loss: 4.809  loss_ce: 2.275  loss_objectness: 0.3561  loss_dice: 1.78  loss_mask: 0.3243    time: 0.3063  last_time: 0.3020  data_time: 0.0048  last_data_time: 0.0045   lr: 2.997e-06  max_mem: 2554M
[11/22 05:44:49] d2.utils.events INFO:  eta: 1:15:10  iter: 79  total_loss: 4.359  loss_ce: 2.01  loss_objectness: 0.3032  loss_dice: 1.8  loss_mask: 0.2717    time: 0.3054  last_time: 0.3041  data_time: 0.0049  last_data_time: 0.0051   lr: 3.9961e-06  max_mem: 2557M
[11/22 05:44:53] d2.engine.hooks INFO: Overall training speed: 91 iterations in 0:00:28 (0.3078 s / it)
[11/22 05:44:53] d2.engine.hooks INFO: Total training time: 0:00:28 (0:00:00 on hooks)
[11/22 05:44:53] d2.utils.events INFO:  eta: 1:15:03  iter: 93  total_loss: 4.047  loss_ce: 1.699  loss_objectness: 0.3146  loss_dice: 1.64  loss_mask: 0.3123    time: 0.3047  last_time: 0.2999  data_time: 0.0048  last_data_time: 0.0043   lr: 4.6454e-06  max_mem: 2557M
[11/22 05:45:06] detectron2 INFO: Rank of current process: 0. World size: 1
[11/22 05:45:06] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]
numpy                            2.2.6
detectron2                       0.6 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\detectron2
Compiler                         MSVC 195035718
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.9.1+cu126 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  True
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4060 (arch=8.9)
Driver version                   572.42
CUDA_HOME                        None - invalid!
Pillow                           12.0.0
torchvision                      0.24.1+cu126 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torchvision
torchvision arch flags           C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 194234444
  - Intel(R) oneAPI Math Kernel Library Version 2025.3-Product Build 20251007 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.7.1 (Git Hash 8d263e693366ef8db40acc569cc7d8edf644556d)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.6
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 91.0.2  (built against CUDA 12.9)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, COMMIT_SHA=5811a8d7da873dd699ff6687092c225caffcf1bb, CUDA_VERSION=12.6, CUDNN_VERSION=9.10.2, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/pytorch/.ci/pytorch/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, USE_XCCL=OFF, USE_XPU=OFF, 

[11/22 05:45:06] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sparse_inst_r50_giam_crack.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:49153', opts=['SOLVER.STEPS', '(10000,)', 'SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.00005', 'SOLVER.AMP.ENABLED', 'True', 'INPUT.MIN_SIZE_TRAIN', '(512,)', 'INPUT.MIN_SIZE_TEST', '512', 'OUTPUT_DIR', 'output/crack_model_turbo'])
[11/22 05:45:06] detectron2 INFO: Contents of args.config_file=configs/sparse_inst_r50_giam_crack.yaml:
# Configuration for SparseInst with ResNet-50 backbone for crack detection
# Based on sparse_inst_r50_giam.yaml but adapted for single-class crack detection

_BASE_: "Base-SparseInst.yaml"

MODEL:
  WEIGHTS: "pretrained_models/R-50.pkl"
  SPARSE_INST:
    DECODER:
      NUM_CLASSES: 1  # Only one class: crack
      NUM_MASKS: 100  # Maximum number of instances to detect

DATASETS:
  # Update these names after registering your dataset
  # Example: ("deepcracks_train",)
  TRAIN: ("deepcracks_train",)
  TEST: ("deepcracks_val",)

SOLVER:
  IMS_PER_BATCH: 16  # Reduced from 64 for smaller datasets, adjust based on GPU memory
  BASE_LR: 0.0001  # Slightly higher learning rate for fine-tuning
  STEPS: (10000, 15000)  # Adjust based on your dataset size
  MAX_ITER: 15000  # Adjust based on your dataset size
  WEIGHT_DECAY: 0.05
  # For smaller datasets, you might want to reduce learning rate schedule
  # STEPS: (5000, 10000)
  # MAX_ITER: 15000

INPUT:
  MIN_SIZE_TRAIN: (416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 853
  MIN_SIZE_TEST: 640
  MAX_SIZE_TEST: 853
  FORMAT: "RGB"
  MASK_FORMAT: "bitmask"

TEST:
  EVAL_PERIOD: 1000  # Evaluate every 1000 iterations

DATALOADER:
  NUM_WORKERS: 4  # Adjust based on your system

OUTPUT_DIR: "output/sparse_inst_r50_giam_crack"


[11/22 05:45:06] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - deepcracks_val
  TRAIN:
  - deepcracks_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: RGB
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 853
  MAX_SIZE_TRAIN: 853
  MIN_SIZE_TEST: 512
  MIN_SIZE_TRAIN:
  - 512
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_backbone
  CSPNET:
    NAME: darknet53
    NORM: ''
    OUT_FEATURES:
    - csp1
    - csp2
    - csp3
    - csp4
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: SparseInst
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  PVT:
    LINEAR: false
    NAME: b1
    OUT_FEATURES:
    - p2
    - p3
    - p4
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SPARSE_INST:
    CLS_THRESHOLD: 0.005
    DATASET_MAPPER: SparseInstDatasetMapper
    DECODER:
      GROUPS: 4
      INST:
        CONVS: 4
        DIM: 256
      KERNEL_DIM: 128
      MASK:
        CONVS: 4
        DIM: 256
      NAME: GroupIAMDecoder
      NUM_CLASSES: 1
      NUM_MASKS: 100
      OUTPUT_IAM: false
      SCALE_FACTOR: 2.0
    ENCODER:
      IN_FEATURES:
      - res3
      - res4
      - res5
      NAME: InstanceContextEncoder
      NORM: ''
      NUM_CHANNELS: 256
    LOSS:
      CLASS_WEIGHT: 2.0
      ITEMS:
      - labels
      - masks
      MASK_DICE_WEIGHT: 2.0
      MASK_PIXEL_WEIGHT: 5.0
      NAME: SparseInstCriterion
      OBJECTNESS_WEIGHT: 1.0
    MASK_THRESHOLD: 0.45
    MATCHER:
      ALPHA: 0.8
      BETA: 0.2
      NAME: SparseInstMatcher
    MAX_DETECTIONS: 100
  WEIGHTS: pretrained_models/R-50.pkl
OUTPUT_DIR: output/crack_model_turbo
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  AMSGRAD: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 15000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 10000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/22 05:45:06] detectron2 INFO: Full config saved to output/crack_model_turbo\config.yaml
[11/22 05:45:06] d2.utils.env INFO: Using a generated random seed 6765860
[11/22 05:45:07] d2.engine.defaults INFO: Model:
SparseInst(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (encoder): InstanceContextEncoder(
    (fpn_laterals): ModuleList(
      (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (fpn_outputs): ModuleList(
      (0-2): 3 x Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (ppm): PyramidPoolingModule(
      (stages): ModuleList(
        (0): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(2, 2))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(3, 3))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(6, 6))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (bottleneck): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (fusion): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
  )
  (decoder): GroupIAMDecoder(
    (inst_branch): GroupInstanceBranch(
      (inst_convs): Sequential(
        (0): Conv2d(258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU(inplace=True)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU(inplace=True)
      )
      (iam_conv): Conv2d(256, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)
      (fc): Linear(in_features=1024, out_features=1024, bias=True)
      (cls_score): Linear(in_features=1024, out_features=1, bias=True)
      (mask_kernel): Linear(in_features=1024, out_features=128, bias=True)
      (objectness): Linear(in_features=1024, out_features=1, bias=True)
    )
    (mask_branch): MaskBranch(
      (mask_convs): Sequential(
        (0): Conv2d(258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU(inplace=True)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU(inplace=True)
      )
      (projection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (criterion): SparseInstCriterion(
    (matcher): SparseInstMatcher()
  )
)
[11/22 05:45:07] sparseinst.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(512,), max_size=853, sample_style='choice')]
[11/22 05:45:07] d2.data.datasets.coco INFO: Loaded 382 images in COCO format from datasets/DeepCrack/annotations/train.json
[11/22 05:45:07] d2.data.build INFO: Removed 0 images with no usable annotations. 382 images left.
[11/22 05:45:07] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   crack    | 1250         |
|            |              |[0m
[11/22 05:45:07] d2.data.build INFO: Using training sampler TrainingSampler
[11/22 05:45:07] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 05:45:07] d2.data.common INFO: Serializing 382 elements to byte tensors and concatenating them all ...
[11/22 05:45:07] d2.data.common INFO: Serialized dataset takes 0.66 MiB
[11/22 05:45:07] d2.data.build INFO: Making batched data loader with batch_size=4
[11/22 05:45:07] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from pretrained_models/R-50.pkl ...
[11/22 05:45:07] fvcore.common.checkpoint INFO: [Checkpointer] Loading from pretrained_models/R-50.pkl ...
[11/22 05:45:07] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[11/22 05:45:07] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone - Total num: 54
[11/22 05:45:07] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mdecoder.inst_branch.cls_score.{bias, weight}[0m
[34mdecoder.inst_branch.fc.{bias, weight}[0m
[34mdecoder.inst_branch.iam_conv.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.0.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.2.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.4.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.6.{bias, weight}[0m
[34mdecoder.inst_branch.mask_kernel.{bias, weight}[0m
[34mdecoder.inst_branch.objectness.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.0.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.2.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.4.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.6.{bias, weight}[0m
[34mdecoder.mask_branch.projection.{bias, weight}[0m
[34mencoder.fpn_laterals.0.{bias, weight}[0m
[34mencoder.fpn_laterals.1.{bias, weight}[0m
[34mencoder.fpn_laterals.2.{bias, weight}[0m
[34mencoder.fpn_outputs.0.{bias, weight}[0m
[34mencoder.fpn_outputs.1.{bias, weight}[0m
[34mencoder.fpn_outputs.2.{bias, weight}[0m
[34mencoder.fusion.{bias, weight}[0m
[34mencoder.ppm.bottleneck.{bias, weight}[0m
[34mencoder.ppm.stages.0.1.{bias, weight}[0m
[34mencoder.ppm.stages.1.1.{bias, weight}[0m
[34mencoder.ppm.stages.2.1.{bias, weight}[0m
[34mencoder.ppm.stages.3.1.{bias, weight}[0m
[11/22 05:45:07] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[11/22 05:45:07] d2.engine.train_loop INFO: Starting training from iteration 0
[11/22 05:45:15] d2.utils.events INFO:  eta: 0:40:12  iter: 19  total_loss: 76.15  loss_ce: 2.066  loss_objectness: 0.6737  loss_dice: 1.937  loss_mask: 71.48    time: 0.1649  last_time: 0.1633  data_time: 0.2045  last_data_time: 0.0025   lr: 9.9905e-07  max_mem: 1578M
[11/22 05:45:18] d2.utils.events INFO:  eta: 0:40:22  iter: 39  total_loss: 5.842  loss_ce: 2.078  loss_objectness: 0.5699  loss_dice: 1.995  loss_mask: 1.184    time: 0.1645  last_time: 0.1820  data_time: 0.0034  last_data_time: 0.0159   lr: 1.998e-06  max_mem: 1583M
[11/22 05:45:22] d2.utils.events INFO:  eta: 0:40:26  iter: 59  total_loss: 6.587  loss_ce: 2.061  loss_objectness: 0.5269  loss_dice: 2  loss_mask: 2.003    time: 0.1640  last_time: 0.1618  data_time: 0.0027  last_data_time: 0.0025   lr: 2.997e-06  max_mem: 1583M
[11/22 05:45:25] d2.utils.events INFO:  eta: 0:40:24  iter: 79  total_loss: 5.272  loss_ce: 2.024  loss_objectness: 0.4941  loss_dice: 2  loss_mask: 0.7612    time: 0.1637  last_time: 0.1650  data_time: 0.0028  last_data_time: 0.0031   lr: 3.9961e-06  max_mem: 1586M
[11/22 05:45:28] d2.utils.events INFO:  eta: 0:40:28  iter: 99  total_loss: 5.106  loss_ce: 1.971  loss_objectness: 0.4523  loss_dice: 1.995  loss_mask: 0.6924    time: 0.1640  last_time: 0.1671  data_time: 0.0029  last_data_time: 0.0022   lr: 4.9951e-06  max_mem: 1595M
[11/22 05:45:31] d2.utils.events INFO:  eta: 0:40:21  iter: 119  total_loss: 4.691  loss_ce: 1.889  loss_objectness: 0.4216  loss_dice: 1.89  loss_mask: 0.5136    time: 0.1638  last_time: 0.1595  data_time: 0.0027  last_data_time: 0.0024   lr: 5.9941e-06  max_mem: 1595M
[11/22 05:45:35] d2.utils.events INFO:  eta: 0:40:23  iter: 139  total_loss: 4.288  loss_ce: 1.773  loss_objectness: 0.3838  loss_dice: 1.851  loss_mask: 0.3574    time: 0.1638  last_time: 0.1584  data_time: 0.0029  last_data_time: 0.0025   lr: 6.993e-06  max_mem: 1595M
[11/22 05:45:38] d2.utils.events INFO:  eta: 0:40:22  iter: 159  total_loss: 4.028  loss_ce: 1.614  loss_objectness: 0.323  loss_dice: 1.814  loss_mask: 0.2838    time: 0.1640  last_time: 0.1605  data_time: 0.0030  last_data_time: 0.0028   lr: 7.9921e-06  max_mem: 1595M
[11/22 05:45:41] d2.utils.events INFO:  eta: 0:40:17  iter: 179  total_loss: 3.803  loss_ce: 1.403  loss_objectness: 0.3476  loss_dice: 1.636  loss_mask: 0.356    time: 0.1639  last_time: 0.1643  data_time: 0.0027  last_data_time: 0.0032   lr: 8.9911e-06  max_mem: 1595M
[11/22 05:45:45] d2.utils.events INFO:  eta: 0:40:13  iter: 199  total_loss: 3.329  loss_ce: 1.058  loss_objectness: 0.2999  loss_dice: 1.669  loss_mask: 0.3124    time: 0.1638  last_time: 0.1658  data_time: 0.0027  last_data_time: 0.0023   lr: 9.99e-06  max_mem: 1595M
[11/22 05:45:48] d2.utils.events INFO:  eta: 0:40:13  iter: 219  total_loss: 3.091  loss_ce: 0.7901  loss_objectness: 0.2791  loss_dice: 1.693  loss_mask: 0.2893    time: 0.1640  last_time: 0.1656  data_time: 0.0031  last_data_time: 0.0042   lr: 1.0989e-05  max_mem: 1596M
[11/22 05:45:51] d2.utils.events INFO:  eta: 0:40:10  iter: 239  total_loss: 3.021  loss_ce: 0.742  loss_objectness: 0.3906  loss_dice: 1.528  loss_mask: 0.3747    time: 0.1643  last_time: 0.1612  data_time: 0.0030  last_data_time: 0.0028   lr: 1.1988e-05  max_mem: 1596M
[11/22 05:45:55] d2.utils.events INFO:  eta: 0:40:11  iter: 259  total_loss: 2.878  loss_ce: 0.6257  loss_objectness: 0.3308  loss_dice: 1.603  loss_mask: 0.2751    time: 0.1647  last_time: 0.1695  data_time: 0.0034  last_data_time: 0.0033   lr: 1.2987e-05  max_mem: 1596M
[11/22 05:45:58] d2.utils.events INFO:  eta: 0:40:12  iter: 279  total_loss: 2.909  loss_ce: 0.6224  loss_objectness: 0.3664  loss_dice: 1.584  loss_mask: 0.4008    time: 0.1650  last_time: 0.1659  data_time: 0.0030  last_data_time: 0.0031   lr: 1.3986e-05  max_mem: 1596M
[11/22 05:46:01] d2.utils.events INFO:  eta: 0:40:13  iter: 299  total_loss: 2.748  loss_ce: 0.5668  loss_objectness: 0.373  loss_dice: 1.52  loss_mask: 0.2705    time: 0.1655  last_time: 0.1696  data_time: 0.0033  last_data_time: 0.0028   lr: 1.4985e-05  max_mem: 1599M
[11/22 05:46:05] d2.utils.events INFO:  eta: 0:40:14  iter: 319  total_loss: 2.616  loss_ce: 0.5163  loss_objectness: 0.4282  loss_dice: 1.413  loss_mask: 0.2575    time: 0.1659  last_time: 0.1733  data_time: 0.0033  last_data_time: 0.0029   lr: 1.5984e-05  max_mem: 1599M
[11/22 05:46:08] d2.utils.events INFO:  eta: 0:40:16  iter: 339  total_loss: 2.651  loss_ce: 0.5201  loss_objectness: 0.3801  loss_dice: 1.537  loss_mask: 0.2308    time: 0.1664  last_time: 0.1705  data_time: 0.0035  last_data_time: 0.0043   lr: 1.6983e-05  max_mem: 1599M
[11/22 05:46:12] d2.utils.events INFO:  eta: 0:40:11  iter: 359  total_loss: 2.633  loss_ce: 0.5309  loss_objectness: 0.4467  loss_dice: 1.398  loss_mask: 0.2378    time: 0.1664  last_time: 0.1630  data_time: 0.0031  last_data_time: 0.0027   lr: 1.7982e-05  max_mem: 1599M
[11/22 05:46:15] d2.utils.events INFO:  eta: 0:40:07  iter: 379  total_loss: 2.635  loss_ce: 0.5376  loss_objectness: 0.3938  loss_dice: 1.483  loss_mask: 0.1532    time: 0.1663  last_time: 0.1661  data_time: 0.0028  last_data_time: 0.0025   lr: 1.8981e-05  max_mem: 1599M
[11/22 05:46:18] d2.utils.events INFO:  eta: 0:40:02  iter: 399  total_loss: 2.565  loss_ce: 0.508  loss_objectness: 0.4422  loss_dice: 1.37  loss_mask: 0.2381    time: 0.1662  last_time: 0.1621  data_time: 0.0028  last_data_time: 0.0024   lr: 1.998e-05  max_mem: 1599M
[11/22 05:46:22] d2.utils.events INFO:  eta: 0:39:58  iter: 419  total_loss: 2.527  loss_ce: 0.5684  loss_objectness: 0.4773  loss_dice: 1.313  loss_mask: 0.1892    time: 0.1661  last_time: 0.1627  data_time: 0.0028  last_data_time: 0.0029   lr: 2.0979e-05  max_mem: 1614M
[11/22 05:46:25] d2.utils.events INFO:  eta: 0:39:55  iter: 439  total_loss: 2.563  loss_ce: 0.5711  loss_objectness: 0.4098  loss_dice: 1.467  loss_mask: 0.1343    time: 0.1661  last_time: 0.1699  data_time: 0.0030  last_data_time: 0.0028   lr: 2.1978e-05  max_mem: 1614M
[11/22 05:46:28] d2.utils.events INFO:  eta: 0:39:53  iter: 459  total_loss: 2.493  loss_ce: 0.5098  loss_objectness: 0.3983  loss_dice: 1.431  loss_mask: 0.1476    time: 0.1661  last_time: 0.1640  data_time: 0.0032  last_data_time: 0.0023   lr: 2.2977e-05  max_mem: 1614M
[11/22 05:46:32] d2.utils.events INFO:  eta: 0:39:48  iter: 479  total_loss: 2.424  loss_ce: 0.5171  loss_objectness: 0.4294  loss_dice: 1.339  loss_mask: 0.1586    time: 0.1660  last_time: 0.1662  data_time: 0.0029  last_data_time: 0.0026   lr: 2.3976e-05  max_mem: 1614M
[11/22 05:46:35] d2.utils.events INFO:  eta: 0:39:43  iter: 499  total_loss: 2.434  loss_ce: 0.516  loss_objectness: 0.4951  loss_dice: 1.282  loss_mask: 0.1708    time: 0.1659  last_time: 0.1625  data_time: 0.0028  last_data_time: 0.0028   lr: 2.4975e-05  max_mem: 1614M
[11/22 05:46:38] d2.utils.events INFO:  eta: 0:39:39  iter: 519  total_loss: 2.569  loss_ce: 0.5402  loss_objectness: 0.4216  loss_dice: 1.395  loss_mask: 0.161    time: 0.1658  last_time: 0.1620  data_time: 0.0029  last_data_time: 0.0023   lr: 2.5974e-05  max_mem: 1614M
[11/22 05:46:41] d2.utils.events INFO:  eta: 0:39:35  iter: 539  total_loss: 2.512  loss_ce: 0.5234  loss_objectness: 0.4516  loss_dice: 1.354  loss_mask: 0.1948    time: 0.1658  last_time: 0.1629  data_time: 0.0029  last_data_time: 0.0025   lr: 2.6973e-05  max_mem: 1614M
[11/22 05:46:45] d2.utils.events INFO:  eta: 0:39:31  iter: 559  total_loss: 2.482  loss_ce: 0.5537  loss_objectness: 0.4673  loss_dice: 1.346  loss_mask: 0.1531    time: 0.1657  last_time: 0.1592  data_time: 0.0028  last_data_time: 0.0030   lr: 2.7972e-05  max_mem: 1614M
[11/22 05:46:48] d2.utils.events INFO:  eta: 0:39:27  iter: 579  total_loss: 2.462  loss_ce: 0.518  loss_objectness: 0.4941  loss_dice: 1.253  loss_mask: 0.1659    time: 0.1656  last_time: 0.1637  data_time: 0.0027  last_data_time: 0.0028   lr: 2.8971e-05  max_mem: 1614M
[11/22 05:46:51] d2.utils.events INFO:  eta: 0:39:23  iter: 599  total_loss: 2.528  loss_ce: 0.6033  loss_objectness: 0.4322  loss_dice: 1.303  loss_mask: 0.1395    time: 0.1655  last_time: 0.1659  data_time: 0.0029  last_data_time: 0.0040   lr: 2.997e-05  max_mem: 1614M
[11/22 05:46:55] d2.utils.events INFO:  eta: 0:39:20  iter: 619  total_loss: 2.446  loss_ce: 0.5681  loss_objectness: 0.461  loss_dice: 1.282  loss_mask: 0.1201    time: 0.1655  last_time: 0.1637  data_time: 0.0035  last_data_time: 0.0025   lr: 3.0969e-05  max_mem: 1614M
[11/22 05:46:58] d2.utils.events INFO:  eta: 0:39:16  iter: 639  total_loss: 2.376  loss_ce: 0.5182  loss_objectness: 0.4806  loss_dice: 1.263  loss_mask: 0.1414    time: 0.1654  last_time: 0.1639  data_time: 0.0029  last_data_time: 0.0026   lr: 3.1968e-05  max_mem: 1614M
[11/22 05:47:01] d2.utils.events INFO:  eta: 0:39:12  iter: 659  total_loss: 2.423  loss_ce: 0.5564  loss_objectness: 0.511  loss_dice: 1.193  loss_mask: 0.1411    time: 0.1653  last_time: 0.1612  data_time: 0.0027  last_data_time: 0.0024   lr: 3.2967e-05  max_mem: 1614M
[11/22 05:47:04] d2.utils.events INFO:  eta: 0:39:09  iter: 679  total_loss: 2.355  loss_ce: 0.4867  loss_objectness: 0.5536  loss_dice: 1.138  loss_mask: 0.1675    time: 0.1654  last_time: 0.1638  data_time: 0.0031  last_data_time: 0.0027   lr: 3.3966e-05  max_mem: 1614M
[11/22 05:47:08] d2.utils.events INFO:  eta: 0:39:06  iter: 699  total_loss: 2.324  loss_ce: 0.5425  loss_objectness: 0.5298  loss_dice: 1.176  loss_mask: 0.102    time: 0.1654  last_time: 0.1644  data_time: 0.0030  last_data_time: 0.0026   lr: 3.4965e-05  max_mem: 1614M
[11/22 05:47:11] d2.utils.events INFO:  eta: 0:39:03  iter: 719  total_loss: 2.464  loss_ce: 0.5696  loss_objectness: 0.4976  loss_dice: 1.234  loss_mask: 0.1499    time: 0.1653  last_time: 0.1635  data_time: 0.0029  last_data_time: 0.0034   lr: 3.5964e-05  max_mem: 1614M
[11/22 05:47:14] d2.utils.events INFO:  eta: 0:38:59  iter: 739  total_loss: 2.431  loss_ce: 0.6362  loss_objectness: 0.51  loss_dice: 1.19  loss_mask: 0.143    time: 0.1653  last_time: 0.1610  data_time: 0.0029  last_data_time: 0.0025   lr: 3.6963e-05  max_mem: 1614M
[11/22 05:47:18] d2.utils.events INFO:  eta: 0:38:55  iter: 759  total_loss: 2.476  loss_ce: 0.6086  loss_objectness: 0.4947  loss_dice: 1.233  loss_mask: 0.131    time: 0.1652  last_time: 0.1632  data_time: 0.0032  last_data_time: 0.0025   lr: 3.7962e-05  max_mem: 1614M
[11/22 05:47:21] d2.utils.events INFO:  eta: 0:38:52  iter: 779  total_loss: 2.477  loss_ce: 0.5494  loss_objectness: 0.5183  loss_dice: 1.244  loss_mask: 0.1307    time: 0.1652  last_time: 0.1637  data_time: 0.0028  last_data_time: 0.0035   lr: 3.8961e-05  max_mem: 1614M
[11/22 05:47:24] d2.utils.events INFO:  eta: 0:38:49  iter: 799  total_loss: 2.362  loss_ce: 0.5475  loss_objectness: 0.4725  loss_dice: 1.213  loss_mask: 0.09186    time: 0.1652  last_time: 0.1665  data_time: 0.0029  last_data_time: 0.0032   lr: 3.996e-05  max_mem: 1614M
[11/22 05:47:27] d2.utils.events INFO:  eta: 0:38:45  iter: 819  total_loss: 2.273  loss_ce: 0.536  loss_objectness: 0.5686  loss_dice: 1.045  loss_mask: 0.1296    time: 0.1651  last_time: 0.1644  data_time: 0.0027  last_data_time: 0.0032   lr: 4.0959e-05  max_mem: 1614M
[11/22 05:47:31] d2.utils.events INFO:  eta: 0:38:42  iter: 839  total_loss: 2.376  loss_ce: 0.5353  loss_objectness: 0.4953  loss_dice: 1.172  loss_mask: 0.0845    time: 0.1651  last_time: 0.1648  data_time: 0.0029  last_data_time: 0.0024   lr: 4.1958e-05  max_mem: 1614M
[11/22 05:47:34] d2.utils.events INFO:  eta: 0:38:38  iter: 859  total_loss: 2.386  loss_ce: 0.5726  loss_objectness: 0.5252  loss_dice: 1.119  loss_mask: 0.1156    time: 0.1651  last_time: 0.1646  data_time: 0.0029  last_data_time: 0.0032   lr: 4.2957e-05  max_mem: 1614M
[11/22 05:47:37] d2.utils.events INFO:  eta: 0:38:34  iter: 879  total_loss: 2.293  loss_ce: 0.5799  loss_objectness: 0.5551  loss_dice: 1.053  loss_mask: 0.1305    time: 0.1651  last_time: 0.1647  data_time: 0.0028  last_data_time: 0.0027   lr: 4.3956e-05  max_mem: 1614M
[11/22 05:47:41] d2.utils.events INFO:  eta: 0:38:31  iter: 899  total_loss: 2.339  loss_ce: 0.5516  loss_objectness: 0.5412  loss_dice: 1.081  loss_mask: 0.1072    time: 0.1650  last_time: 0.1636  data_time: 0.0029  last_data_time: 0.0034   lr: 4.4955e-05  max_mem: 1614M
[11/22 05:47:44] d2.utils.events INFO:  eta: 0:38:27  iter: 919  total_loss: 2.302  loss_ce: 0.5441  loss_objectness: 0.5248  loss_dice: 1.088  loss_mask: 0.1173    time: 0.1650  last_time: 0.1644  data_time: 0.0028  last_data_time: 0.0026   lr: 4.5954e-05  max_mem: 1614M
[11/22 05:47:47] d2.utils.events INFO:  eta: 0:38:24  iter: 939  total_loss: 2.262  loss_ce: 0.512  loss_objectness: 0.5694  loss_dice: 0.9739  loss_mask: 0.1226    time: 0.1649  last_time: 0.1629  data_time: 0.0028  last_data_time: 0.0025   lr: 4.6953e-05  max_mem: 1614M
[11/22 05:47:50] d2.utils.events INFO:  eta: 0:38:20  iter: 959  total_loss: 2.279  loss_ce: 0.5442  loss_objectness: 0.5542  loss_dice: 1.08  loss_mask: 0.128    time: 0.1649  last_time: 0.1632  data_time: 0.0029  last_data_time: 0.0026   lr: 4.7952e-05  max_mem: 1614M
[11/22 05:47:54] d2.utils.events INFO:  eta: 0:38:17  iter: 979  total_loss: 2.368  loss_ce: 0.6286  loss_objectness: 0.5764  loss_dice: 1.043  loss_mask: 0.1316    time: 0.1649  last_time: 0.1612  data_time: 0.0028  last_data_time: 0.0025   lr: 4.8951e-05  max_mem: 1614M
[11/22 05:47:57] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 05:47:57] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   crack    | 376          |
|            |              |[0m
[11/22 05:47:57] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 05:47:57] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 05:47:57] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 05:47:57] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 05:47:57] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 05:48:04] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0456 s/iter. Eval: 0.0528 s/iter. Total: 0.0988 s/iter. ETA=0:00:10
[11/22 05:48:09] d2.evaluation.evaluator INFO: Inference done 78/120. Dataloading: 0.0004 s/iter. Inference: 0.0289 s/iter. Eval: 0.0478 s/iter. Total: 0.0772 s/iter. ETA=0:00:03
[11/22 05:48:13] d2.evaluation.evaluator INFO: Total inference time: 0:00:09.684404 (0.084212 s / iter per device, on 1 devices)
[11/22 05:48:13] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:03 (0.028058 s / iter per device, on 1 devices)
[11/22 05:48:13] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 05:48:13] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 05:48:13] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 05:48:13] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 05:48:13] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.09 seconds.
[11/22 05:48:13] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 05:48:13] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 05:48:13] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 4.015 | 11.096 | 2.704  | 0.022 | 8.784 | 27.767 |
[11/22 05:48:13] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 05:48:13] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 05:48:13] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 05:48:13] d2.evaluation.testing INFO: copypaste: 4.0149,11.0961,2.7041,0.0219,8.7841,27.7671
[11/22 05:48:13] d2.utils.events INFO:  eta: 0:38:13  iter: 999  total_loss: 2.404  loss_ce: 0.6115  loss_objectness: 0.5556  loss_dice: 1.152  loss_mask: 0.1311    time: 0.1649  last_time: 0.1640  data_time: 0.0028  last_data_time: 0.0031   lr: 4.995e-05  max_mem: 1614M
[11/22 05:48:17] d2.utils.events INFO:  eta: 0:38:10  iter: 1019  total_loss: 2.43  loss_ce: 0.6583  loss_objectness: 0.5097  loss_dice: 1.167  loss_mask: 0.1065    time: 0.1649  last_time: 0.1649  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1614M
[11/22 05:48:20] d2.utils.events INFO:  eta: 0:38:07  iter: 1039  total_loss: 2.326  loss_ce: 0.5108  loss_objectness: 0.5543  loss_dice: 1.089  loss_mask: 0.1318    time: 0.1649  last_time: 0.1644  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1614M
[11/22 05:48:23] d2.utils.events INFO:  eta: 0:38:06  iter: 1059  total_loss: 2.399  loss_ce: 0.6083  loss_objectness: 0.5697  loss_dice: 1.064  loss_mask: 0.1166    time: 0.1649  last_time: 0.1655  data_time: 0.0030  last_data_time: 0.0027   lr: 5e-05  max_mem: 1614M
[11/22 05:48:27] d2.utils.events INFO:  eta: 0:38:03  iter: 1079  total_loss: 2.354  loss_ce: 0.5552  loss_objectness: 0.5861  loss_dice: 1.059  loss_mask: 0.1212    time: 0.1649  last_time: 0.1632  data_time: 0.0030  last_data_time: 0.0032   lr: 5e-05  max_mem: 1614M
[11/22 05:48:30] d2.utils.events INFO:  eta: 0:37:59  iter: 1099  total_loss: 2.325  loss_ce: 0.5814  loss_objectness: 0.5586  loss_dice: 1.061  loss_mask: 0.1006    time: 0.1649  last_time: 0.1638  data_time: 0.0028  last_data_time: 0.0022   lr: 5e-05  max_mem: 1614M
[11/22 05:48:33] d2.utils.events INFO:  eta: 0:37:56  iter: 1119  total_loss: 2.197  loss_ce: 0.5546  loss_objectness: 0.5841  loss_dice: 0.9678  loss_mask: 0.08598    time: 0.1649  last_time: 0.1657  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1614M
[11/22 05:48:36] d2.utils.events INFO:  eta: 0:37:53  iter: 1139  total_loss: 2.321  loss_ce: 0.5741  loss_objectness: 0.5622  loss_dice: 0.996  loss_mask: 0.1331    time: 0.1649  last_time: 0.1641  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1614M
[11/22 05:48:40] d2.utils.events INFO:  eta: 0:37:50  iter: 1159  total_loss: 2.34  loss_ce: 0.5519  loss_objectness: 0.543  loss_dice: 1.117  loss_mask: 0.1637    time: 0.1649  last_time: 0.1641  data_time: 0.0028  last_data_time: 0.0022   lr: 5e-05  max_mem: 1614M
[11/22 05:48:43] d2.utils.events INFO:  eta: 0:37:47  iter: 1179  total_loss: 2.414  loss_ce: 0.6104  loss_objectness: 0.5182  loss_dice: 1.182  loss_mask: 0.09605    time: 0.1649  last_time: 0.1685  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1614M
[11/22 05:48:46] d2.utils.events INFO:  eta: 0:37:44  iter: 1199  total_loss: 2.227  loss_ce: 0.5594  loss_objectness: 0.5933  loss_dice: 0.9836  loss_mask: 0.0898    time: 0.1650  last_time: 0.1633  data_time: 0.0030  last_data_time: 0.0033   lr: 5e-05  max_mem: 1614M
[11/22 05:48:50] d2.utils.events INFO:  eta: 0:37:41  iter: 1219  total_loss: 2.226  loss_ce: 0.5389  loss_objectness: 0.5826  loss_dice: 0.9977  loss_mask: 0.111    time: 0.1651  last_time: 0.1680  data_time: 0.0040  last_data_time: 0.0028   lr: 5e-05  max_mem: 1614M
[11/22 05:48:53] d2.utils.events INFO:  eta: 0:37:39  iter: 1239  total_loss: 2.134  loss_ce: 0.4771  loss_objectness: 0.6306  loss_dice: 0.9036  loss_mask: 0.1087    time: 0.1652  last_time: 0.1703  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-05  max_mem: 1614M
[11/22 05:48:57] d2.utils.events INFO:  eta: 0:37:36  iter: 1259  total_loss: 2.181  loss_ce: 0.5189  loss_objectness: 0.5937  loss_dice: 0.9938  loss_mask: 0.09402    time: 0.1652  last_time: 0.1684  data_time: 0.0031  last_data_time: 0.0035   lr: 5e-05  max_mem: 1614M
[11/22 05:49:00] d2.utils.events INFO:  eta: 0:37:33  iter: 1279  total_loss: 2.267  loss_ce: 0.597  loss_objectness: 0.5863  loss_dice: 1.018  loss_mask: 0.07675    time: 0.1653  last_time: 0.1683  data_time: 0.0039  last_data_time: 0.0032   lr: 5e-05  max_mem: 1614M
[11/22 05:49:04] d2.utils.events INFO:  eta: 0:37:29  iter: 1299  total_loss: 2.031  loss_ce: 0.5287  loss_objectness: 0.6145  loss_dice: 0.7848  loss_mask: 0.09532    time: 0.1654  last_time: 0.1742  data_time: 0.0030  last_data_time: 0.0027   lr: 5e-05  max_mem: 1614M
[11/22 05:49:07] d2.utils.events INFO:  eta: 0:37:26  iter: 1319  total_loss: 2.124  loss_ce: 0.5255  loss_objectness: 0.6015  loss_dice: 0.8805  loss_mask: 0.1099    time: 0.1655  last_time: 0.1689  data_time: 0.0034  last_data_time: 0.0024   lr: 5e-05  max_mem: 1614M
[11/22 05:49:10] d2.utils.events INFO:  eta: 0:37:21  iter: 1339  total_loss: 2.085  loss_ce: 0.4818  loss_objectness: 0.6025  loss_dice: 0.918  loss_mask: 0.0834    time: 0.1655  last_time: 0.1635  data_time: 0.0028  last_data_time: 0.0020   lr: 5e-05  max_mem: 1614M
[11/22 05:49:14] d2.utils.events INFO:  eta: 0:37:18  iter: 1359  total_loss: 2.129  loss_ce: 0.495  loss_objectness: 0.6174  loss_dice: 0.932  loss_mask: 0.08463    time: 0.1655  last_time: 0.1651  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-05  max_mem: 1614M
[11/22 05:49:17] d2.utils.events INFO:  eta: 0:37:15  iter: 1379  total_loss: 2.136  loss_ce: 0.5245  loss_objectness: 0.5938  loss_dice: 0.9307  loss_mask: 0.09642    time: 0.1655  last_time: 0.1670  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1614M
[11/22 05:49:20] d2.utils.events INFO:  eta: 0:37:12  iter: 1399  total_loss: 2.099  loss_ce: 0.5225  loss_objectness: 0.6183  loss_dice: 0.8344  loss_mask: 0.1037    time: 0.1654  last_time: 0.1634  data_time: 0.0028  last_data_time: 0.0032   lr: 5e-05  max_mem: 1614M
[11/22 05:49:23] d2.utils.events INFO:  eta: 0:37:08  iter: 1419  total_loss: 2.164  loss_ce: 0.5673  loss_objectness: 0.6243  loss_dice: 0.888  loss_mask: 0.07629    time: 0.1654  last_time: 0.1631  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1614M
[11/22 05:49:27] d2.utils.events INFO:  eta: 0:37:05  iter: 1439  total_loss: 2.221  loss_ce: 0.5147  loss_objectness: 0.58  loss_dice: 1.04  loss_mask: 0.1043    time: 0.1654  last_time: 0.1682  data_time: 0.0029  last_data_time: 0.0041   lr: 5e-05  max_mem: 1614M
[11/22 05:49:30] d2.utils.events INFO:  eta: 0:37:01  iter: 1459  total_loss: 2.114  loss_ce: 0.5322  loss_objectness: 0.6139  loss_dice: 0.8238  loss_mask: 0.09083    time: 0.1654  last_time: 0.1646  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1614M
[11/22 05:49:33] d2.utils.events INFO:  eta: 0:36:57  iter: 1479  total_loss: 2.188  loss_ce: 0.546  loss_objectness: 0.6275  loss_dice: 0.8141  loss_mask: 0.09379    time: 0.1654  last_time: 0.1614  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1614M
[11/22 05:49:37] d2.utils.events INFO:  eta: 0:36:54  iter: 1499  total_loss: 2.137  loss_ce: 0.5425  loss_objectness: 0.6307  loss_dice: 0.8565  loss_mask: 0.07863    time: 0.1653  last_time: 0.1614  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1614M
[11/22 05:49:40] d2.utils.events INFO:  eta: 0:36:51  iter: 1519  total_loss: 2.171  loss_ce: 0.5503  loss_objectness: 0.5965  loss_dice: 0.8999  loss_mask: 0.08733    time: 0.1653  last_time: 0.1629  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1614M
[11/22 05:49:43] d2.utils.events INFO:  eta: 0:36:48  iter: 1539  total_loss: 2.143  loss_ce: 0.5292  loss_objectness: 0.6411  loss_dice: 0.8283  loss_mask: 0.09542    time: 0.1653  last_time: 0.1649  data_time: 0.0031  last_data_time: 0.0036   lr: 5e-05  max_mem: 1614M
[11/22 05:49:47] d2.utils.events INFO:  eta: 0:36:44  iter: 1559  total_loss: 2.134  loss_ce: 0.5443  loss_objectness: 0.6214  loss_dice: 0.8527  loss_mask: 0.08855    time: 0.1653  last_time: 0.1739  data_time: 0.0030  last_data_time: 0.0035   lr: 5e-05  max_mem: 1614M
[11/22 05:49:50] d2.utils.events INFO:  eta: 0:36:42  iter: 1579  total_loss: 2.147  loss_ce: 0.5385  loss_objectness: 0.6316  loss_dice: 0.8896  loss_mask: 0.08327    time: 0.1653  last_time: 0.1631  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1614M
[11/22 05:49:53] d2.utils.events INFO:  eta: 0:36:38  iter: 1599  total_loss: 2.166  loss_ce: 0.5328  loss_objectness: 0.6296  loss_dice: 0.8938  loss_mask: 0.09832    time: 0.1653  last_time: 0.1642  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1614M
[11/22 05:49:56] d2.utils.events INFO:  eta: 0:36:35  iter: 1619  total_loss: 2.143  loss_ce: 0.5588  loss_objectness: 0.6349  loss_dice: 0.7972  loss_mask: 0.06747    time: 0.1653  last_time: 0.1641  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1614M
[11/22 05:50:00] d2.utils.events INFO:  eta: 0:36:32  iter: 1639  total_loss: 2.102  loss_ce: 0.512  loss_objectness: 0.6237  loss_dice: 0.7761  loss_mask: 0.1051    time: 0.1653  last_time: 0.1658  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-05  max_mem: 1614M
[11/22 05:50:03] d2.utils.events INFO:  eta: 0:36:29  iter: 1659  total_loss: 2.251  loss_ce: 0.5898  loss_objectness: 0.6176  loss_dice: 0.9299  loss_mask: 0.1077    time: 0.1653  last_time: 0.1643  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1614M
[11/22 05:50:06] d2.utils.events INFO:  eta: 0:36:26  iter: 1679  total_loss: 2.173  loss_ce: 0.5767  loss_objectness: 0.6282  loss_dice: 0.8272  loss_mask: 0.1047    time: 0.1653  last_time: 0.1617  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1614M
[11/22 05:50:10] d2.utils.events INFO:  eta: 0:36:22  iter: 1699  total_loss: 2.163  loss_ce: 0.5671  loss_objectness: 0.5952  loss_dice: 0.8928  loss_mask: 0.07507    time: 0.1653  last_time: 0.1631  data_time: 0.0029  last_data_time: 0.0037   lr: 5e-05  max_mem: 1614M
[11/22 05:50:13] d2.utils.events INFO:  eta: 0:36:19  iter: 1719  total_loss: 2.171  loss_ce: 0.5142  loss_objectness: 0.625  loss_dice: 0.9  loss_mask: 0.1158    time: 0.1653  last_time: 0.1656  data_time: 0.0029  last_data_time: 0.0043   lr: 5e-05  max_mem: 1614M
[11/22 05:50:16] d2.utils.events INFO:  eta: 0:36:16  iter: 1739  total_loss: 2.142  loss_ce: 0.5727  loss_objectness: 0.6087  loss_dice: 0.8276  loss_mask: 0.08155    time: 0.1652  last_time: 0.1644  data_time: 0.0028  last_data_time: 0.0034   lr: 5e-05  max_mem: 1614M
[11/22 05:50:20] d2.utils.events INFO:  eta: 0:36:13  iter: 1759  total_loss: 2.059  loss_ce: 0.4865  loss_objectness: 0.6262  loss_dice: 0.8795  loss_mask: 0.07154    time: 0.1652  last_time: 0.1609  data_time: 0.0031  last_data_time: 0.0029   lr: 5e-05  max_mem: 1614M
[11/22 05:50:23] d2.utils.events INFO:  eta: 0:36:09  iter: 1779  total_loss: 2.073  loss_ce: 0.4667  loss_objectness: 0.6204  loss_dice: 0.8699  loss_mask: 0.09511    time: 0.1652  last_time: 0.1625  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1614M
[11/22 05:50:26] d2.utils.events INFO:  eta: 0:36:05  iter: 1799  total_loss: 2.052  loss_ce: 0.5278  loss_objectness: 0.6085  loss_dice: 0.8008  loss_mask: 0.07672    time: 0.1652  last_time: 0.1630  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1614M
[11/22 05:50:29] d2.utils.events INFO:  eta: 0:36:02  iter: 1819  total_loss: 2.128  loss_ce: 0.5598  loss_objectness: 0.6239  loss_dice: 0.8485  loss_mask: 0.06612    time: 0.1652  last_time: 0.1620  data_time: 0.0030  last_data_time: 0.0034   lr: 5e-05  max_mem: 1614M
[11/22 05:50:33] d2.utils.events INFO:  eta: 0:35:59  iter: 1839  total_loss: 2.104  loss_ce: 0.5575  loss_objectness: 0.64  loss_dice: 0.7793  loss_mask: 0.07906    time: 0.1652  last_time: 0.1649  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-05  max_mem: 1614M
[11/22 05:50:36] d2.utils.events INFO:  eta: 0:35:56  iter: 1859  total_loss: 2.1  loss_ce: 0.5518  loss_objectness: 0.6233  loss_dice: 0.7801  loss_mask: 0.0652    time: 0.1651  last_time: 0.1624  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1614M
[11/22 05:50:39] d2.utils.events INFO:  eta: 0:35:52  iter: 1879  total_loss: 2.128  loss_ce: 0.492  loss_objectness: 0.6079  loss_dice: 0.9244  loss_mask: 0.08343    time: 0.1651  last_time: 0.1618  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1614M
[11/22 05:50:43] d2.utils.events INFO:  eta: 0:35:50  iter: 1899  total_loss: 2.024  loss_ce: 0.5062  loss_objectness: 0.6606  loss_dice: 0.7757  loss_mask: 0.08217    time: 0.1651  last_time: 0.1625  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1614M
[11/22 05:50:46] d2.utils.events INFO:  eta: 0:35:47  iter: 1919  total_loss: 1.945  loss_ce: 0.4488  loss_objectness: 0.6208  loss_dice: 0.7717  loss_mask: 0.08824    time: 0.1651  last_time: 0.1643  data_time: 0.0030  last_data_time: 0.0023   lr: 5e-05  max_mem: 1614M
[11/22 05:50:49] d2.utils.events INFO:  eta: 0:35:44  iter: 1939  total_loss: 1.976  loss_ce: 0.4848  loss_objectness: 0.6469  loss_dice: 0.7628  loss_mask: 0.07289    time: 0.1651  last_time: 0.1661  data_time: 0.0029  last_data_time: 0.0035   lr: 5e-05  max_mem: 1614M
[11/22 05:50:52] d2.utils.events INFO:  eta: 0:35:41  iter: 1959  total_loss: 1.868  loss_ce: 0.4353  loss_objectness: 0.6544  loss_dice: 0.697  loss_mask: 0.07434    time: 0.1651  last_time: 0.1652  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1614M
[11/22 05:50:56] d2.utils.events INFO:  eta: 0:35:37  iter: 1979  total_loss: 2.067  loss_ce: 0.4476  loss_objectness: 0.6158  loss_dice: 0.8591  loss_mask: 0.07689    time: 0.1651  last_time: 0.1616  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-05  max_mem: 1614M
[11/22 05:50:59] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 05:50:59] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 05:50:59] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 05:50:59] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 05:50:59] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 05:50:59] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 05:51:04] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0229 s/iter. Eval: 0.0416 s/iter. Total: 0.0648 s/iter. ETA=0:00:07
[11/22 05:51:09] d2.evaluation.evaluator INFO: Inference done 89/120. Dataloading: 0.0004 s/iter. Inference: 0.0227 s/iter. Eval: 0.0416 s/iter. Total: 0.0647 s/iter. ETA=0:00:02
[11/22 05:51:12] d2.evaluation.evaluator INFO: Total inference time: 0:00:08.568897 (0.074512 s / iter per device, on 1 devices)
[11/22 05:51:12] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.023251 s / iter per device, on 1 devices)
[11/22 05:51:12] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 05:51:12] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 05:51:12] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 05:51:12] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 05:51:12] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.05 seconds.
[11/22 05:51:12] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 05:51:12] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 05:51:12] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 4.077 | 11.215 | 2.563  | 0.019 | 8.406 | 27.434 |
[11/22 05:51:12] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 05:51:12] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 05:51:12] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 05:51:12] d2.evaluation.testing INFO: copypaste: 4.0774,11.2151,2.5626,0.0193,8.4058,27.4342
[11/22 05:51:12] d2.utils.events INFO:  eta: 0:35:34  iter: 1999  total_loss: 2.065  loss_ce: 0.5246  loss_objectness: 0.635  loss_dice: 0.8192  loss_mask: 0.1117    time: 0.1651  last_time: 0.1642  data_time: 0.0027  last_data_time: 0.0033   lr: 5e-05  max_mem: 1614M
[11/22 05:51:16] d2.utils.events INFO:  eta: 0:35:30  iter: 2019  total_loss: 2.147  loss_ce: 0.5215  loss_objectness: 0.5997  loss_dice: 0.936  loss_mask: 0.06876    time: 0.1651  last_time: 0.1621  data_time: 0.0029  last_data_time: 0.0022   lr: 5e-05  max_mem: 1614M
[11/22 05:51:19] d2.utils.events INFO:  eta: 0:35:27  iter: 2039  total_loss: 2.022  loss_ce: 0.5238  loss_objectness: 0.6328  loss_dice: 0.7826  loss_mask: 0.07458    time: 0.1651  last_time: 0.1625  data_time: 0.0035  last_data_time: 0.0027   lr: 5e-05  max_mem: 1614M
[11/22 05:51:22] d2.utils.events INFO:  eta: 0:35:23  iter: 2059  total_loss: 1.851  loss_ce: 0.4464  loss_objectness: 0.6657  loss_dice: 0.6304  loss_mask: 0.08065    time: 0.1651  last_time: 0.1641  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1614M
[11/22 05:51:26] d2.utils.events INFO:  eta: 0:35:20  iter: 2079  total_loss: 2.026  loss_ce: 0.486  loss_objectness: 0.6513  loss_dice: 0.7466  loss_mask: 0.103    time: 0.1651  last_time: 0.1632  data_time: 0.0030  last_data_time: 0.0028   lr: 5e-05  max_mem: 1614M
[11/22 05:51:29] d2.utils.events INFO:  eta: 0:35:17  iter: 2099  total_loss: 2.04  loss_ce: 0.5281  loss_objectness: 0.6129  loss_dice: 0.8785  loss_mask: 0.07067    time: 0.1651  last_time: 0.1642  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1614M
[11/22 05:51:32] d2.utils.events INFO:  eta: 0:35:14  iter: 2119  total_loss: 1.981  loss_ce: 0.4567  loss_objectness: 0.6203  loss_dice: 0.7556  loss_mask: 0.1007    time: 0.1651  last_time: 0.1618  data_time: 0.0027  last_data_time: 0.0032   lr: 5e-05  max_mem: 1614M
[11/22 05:51:35] d2.utils.events INFO:  eta: 0:35:10  iter: 2139  total_loss: 2.025  loss_ce: 0.5366  loss_objectness: 0.627  loss_dice: 0.822  loss_mask: 0.07567    time: 0.1651  last_time: 0.1622  data_time: 0.0030  last_data_time: 0.0044   lr: 5e-05  max_mem: 1614M
[11/22 05:51:39] d2.utils.events INFO:  eta: 0:35:07  iter: 2159  total_loss: 1.986  loss_ce: 0.5472  loss_objectness: 0.6294  loss_dice: 0.7334  loss_mask: 0.06322    time: 0.1651  last_time: 0.1655  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-05  max_mem: 1614M
[11/22 05:51:42] d2.utils.events INFO:  eta: 0:35:03  iter: 2179  total_loss: 1.998  loss_ce: 0.4571  loss_objectness: 0.6257  loss_dice: 0.7921  loss_mask: 0.08982    time: 0.1651  last_time: 0.1631  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1614M
[11/22 05:51:45] d2.utils.events INFO:  eta: 0:34:59  iter: 2199  total_loss: 1.93  loss_ce: 0.4542  loss_objectness: 0.644  loss_dice: 0.686  loss_mask: 0.07949    time: 0.1651  last_time: 0.1628  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1614M
[11/22 05:51:49] d2.utils.events INFO:  eta: 0:34:55  iter: 2219  total_loss: 1.985  loss_ce: 0.4573  loss_objectness: 0.6524  loss_dice: 0.7862  loss_mask: 0.05923    time: 0.1650  last_time: 0.1623  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1614M
[11/22 05:51:52] d2.utils.events INFO:  eta: 0:34:51  iter: 2239  total_loss: 2.062  loss_ce: 0.4724  loss_objectness: 0.5888  loss_dice: 0.8187  loss_mask: 0.07302    time: 0.1650  last_time: 0.1618  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1614M
[11/22 05:51:55] d2.utils.events INFO:  eta: 0:34:47  iter: 2259  total_loss: 1.969  loss_ce: 0.4985  loss_objectness: 0.6526  loss_dice: 0.7308  loss_mask: 0.06666    time: 0.1650  last_time: 0.1627  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1614M
[11/22 05:51:58] d2.utils.events INFO:  eta: 0:34:42  iter: 2279  total_loss: 2.04  loss_ce: 0.5248  loss_objectness: 0.6576  loss_dice: 0.6995  loss_mask: 0.07308    time: 0.1650  last_time: 0.1644  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1614M
[11/22 05:52:02] d2.utils.events INFO:  eta: 0:34:38  iter: 2299  total_loss: 2.026  loss_ce: 0.497  loss_objectness: 0.6324  loss_dice: 0.8152  loss_mask: 0.06987    time: 0.1650  last_time: 0.1655  data_time: 0.0027  last_data_time: 0.0030   lr: 5e-05  max_mem: 1614M
[11/22 05:52:05] d2.utils.events INFO:  eta: 0:34:34  iter: 2319  total_loss: 1.996  loss_ce: 0.4903  loss_objectness: 0.6498  loss_dice: 0.7411  loss_mask: 0.07037    time: 0.1650  last_time: 0.1616  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1614M
[11/22 05:52:08] d2.utils.events INFO:  eta: 0:34:31  iter: 2339  total_loss: 1.945  loss_ce: 0.454  loss_objectness: 0.6312  loss_dice: 0.7101  loss_mask: 0.05947    time: 0.1649  last_time: 0.1616  data_time: 0.0027  last_data_time: 0.0028   lr: 5e-05  max_mem: 1614M
[11/22 05:52:11] d2.utils.events INFO:  eta: 0:34:28  iter: 2359  total_loss: 2.038  loss_ce: 0.4652  loss_objectness: 0.6468  loss_dice: 0.7347  loss_mask: 0.08079    time: 0.1649  last_time: 0.1652  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1614M
[11/22 05:52:15] d2.utils.events INFO:  eta: 0:34:24  iter: 2379  total_loss: 1.972  loss_ce: 0.5118  loss_objectness: 0.6661  loss_dice: 0.7031  loss_mask: 0.07043    time: 0.1649  last_time: 0.1605  data_time: 0.0027  last_data_time: 0.0028   lr: 5e-05  max_mem: 1614M
[11/22 05:52:18] d2.utils.events INFO:  eta: 0:34:21  iter: 2399  total_loss: 2.086  loss_ce: 0.5005  loss_objectness: 0.6368  loss_dice: 0.8247  loss_mask: 0.09863    time: 0.1649  last_time: 0.1654  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1614M
[11/22 05:52:21] d2.utils.events INFO:  eta: 0:34:18  iter: 2419  total_loss: 1.976  loss_ce: 0.4684  loss_objectness: 0.6344  loss_dice: 0.7679  loss_mask: 0.07272    time: 0.1649  last_time: 0.1664  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1614M
[11/22 05:52:25] d2.utils.events INFO:  eta: 0:34:15  iter: 2439  total_loss: 1.929  loss_ce: 0.5426  loss_objectness: 0.6634  loss_dice: 0.7165  loss_mask: 0.0889    time: 0.1649  last_time: 0.1602  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1614M
[11/22 05:52:28] d2.utils.events INFO:  eta: 0:34:11  iter: 2459  total_loss: 1.92  loss_ce: 0.4848  loss_objectness: 0.6296  loss_dice: 0.6982  loss_mask: 0.06912    time: 0.1649  last_time: 0.1667  data_time: 0.0028  last_data_time: 0.0046   lr: 5e-05  max_mem: 1614M
[11/22 05:52:31] d2.utils.events INFO:  eta: 0:34:08  iter: 2479  total_loss: 2.055  loss_ce: 0.4741  loss_objectness: 0.6427  loss_dice: 0.8217  loss_mask: 0.05062    time: 0.1649  last_time: 0.1635  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1614M
[11/22 05:52:34] d2.utils.events INFO:  eta: 0:34:05  iter: 2499  total_loss: 1.856  loss_ce: 0.4108  loss_objectness: 0.6481  loss_dice: 0.6382  loss_mask: 0.06166    time: 0.1649  last_time: 0.1633  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1614M
[11/22 05:52:38] d2.utils.events INFO:  eta: 0:34:02  iter: 2519  total_loss: 1.935  loss_ce: 0.5057  loss_objectness: 0.6557  loss_dice: 0.6674  loss_mask: 0.07731    time: 0.1648  last_time: 0.1657  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1614M
[11/22 05:52:41] d2.utils.events INFO:  eta: 0:33:58  iter: 2539  total_loss: 1.952  loss_ce: 0.4759  loss_objectness: 0.6413  loss_dice: 0.7504  loss_mask: 0.05433    time: 0.1648  last_time: 0.1678  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1614M
[11/22 05:52:44] d2.utils.events INFO:  eta: 0:33:55  iter: 2559  total_loss: 1.973  loss_ce: 0.4831  loss_objectness: 0.6512  loss_dice: 0.7538  loss_mask: 0.05855    time: 0.1648  last_time: 0.1634  data_time: 0.0030  last_data_time: 0.0029   lr: 5e-05  max_mem: 1614M
[11/22 05:52:48] d2.utils.events INFO:  eta: 0:33:51  iter: 2579  total_loss: 1.89  loss_ce: 0.4775  loss_objectness: 0.6671  loss_dice: 0.6324  loss_mask: 0.0731    time: 0.1648  last_time: 0.1595  data_time: 0.0026  last_data_time: 0.0026   lr: 5e-05  max_mem: 1614M
[11/22 05:52:51] d2.utils.events INFO:  eta: 0:33:47  iter: 2599  total_loss: 1.961  loss_ce: 0.4865  loss_objectness: 0.6472  loss_dice: 0.7774  loss_mask: 0.06187    time: 0.1648  last_time: 0.1666  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1614M
[11/22 05:52:54] d2.utils.events INFO:  eta: 0:33:44  iter: 2619  total_loss: 1.857  loss_ce: 0.4599  loss_objectness: 0.6479  loss_dice: 0.6504  loss_mask: 0.08813    time: 0.1648  last_time: 0.1645  data_time: 0.0026  last_data_time: 0.0025   lr: 5e-05  max_mem: 1614M
[11/22 05:52:57] d2.utils.events INFO:  eta: 0:33:40  iter: 2639  total_loss: 1.859  loss_ce: 0.4786  loss_objectness: 0.6592  loss_dice: 0.6004  loss_mask: 0.06579    time: 0.1648  last_time: 0.1611  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1614M
[11/22 05:53:01] d2.utils.events INFO:  eta: 0:33:37  iter: 2659  total_loss: 2.036  loss_ce: 0.5452  loss_objectness: 0.6378  loss_dice: 0.8104  loss_mask: 0.0619    time: 0.1648  last_time: 0.1637  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1614M
[11/22 05:53:04] d2.utils.events INFO:  eta: 0:33:33  iter: 2679  total_loss: 1.862  loss_ce: 0.4595  loss_objectness: 0.6618  loss_dice: 0.5844  loss_mask: 0.08201    time: 0.1648  last_time: 0.1645  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-05  max_mem: 1614M
[11/22 05:53:07] d2.utils.events INFO:  eta: 0:33:30  iter: 2699  total_loss: 1.788  loss_ce: 0.4724  loss_objectness: 0.6681  loss_dice: 0.5792  loss_mask: 0.06804    time: 0.1648  last_time: 0.1649  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-05  max_mem: 1614M
[11/22 05:53:11] d2.utils.events INFO:  eta: 0:33:26  iter: 2719  total_loss: 1.964  loss_ce: 0.5369  loss_objectness: 0.6787  loss_dice: 0.6573  loss_mask: 0.06231    time: 0.1647  last_time: 0.1620  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-05  max_mem: 1614M
[11/22 05:53:14] d2.utils.events INFO:  eta: 0:33:23  iter: 2739  total_loss: 1.964  loss_ce: 0.4826  loss_objectness: 0.6288  loss_dice: 0.7473  loss_mask: 0.05638    time: 0.1647  last_time: 0.1606  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-05  max_mem: 1614M
[11/22 05:53:17] d2.utils.events INFO:  eta: 0:33:20  iter: 2759  total_loss: 1.911  loss_ce: 0.4949  loss_objectness: 0.6613  loss_dice: 0.6259  loss_mask: 0.06691    time: 0.1647  last_time: 0.1629  data_time: 0.0036  last_data_time: 0.0026   lr: 5e-05  max_mem: 1614M
[11/22 05:53:20] d2.utils.events INFO:  eta: 0:33:16  iter: 2779  total_loss: 1.772  loss_ce: 0.4795  loss_objectness: 0.6607  loss_dice: 0.5558  loss_mask: 0.05456    time: 0.1647  last_time: 0.1612  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1614M
[11/22 05:53:24] d2.utils.events INFO:  eta: 0:33:13  iter: 2799  total_loss: 1.985  loss_ce: 0.5359  loss_objectness: 0.6302  loss_dice: 0.6932  loss_mask: 0.05844    time: 0.1647  last_time: 0.1625  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-05  max_mem: 1614M
[11/22 05:53:27] d2.utils.events INFO:  eta: 0:33:10  iter: 2819  total_loss: 1.942  loss_ce: 0.5424  loss_objectness: 0.6675  loss_dice: 0.6189  loss_mask: 0.07072    time: 0.1647  last_time: 0.1636  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-05  max_mem: 1614M
[11/22 05:53:30] d2.utils.events INFO:  eta: 0:33:07  iter: 2839  total_loss: 1.898  loss_ce: 0.5634  loss_objectness: 0.6711  loss_dice: 0.6643  loss_mask: 0.05781    time: 0.1647  last_time: 0.1648  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-05  max_mem: 1614M
[11/22 05:53:33] d2.utils.events INFO:  eta: 0:33:03  iter: 2859  total_loss: 1.903  loss_ce: 0.5653  loss_objectness: 0.6599  loss_dice: 0.618  loss_mask: 0.07092    time: 0.1647  last_time: 0.1667  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1614M
[11/22 05:53:37] d2.utils.events INFO:  eta: 0:32:59  iter: 2879  total_loss: 1.897  loss_ce: 0.4909  loss_objectness: 0.6581  loss_dice: 0.6579  loss_mask: 0.0605    time: 0.1647  last_time: 0.1630  data_time: 0.0030  last_data_time: 0.0031   lr: 5e-05  max_mem: 1614M
[11/22 05:53:40] d2.utils.events INFO:  eta: 0:32:56  iter: 2899  total_loss: 1.876  loss_ce: 0.5128  loss_objectness: 0.6659  loss_dice: 0.6162  loss_mask: 0.05235    time: 0.1647  last_time: 0.1679  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1614M
[11/22 05:53:43] d2.utils.events INFO:  eta: 0:32:53  iter: 2919  total_loss: 1.827  loss_ce: 0.4652  loss_objectness: 0.6759  loss_dice: 0.6143  loss_mask: 0.0779    time: 0.1647  last_time: 0.1668  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-05  max_mem: 1614M
[11/22 05:53:47] d2.utils.events INFO:  eta: 0:32:49  iter: 2939  total_loss: 1.828  loss_ce: 0.4319  loss_objectness: 0.637  loss_dice: 0.6169  loss_mask: 0.06878    time: 0.1647  last_time: 0.1673  data_time: 0.0028  last_data_time: 0.0035   lr: 5e-05  max_mem: 1614M
[11/22 05:53:50] d2.utils.events INFO:  eta: 0:32:46  iter: 2959  total_loss: 1.84  loss_ce: 0.4406  loss_objectness: 0.647  loss_dice: 0.6371  loss_mask: 0.05518    time: 0.1647  last_time: 0.1635  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-05  max_mem: 1614M
[11/22 05:53:53] d2.utils.events INFO:  eta: 0:32:43  iter: 2979  total_loss: 1.935  loss_ce: 0.4448  loss_objectness: 0.6291  loss_dice: 0.7752  loss_mask: 0.0622    time: 0.1646  last_time: 0.1667  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1614M
[11/22 05:53:56] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 05:53:56] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 05:53:56] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 05:53:56] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 05:53:56] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 05:53:56] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 05:54:01] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0386 s/iter. Eval: 0.0398 s/iter. Total: 0.0787 s/iter. ETA=0:00:08
[11/22 05:54:06] d2.evaluation.evaluator INFO: Inference done 86/120. Dataloading: 0.0004 s/iter. Inference: 0.0256 s/iter. Eval: 0.0420 s/iter. Total: 0.0680 s/iter. ETA=0:00:02
[11/22 05:54:09] d2.evaluation.evaluator INFO: Total inference time: 0:00:08.510817 (0.074007 s / iter per device, on 1 devices)
[11/22 05:54:09] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.024544 s / iter per device, on 1 devices)
[11/22 05:54:09] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 05:54:09] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 05:54:09] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 05:54:10] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 05:54:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.06 seconds.
[11/22 05:54:10] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 05:54:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 05:54:10] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.611 | 15.498 | 5.386  | 0.112 | 14.545 | 39.152 |
[11/22 05:54:10] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 05:54:10] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 05:54:10] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 05:54:10] d2.evaluation.testing INFO: copypaste: 6.6106,15.4982,5.3861,0.1122,14.5453,39.1523
[11/22 05:54:10] d2.utils.events INFO:  eta: 0:32:39  iter: 2999  total_loss: 1.815  loss_ce: 0.457  loss_objectness: 0.6586  loss_dice: 0.5691  loss_mask: 0.08839    time: 0.1646  last_time: 0.1626  data_time: 0.0027  last_data_time: 0.0021   lr: 5e-05  max_mem: 1614M
[11/22 05:54:13] d2.utils.events INFO:  eta: 0:32:36  iter: 3019  total_loss: 1.918  loss_ce: 0.4826  loss_objectness: 0.6563  loss_dice: 0.6437  loss_mask: 0.07005    time: 0.1647  last_time: 0.1621  data_time: 0.0036  last_data_time: 0.0027   lr: 5e-05  max_mem: 1614M
[11/22 05:54:16] d2.utils.events INFO:  eta: 0:32:33  iter: 3039  total_loss: 1.901  loss_ce: 0.5186  loss_objectness: 0.6625  loss_dice: 0.684  loss_mask: 0.06756    time: 0.1647  last_time: 0.1651  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-05  max_mem: 1614M
[11/22 05:54:20] d2.utils.events INFO:  eta: 0:32:30  iter: 3059  total_loss: 1.851  loss_ce: 0.5209  loss_objectness: 0.6397  loss_dice: 0.57  loss_mask: 0.05974    time: 0.1647  last_time: 0.1648  data_time: 0.0030  last_data_time: 0.0030   lr: 5e-05  max_mem: 1614M
[11/22 05:54:23] d2.utils.events INFO:  eta: 0:32:26  iter: 3079  total_loss: 1.791  loss_ce: 0.4657  loss_objectness: 0.6502  loss_dice: 0.5679  loss_mask: 0.05844    time: 0.1647  last_time: 0.1631  data_time: 0.0028  last_data_time: 0.0022   lr: 5e-05  max_mem: 1614M
[11/22 05:54:26] d2.utils.events INFO:  eta: 0:32:22  iter: 3099  total_loss: 1.816  loss_ce: 0.4346  loss_objectness: 0.6689  loss_dice: 0.5918  loss_mask: 0.07568    time: 0.1646  last_time: 0.1630  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1614M
[11/22 05:54:29] d2.utils.events INFO:  eta: 0:32:19  iter: 3119  total_loss: 1.881  loss_ce: 0.4461  loss_objectness: 0.6474  loss_dice: 0.6193  loss_mask: 0.09332    time: 0.1646  last_time: 0.1700  data_time: 0.0028  last_data_time: 0.0045   lr: 5e-05  max_mem: 1614M
[11/22 05:54:33] d2.utils.events INFO:  eta: 0:32:15  iter: 3139  total_loss: 1.934  loss_ce: 0.4833  loss_objectness: 0.6468  loss_dice: 0.6827  loss_mask: 0.05942    time: 0.1646  last_time: 0.1624  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1614M
[11/22 05:54:36] d2.utils.events INFO:  eta: 0:32:12  iter: 3159  total_loss: 1.936  loss_ce: 0.5202  loss_objectness: 0.6319  loss_dice: 0.6902  loss_mask: 0.07019    time: 0.1646  last_time: 0.1627  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1614M
[11/22 05:54:39] d2.utils.events INFO:  eta: 0:32:09  iter: 3179  total_loss: 1.806  loss_ce: 0.4282  loss_objectness: 0.6479  loss_dice: 0.6806  loss_mask: 0.05997    time: 0.1646  last_time: 0.1669  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1614M
[11/22 05:54:43] d2.utils.events INFO:  eta: 0:32:06  iter: 3199  total_loss: 1.948  loss_ce: 0.4759  loss_objectness: 0.6622  loss_dice: 0.7386  loss_mask: 0.06366    time: 0.1646  last_time: 0.1610  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-05  max_mem: 1614M
[11/22 05:54:46] d2.utils.events INFO:  eta: 0:32:03  iter: 3219  total_loss: 1.908  loss_ce: 0.4457  loss_objectness: 0.6342  loss_dice: 0.728  loss_mask: 0.07699    time: 0.1646  last_time: 0.1633  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-05  max_mem: 1614M
[11/22 05:54:49] d2.utils.events INFO:  eta: 0:31:59  iter: 3239  total_loss: 1.891  loss_ce: 0.4927  loss_objectness: 0.6438  loss_dice: 0.6871  loss_mask: 0.07548    time: 0.1646  last_time: 0.1623  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-05  max_mem: 1614M
[11/22 05:54:52] d2.utils.events INFO:  eta: 0:31:56  iter: 3259  total_loss: 1.885  loss_ce: 0.4146  loss_objectness: 0.6578  loss_dice: 0.6432  loss_mask: 0.06265    time: 0.1646  last_time: 0.1688  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1614M
[11/22 05:54:56] d2.utils.events INFO:  eta: 0:31:54  iter: 3279  total_loss: 1.823  loss_ce: 0.4458  loss_objectness: 0.651  loss_dice: 0.6344  loss_mask: 0.06066    time: 0.1646  last_time: 0.1694  data_time: 0.0030  last_data_time: 0.0038   lr: 5e-05  max_mem: 1614M
[11/22 05:54:59] d2.utils.events INFO:  eta: 0:31:51  iter: 3299  total_loss: 1.818  loss_ce: 0.3958  loss_objectness: 0.648  loss_dice: 0.6292  loss_mask: 0.05645    time: 0.1646  last_time: 0.1651  data_time: 0.0029  last_data_time: 0.0050   lr: 5e-05  max_mem: 1617M
[11/22 05:55:02] d2.utils.events INFO:  eta: 0:31:47  iter: 3319  total_loss: 1.92  loss_ce: 0.5201  loss_objectness: 0.6537  loss_dice: 0.6827  loss_mask: 0.07508    time: 0.1646  last_time: 0.1638  data_time: 0.0027  last_data_time: 0.0022   lr: 5e-05  max_mem: 1617M
[11/22 05:55:06] d2.utils.events INFO:  eta: 0:31:44  iter: 3339  total_loss: 1.881  loss_ce: 0.4901  loss_objectness: 0.6638  loss_dice: 0.5634  loss_mask: 0.0624    time: 0.1646  last_time: 0.1666  data_time: 0.0027  last_data_time: 0.0022   lr: 5e-05  max_mem: 1617M
[11/22 05:55:09] d2.utils.events INFO:  eta: 0:31:41  iter: 3359  total_loss: 1.86  loss_ce: 0.4472  loss_objectness: 0.6396  loss_dice: 0.6695  loss_mask: 0.07143    time: 0.1646  last_time: 0.1653  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1617M
[11/22 05:55:12] d2.utils.events INFO:  eta: 0:31:38  iter: 3379  total_loss: 1.815  loss_ce: 0.4437  loss_objectness: 0.6282  loss_dice: 0.6163  loss_mask: 0.05653    time: 0.1646  last_time: 0.1662  data_time: 0.0029  last_data_time: 0.0047   lr: 5e-05  max_mem: 1617M
[11/22 05:55:15] d2.utils.events INFO:  eta: 0:31:34  iter: 3399  total_loss: 1.776  loss_ce: 0.4747  loss_objectness: 0.6565  loss_dice: 0.5398  loss_mask: 0.05157    time: 0.1646  last_time: 0.1597  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1617M
[11/22 05:55:19] d2.utils.events INFO:  eta: 0:31:30  iter: 3419  total_loss: 1.821  loss_ce: 0.4407  loss_objectness: 0.6528  loss_dice: 0.5962  loss_mask: 0.06507    time: 0.1645  last_time: 0.1619  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1617M
[11/22 05:55:22] d2.utils.events INFO:  eta: 0:31:27  iter: 3439  total_loss: 1.735  loss_ce: 0.3978  loss_objectness: 0.658  loss_dice: 0.6058  loss_mask: 0.05396    time: 0.1645  last_time: 0.1639  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1617M
[11/22 05:55:25] d2.utils.events INFO:  eta: 0:31:24  iter: 3459  total_loss: 1.816  loss_ce: 0.4457  loss_objectness: 0.6683  loss_dice: 0.6047  loss_mask: 0.05825    time: 0.1645  last_time: 0.1652  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1617M
[11/22 05:55:29] d2.utils.events INFO:  eta: 0:31:20  iter: 3479  total_loss: 1.768  loss_ce: 0.4395  loss_objectness: 0.6533  loss_dice: 0.6055  loss_mask: 0.06176    time: 0.1645  last_time: 0.1613  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1617M
[11/22 05:55:32] d2.utils.events INFO:  eta: 0:31:16  iter: 3499  total_loss: 1.671  loss_ce: 0.4019  loss_objectness: 0.6727  loss_dice: 0.5407  loss_mask: 0.06417    time: 0.1645  last_time: 0.1622  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1617M
[11/22 05:55:35] d2.utils.events INFO:  eta: 0:31:13  iter: 3519  total_loss: 1.774  loss_ce: 0.4315  loss_objectness: 0.6504  loss_dice: 0.5633  loss_mask: 0.05569    time: 0.1645  last_time: 0.1680  data_time: 0.0028  last_data_time: 0.0038   lr: 5e-05  max_mem: 1617M
[11/22 05:55:38] d2.utils.events INFO:  eta: 0:31:10  iter: 3539  total_loss: 1.795  loss_ce: 0.4631  loss_objectness: 0.6393  loss_dice: 0.6671  loss_mask: 0.05594    time: 0.1645  last_time: 0.1616  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-05  max_mem: 1617M
[11/22 05:55:42] d2.utils.events INFO:  eta: 0:31:07  iter: 3559  total_loss: 1.803  loss_ce: 0.4415  loss_objectness: 0.6625  loss_dice: 0.6353  loss_mask: 0.04254    time: 0.1645  last_time: 0.1617  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-05  max_mem: 1617M
[11/22 05:55:45] d2.utils.events INFO:  eta: 0:31:04  iter: 3579  total_loss: 1.993  loss_ce: 0.5602  loss_objectness: 0.6526  loss_dice: 0.7193  loss_mask: 0.06115    time: 0.1645  last_time: 0.1639  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1617M
[11/22 05:55:48] d2.utils.events INFO:  eta: 0:31:00  iter: 3599  total_loss: 1.733  loss_ce: 0.4435  loss_objectness: 0.6724  loss_dice: 0.5355  loss_mask: 0.05858    time: 0.1645  last_time: 0.1622  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1617M
[11/22 05:55:51] d2.utils.events INFO:  eta: 0:30:57  iter: 3619  total_loss: 1.882  loss_ce: 0.4031  loss_objectness: 0.6315  loss_dice: 0.693  loss_mask: 0.07842    time: 0.1645  last_time: 0.1642  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1617M
[11/22 05:55:55] d2.utils.events INFO:  eta: 0:30:54  iter: 3639  total_loss: 1.844  loss_ce: 0.4602  loss_objectness: 0.6742  loss_dice: 0.5988  loss_mask: 0.08916    time: 0.1645  last_time: 0.1627  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-05  max_mem: 1617M
[11/22 05:55:58] d2.utils.events INFO:  eta: 0:30:50  iter: 3659  total_loss: 1.843  loss_ce: 0.4871  loss_objectness: 0.6523  loss_dice: 0.6547  loss_mask: 0.0689    time: 0.1645  last_time: 0.1650  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1617M
[11/22 05:56:01] d2.utils.events INFO:  eta: 0:30:47  iter: 3679  total_loss: 1.846  loss_ce: 0.4439  loss_objectness: 0.6465  loss_dice: 0.638  loss_mask: 0.05618    time: 0.1645  last_time: 0.1658  data_time: 0.0031  last_data_time: 0.0030   lr: 5e-05  max_mem: 1617M
[11/22 05:56:05] d2.utils.events INFO:  eta: 0:30:44  iter: 3699  total_loss: 1.69  loss_ce: 0.3691  loss_objectness: 0.6606  loss_dice: 0.5646  loss_mask: 0.06635    time: 0.1645  last_time: 0.1617  data_time: 0.0026  last_data_time: 0.0024   lr: 5e-05  max_mem: 1617M
[11/22 05:56:08] d2.utils.events INFO:  eta: 0:30:40  iter: 3719  total_loss: 1.774  loss_ce: 0.5057  loss_objectness: 0.6547  loss_dice: 0.5587  loss_mask: 0.07433    time: 0.1645  last_time: 0.1671  data_time: 0.0028  last_data_time: 0.0046   lr: 5e-05  max_mem: 1617M
[11/22 05:56:11] d2.utils.events INFO:  eta: 0:30:39  iter: 3739  total_loss: 1.763  loss_ce: 0.439  loss_objectness: 0.6556  loss_dice: 0.618  loss_mask: 0.05779    time: 0.1645  last_time: 0.1638  data_time: 0.0031  last_data_time: 0.0024   lr: 5e-05  max_mem: 1617M
[11/22 05:56:14] d2.utils.events INFO:  eta: 0:30:35  iter: 3759  total_loss: 1.787  loss_ce: 0.4477  loss_objectness: 0.6516  loss_dice: 0.6195  loss_mask: 0.05218    time: 0.1645  last_time: 0.1597  data_time: 0.0030  last_data_time: 0.0027   lr: 5e-05  max_mem: 1617M
[11/22 05:56:18] d2.utils.events INFO:  eta: 0:30:32  iter: 3779  total_loss: 1.772  loss_ce: 0.4646  loss_objectness: 0.6617  loss_dice: 0.5223  loss_mask: 0.05308    time: 0.1645  last_time: 0.1682  data_time: 0.0035  last_data_time: 0.0032   lr: 5e-05  max_mem: 1617M
[11/22 05:56:21] d2.utils.events INFO:  eta: 0:30:29  iter: 3799  total_loss: 1.658  loss_ce: 0.3819  loss_objectness: 0.6483  loss_dice: 0.5117  loss_mask: 0.07688    time: 0.1645  last_time: 0.1671  data_time: 0.0026  last_data_time: 0.0032   lr: 5e-05  max_mem: 1617M
[11/22 05:56:24] d2.utils.events INFO:  eta: 0:30:25  iter: 3819  total_loss: 1.747  loss_ce: 0.4324  loss_objectness: 0.6427  loss_dice: 0.6043  loss_mask: 0.06368    time: 0.1644  last_time: 0.1612  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1617M
[11/22 05:56:28] d2.utils.events INFO:  eta: 0:30:22  iter: 3839  total_loss: 1.942  loss_ce: 0.513  loss_objectness: 0.6665  loss_dice: 0.656  loss_mask: 0.06641    time: 0.1644  last_time: 0.1623  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-05  max_mem: 1617M
[11/22 05:56:31] d2.utils.events INFO:  eta: 0:30:18  iter: 3859  total_loss: 1.669  loss_ce: 0.422  loss_objectness: 0.6652  loss_dice: 0.5298  loss_mask: 0.06585    time: 0.1644  last_time: 0.1633  data_time: 0.0027  last_data_time: 0.0029   lr: 5e-05  max_mem: 1617M
[11/22 05:56:34] d2.utils.events INFO:  eta: 0:30:16  iter: 3879  total_loss: 1.765  loss_ce: 0.4323  loss_objectness: 0.6483  loss_dice: 0.555  loss_mask: 0.05296    time: 0.1644  last_time: 0.1632  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1617M
[11/22 05:56:37] d2.utils.events INFO:  eta: 0:30:11  iter: 3899  total_loss: 1.647  loss_ce: 0.4365  loss_objectness: 0.6425  loss_dice: 0.472  loss_mask: 0.06476    time: 0.1644  last_time: 0.1640  data_time: 0.0027  last_data_time: 0.0020   lr: 5e-05  max_mem: 1617M
[11/22 05:56:41] d2.utils.events INFO:  eta: 0:30:08  iter: 3919  total_loss: 1.803  loss_ce: 0.4876  loss_objectness: 0.648  loss_dice: 0.6747  loss_mask: 0.046    time: 0.1644  last_time: 0.1602  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-05  max_mem: 1617M
[11/22 05:56:44] d2.utils.events INFO:  eta: 0:30:05  iter: 3939  total_loss: 1.737  loss_ce: 0.4096  loss_objectness: 0.6768  loss_dice: 0.556  loss_mask: 0.06745    time: 0.1644  last_time: 0.1663  data_time: 0.0028  last_data_time: 0.0034   lr: 5e-05  max_mem: 1617M
[11/22 05:56:47] d2.utils.events INFO:  eta: 0:30:02  iter: 3959  total_loss: 1.693  loss_ce: 0.3944  loss_objectness: 0.6553  loss_dice: 0.5119  loss_mask: 0.052    time: 0.1644  last_time: 0.1617  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1617M
[11/22 05:56:51] d2.utils.events INFO:  eta: 0:29:58  iter: 3979  total_loss: 1.843  loss_ce: 0.4692  loss_objectness: 0.6581  loss_dice: 0.5876  loss_mask: 0.05559    time: 0.1644  last_time: 0.1630  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1617M
[11/22 05:56:54] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 05:56:54] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 05:56:54] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 05:56:54] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 05:56:54] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 05:56:54] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 05:56:59] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0225 s/iter. Eval: 0.0386 s/iter. Total: 0.0614 s/iter. ETA=0:00:06
[11/22 05:57:04] d2.evaluation.evaluator INFO: Inference done 92/120. Dataloading: 0.0004 s/iter. Inference: 0.0216 s/iter. Eval: 0.0402 s/iter. Total: 0.0622 s/iter. ETA=0:00:01
[11/22 05:57:06] d2.evaluation.evaluator INFO: Total inference time: 0:00:08.011860 (0.069668 s / iter per device, on 1 devices)
[11/22 05:57:06] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.021671 s / iter per device, on 1 devices)
[11/22 05:57:06] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 05:57:06] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 05:57:06] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 05:57:06] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 05:57:07] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.06 seconds.
[11/22 05:57:07] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 05:57:07] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 05:57:07] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 5.961 | 14.250 | 5.647  | 0.112 | 12.805 | 36.429 |
[11/22 05:57:07] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 05:57:07] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 05:57:07] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 05:57:07] d2.evaluation.testing INFO: copypaste: 5.9608,14.2502,5.6472,0.1123,12.8049,36.4290
[11/22 05:57:07] d2.utils.events INFO:  eta: 0:29:54  iter: 3999  total_loss: 1.855  loss_ce: 0.4842  loss_objectness: 0.6658  loss_dice: 0.6072  loss_mask: 0.05442    time: 0.1644  last_time: 0.1630  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1617M
[11/22 05:57:10] d2.utils.events INFO:  eta: 0:29:51  iter: 4019  total_loss: 1.714  loss_ce: 0.4546  loss_objectness: 0.6635  loss_dice: 0.5413  loss_mask: 0.06487    time: 0.1644  last_time: 0.1606  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1617M
[11/22 05:57:13] d2.utils.events INFO:  eta: 0:29:48  iter: 4039  total_loss: 1.736  loss_ce: 0.4432  loss_objectness: 0.6517  loss_dice: 0.5313  loss_mask: 0.05639    time: 0.1644  last_time: 0.1626  data_time: 0.0028  last_data_time: 0.0032   lr: 5e-05  max_mem: 1617M
[11/22 05:57:16] d2.utils.events INFO:  eta: 0:29:44  iter: 4059  total_loss: 1.759  loss_ce: 0.4363  loss_objectness: 0.6677  loss_dice: 0.549  loss_mask: 0.05857    time: 0.1644  last_time: 0.1644  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1632M
[11/22 05:57:20] d2.utils.events INFO:  eta: 0:29:41  iter: 4079  total_loss: 1.755  loss_ce: 0.4452  loss_objectness: 0.6553  loss_dice: 0.5559  loss_mask: 0.04967    time: 0.1644  last_time: 0.1628  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 05:57:23] d2.utils.events INFO:  eta: 0:29:38  iter: 4099  total_loss: 1.771  loss_ce: 0.4734  loss_objectness: 0.6387  loss_dice: 0.5352  loss_mask: 0.04846    time: 0.1644  last_time: 0.1628  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 05:57:26] d2.utils.events INFO:  eta: 0:29:34  iter: 4119  total_loss: 1.748  loss_ce: 0.4783  loss_objectness: 0.6579  loss_dice: 0.5357  loss_mask: 0.0458    time: 0.1644  last_time: 0.1618  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 05:57:30] d2.utils.events INFO:  eta: 0:29:31  iter: 4139  total_loss: 1.756  loss_ce: 0.441  loss_objectness: 0.6531  loss_dice: 0.5898  loss_mask: 0.04302    time: 0.1644  last_time: 0.1656  data_time: 0.0029  last_data_time: 0.0022   lr: 5e-05  max_mem: 1632M
[11/22 05:57:33] d2.utils.events INFO:  eta: 0:29:28  iter: 4159  total_loss: 1.794  loss_ce: 0.4621  loss_objectness: 0.6577  loss_dice: 0.543  loss_mask: 0.04627    time: 0.1644  last_time: 0.1676  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 05:57:36] d2.utils.events INFO:  eta: 0:29:24  iter: 4179  total_loss: 1.855  loss_ce: 0.4954  loss_objectness: 0.6638  loss_dice: 0.5976  loss_mask: 0.07269    time: 0.1644  last_time: 0.1621  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1632M
[11/22 05:57:39] d2.utils.events INFO:  eta: 0:29:21  iter: 4199  total_loss: 1.763  loss_ce: 0.4022  loss_objectness: 0.6772  loss_dice: 0.5223  loss_mask: 0.0691    time: 0.1644  last_time: 0.1660  data_time: 0.0028  last_data_time: 0.0022   lr: 5e-05  max_mem: 1632M
[11/22 05:57:43] d2.utils.events INFO:  eta: 0:29:17  iter: 4219  total_loss: 1.731  loss_ce: 0.3999  loss_objectness: 0.6582  loss_dice: 0.4876  loss_mask: 0.06939    time: 0.1644  last_time: 0.1685  data_time: 0.0026  last_data_time: 0.0033   lr: 5e-05  max_mem: 1632M
[11/22 05:57:46] d2.utils.events INFO:  eta: 0:29:14  iter: 4239  total_loss: 1.755  loss_ce: 0.4545  loss_objectness: 0.6613  loss_dice: 0.5085  loss_mask: 0.05113    time: 0.1644  last_time: 0.1634  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 05:57:49] d2.utils.events INFO:  eta: 0:29:11  iter: 4259  total_loss: 1.787  loss_ce: 0.4688  loss_objectness: 0.6795  loss_dice: 0.5879  loss_mask: 0.05702    time: 0.1644  last_time: 0.1613  data_time: 0.0028  last_data_time: 0.0033   lr: 5e-05  max_mem: 1632M
[11/22 05:57:53] d2.utils.events INFO:  eta: 0:29:07  iter: 4279  total_loss: 1.782  loss_ce: 0.4364  loss_objectness: 0.6412  loss_dice: 0.5841  loss_mask: 0.05941    time: 0.1643  last_time: 0.1612  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 05:57:56] d2.utils.events INFO:  eta: 0:29:04  iter: 4299  total_loss: 1.792  loss_ce: 0.4216  loss_objectness: 0.6792  loss_dice: 0.5393  loss_mask: 0.07066    time: 0.1643  last_time: 0.1640  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1632M
[11/22 05:57:59] d2.utils.events INFO:  eta: 0:29:00  iter: 4319  total_loss: 1.67  loss_ce: 0.4255  loss_objectness: 0.6683  loss_dice: 0.5365  loss_mask: 0.05284    time: 0.1643  last_time: 0.1597  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 05:58:02] d2.utils.events INFO:  eta: 0:28:57  iter: 4339  total_loss: 1.731  loss_ce: 0.3961  loss_objectness: 0.6634  loss_dice: 0.5126  loss_mask: 0.06567    time: 0.1643  last_time: 0.1585  data_time: 0.0027  last_data_time: 0.0021   lr: 5e-05  max_mem: 1632M
[11/22 05:58:06] d2.utils.events INFO:  eta: 0:28:54  iter: 4359  total_loss: 1.737  loss_ce: 0.3892  loss_objectness: 0.6561  loss_dice: 0.6008  loss_mask: 0.04206    time: 0.1643  last_time: 0.1627  data_time: 0.0037  last_data_time: 0.0041   lr: 5e-05  max_mem: 1632M
[11/22 05:58:09] d2.utils.events INFO:  eta: 0:28:50  iter: 4379  total_loss: 1.691  loss_ce: 0.4004  loss_objectness: 0.6656  loss_dice: 0.5859  loss_mask: 0.05674    time: 0.1643  last_time: 0.1628  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 05:58:12] d2.utils.events INFO:  eta: 0:28:47  iter: 4399  total_loss: 1.832  loss_ce: 0.4425  loss_objectness: 0.6512  loss_dice: 0.6766  loss_mask: 0.05056    time: 0.1643  last_time: 0.1692  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 05:58:16] d2.utils.events INFO:  eta: 0:28:44  iter: 4419  total_loss: 1.692  loss_ce: 0.4527  loss_objectness: 0.6695  loss_dice: 0.5046  loss_mask: 0.05054    time: 0.1643  last_time: 0.1600  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 05:58:19] d2.utils.events INFO:  eta: 0:28:41  iter: 4439  total_loss: 1.722  loss_ce: 0.4306  loss_objectness: 0.6702  loss_dice: 0.5274  loss_mask: 0.05203    time: 0.1643  last_time: 0.1604  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 05:58:22] d2.utils.events INFO:  eta: 0:28:38  iter: 4459  total_loss: 1.799  loss_ce: 0.4497  loss_objectness: 0.6641  loss_dice: 0.547  loss_mask: 0.05988    time: 0.1643  last_time: 0.1594  data_time: 0.0026  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 05:58:25] d2.utils.events INFO:  eta: 0:28:35  iter: 4479  total_loss: 1.827  loss_ce: 0.4743  loss_objectness: 0.6614  loss_dice: 0.611  loss_mask: 0.0644    time: 0.1643  last_time: 0.1668  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 05:58:29] d2.utils.events INFO:  eta: 0:28:31  iter: 4499  total_loss: 1.604  loss_ce: 0.4062  loss_objectness: 0.6476  loss_dice: 0.435  loss_mask: 0.05807    time: 0.1643  last_time: 0.1632  data_time: 0.0026  last_data_time: 0.0029   lr: 5e-05  max_mem: 1632M
[11/22 05:58:32] d2.utils.events INFO:  eta: 0:28:28  iter: 4519  total_loss: 1.674  loss_ce: 0.4214  loss_objectness: 0.6588  loss_dice: 0.5332  loss_mask: 0.05634    time: 0.1643  last_time: 0.1646  data_time: 0.0029  last_data_time: 0.0037   lr: 5e-05  max_mem: 1632M
[11/22 05:58:35] d2.utils.events INFO:  eta: 0:28:25  iter: 4539  total_loss: 1.557  loss_ce: 0.4118  loss_objectness: 0.6456  loss_dice: 0.4245  loss_mask: 0.05972    time: 0.1643  last_time: 0.1617  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1632M
[11/22 05:58:39] d2.utils.events INFO:  eta: 0:28:22  iter: 4559  total_loss: 1.633  loss_ce: 0.4516  loss_objectness: 0.6473  loss_dice: 0.4823  loss_mask: 0.04826    time: 0.1643  last_time: 0.1617  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 05:58:42] d2.utils.events INFO:  eta: 0:28:18  iter: 4579  total_loss: 1.779  loss_ce: 0.4914  loss_objectness: 0.6564  loss_dice: 0.5698  loss_mask: 0.05117    time: 0.1643  last_time: 0.1628  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 05:58:45] d2.utils.events INFO:  eta: 0:28:15  iter: 4599  total_loss: 1.754  loss_ce: 0.4591  loss_objectness: 0.634  loss_dice: 0.5576  loss_mask: 0.04102    time: 0.1643  last_time: 0.1619  data_time: 0.0030  last_data_time: 0.0024   lr: 5e-05  max_mem: 1632M
[11/22 05:58:48] d2.utils.events INFO:  eta: 0:28:11  iter: 4619  total_loss: 1.629  loss_ce: 0.4689  loss_objectness: 0.6542  loss_dice: 0.4456  loss_mask: 0.04503    time: 0.1643  last_time: 0.1610  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 05:58:52] d2.utils.events INFO:  eta: 0:28:08  iter: 4639  total_loss: 1.657  loss_ce: 0.4358  loss_objectness: 0.6639  loss_dice: 0.4737  loss_mask: 0.04688    time: 0.1643  last_time: 0.1587  data_time: 0.0028  last_data_time: 0.0022   lr: 5e-05  max_mem: 1632M
[11/22 05:58:55] d2.utils.events INFO:  eta: 0:28:05  iter: 4659  total_loss: 1.674  loss_ce: 0.4146  loss_objectness: 0.6546  loss_dice: 0.5057  loss_mask: 0.05703    time: 0.1643  last_time: 0.1641  data_time: 0.0036  last_data_time: 0.0024   lr: 5e-05  max_mem: 1632M
[11/22 05:58:58] d2.utils.events INFO:  eta: 0:28:02  iter: 4679  total_loss: 1.715  loss_ce: 0.483  loss_objectness: 0.6214  loss_dice: 0.5266  loss_mask: 0.04911    time: 0.1643  last_time: 0.1595  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 05:59:01] d2.utils.events INFO:  eta: 0:27:58  iter: 4699  total_loss: 1.852  loss_ce: 0.4776  loss_objectness: 0.6482  loss_dice: 0.5971  loss_mask: 0.06656    time: 0.1643  last_time: 0.1669  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 05:59:05] d2.utils.events INFO:  eta: 0:27:56  iter: 4719  total_loss: 1.681  loss_ce: 0.4528  loss_objectness: 0.6643  loss_dice: 0.5025  loss_mask: 0.04384    time: 0.1643  last_time: 0.1731  data_time: 0.0031  last_data_time: 0.0029   lr: 5e-05  max_mem: 1632M
[11/22 05:59:08] d2.utils.events INFO:  eta: 0:27:52  iter: 4739  total_loss: 1.621  loss_ce: 0.4371  loss_objectness: 0.6512  loss_dice: 0.4702  loss_mask: 0.0599    time: 0.1643  last_time: 0.1658  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 05:59:11] d2.utils.events INFO:  eta: 0:27:49  iter: 4759  total_loss: 1.52  loss_ce: 0.4069  loss_objectness: 0.6343  loss_dice: 0.4151  loss_mask: 0.05718    time: 0.1643  last_time: 0.1657  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1632M
[11/22 05:59:15] d2.utils.events INFO:  eta: 0:27:46  iter: 4779  total_loss: 1.629  loss_ce: 0.4094  loss_objectness: 0.6494  loss_dice: 0.4971  loss_mask: 0.04864    time: 0.1643  last_time: 0.1639  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 05:59:18] d2.utils.events INFO:  eta: 0:27:43  iter: 4799  total_loss: 1.756  loss_ce: 0.4906  loss_objectness: 0.6753  loss_dice: 0.5078  loss_mask: 0.05469    time: 0.1643  last_time: 0.1672  data_time: 0.0030  last_data_time: 0.0033   lr: 5e-05  max_mem: 1632M
[11/22 05:59:21] d2.utils.events INFO:  eta: 0:27:41  iter: 4819  total_loss: 1.698  loss_ce: 0.4142  loss_objectness: 0.6463  loss_dice: 0.5326  loss_mask: 0.04866    time: 0.1643  last_time: 0.1708  data_time: 0.0029  last_data_time: 0.0033   lr: 5e-05  max_mem: 1632M
[11/22 05:59:25] d2.utils.events INFO:  eta: 0:27:38  iter: 4839  total_loss: 1.534  loss_ce: 0.3958  loss_objectness: 0.6447  loss_dice: 0.385  loss_mask: 0.05281    time: 0.1643  last_time: 0.1653  data_time: 0.0028  last_data_time: 0.0022   lr: 5e-05  max_mem: 1632M
[11/22 05:59:28] d2.utils.events INFO:  eta: 0:27:35  iter: 4859  total_loss: 1.703  loss_ce: 0.468  loss_objectness: 0.6502  loss_dice: 0.5004  loss_mask: 0.04938    time: 0.1643  last_time: 0.1681  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 05:59:31] d2.utils.events INFO:  eta: 0:27:32  iter: 4879  total_loss: 1.61  loss_ce: 0.4104  loss_objectness: 0.6538  loss_dice: 0.467  loss_mask: 0.04718    time: 0.1643  last_time: 0.1640  data_time: 0.0034  last_data_time: 0.0029   lr: 5e-05  max_mem: 1632M
[11/22 05:59:35] d2.utils.events INFO:  eta: 0:27:30  iter: 4899  total_loss: 1.623  loss_ce: 0.4268  loss_objectness: 0.6608  loss_dice: 0.4838  loss_mask: 0.05511    time: 0.1643  last_time: 0.1642  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 05:59:38] d2.utils.events INFO:  eta: 0:27:27  iter: 4919  total_loss: 1.642  loss_ce: 0.4234  loss_objectness: 0.6396  loss_dice: 0.4667  loss_mask: 0.0569    time: 0.1643  last_time: 0.1687  data_time: 0.0029  last_data_time: 0.0037   lr: 5e-05  max_mem: 1632M
[11/22 05:59:41] d2.utils.events INFO:  eta: 0:27:24  iter: 4939  total_loss: 1.653  loss_ce: 0.4368  loss_objectness: 0.6487  loss_dice: 0.5071  loss_mask: 0.05491    time: 0.1643  last_time: 0.1675  data_time: 0.0026  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 05:59:45] d2.utils.events INFO:  eta: 0:27:21  iter: 4959  total_loss: 1.581  loss_ce: 0.3933  loss_objectness: 0.6572  loss_dice: 0.4227  loss_mask: 0.05733    time: 0.1643  last_time: 0.1649  data_time: 0.0030  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 05:59:48] d2.utils.events INFO:  eta: 0:27:19  iter: 4979  total_loss: 1.542  loss_ce: 0.3695  loss_objectness: 0.6347  loss_dice: 0.4476  loss_mask: 0.04156    time: 0.1643  last_time: 0.1662  data_time: 0.0030  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 05:59:51] fvcore.common.checkpoint INFO: Saving checkpoint to output/crack_model_turbo\model_0004999.pth
[11/22 05:59:52] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 05:59:52] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 05:59:52] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 05:59:52] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 05:59:52] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 05:59:52] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 05:59:58] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0225 s/iter. Eval: 0.0562 s/iter. Total: 0.0790 s/iter. ETA=0:00:08
[11/22 06:00:03] d2.evaluation.evaluator INFO: Inference done 75/120. Dataloading: 0.0004 s/iter. Inference: 0.0264 s/iter. Eval: 0.0521 s/iter. Total: 0.0789 s/iter. ETA=0:00:03
[11/22 06:00:07] d2.evaluation.evaluator INFO: Total inference time: 0:00:09.583837 (0.083338 s / iter per device, on 1 devices)
[11/22 06:00:07] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:03 (0.026182 s / iter per device, on 1 devices)
[11/22 06:00:07] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 06:00:07] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 06:00:07] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 06:00:07] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 06:00:07] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.07 seconds.
[11/22 06:00:07] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 06:00:07] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 06:00:07] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 7.020 | 15.791 | 6.057  | 0.133 | 15.449 | 42.764 |
[11/22 06:00:07] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 06:00:07] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 06:00:07] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 06:00:07] d2.evaluation.testing INFO: copypaste: 7.0204,15.7912,6.0566,0.1331,15.4487,42.7636
[11/22 06:00:07] d2.utils.events INFO:  eta: 0:27:17  iter: 4999  total_loss: 1.692  loss_ce: 0.446  loss_objectness: 0.6744  loss_dice: 0.5018  loss_mask: 0.07223    time: 0.1643  last_time: 0.1640  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:00:10] d2.utils.events INFO:  eta: 0:27:13  iter: 5019  total_loss: 1.561  loss_ce: 0.3968  loss_objectness: 0.6338  loss_dice: 0.4691  loss_mask: 0.04442    time: 0.1644  last_time: 0.1617  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:00:14] d2.utils.events INFO:  eta: 0:27:11  iter: 5039  total_loss: 1.641  loss_ce: 0.4016  loss_objectness: 0.6576  loss_dice: 0.4838  loss_mask: 0.05111    time: 0.1644  last_time: 0.1705  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:00:17] d2.utils.events INFO:  eta: 0:27:08  iter: 5059  total_loss: 1.689  loss_ce: 0.4435  loss_objectness: 0.6685  loss_dice: 0.4508  loss_mask: 0.04272    time: 0.1644  last_time: 0.1865  data_time: 0.0036  last_data_time: 0.0191   lr: 5e-05  max_mem: 1632M
[11/22 06:00:20] d2.utils.events INFO:  eta: 0:27:04  iter: 5079  total_loss: 1.688  loss_ce: 0.4599  loss_objectness: 0.6564  loss_dice: 0.4763  loss_mask: 0.03899    time: 0.1644  last_time: 0.1674  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:00:24] d2.utils.events INFO:  eta: 0:27:02  iter: 5099  total_loss: 1.613  loss_ce: 0.4563  loss_objectness: 0.645  loss_dice: 0.4178  loss_mask: 0.04954    time: 0.1644  last_time: 0.1715  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 06:00:27] d2.utils.events INFO:  eta: 0:26:59  iter: 5119  total_loss: 1.693  loss_ce: 0.4919  loss_objectness: 0.6627  loss_dice: 0.4359  loss_mask: 0.05013    time: 0.1644  last_time: 0.1746  data_time: 0.0035  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:00:31] d2.utils.events INFO:  eta: 0:26:56  iter: 5139  total_loss: 1.553  loss_ce: 0.3881  loss_objectness: 0.6489  loss_dice: 0.4559  loss_mask: 0.04396    time: 0.1644  last_time: 0.1682  data_time: 0.0043  last_data_time: 0.0036   lr: 5e-05  max_mem: 1632M
[11/22 06:00:34] d2.utils.events INFO:  eta: 0:26:53  iter: 5159  total_loss: 1.643  loss_ce: 0.431  loss_objectness: 0.6358  loss_dice: 0.5267  loss_mask: 0.0539    time: 0.1645  last_time: 0.1663  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1632M
[11/22 06:00:37] d2.utils.events INFO:  eta: 0:26:50  iter: 5179  total_loss: 1.577  loss_ce: 0.4183  loss_objectness: 0.6466  loss_dice: 0.418  loss_mask: 0.0473    time: 0.1645  last_time: 0.1652  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:00:41] d2.utils.events INFO:  eta: 0:26:47  iter: 5199  total_loss: 1.521  loss_ce: 0.3848  loss_objectness: 0.6283  loss_dice: 0.3933  loss_mask: 0.04714    time: 0.1645  last_time: 0.1658  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:00:44] d2.utils.events INFO:  eta: 0:26:44  iter: 5219  total_loss: 1.643  loss_ce: 0.3961  loss_objectness: 0.6536  loss_dice: 0.516  loss_mask: 0.04715    time: 0.1645  last_time: 0.1628  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 06:00:47] d2.utils.events INFO:  eta: 0:26:41  iter: 5239  total_loss: 1.616  loss_ce: 0.4543  loss_objectness: 0.6535  loss_dice: 0.4929  loss_mask: 0.0376    time: 0.1645  last_time: 0.1644  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:00:50] d2.utils.events INFO:  eta: 0:26:38  iter: 5259  total_loss: 1.331  loss_ce: 0.3706  loss_objectness: 0.6147  loss_dice: 0.289  loss_mask: 0.04322    time: 0.1644  last_time: 0.1619  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 06:00:54] d2.utils.events INFO:  eta: 0:26:34  iter: 5279  total_loss: 1.523  loss_ce: 0.4135  loss_objectness: 0.6411  loss_dice: 0.3764  loss_mask: 0.04898    time: 0.1644  last_time: 0.1634  data_time: 0.0027  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 06:00:57] d2.utils.events INFO:  eta: 0:26:31  iter: 5299  total_loss: 1.578  loss_ce: 0.3962  loss_objectness: 0.656  loss_dice: 0.4309  loss_mask: 0.04128    time: 0.1644  last_time: 0.1626  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:01:00] d2.utils.events INFO:  eta: 0:26:28  iter: 5319  total_loss: 1.506  loss_ce: 0.3922  loss_objectness: 0.6508  loss_dice: 0.4477  loss_mask: 0.04694    time: 0.1644  last_time: 0.1637  data_time: 0.0030  last_data_time: 0.0036   lr: 5e-05  max_mem: 1632M
[11/22 06:01:04] d2.utils.events INFO:  eta: 0:26:25  iter: 5339  total_loss: 1.447  loss_ce: 0.3841  loss_objectness: 0.6263  loss_dice: 0.3857  loss_mask: 0.05048    time: 0.1644  last_time: 0.1642  data_time: 0.0027  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:01:07] d2.utils.events INFO:  eta: 0:26:22  iter: 5359  total_loss: 1.711  loss_ce: 0.4302  loss_objectness: 0.6517  loss_dice: 0.5114  loss_mask: 0.04685    time: 0.1644  last_time: 0.1656  data_time: 0.0029  last_data_time: 0.0036   lr: 5e-05  max_mem: 1632M
[11/22 06:01:10] d2.utils.events INFO:  eta: 0:26:18  iter: 5379  total_loss: 1.54  loss_ce: 0.3928  loss_objectness: 0.6455  loss_dice: 0.4354  loss_mask: 0.04873    time: 0.1644  last_time: 0.1651  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:01:13] d2.utils.events INFO:  eta: 0:26:15  iter: 5399  total_loss: 1.596  loss_ce: 0.4018  loss_objectness: 0.658  loss_dice: 0.466  loss_mask: 0.04516    time: 0.1644  last_time: 0.1671  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1632M
[11/22 06:01:17] d2.utils.events INFO:  eta: 0:26:12  iter: 5419  total_loss: 1.597  loss_ce: 0.4157  loss_objectness: 0.6496  loss_dice: 0.482  loss_mask: 0.05547    time: 0.1644  last_time: 0.1644  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:01:20] d2.utils.events INFO:  eta: 0:26:09  iter: 5439  total_loss: 1.496  loss_ce: 0.3777  loss_objectness: 0.6525  loss_dice: 0.4232  loss_mask: 0.04234    time: 0.1644  last_time: 0.1616  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:01:23] d2.utils.events INFO:  eta: 0:26:07  iter: 5459  total_loss: 1.571  loss_ce: 0.4141  loss_objectness: 0.6512  loss_dice: 0.4418  loss_mask: 0.04658    time: 0.1644  last_time: 0.1651  data_time: 0.0030  last_data_time: 0.0044   lr: 5e-05  max_mem: 1632M
[11/22 06:01:27] d2.utils.events INFO:  eta: 0:26:04  iter: 5479  total_loss: 1.703  loss_ce: 0.493  loss_objectness: 0.6573  loss_dice: 0.5059  loss_mask: 0.03888    time: 0.1644  last_time: 0.1605  data_time: 0.0030  last_data_time: 0.0020   lr: 5e-05  max_mem: 1632M
[11/22 06:01:30] d2.utils.events INFO:  eta: 0:26:01  iter: 5499  total_loss: 1.577  loss_ce: 0.3614  loss_objectness: 0.6316  loss_dice: 0.5095  loss_mask: 0.0523    time: 0.1644  last_time: 0.1618  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:01:33] d2.utils.events INFO:  eta: 0:25:58  iter: 5519  total_loss: 1.555  loss_ce: 0.3899  loss_objectness: 0.6464  loss_dice: 0.4484  loss_mask: 0.05077    time: 0.1644  last_time: 0.1681  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-05  max_mem: 1632M
[11/22 06:01:37] d2.utils.events INFO:  eta: 0:25:54  iter: 5539  total_loss: 1.435  loss_ce: 0.3494  loss_objectness: 0.6578  loss_dice: 0.3603  loss_mask: 0.04478    time: 0.1644  last_time: 0.1632  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:01:40] d2.utils.events INFO:  eta: 0:25:51  iter: 5559  total_loss: 1.55  loss_ce: 0.4004  loss_objectness: 0.6509  loss_dice: 0.4219  loss_mask: 0.04473    time: 0.1644  last_time: 0.1626  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:01:43] d2.utils.events INFO:  eta: 0:25:48  iter: 5579  total_loss: 1.523  loss_ce: 0.3984  loss_objectness: 0.6468  loss_dice: 0.3786  loss_mask: 0.05075    time: 0.1644  last_time: 0.1637  data_time: 0.0027  last_data_time: 0.0033   lr: 5e-05  max_mem: 1632M
[11/22 06:01:46] d2.utils.events INFO:  eta: 0:25:44  iter: 5599  total_loss: 1.546  loss_ce: 0.391  loss_objectness: 0.6389  loss_dice: 0.3905  loss_mask: 0.04649    time: 0.1644  last_time: 0.1650  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:01:50] d2.utils.events INFO:  eta: 0:25:41  iter: 5619  total_loss: 1.618  loss_ce: 0.3928  loss_objectness: 0.6526  loss_dice: 0.4538  loss_mask: 0.05711    time: 0.1644  last_time: 0.1667  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-05  max_mem: 1632M
[11/22 06:01:53] d2.utils.events INFO:  eta: 0:25:38  iter: 5639  total_loss: 1.506  loss_ce: 0.3762  loss_objectness: 0.6426  loss_dice: 0.4019  loss_mask: 0.04333    time: 0.1644  last_time: 0.1668  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:01:56] d2.utils.events INFO:  eta: 0:25:34  iter: 5659  total_loss: 1.548  loss_ce: 0.3912  loss_objectness: 0.6591  loss_dice: 0.4578  loss_mask: 0.04311    time: 0.1644  last_time: 0.1620  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:01:59] d2.utils.events INFO:  eta: 0:25:31  iter: 5679  total_loss: 1.546  loss_ce: 0.407  loss_objectness: 0.6284  loss_dice: 0.4615  loss_mask: 0.05273    time: 0.1644  last_time: 0.1647  data_time: 0.0028  last_data_time: 0.0037   lr: 5e-05  max_mem: 1632M
[11/22 06:02:03] d2.utils.events INFO:  eta: 0:25:28  iter: 5699  total_loss: 1.616  loss_ce: 0.3943  loss_objectness: 0.6613  loss_dice: 0.4885  loss_mask: 0.03744    time: 0.1644  last_time: 0.1680  data_time: 0.0029  last_data_time: 0.0034   lr: 5e-05  max_mem: 1632M
[11/22 06:02:06] d2.utils.events INFO:  eta: 0:25:24  iter: 5719  total_loss: 1.552  loss_ce: 0.3771  loss_objectness: 0.6509  loss_dice: 0.4544  loss_mask: 0.04006    time: 0.1644  last_time: 0.1618  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1632M
[11/22 06:02:09] d2.utils.events INFO:  eta: 0:25:20  iter: 5739  total_loss: 1.412  loss_ce: 0.3433  loss_objectness: 0.6354  loss_dice: 0.3602  loss_mask: 0.04594    time: 0.1644  last_time: 0.1646  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-05  max_mem: 1632M
[11/22 06:02:13] d2.utils.events INFO:  eta: 0:25:17  iter: 5759  total_loss: 1.526  loss_ce: 0.3703  loss_objectness: 0.658  loss_dice: 0.4426  loss_mask: 0.03845    time: 0.1644  last_time: 0.1648  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:02:16] d2.utils.events INFO:  eta: 0:25:13  iter: 5779  total_loss: 1.481  loss_ce: 0.3849  loss_objectness: 0.628  loss_dice: 0.3698  loss_mask: 0.04785    time: 0.1644  last_time: 0.1640  data_time: 0.0027  last_data_time: 0.0032   lr: 5e-05  max_mem: 1632M
[11/22 06:02:19] d2.utils.events INFO:  eta: 0:25:10  iter: 5799  total_loss: 1.389  loss_ce: 0.3377  loss_objectness: 0.6333  loss_dice: 0.3494  loss_mask: 0.04169    time: 0.1644  last_time: 0.1649  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:02:23] d2.utils.events INFO:  eta: 0:25:06  iter: 5819  total_loss: 1.523  loss_ce: 0.333  loss_objectness: 0.6281  loss_dice: 0.4127  loss_mask: 0.04432    time: 0.1644  last_time: 0.1626  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:02:26] d2.utils.events INFO:  eta: 0:25:03  iter: 5839  total_loss: 1.62  loss_ce: 0.4097  loss_objectness: 0.6567  loss_dice: 0.4508  loss_mask: 0.04448    time: 0.1644  last_time: 0.1605  data_time: 0.0034  last_data_time: 0.0022   lr: 5e-05  max_mem: 1632M
[11/22 06:02:29] d2.utils.events INFO:  eta: 0:24:59  iter: 5859  total_loss: 1.484  loss_ce: 0.3703  loss_objectness: 0.636  loss_dice: 0.3967  loss_mask: 0.04292    time: 0.1644  last_time: 0.1656  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-05  max_mem: 1632M
[11/22 06:02:32] d2.utils.events INFO:  eta: 0:24:55  iter: 5879  total_loss: 1.418  loss_ce: 0.3518  loss_objectness: 0.6511  loss_dice: 0.4419  loss_mask: 0.03567    time: 0.1644  last_time: 0.1637  data_time: 0.0028  last_data_time: 0.0022   lr: 5e-05  max_mem: 1632M
[11/22 06:02:36] d2.utils.events INFO:  eta: 0:24:52  iter: 5899  total_loss: 1.453  loss_ce: 0.3313  loss_objectness: 0.6469  loss_dice: 0.4216  loss_mask: 0.04112    time: 0.1644  last_time: 0.1638  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:02:39] d2.utils.events INFO:  eta: 0:24:48  iter: 5919  total_loss: 1.427  loss_ce: 0.3854  loss_objectness: 0.6358  loss_dice: 0.3492  loss_mask: 0.0385    time: 0.1644  last_time: 0.1635  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:02:42] d2.utils.events INFO:  eta: 0:24:44  iter: 5939  total_loss: 1.486  loss_ce: 0.3622  loss_objectness: 0.6452  loss_dice: 0.4028  loss_mask: 0.04691    time: 0.1644  last_time: 0.1671  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:02:46] d2.utils.events INFO:  eta: 0:24:41  iter: 5959  total_loss: 1.489  loss_ce: 0.3742  loss_objectness: 0.6321  loss_dice: 0.4145  loss_mask: 0.04042    time: 0.1644  last_time: 0.1587  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:02:49] d2.utils.events INFO:  eta: 0:24:37  iter: 5979  total_loss: 1.499  loss_ce: 0.3767  loss_objectness: 0.6475  loss_dice: 0.3882  loss_mask: 0.04207    time: 0.1644  last_time: 0.1684  data_time: 0.0029  last_data_time: 0.0033   lr: 5e-05  max_mem: 1632M
[11/22 06:02:52] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 06:02:52] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 06:02:52] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 06:02:52] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 06:02:52] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 06:02:52] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 06:02:57] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0221 s/iter. Eval: 0.0599 s/iter. Total: 0.0823 s/iter. ETA=0:00:08
[11/22 06:03:02] d2.evaluation.evaluator INFO: Inference done 93/120. Dataloading: 0.0004 s/iter. Inference: 0.0213 s/iter. Eval: 0.0408 s/iter. Total: 0.0625 s/iter. ETA=0:00:01
[11/22 06:03:04] d2.evaluation.evaluator INFO: Total inference time: 0:00:07.984574 (0.069431 s / iter per device, on 1 devices)
[11/22 06:03:04] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.021380 s / iter per device, on 1 devices)
[11/22 06:03:04] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 06:03:04] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 06:03:04] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 06:03:05] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 06:03:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.05 seconds.
[11/22 06:03:05] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 06:03:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 06:03:05] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.614 | 15.875 | 5.372  | 0.043 | 14.661 | 40.430 |
[11/22 06:03:05] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 06:03:05] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 06:03:05] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 06:03:05] d2.evaluation.testing INFO: copypaste: 6.6139,15.8748,5.3720,0.0427,14.6612,40.4302
[11/22 06:03:05] d2.utils.events INFO:  eta: 0:24:33  iter: 5999  total_loss: 1.461  loss_ce: 0.383  loss_objectness: 0.626  loss_dice: 0.3762  loss_mask: 0.04159    time: 0.1644  last_time: 0.1641  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:03:08] d2.utils.events INFO:  eta: 0:24:30  iter: 6019  total_loss: 1.406  loss_ce: 0.3453  loss_objectness: 0.6317  loss_dice: 0.3565  loss_mask: 0.04271    time: 0.1644  last_time: 0.1606  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:03:11] d2.utils.events INFO:  eta: 0:24:27  iter: 6039  total_loss: 1.525  loss_ce: 0.3694  loss_objectness: 0.643  loss_dice: 0.4389  loss_mask: 0.0408    time: 0.1644  last_time: 0.1613  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-05  max_mem: 1632M
[11/22 06:03:15] d2.utils.events INFO:  eta: 0:24:23  iter: 6059  total_loss: 1.424  loss_ce: 0.3791  loss_objectness: 0.6286  loss_dice: 0.4134  loss_mask: 0.03667    time: 0.1644  last_time: 0.1595  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:03:18] d2.utils.events INFO:  eta: 0:24:20  iter: 6079  total_loss: 1.435  loss_ce: 0.3521  loss_objectness: 0.6404  loss_dice: 0.3958  loss_mask: 0.03873    time: 0.1644  last_time: 0.1658  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:03:21] d2.utils.events INFO:  eta: 0:24:17  iter: 6099  total_loss: 1.362  loss_ce: 0.3608  loss_objectness: 0.6223  loss_dice: 0.3494  loss_mask: 0.03499    time: 0.1644  last_time: 0.1640  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:03:24] d2.utils.events INFO:  eta: 0:24:13  iter: 6119  total_loss: 1.348  loss_ce: 0.3424  loss_objectness: 0.6038  loss_dice: 0.3393  loss_mask: 0.0328    time: 0.1644  last_time: 0.1598  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:03:28] d2.utils.events INFO:  eta: 0:24:09  iter: 6139  total_loss: 1.354  loss_ce: 0.364  loss_objectness: 0.6128  loss_dice: 0.3481  loss_mask: 0.03874    time: 0.1644  last_time: 0.1620  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 06:03:31] d2.utils.events INFO:  eta: 0:24:05  iter: 6159  total_loss: 1.442  loss_ce: 0.3234  loss_objectness: 0.6065  loss_dice: 0.3675  loss_mask: 0.04295    time: 0.1644  last_time: 0.1638  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:03:34] d2.utils.events INFO:  eta: 0:24:01  iter: 6179  total_loss: 1.346  loss_ce: 0.3118  loss_objectness: 0.6383  loss_dice: 0.3419  loss_mask: 0.04501    time: 0.1644  last_time: 0.1624  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:03:38] d2.utils.events INFO:  eta: 0:23:58  iter: 6199  total_loss: 1.415  loss_ce: 0.3278  loss_objectness: 0.6384  loss_dice: 0.4022  loss_mask: 0.03402    time: 0.1644  last_time: 0.1621  data_time: 0.0027  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:03:41] d2.utils.events INFO:  eta: 0:23:54  iter: 6219  total_loss: 1.481  loss_ce: 0.3542  loss_objectness: 0.6502  loss_dice: 0.404  loss_mask: 0.03695    time: 0.1644  last_time: 0.1639  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:03:44] d2.utils.events INFO:  eta: 0:23:51  iter: 6239  total_loss: 1.523  loss_ce: 0.3852  loss_objectness: 0.6542  loss_dice: 0.439  loss_mask: 0.035    time: 0.1644  last_time: 0.1652  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:03:48] d2.utils.events INFO:  eta: 0:23:48  iter: 6259  total_loss: 1.445  loss_ce: 0.3434  loss_objectness: 0.6445  loss_dice: 0.4045  loss_mask: 0.0343    time: 0.1644  last_time: 0.1622  data_time: 0.0029  last_data_time: 0.0033   lr: 5e-05  max_mem: 1632M
[11/22 06:03:51] d2.utils.events INFO:  eta: 0:23:45  iter: 6279  total_loss: 1.172  loss_ce: 0.2719  loss_objectness: 0.6172  loss_dice: 0.2974  loss_mask: 0.04541    time: 0.1644  last_time: 0.1642  data_time: 0.0026  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:03:54] d2.utils.events INFO:  eta: 0:23:42  iter: 6299  total_loss: 1.415  loss_ce: 0.3896  loss_objectness: 0.6378  loss_dice: 0.3837  loss_mask: 0.04289    time: 0.1644  last_time: 0.1671  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 06:03:57] d2.utils.events INFO:  eta: 0:23:39  iter: 6319  total_loss: 1.464  loss_ce: 0.3834  loss_objectness: 0.6548  loss_dice: 0.3706  loss_mask: 0.04651    time: 0.1644  last_time: 0.1646  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 06:04:01] d2.utils.events INFO:  eta: 0:23:36  iter: 6339  total_loss: 1.419  loss_ce: 0.3205  loss_objectness: 0.6287  loss_dice: 0.3997  loss_mask: 0.03473    time: 0.1644  last_time: 0.1640  data_time: 0.0030  last_data_time: 0.0022   lr: 5e-05  max_mem: 1632M
[11/22 06:04:04] d2.utils.events INFO:  eta: 0:23:34  iter: 6359  total_loss: 1.328  loss_ce: 0.3166  loss_objectness: 0.6304  loss_dice: 0.3387  loss_mask: 0.04552    time: 0.1644  last_time: 0.1632  data_time: 0.0030  last_data_time: 0.0034   lr: 5e-05  max_mem: 1632M
[11/22 06:04:07] d2.utils.events INFO:  eta: 0:23:30  iter: 6379  total_loss: 1.415  loss_ce: 0.3365  loss_objectness: 0.6178  loss_dice: 0.3787  loss_mask: 0.04045    time: 0.1644  last_time: 0.1648  data_time: 0.0029  last_data_time: 0.0034   lr: 5e-05  max_mem: 1632M
[11/22 06:04:11] d2.utils.events INFO:  eta: 0:23:27  iter: 6399  total_loss: 1.54  loss_ce: 0.3523  loss_objectness: 0.6367  loss_dice: 0.4465  loss_mask: 0.0404    time: 0.1644  last_time: 0.1714  data_time: 0.0030  last_data_time: 0.0029   lr: 5e-05  max_mem: 1632M
[11/22 06:04:14] d2.utils.events INFO:  eta: 0:23:24  iter: 6419  total_loss: 1.318  loss_ce: 0.3003  loss_objectness: 0.6287  loss_dice: 0.3482  loss_mask: 0.03941    time: 0.1644  last_time: 0.1668  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 06:04:17] d2.utils.events INFO:  eta: 0:23:21  iter: 6439  total_loss: 1.472  loss_ce: 0.3524  loss_objectness: 0.6478  loss_dice: 0.3978  loss_mask: 0.03784    time: 0.1644  last_time: 0.1625  data_time: 0.0034  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:04:21] d2.utils.events INFO:  eta: 0:23:18  iter: 6459  total_loss: 1.586  loss_ce: 0.3905  loss_objectness: 0.6556  loss_dice: 0.4644  loss_mask: 0.03697    time: 0.1644  last_time: 0.1671  data_time: 0.0032  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:04:24] d2.utils.events INFO:  eta: 0:23:15  iter: 6479  total_loss: 1.475  loss_ce: 0.3246  loss_objectness: 0.6308  loss_dice: 0.4169  loss_mask: 0.04418    time: 0.1644  last_time: 0.1661  data_time: 0.0027  last_data_time: 0.0021   lr: 5e-05  max_mem: 1632M
[11/22 06:04:28] d2.utils.events INFO:  eta: 0:23:12  iter: 6499  total_loss: 1.585  loss_ce: 0.4037  loss_objectness: 0.6542  loss_dice: 0.4276  loss_mask: 0.04471    time: 0.1644  last_time: 0.1638  data_time: 0.0031  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 06:04:31] d2.utils.events INFO:  eta: 0:23:08  iter: 6519  total_loss: 1.616  loss_ce: 0.4573  loss_objectness: 0.646  loss_dice: 0.4233  loss_mask: 0.05272    time: 0.1644  last_time: 0.1617  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 06:04:34] d2.utils.events INFO:  eta: 0:23:05  iter: 6539  total_loss: 1.69  loss_ce: 0.3946  loss_objectness: 0.6623  loss_dice: 0.5254  loss_mask: 0.07175    time: 0.1644  last_time: 0.1663  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-05  max_mem: 1632M
[11/22 06:04:37] d2.utils.events INFO:  eta: 0:23:02  iter: 6559  total_loss: 1.543  loss_ce: 0.372  loss_objectness: 0.652  loss_dice: 0.4649  loss_mask: 0.04491    time: 0.1644  last_time: 0.1649  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:04:41] d2.utils.events INFO:  eta: 0:22:59  iter: 6579  total_loss: 1.591  loss_ce: 0.3718  loss_objectness: 0.667  loss_dice: 0.4566  loss_mask: 0.04761    time: 0.1645  last_time: 0.1738  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:04:44] d2.utils.events INFO:  eta: 0:22:57  iter: 6599  total_loss: 1.61  loss_ce: 0.3956  loss_objectness: 0.6546  loss_dice: 0.4766  loss_mask: 0.0642    time: 0.1645  last_time: 0.1687  data_time: 0.0030  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:04:48] d2.utils.events INFO:  eta: 0:22:54  iter: 6619  total_loss: 1.45  loss_ce: 0.3389  loss_objectness: 0.6568  loss_dice: 0.396  loss_mask: 0.04413    time: 0.1645  last_time: 0.1649  data_time: 0.0031  last_data_time: 0.0037   lr: 5e-05  max_mem: 1632M
[11/22 06:04:51] d2.utils.events INFO:  eta: 0:22:51  iter: 6639  total_loss: 1.474  loss_ce: 0.3964  loss_objectness: 0.6361  loss_dice: 0.3912  loss_mask: 0.04245    time: 0.1645  last_time: 0.1636  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:04:54] d2.utils.events INFO:  eta: 0:22:48  iter: 6659  total_loss: 1.337  loss_ce: 0.2903  loss_objectness: 0.6267  loss_dice: 0.3154  loss_mask: 0.03761    time: 0.1645  last_time: 0.1637  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 06:04:58] d2.utils.events INFO:  eta: 0:22:45  iter: 6679  total_loss: 1.302  loss_ce: 0.2962  loss_objectness: 0.6088  loss_dice: 0.3063  loss_mask: 0.04142    time: 0.1645  last_time: 0.1635  data_time: 0.0030  last_data_time: 0.0037   lr: 5e-05  max_mem: 1632M
[11/22 06:05:01] d2.utils.events INFO:  eta: 0:22:42  iter: 6699  total_loss: 1.32  loss_ce: 0.3001  loss_objectness: 0.6416  loss_dice: 0.344  loss_mask: 0.03275    time: 0.1645  last_time: 0.1629  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:05:04] d2.utils.events INFO:  eta: 0:22:39  iter: 6719  total_loss: 1.254  loss_ce: 0.2689  loss_objectness: 0.6119  loss_dice: 0.3016  loss_mask: 0.04206    time: 0.1645  last_time: 0.1630  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:05:08] d2.utils.events INFO:  eta: 0:22:36  iter: 6739  total_loss: 1.552  loss_ce: 0.366  loss_objectness: 0.6431  loss_dice: 0.4536  loss_mask: 0.04088    time: 0.1645  last_time: 0.1669  data_time: 0.0030  last_data_time: 0.0034   lr: 5e-05  max_mem: 1632M
[11/22 06:05:11] d2.utils.events INFO:  eta: 0:22:32  iter: 6759  total_loss: 1.343  loss_ce: 0.2762  loss_objectness: 0.6429  loss_dice: 0.3793  loss_mask: 0.04849    time: 0.1645  last_time: 0.1609  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-05  max_mem: 1632M
[11/22 06:05:14] d2.utils.events INFO:  eta: 0:22:29  iter: 6779  total_loss: 1.323  loss_ce: 0.3094  loss_objectness: 0.6318  loss_dice: 0.3246  loss_mask: 0.03893    time: 0.1645  last_time: 0.1631  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:05:17] d2.utils.events INFO:  eta: 0:22:26  iter: 6799  total_loss: 1.248  loss_ce: 0.2904  loss_objectness: 0.6267  loss_dice: 0.2893  loss_mask: 0.03869    time: 0.1645  last_time: 0.1639  data_time: 0.0029  last_data_time: 0.0039   lr: 5e-05  max_mem: 1632M
[11/22 06:05:21] d2.utils.events INFO:  eta: 0:22:22  iter: 6819  total_loss: 1.25  loss_ce: 0.291  loss_objectness: 0.6211  loss_dice: 0.3044  loss_mask: 0.04502    time: 0.1645  last_time: 0.1621  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:05:24] d2.utils.events INFO:  eta: 0:22:19  iter: 6839  total_loss: 1.418  loss_ce: 0.352  loss_objectness: 0.6326  loss_dice: 0.3683  loss_mask: 0.03566    time: 0.1645  last_time: 0.1651  data_time: 0.0028  last_data_time: 0.0033   lr: 5e-05  max_mem: 1632M
[11/22 06:05:27] d2.utils.events INFO:  eta: 0:22:16  iter: 6859  total_loss: 1.254  loss_ce: 0.2914  loss_objectness: 0.6135  loss_dice: 0.2964  loss_mask: 0.03428    time: 0.1645  last_time: 0.1629  data_time: 0.0027  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:05:31] d2.utils.events INFO:  eta: 0:22:13  iter: 6879  total_loss: 1.342  loss_ce: 0.3272  loss_objectness: 0.6237  loss_dice: 0.3102  loss_mask: 0.03577    time: 0.1645  last_time: 0.1651  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:05:34] d2.utils.events INFO:  eta: 0:22:10  iter: 6899  total_loss: 1.37  loss_ce: 0.3434  loss_objectness: 0.6379  loss_dice: 0.3218  loss_mask: 0.0396    time: 0.1645  last_time: 0.1612  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1632M
[11/22 06:05:37] d2.utils.events INFO:  eta: 0:22:06  iter: 6919  total_loss: 1.484  loss_ce: 0.338  loss_objectness: 0.6526  loss_dice: 0.3873  loss_mask: 0.04843    time: 0.1645  last_time: 0.1689  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:05:40] d2.utils.events INFO:  eta: 0:22:03  iter: 6939  total_loss: 1.498  loss_ce: 0.4103  loss_objectness: 0.6316  loss_dice: 0.4057  loss_mask: 0.03786    time: 0.1645  last_time: 0.1689  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1632M
[11/22 06:05:44] d2.utils.events INFO:  eta: 0:22:00  iter: 6959  total_loss: 1.439  loss_ce: 0.3509  loss_objectness: 0.6408  loss_dice: 0.3796  loss_mask: 0.04607    time: 0.1645  last_time: 0.1618  data_time: 0.0030  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:05:47] d2.utils.events INFO:  eta: 0:21:56  iter: 6979  total_loss: 1.361  loss_ce: 0.2814  loss_objectness: 0.6294  loss_dice: 0.3567  loss_mask: 0.03751    time: 0.1645  last_time: 0.1627  data_time: 0.0027  last_data_time: 0.0040   lr: 5e-05  max_mem: 1632M
[11/22 06:05:50] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 06:05:50] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 06:05:50] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 06:05:50] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 06:05:50] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 06:05:50] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 06:05:55] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0408 s/iter. Eval: 0.0416 s/iter. Total: 0.0827 s/iter. ETA=0:00:09
[11/22 06:06:01] d2.evaluation.evaluator INFO: Inference done 90/120. Dataloading: 0.0004 s/iter. Inference: 0.0254 s/iter. Eval: 0.0409 s/iter. Total: 0.0667 s/iter. ETA=0:00:02
[11/22 06:06:03] d2.evaluation.evaluator INFO: Total inference time: 0:00:08.441481 (0.073404 s / iter per device, on 1 devices)
[11/22 06:06:03] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.024947 s / iter per device, on 1 devices)
[11/22 06:06:03] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 06:06:03] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 06:06:03] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 06:06:03] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 06:06:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.06 seconds.
[11/22 06:06:04] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 06:06:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 06:06:04] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.506 | 16.580 | 5.180  | 0.104 | 14.163 | 40.774 |
[11/22 06:06:04] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 06:06:04] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 06:06:04] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 06:06:04] d2.evaluation.testing INFO: copypaste: 6.5061,16.5799,5.1796,0.1040,14.1633,40.7736
[11/22 06:06:04] d2.utils.events INFO:  eta: 0:21:53  iter: 6999  total_loss: 1.333  loss_ce: 0.2959  loss_objectness: 0.6278  loss_dice: 0.3522  loss_mask: 0.03505    time: 0.1645  last_time: 0.1646  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:06:07] d2.utils.events INFO:  eta: 0:21:49  iter: 7019  total_loss: 1.41  loss_ce: 0.3463  loss_objectness: 0.6497  loss_dice: 0.3645  loss_mask: 0.0337    time: 0.1645  last_time: 0.1602  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:06:10] d2.utils.events INFO:  eta: 0:21:46  iter: 7039  total_loss: 1.334  loss_ce: 0.3034  loss_objectness: 0.6149  loss_dice: 0.3376  loss_mask: 0.04642    time: 0.1645  last_time: 0.1640  data_time: 0.0027  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:06:14] d2.utils.events INFO:  eta: 0:21:43  iter: 7059  total_loss: 1.336  loss_ce: 0.2844  loss_objectness: 0.6173  loss_dice: 0.3426  loss_mask: 0.03998    time: 0.1645  last_time: 0.1653  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 06:06:17] d2.utils.events INFO:  eta: 0:21:40  iter: 7079  total_loss: 1.407  loss_ce: 0.3028  loss_objectness: 0.6325  loss_dice: 0.3846  loss_mask: 0.0459    time: 0.1645  last_time: 0.1646  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1632M
[11/22 06:06:20] d2.utils.events INFO:  eta: 0:21:36  iter: 7099  total_loss: 1.372  loss_ce: 0.2764  loss_objectness: 0.6391  loss_dice: 0.3805  loss_mask: 0.05269    time: 0.1645  last_time: 0.1649  data_time: 0.0029  last_data_time: 0.0041   lr: 5e-05  max_mem: 1632M
[11/22 06:06:23] d2.utils.events INFO:  eta: 0:21:33  iter: 7119  total_loss: 1.539  loss_ce: 0.3683  loss_objectness: 0.6478  loss_dice: 0.4719  loss_mask: 0.04454    time: 0.1645  last_time: 0.1651  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:06:27] d2.utils.events INFO:  eta: 0:21:30  iter: 7139  total_loss: 1.44  loss_ce: 0.3347  loss_objectness: 0.6492  loss_dice: 0.3702  loss_mask: 0.03872    time: 0.1645  last_time: 0.1613  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:06:30] d2.utils.events INFO:  eta: 0:21:27  iter: 7159  total_loss: 1.344  loss_ce: 0.329  loss_objectness: 0.6297  loss_dice: 0.3583  loss_mask: 0.04385    time: 0.1645  last_time: 0.1670  data_time: 0.0028  last_data_time: 0.0032   lr: 5e-05  max_mem: 1632M
[11/22 06:06:33] d2.utils.events INFO:  eta: 0:21:24  iter: 7179  total_loss: 1.423  loss_ce: 0.3451  loss_objectness: 0.6285  loss_dice: 0.3638  loss_mask: 0.04475    time: 0.1645  last_time: 0.1676  data_time: 0.0029  last_data_time: 0.0034   lr: 5e-05  max_mem: 1632M
[11/22 06:06:37] d2.utils.events INFO:  eta: 0:21:21  iter: 7199  total_loss: 1.281  loss_ce: 0.2467  loss_objectness: 0.6174  loss_dice: 0.3316  loss_mask: 0.04549    time: 0.1645  last_time: 0.1692  data_time: 0.0032  last_data_time: 0.0037   lr: 5e-05  max_mem: 1632M
[11/22 06:06:40] d2.utils.events INFO:  eta: 0:21:18  iter: 7219  total_loss: 1.405  loss_ce: 0.3252  loss_objectness: 0.6392  loss_dice: 0.3131  loss_mask: 0.04716    time: 0.1645  last_time: 0.1708  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:06:43] d2.utils.events INFO:  eta: 0:21:15  iter: 7239  total_loss: 1.41  loss_ce: 0.3623  loss_objectness: 0.6414  loss_dice: 0.4106  loss_mask: 0.04357    time: 0.1645  last_time: 0.1618  data_time: 0.0029  last_data_time: 0.0034   lr: 5e-05  max_mem: 1632M
[11/22 06:06:47] d2.utils.events INFO:  eta: 0:21:11  iter: 7259  total_loss: 1.424  loss_ce: 0.3164  loss_objectness: 0.632  loss_dice: 0.3867  loss_mask: 0.04634    time: 0.1645  last_time: 0.1612  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 06:06:50] d2.utils.events INFO:  eta: 0:21:08  iter: 7279  total_loss: 1.26  loss_ce: 0.2734  loss_objectness: 0.6045  loss_dice: 0.3222  loss_mask: 0.05372    time: 0.1645  last_time: 0.1621  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:06:53] d2.utils.events INFO:  eta: 0:21:05  iter: 7299  total_loss: 1.395  loss_ce: 0.3203  loss_objectness: 0.6641  loss_dice: 0.3858  loss_mask: 0.04355    time: 0.1645  last_time: 0.1655  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:06:56] d2.utils.events INFO:  eta: 0:21:01  iter: 7319  total_loss: 1.382  loss_ce: 0.311  loss_objectness: 0.6312  loss_dice: 0.371  loss_mask: 0.03893    time: 0.1645  last_time: 0.1613  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:07:00] d2.utils.events INFO:  eta: 0:20:58  iter: 7339  total_loss: 1.379  loss_ce: 0.3033  loss_objectness: 0.6536  loss_dice: 0.389  loss_mask: 0.03452    time: 0.1645  last_time: 0.1647  data_time: 0.0029  last_data_time: 0.0041   lr: 5e-05  max_mem: 1632M
[11/22 06:07:03] d2.utils.events INFO:  eta: 0:20:54  iter: 7359  total_loss: 1.361  loss_ce: 0.3224  loss_objectness: 0.6155  loss_dice: 0.3738  loss_mask: 0.03427    time: 0.1645  last_time: 0.1644  data_time: 0.0028  last_data_time: 0.0032   lr: 5e-05  max_mem: 1632M
[11/22 06:07:06] d2.utils.events INFO:  eta: 0:20:51  iter: 7379  total_loss: 1.28  loss_ce: 0.3119  loss_objectness: 0.6348  loss_dice: 0.3161  loss_mask: 0.03729    time: 0.1645  last_time: 0.1598  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:07:10] d2.utils.events INFO:  eta: 0:20:47  iter: 7399  total_loss: 1.374  loss_ce: 0.3456  loss_objectness: 0.6353  loss_dice: 0.3562  loss_mask: 0.04015    time: 0.1645  last_time: 0.1605  data_time: 0.0031  last_data_time: 0.0036   lr: 5e-05  max_mem: 1632M
[11/22 06:07:13] d2.utils.events INFO:  eta: 0:20:44  iter: 7419  total_loss: 1.164  loss_ce: 0.2416  loss_objectness: 0.6102  loss_dice: 0.2741  loss_mask: 0.04401    time: 0.1645  last_time: 0.1664  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:07:16] d2.utils.events INFO:  eta: 0:20:40  iter: 7439  total_loss: 1.274  loss_ce: 0.2753  loss_objectness: 0.6072  loss_dice: 0.3205  loss_mask: 0.03547    time: 0.1645  last_time: 0.1660  data_time: 0.0028  last_data_time: 0.0036   lr: 5e-05  max_mem: 1632M
[11/22 06:07:19] d2.utils.events INFO:  eta: 0:20:37  iter: 7459  total_loss: 1.378  loss_ce: 0.2978  loss_objectness: 0.6238  loss_dice: 0.3752  loss_mask: 0.03628    time: 0.1645  last_time: 0.1600  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:07:23] d2.utils.events INFO:  eta: 0:20:33  iter: 7479  total_loss: 1.206  loss_ce: 0.2415  loss_objectness: 0.5931  loss_dice: 0.3011  loss_mask: 0.03606    time: 0.1645  last_time: 0.1612  data_time: 0.0027  last_data_time: 0.0022   lr: 5e-05  max_mem: 1632M
[11/22 06:07:26] d2.utils.events INFO:  eta: 0:20:30  iter: 7499  total_loss: 1.172  loss_ce: 0.2325  loss_objectness: 0.6263  loss_dice: 0.3048  loss_mask: 0.03325    time: 0.1645  last_time: 0.1586  data_time: 0.0037  last_data_time: 0.0022   lr: 5e-05  max_mem: 1632M
[11/22 06:07:29] d2.utils.events INFO:  eta: 0:20:27  iter: 7519  total_loss: 1.325  loss_ce: 0.2881  loss_objectness: 0.624  loss_dice: 0.3352  loss_mask: 0.03239    time: 0.1645  last_time: 0.1643  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:07:33] d2.utils.events INFO:  eta: 0:20:23  iter: 7539  total_loss: 1.193  loss_ce: 0.2845  loss_objectness: 0.6089  loss_dice: 0.3127  loss_mask: 0.03464    time: 0.1645  last_time: 0.1621  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:07:36] d2.utils.events INFO:  eta: 0:20:20  iter: 7559  total_loss: 1.203  loss_ce: 0.2682  loss_objectness: 0.6036  loss_dice: 0.3002  loss_mask: 0.0395    time: 0.1645  last_time: 0.1627  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:07:39] d2.utils.events INFO:  eta: 0:20:16  iter: 7579  total_loss: 1.312  loss_ce: 0.2892  loss_objectness: 0.6331  loss_dice: 0.291  loss_mask: 0.03108    time: 0.1645  last_time: 0.1632  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 06:07:42] d2.utils.events INFO:  eta: 0:20:12  iter: 7599  total_loss: 1.146  loss_ce: 0.2417  loss_objectness: 0.5962  loss_dice: 0.2703  loss_mask: 0.03009    time: 0.1645  last_time: 0.1597  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:07:46] d2.utils.events INFO:  eta: 0:20:09  iter: 7619  total_loss: 1.098  loss_ce: 0.2079  loss_objectness: 0.5847  loss_dice: 0.2703  loss_mask: 0.03022    time: 0.1645  last_time: 0.1614  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 06:07:49] d2.utils.events INFO:  eta: 0:20:05  iter: 7639  total_loss: 1.254  loss_ce: 0.2834  loss_objectness: 0.6252  loss_dice: 0.3586  loss_mask: 0.03404    time: 0.1645  last_time: 0.1634  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:07:52] d2.utils.events INFO:  eta: 0:20:01  iter: 7659  total_loss: 1.224  loss_ce: 0.2218  loss_objectness: 0.627  loss_dice: 0.3175  loss_mask: 0.03718    time: 0.1645  last_time: 0.1612  data_time: 0.0029  last_data_time: 0.0039   lr: 5e-05  max_mem: 1632M
[11/22 06:07:56] d2.utils.events INFO:  eta: 0:19:58  iter: 7679  total_loss: 1.401  loss_ce: 0.3087  loss_objectness: 0.6396  loss_dice: 0.397  loss_mask: 0.04051    time: 0.1645  last_time: 0.1643  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 06:07:59] d2.utils.events INFO:  eta: 0:19:54  iter: 7699  total_loss: 1.321  loss_ce: 0.2924  loss_objectness: 0.6193  loss_dice: 0.3336  loss_mask: 0.03632    time: 0.1644  last_time: 0.1655  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:08:02] d2.utils.events INFO:  eta: 0:19:51  iter: 7719  total_loss: 1.335  loss_ce: 0.2828  loss_objectness: 0.6433  loss_dice: 0.3679  loss_mask: 0.04552    time: 0.1645  last_time: 0.1644  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1632M
[11/22 06:08:05] d2.utils.events INFO:  eta: 0:19:48  iter: 7739  total_loss: 1.227  loss_ce: 0.2479  loss_objectness: 0.6091  loss_dice: 0.3175  loss_mask: 0.03908    time: 0.1645  last_time: 0.1646  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:08:09] d2.utils.events INFO:  eta: 0:19:45  iter: 7759  total_loss: 1.152  loss_ce: 0.2014  loss_objectness: 0.5924  loss_dice: 0.271  loss_mask: 0.04309    time: 0.1645  last_time: 0.1715  data_time: 0.0030  last_data_time: 0.0029   lr: 5e-05  max_mem: 1632M
[11/22 06:08:12] d2.utils.events INFO:  eta: 0:19:42  iter: 7779  total_loss: 1.305  loss_ce: 0.2725  loss_objectness: 0.6433  loss_dice: 0.3553  loss_mask: 0.03173    time: 0.1645  last_time: 0.1740  data_time: 0.0031  last_data_time: 0.0029   lr: 5e-05  max_mem: 1632M
[11/22 06:08:16] d2.utils.events INFO:  eta: 0:19:39  iter: 7799  total_loss: 1.243  loss_ce: 0.2289  loss_objectness: 0.6175  loss_dice: 0.3565  loss_mask: 0.03881    time: 0.1645  last_time: 0.1709  data_time: 0.0032  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 06:08:19] d2.utils.events INFO:  eta: 0:19:36  iter: 7819  total_loss: 1.384  loss_ce: 0.277  loss_objectness: 0.6248  loss_dice: 0.3519  loss_mask: 0.03916    time: 0.1645  last_time: 0.1699  data_time: 0.0031  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:08:23] d2.utils.events INFO:  eta: 0:19:33  iter: 7839  total_loss: 1.38  loss_ce: 0.3027  loss_objectness: 0.6221  loss_dice: 0.3725  loss_mask: 0.04105    time: 0.1646  last_time: 0.1703  data_time: 0.0033  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:08:26] d2.utils.events INFO:  eta: 0:19:30  iter: 7859  total_loss: 1.26  loss_ce: 0.2591  loss_objectness: 0.6011  loss_dice: 0.2937  loss_mask: 0.03523    time: 0.1646  last_time: 0.1666  data_time: 0.0033  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 06:08:30] d2.utils.events INFO:  eta: 0:19:27  iter: 7879  total_loss: 1.276  loss_ce: 0.2346  loss_objectness: 0.6334  loss_dice: 0.3624  loss_mask: 0.04079    time: 0.1646  last_time: 0.1646  data_time: 0.0031  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:08:33] d2.utils.events INFO:  eta: 0:19:24  iter: 7899  total_loss: 1.366  loss_ce: 0.3129  loss_objectness: 0.6133  loss_dice: 0.3539  loss_mask: 0.05088    time: 0.1646  last_time: 0.1663  data_time: 0.0039  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:08:37] d2.utils.events INFO:  eta: 0:19:21  iter: 7919  total_loss: 1.311  loss_ce: 0.3139  loss_objectness: 0.6316  loss_dice: 0.3444  loss_mask: 0.03125    time: 0.1646  last_time: 0.1650  data_time: 0.0034  last_data_time: 0.0037   lr: 5e-05  max_mem: 1632M
[11/22 06:08:40] d2.utils.events INFO:  eta: 0:19:18  iter: 7939  total_loss: 1.232  loss_ce: 0.2236  loss_objectness: 0.5956  loss_dice: 0.3305  loss_mask: 0.05018    time: 0.1646  last_time: 0.1667  data_time: 0.0031  last_data_time: 0.0035   lr: 5e-05  max_mem: 1632M
[11/22 06:08:43] d2.utils.events INFO:  eta: 0:19:16  iter: 7959  total_loss: 1.297  loss_ce: 0.2719  loss_objectness: 0.6326  loss_dice: 0.3521  loss_mask: 0.03633    time: 0.1647  last_time: 0.1632  data_time: 0.0031  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 06:08:47] d2.utils.events INFO:  eta: 0:19:13  iter: 7979  total_loss: 1.216  loss_ce: 0.2446  loss_objectness: 0.6169  loss_dice: 0.284  loss_mask: 0.03761    time: 0.1647  last_time: 0.1851  data_time: 0.0031  last_data_time: 0.0041   lr: 5e-05  max_mem: 1632M
[11/22 06:08:50] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 06:08:50] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 06:08:50] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 06:08:50] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 06:08:50] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 06:08:50] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 06:08:56] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0404 s/iter. Eval: 0.0474 s/iter. Total: 0.0882 s/iter. ETA=0:00:09
[11/22 06:09:01] d2.evaluation.evaluator INFO: Inference done 75/120. Dataloading: 0.0005 s/iter. Inference: 0.0290 s/iter. Eval: 0.0505 s/iter. Total: 0.0800 s/iter. ETA=0:00:03
[11/22 06:09:06] d2.evaluation.evaluator INFO: Total inference time: 0:00:10.055981 (0.087443 s / iter per device, on 1 devices)
[11/22 06:09:06] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:03 (0.028562 s / iter per device, on 1 devices)
[11/22 06:09:06] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 06:09:06] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 06:09:06] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 06:09:06] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 06:09:06] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.06 seconds.
[11/22 06:09:06] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 06:09:06] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 06:09:06] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.839 | 15.253 | 5.211  | 0.134 | 14.707 | 42.891 |
[11/22 06:09:06] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 06:09:06] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 06:09:06] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 06:09:06] d2.evaluation.testing INFO: copypaste: 6.8387,15.2532,5.2114,0.1341,14.7071,42.8912
[11/22 06:09:06] d2.utils.events INFO:  eta: 0:19:10  iter: 7999  total_loss: 1.232  loss_ce: 0.2568  loss_objectness: 0.6306  loss_dice: 0.313  loss_mask: 0.03338    time: 0.1647  last_time: 0.1768  data_time: 0.0040  last_data_time: 0.0075   lr: 5e-05  max_mem: 1632M
[11/22 06:09:10] d2.utils.events INFO:  eta: 0:19:07  iter: 8019  total_loss: 1.277  loss_ce: 0.2788  loss_objectness: 0.6369  loss_dice: 0.3308  loss_mask: 0.03247    time: 0.1647  last_time: 0.1711  data_time: 0.0034  last_data_time: 0.0035   lr: 5e-05  max_mem: 1632M
[11/22 06:09:13] d2.utils.events INFO:  eta: 0:19:05  iter: 8039  total_loss: 1.175  loss_ce: 0.2297  loss_objectness: 0.6185  loss_dice: 0.3014  loss_mask: 0.03493    time: 0.1647  last_time: 0.1945  data_time: 0.0043  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:09:17] d2.utils.events INFO:  eta: 0:19:02  iter: 8059  total_loss: 1.151  loss_ce: 0.2076  loss_objectness: 0.6035  loss_dice: 0.2822  loss_mask: 0.04694    time: 0.1648  last_time: 0.1755  data_time: 0.0032  last_data_time: 0.0029   lr: 5e-05  max_mem: 1632M
[11/22 06:09:20] d2.utils.events INFO:  eta: 0:19:00  iter: 8079  total_loss: 1.289  loss_ce: 0.2657  loss_objectness: 0.6332  loss_dice: 0.3389  loss_mask: 0.03225    time: 0.1648  last_time: 0.1707  data_time: 0.0043  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 06:09:24] d2.utils.events INFO:  eta: 0:18:59  iter: 8099  total_loss: 1.351  loss_ce: 0.2939  loss_objectness: 0.6193  loss_dice: 0.3765  loss_mask: 0.03618    time: 0.1648  last_time: 0.1943  data_time: 0.0047  last_data_time: 0.0250   lr: 5e-05  max_mem: 1632M
[11/22 06:09:27] d2.utils.events INFO:  eta: 0:18:56  iter: 8119  total_loss: 1.307  loss_ce: 0.2695  loss_objectness: 0.6261  loss_dice: 0.345  loss_mask: 0.03621    time: 0.1648  last_time: 0.1658  data_time: 0.0043  last_data_time: 0.0039   lr: 5e-05  max_mem: 1632M
[11/22 06:09:31] d2.utils.events INFO:  eta: 0:18:53  iter: 8139  total_loss: 1.129  loss_ce: 0.2099  loss_objectness: 0.5897  loss_dice: 0.2618  loss_mask: 0.03492    time: 0.1649  last_time: 0.1622  data_time: 0.0032  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:09:34] d2.utils.events INFO:  eta: 0:18:51  iter: 8159  total_loss: 1.22  loss_ce: 0.2173  loss_objectness: 0.6096  loss_dice: 0.3305  loss_mask: 0.04096    time: 0.1649  last_time: 0.1652  data_time: 0.0030  last_data_time: 0.0041   lr: 5e-05  max_mem: 1632M
[11/22 06:09:37] d2.utils.events INFO:  eta: 0:18:47  iter: 8179  total_loss: 1.253  loss_ce: 0.2598  loss_objectness: 0.6271  loss_dice: 0.3183  loss_mask: 0.02995    time: 0.1649  last_time: 0.1636  data_time: 0.0031  last_data_time: 0.0029   lr: 5e-05  max_mem: 1632M
[11/22 06:09:41] d2.utils.events INFO:  eta: 0:18:43  iter: 8199  total_loss: 1.231  loss_ce: 0.2544  loss_objectness: 0.6224  loss_dice: 0.3118  loss_mask: 0.02842    time: 0.1649  last_time: 0.1672  data_time: 0.0031  last_data_time: 0.0032   lr: 5e-05  max_mem: 1632M
[11/22 06:09:44] d2.utils.events INFO:  eta: 0:18:40  iter: 8219  total_loss: 1.066  loss_ce: 0.2031  loss_objectness: 0.5981  loss_dice: 0.2734  loss_mask: 0.03569    time: 0.1649  last_time: 0.1663  data_time: 0.0030  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:09:48] d2.utils.events INFO:  eta: 0:18:37  iter: 8239  total_loss: 1.181  loss_ce: 0.1909  loss_objectness: 0.626  loss_dice: 0.317  loss_mask: 0.0352    time: 0.1649  last_time: 0.1649  data_time: 0.0031  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:09:51] d2.utils.events INFO:  eta: 0:18:35  iter: 8259  total_loss: 1.259  loss_ce: 0.2486  loss_objectness: 0.6136  loss_dice: 0.328  loss_mask: 0.02919    time: 0.1649  last_time: 0.1715  data_time: 0.0030  last_data_time: 0.0033   lr: 5e-05  max_mem: 1632M
[11/22 06:09:54] d2.utils.events INFO:  eta: 0:18:32  iter: 8279  total_loss: 1.125  loss_ce: 0.181  loss_objectness: 0.6071  loss_dice: 0.2922  loss_mask: 0.03054    time: 0.1649  last_time: 0.1675  data_time: 0.0035  last_data_time: 0.0029   lr: 5e-05  max_mem: 1632M
[11/22 06:09:58] d2.utils.events INFO:  eta: 0:18:30  iter: 8299  total_loss: 1.075  loss_ce: 0.1671  loss_objectness: 0.5909  loss_dice: 0.2695  loss_mask: 0.03575    time: 0.1649  last_time: 0.1639  data_time: 0.0031  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:10:01] d2.utils.events INFO:  eta: 0:18:27  iter: 8319  total_loss: 1.101  loss_ce: 0.2473  loss_objectness: 0.5966  loss_dice: 0.2575  loss_mask: 0.03153    time: 0.1649  last_time: 0.1698  data_time: 0.0033  last_data_time: 0.0038   lr: 5e-05  max_mem: 1632M
[11/22 06:10:05] d2.utils.events INFO:  eta: 0:18:25  iter: 8339  total_loss: 1.089  loss_ce: 0.2118  loss_objectness: 0.5865  loss_dice: 0.2633  loss_mask: 0.03597    time: 0.1649  last_time: 0.1627  data_time: 0.0031  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:10:08] d2.utils.events INFO:  eta: 0:18:22  iter: 8359  total_loss: 1.383  loss_ce: 0.3107  loss_objectness: 0.6322  loss_dice: 0.3637  loss_mask: 0.03784    time: 0.1649  last_time: 0.1642  data_time: 0.0031  last_data_time: 0.0035   lr: 5e-05  max_mem: 1632M
[11/22 06:10:11] d2.utils.events INFO:  eta: 0:18:20  iter: 8379  total_loss: 1.33  loss_ce: 0.2594  loss_objectness: 0.6395  loss_dice: 0.385  loss_mask: 0.03757    time: 0.1650  last_time: 0.1685  data_time: 0.0035  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 06:10:15] d2.utils.events INFO:  eta: 0:18:18  iter: 8399  total_loss: 1.123  loss_ce: 0.1845  loss_objectness: 0.5919  loss_dice: 0.2711  loss_mask: 0.04213    time: 0.1650  last_time: 0.1725  data_time: 0.0037  last_data_time: 0.0029   lr: 5e-05  max_mem: 1632M
[11/22 06:10:18] d2.utils.events INFO:  eta: 0:18:15  iter: 8419  total_loss: 0.9918  loss_ce: 0.1391  loss_objectness: 0.562  loss_dice: 0.2339  loss_mask: 0.04104    time: 0.1650  last_time: 0.1696  data_time: 0.0030  last_data_time: 0.0029   lr: 5e-05  max_mem: 1632M
[11/22 06:10:22] d2.utils.events INFO:  eta: 0:18:13  iter: 8439  total_loss: 1.126  loss_ce: 0.1929  loss_objectness: 0.6019  loss_dice: 0.2781  loss_mask: 0.03508    time: 0.1650  last_time: 0.1666  data_time: 0.0038  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:10:25] d2.utils.events INFO:  eta: 0:18:11  iter: 8459  total_loss: 1.252  loss_ce: 0.2157  loss_objectness: 0.6153  loss_dice: 0.3381  loss_mask: 0.03779    time: 0.1650  last_time: 0.1877  data_time: 0.0040  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:10:29] d2.utils.events INFO:  eta: 0:18:09  iter: 8479  total_loss: 1.144  loss_ce: 0.2152  loss_objectness: 0.6158  loss_dice: 0.2999  loss_mask: 0.0265    time: 0.1650  last_time: 0.1684  data_time: 0.0041  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 06:10:32] d2.utils.events INFO:  eta: 0:18:07  iter: 8499  total_loss: 1.302  loss_ce: 0.2663  loss_objectness: 0.6146  loss_dice: 0.3341  loss_mask: 0.02894    time: 0.1651  last_time: 0.1698  data_time: 0.0037  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:10:36] d2.utils.events INFO:  eta: 0:18:05  iter: 8519  total_loss: 1.031  loss_ce: 0.1788  loss_objectness: 0.5658  loss_dice: 0.2468  loss_mask: 0.02907    time: 0.1651  last_time: 0.1631  data_time: 0.0033  last_data_time: 0.0041   lr: 5e-05  max_mem: 1632M
[11/22 06:10:39] d2.utils.events INFO:  eta: 0:18:01  iter: 8539  total_loss: 1.037  loss_ce: 0.1818  loss_objectness: 0.5887  loss_dice: 0.2455  loss_mask: 0.03813    time: 0.1651  last_time: 0.1678  data_time: 0.0028  last_data_time: 0.0032   lr: 5e-05  max_mem: 1632M
[11/22 06:10:42] d2.utils.events INFO:  eta: 0:17:58  iter: 8559  total_loss: 1.149  loss_ce: 0.1985  loss_objectness: 0.6111  loss_dice: 0.2785  loss_mask: 0.02846    time: 0.1651  last_time: 0.1700  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:10:45] d2.utils.events INFO:  eta: 0:17:55  iter: 8579  total_loss: 1.068  loss_ce: 0.1802  loss_objectness: 0.5947  loss_dice: 0.2543  loss_mask: 0.03204    time: 0.1651  last_time: 0.1603  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1632M
[11/22 06:10:49] d2.utils.events INFO:  eta: 0:17:52  iter: 8599  total_loss: 1.095  loss_ce: 0.1709  loss_objectness: 0.577  loss_dice: 0.2702  loss_mask: 0.03539    time: 0.1651  last_time: 0.1622  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:10:52] d2.utils.events INFO:  eta: 0:17:48  iter: 8619  total_loss: 1.176  loss_ce: 0.2037  loss_objectness: 0.6096  loss_dice: 0.2544  loss_mask: 0.03399    time: 0.1651  last_time: 0.1609  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 06:10:55] d2.utils.events INFO:  eta: 0:17:45  iter: 8639  total_loss: 1.143  loss_ce: 0.1893  loss_objectness: 0.5859  loss_dice: 0.2989  loss_mask: 0.03989    time: 0.1651  last_time: 0.1654  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 06:10:59] d2.utils.events INFO:  eta: 0:17:42  iter: 8659  total_loss: 1.204  loss_ce: 0.2115  loss_objectness: 0.6269  loss_dice: 0.2918  loss_mask: 0.03151    time: 0.1651  last_time: 0.1622  data_time: 0.0029  last_data_time: 0.0022   lr: 5e-05  max_mem: 1632M
[11/22 06:11:02] d2.utils.events INFO:  eta: 0:17:39  iter: 8679  total_loss: 1.044  loss_ce: 0.1576  loss_objectness: 0.5988  loss_dice: 0.256  loss_mask: 0.02554    time: 0.1651  last_time: 0.1671  data_time: 0.0029  last_data_time: 0.0038   lr: 5e-05  max_mem: 1632M
[11/22 06:11:05] d2.utils.events INFO:  eta: 0:17:35  iter: 8699  total_loss: 1.156  loss_ce: 0.2122  loss_objectness: 0.6149  loss_dice: 0.2959  loss_mask: 0.02814    time: 0.1651  last_time: 0.1630  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:11:09] d2.utils.events INFO:  eta: 0:17:32  iter: 8719  total_loss: 1.182  loss_ce: 0.2477  loss_objectness: 0.6039  loss_dice: 0.2632  loss_mask: 0.03223    time: 0.1651  last_time: 0.1635  data_time: 0.0031  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:11:12] d2.utils.events INFO:  eta: 0:17:30  iter: 8739  total_loss: 1.016  loss_ce: 0.1708  loss_objectness: 0.5743  loss_dice: 0.2571  loss_mask: 0.02711    time: 0.1651  last_time: 0.1619  data_time: 0.0033  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:11:15] d2.utils.events INFO:  eta: 0:17:25  iter: 8759  total_loss: 1.083  loss_ce: 0.1801  loss_objectness: 0.594  loss_dice: 0.2633  loss_mask: 0.03342    time: 0.1651  last_time: 0.1652  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 06:11:19] d2.utils.events INFO:  eta: 0:17:20  iter: 8779  total_loss: 0.9647  loss_ce: 0.1309  loss_objectness: 0.5696  loss_dice: 0.2317  loss_mask: 0.03304    time: 0.1651  last_time: 0.1692  data_time: 0.0028  last_data_time: 0.0021   lr: 5e-05  max_mem: 1632M
[11/22 06:11:22] d2.utils.events INFO:  eta: 0:17:16  iter: 8799  total_loss: 1.104  loss_ce: 0.199  loss_objectness: 0.5946  loss_dice: 0.2898  loss_mask: 0.03009    time: 0.1651  last_time: 0.1657  data_time: 0.0031  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:11:25] d2.utils.events INFO:  eta: 0:17:12  iter: 8819  total_loss: 1.077  loss_ce: 0.1632  loss_objectness: 0.5967  loss_dice: 0.2731  loss_mask: 0.03185    time: 0.1651  last_time: 0.1649  data_time: 0.0032  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:11:29] d2.utils.events INFO:  eta: 0:17:07  iter: 8839  total_loss: 0.9543  loss_ce: 0.0832  loss_objectness: 0.5879  loss_dice: 0.2376  loss_mask: 0.04015    time: 0.1651  last_time: 0.1647  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1632M
[11/22 06:11:32] d2.utils.events INFO:  eta: 0:17:03  iter: 8859  total_loss: 1.237  loss_ce: 0.2283  loss_objectness: 0.6197  loss_dice: 0.3418  loss_mask: 0.03168    time: 0.1651  last_time: 0.1626  data_time: 0.0032  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:11:35] d2.utils.events INFO:  eta: 0:17:00  iter: 8879  total_loss: 1.153  loss_ce: 0.1655  loss_objectness: 0.6388  loss_dice: 0.3154  loss_mask: 0.04014    time: 0.1651  last_time: 0.1642  data_time: 0.0027  last_data_time: 0.0029   lr: 5e-05  max_mem: 1632M
[11/22 06:11:39] d2.utils.events INFO:  eta: 0:16:56  iter: 8899  total_loss: 1.104  loss_ce: 0.1522  loss_objectness: 0.6072  loss_dice: 0.2937  loss_mask: 0.03859    time: 0.1651  last_time: 0.1609  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:11:42] d2.utils.events INFO:  eta: 0:16:52  iter: 8919  total_loss: 1.23  loss_ce: 0.2356  loss_objectness: 0.5917  loss_dice: 0.3045  loss_mask: 0.03255    time: 0.1651  last_time: 0.1633  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:11:45] d2.utils.events INFO:  eta: 0:16:47  iter: 8939  total_loss: 1.07  loss_ce: 0.1432  loss_objectness: 0.6112  loss_dice: 0.2772  loss_mask: 0.03128    time: 0.1651  last_time: 0.1624  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 06:11:48] d2.utils.events INFO:  eta: 0:16:43  iter: 8959  total_loss: 1.2  loss_ce: 0.2445  loss_objectness: 0.6018  loss_dice: 0.2788  loss_mask: 0.03818    time: 0.1651  last_time: 0.1639  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:11:52] d2.utils.events INFO:  eta: 0:16:39  iter: 8979  total_loss: 1.263  loss_ce: 0.2278  loss_objectness: 0.6466  loss_dice: 0.3376  loss_mask: 0.03022    time: 0.1651  last_time: 0.1635  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:11:55] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 06:11:55] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 06:11:55] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 06:11:55] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 06:11:55] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 06:11:55] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 06:12:00] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0342 s/iter. Eval: 0.0390 s/iter. Total: 0.0735 s/iter. ETA=0:00:08
[11/22 06:12:05] d2.evaluation.evaluator INFO: Inference done 91/120. Dataloading: 0.0004 s/iter. Inference: 0.0236 s/iter. Eval: 0.0399 s/iter. Total: 0.0638 s/iter. ETA=0:00:01
[11/22 06:12:08] d2.evaluation.evaluator INFO: Total inference time: 0:00:08.060460 (0.070091 s / iter per device, on 1 devices)
[11/22 06:12:08] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.023016 s / iter per device, on 1 devices)
[11/22 06:12:08] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 06:12:08] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 06:12:08] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 06:12:08] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 06:12:08] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.05 seconds.
[11/22 06:12:08] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 06:12:08] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 06:12:08] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 7.794 | 17.025 | 7.264  | 0.111 | 17.169 | 48.884 |
[11/22 06:12:08] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 06:12:08] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 06:12:08] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 06:12:08] d2.evaluation.testing INFO: copypaste: 7.7938,17.0249,7.2638,0.1112,17.1694,48.8838
[11/22 06:12:08] d2.utils.events INFO:  eta: 0:16:35  iter: 8999  total_loss: 1.136  loss_ce: 0.1559  loss_objectness: 0.6155  loss_dice: 0.2762  loss_mask: 0.03025    time: 0.1651  last_time: 0.1627  data_time: 0.0031  last_data_time: 0.0050   lr: 5e-05  max_mem: 1632M
[11/22 06:12:11] d2.utils.events INFO:  eta: 0:16:31  iter: 9019  total_loss: 1.106  loss_ce: 0.1994  loss_objectness: 0.5908  loss_dice: 0.3084  loss_mask: 0.03242    time: 0.1651  last_time: 0.1620  data_time: 0.0032  last_data_time: 0.0032   lr: 5e-05  max_mem: 1632M
[11/22 06:12:14] d2.utils.events INFO:  eta: 0:16:27  iter: 9039  total_loss: 1.07  loss_ce: 0.1502  loss_objectness: 0.6023  loss_dice: 0.2706  loss_mask: 0.04265    time: 0.1651  last_time: 0.1601  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:12:18] d2.utils.events INFO:  eta: 0:16:23  iter: 9059  total_loss: 1.031  loss_ce: 0.1442  loss_objectness: 0.5859  loss_dice: 0.2255  loss_mask: 0.03534    time: 0.1651  last_time: 0.1622  data_time: 0.0031  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:12:21] d2.utils.events INFO:  eta: 0:16:18  iter: 9079  total_loss: 1.176  loss_ce: 0.2266  loss_objectness: 0.6346  loss_dice: 0.3035  loss_mask: 0.03531    time: 0.1651  last_time: 0.1628  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:12:24] d2.utils.events INFO:  eta: 0:16:14  iter: 9099  total_loss: 1.265  loss_ce: 0.2732  loss_objectness: 0.6204  loss_dice: 0.3482  loss_mask: 0.03626    time: 0.1651  last_time: 0.1643  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:12:27] d2.utils.events INFO:  eta: 0:16:10  iter: 9119  total_loss: 1.14  loss_ce: 0.2308  loss_objectness: 0.6006  loss_dice: 0.3033  loss_mask: 0.03094    time: 0.1650  last_time: 0.1695  data_time: 0.0030  last_data_time: 0.0033   lr: 5e-05  max_mem: 1632M
[11/22 06:12:31] d2.utils.events INFO:  eta: 0:16:07  iter: 9139  total_loss: 1.088  loss_ce: 0.2036  loss_objectness: 0.5903  loss_dice: 0.2424  loss_mask: 0.02841    time: 0.1650  last_time: 0.1625  data_time: 0.0029  last_data_time: 0.0022   lr: 5e-05  max_mem: 1632M
[11/22 06:12:34] d2.utils.events INFO:  eta: 0:16:03  iter: 9159  total_loss: 1.04  loss_ce: 0.1523  loss_objectness: 0.5811  loss_dice: 0.2111  loss_mask: 0.03064    time: 0.1650  last_time: 0.1619  data_time: 0.0027  last_data_time: 0.0021   lr: 5e-05  max_mem: 1632M
[11/22 06:12:37] d2.utils.events INFO:  eta: 0:15:59  iter: 9179  total_loss: 1.169  loss_ce: 0.2006  loss_objectness: 0.6136  loss_dice: 0.2868  loss_mask: 0.02433    time: 0.1650  last_time: 0.1597  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 06:12:41] d2.utils.events INFO:  eta: 0:15:56  iter: 9199  total_loss: 1.094  loss_ce: 0.2072  loss_objectness: 0.5721  loss_dice: 0.2685  loss_mask: 0.04248    time: 0.1650  last_time: 0.1631  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:12:44] d2.utils.events INFO:  eta: 0:15:52  iter: 9219  total_loss: 1.137  loss_ce: 0.2323  loss_objectness: 0.5806  loss_dice: 0.2655  loss_mask: 0.02527    time: 0.1650  last_time: 0.1646  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-05  max_mem: 1632M
[11/22 06:12:47] d2.utils.events INFO:  eta: 0:15:48  iter: 9239  total_loss: 1.069  loss_ce: 0.1617  loss_objectness: 0.5993  loss_dice: 0.2563  loss_mask: 0.03085    time: 0.1650  last_time: 0.1635  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:12:50] d2.utils.events INFO:  eta: 0:15:45  iter: 9259  total_loss: 0.9486  loss_ce: 0.1262  loss_objectness: 0.5596  loss_dice: 0.2127  loss_mask: 0.03019    time: 0.1650  last_time: 0.1609  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:12:54] d2.utils.events INFO:  eta: 0:15:41  iter: 9279  total_loss: 0.9243  loss_ce: 0.08714  loss_objectness: 0.568  loss_dice: 0.225  loss_mask: 0.03661    time: 0.1650  last_time: 0.1629  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:12:57] d2.utils.events INFO:  eta: 0:15:37  iter: 9299  total_loss: 1.063  loss_ce: 0.1597  loss_objectness: 0.5875  loss_dice: 0.2599  loss_mask: 0.02391    time: 0.1650  last_time: 0.1632  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:13:00] d2.utils.events INFO:  eta: 0:15:34  iter: 9319  total_loss: 1.227  loss_ce: 0.222  loss_objectness: 0.6129  loss_dice: 0.3459  loss_mask: 0.02992    time: 0.1650  last_time: 0.1619  data_time: 0.0030  last_data_time: 0.0040   lr: 5e-05  max_mem: 1632M
[11/22 06:13:04] d2.utils.events INFO:  eta: 0:15:30  iter: 9339  total_loss: 1.063  loss_ce: 0.1646  loss_objectness: 0.5932  loss_dice: 0.2719  loss_mask: 0.03586    time: 0.1650  last_time: 0.1639  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:13:07] d2.utils.events INFO:  eta: 0:15:26  iter: 9359  total_loss: 1.045  loss_ce: 0.1554  loss_objectness: 0.602  loss_dice: 0.2429  loss_mask: 0.03378    time: 0.1650  last_time: 0.1654  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 06:13:10] d2.utils.events INFO:  eta: 0:15:22  iter: 9379  total_loss: 1.122  loss_ce: 0.2022  loss_objectness: 0.5986  loss_dice: 0.2533  loss_mask: 0.02914    time: 0.1650  last_time: 0.1660  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:13:13] d2.utils.events INFO:  eta: 0:15:19  iter: 9399  total_loss: 1.125  loss_ce: 0.1839  loss_objectness: 0.5773  loss_dice: 0.2836  loss_mask: 0.03067    time: 0.1650  last_time: 0.1598  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:13:17] d2.utils.events INFO:  eta: 0:15:15  iter: 9419  total_loss: 0.9917  loss_ce: 0.1325  loss_objectness: 0.5649  loss_dice: 0.2409  loss_mask: 0.03273    time: 0.1650  last_time: 0.1623  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:13:20] d2.utils.events INFO:  eta: 0:15:11  iter: 9439  total_loss: 1.147  loss_ce: 0.2043  loss_objectness: 0.5881  loss_dice: 0.2936  loss_mask: 0.0289    time: 0.1650  last_time: 0.1644  data_time: 0.0029  last_data_time: 0.0022   lr: 5e-05  max_mem: 1632M
[11/22 06:13:23] d2.utils.events INFO:  eta: 0:15:08  iter: 9459  total_loss: 1.202  loss_ce: 0.2006  loss_objectness: 0.6205  loss_dice: 0.3265  loss_mask: 0.0307    time: 0.1650  last_time: 0.1655  data_time: 0.0029  last_data_time: 0.0045   lr: 5e-05  max_mem: 1632M
[11/22 06:13:27] d2.utils.events INFO:  eta: 0:15:04  iter: 9479  total_loss: 1.102  loss_ce: 0.1587  loss_objectness: 0.5999  loss_dice: 0.2958  loss_mask: 0.02939    time: 0.1650  last_time: 0.1626  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1632M
[11/22 06:13:30] d2.utils.events INFO:  eta: 0:15:00  iter: 9499  total_loss: 1.136  loss_ce: 0.1686  loss_objectness: 0.6109  loss_dice: 0.2861  loss_mask: 0.026    time: 0.1650  last_time: 0.1611  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:13:33] d2.utils.events INFO:  eta: 0:14:57  iter: 9519  total_loss: 0.9918  loss_ce: 0.1338  loss_objectness: 0.5884  loss_dice: 0.2446  loss_mask: 0.03445    time: 0.1650  last_time: 0.1649  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 06:13:36] d2.utils.events INFO:  eta: 0:14:53  iter: 9539  total_loss: 1.058  loss_ce: 0.137  loss_objectness: 0.5992  loss_dice: 0.2761  loss_mask: 0.02985    time: 0.1650  last_time: 0.1638  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 06:13:40] d2.utils.events INFO:  eta: 0:14:50  iter: 9559  total_loss: 1.145  loss_ce: 0.162  loss_objectness: 0.6173  loss_dice: 0.3202  loss_mask: 0.03228    time: 0.1650  last_time: 0.1602  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:13:43] d2.utils.events INFO:  eta: 0:14:46  iter: 9579  total_loss: 0.9024  loss_ce: 0.09524  loss_objectness: 0.554  loss_dice: 0.2122  loss_mask: 0.03887    time: 0.1650  last_time: 0.1610  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 06:13:46] d2.utils.events INFO:  eta: 0:14:43  iter: 9599  total_loss: 1.142  loss_ce: 0.1815  loss_objectness: 0.6006  loss_dice: 0.3145  loss_mask: 0.02788    time: 0.1650  last_time: 0.1660  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:13:50] d2.utils.events INFO:  eta: 0:14:40  iter: 9619  total_loss: 1.045  loss_ce: 0.123  loss_objectness: 0.6048  loss_dice: 0.2697  loss_mask: 0.03861    time: 0.1650  last_time: 0.1622  data_time: 0.0033  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:13:53] d2.utils.events INFO:  eta: 0:14:36  iter: 9639  total_loss: 1.085  loss_ce: 0.1757  loss_objectness: 0.617  loss_dice: 0.2507  loss_mask: 0.03281    time: 0.1650  last_time: 0.1601  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:13:56] d2.utils.events INFO:  eta: 0:14:33  iter: 9659  total_loss: 1.128  loss_ce: 0.2241  loss_objectness: 0.5878  loss_dice: 0.2803  loss_mask: 0.02821    time: 0.1650  last_time: 0.1648  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:14:00] d2.utils.events INFO:  eta: 0:14:30  iter: 9679  total_loss: 0.9827  loss_ce: 0.1233  loss_objectness: 0.5763  loss_dice: 0.2368  loss_mask: 0.03252    time: 0.1650  last_time: 0.1641  data_time: 0.0035  last_data_time: 0.0024   lr: 5e-05  max_mem: 1632M
[11/22 06:14:03] d2.utils.events INFO:  eta: 0:14:27  iter: 9699  total_loss: 1.139  loss_ce: 0.1671  loss_objectness: 0.6141  loss_dice: 0.3066  loss_mask: 0.02912    time: 0.1650  last_time: 0.1652  data_time: 0.0030  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:14:06] d2.utils.events INFO:  eta: 0:14:23  iter: 9719  total_loss: 1.125  loss_ce: 0.1972  loss_objectness: 0.589  loss_dice: 0.287  loss_mask: 0.03744    time: 0.1650  last_time: 0.1636  data_time: 0.0027  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 06:14:09] d2.utils.events INFO:  eta: 0:14:20  iter: 9739  total_loss: 1.243  loss_ce: 0.208  loss_objectness: 0.6416  loss_dice: 0.3331  loss_mask: 0.03925    time: 0.1650  last_time: 0.1663  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:14:13] d2.utils.events INFO:  eta: 0:14:16  iter: 9759  total_loss: 1.194  loss_ce: 0.2125  loss_objectness: 0.6237  loss_dice: 0.2937  loss_mask: 0.0414    time: 0.1650  last_time: 0.1648  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:14:16] d2.utils.events INFO:  eta: 0:14:13  iter: 9779  total_loss: 1.2  loss_ce: 0.2327  loss_objectness: 0.6097  loss_dice: 0.3119  loss_mask: 0.03437    time: 0.1650  last_time: 0.1602  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:14:19] d2.utils.events INFO:  eta: 0:14:09  iter: 9799  total_loss: 1.336  loss_ce: 0.2705  loss_objectness: 0.6422  loss_dice: 0.3566  loss_mask: 0.03558    time: 0.1650  last_time: 0.1638  data_time: 0.0030  last_data_time: 0.0028   lr: 5e-05  max_mem: 1632M
[11/22 06:14:23] d2.utils.events INFO:  eta: 0:14:06  iter: 9819  total_loss: 1.333  loss_ce: 0.3042  loss_objectness: 0.6211  loss_dice: 0.3914  loss_mask: 0.03308    time: 0.1650  last_time: 0.1639  data_time: 0.0031  last_data_time: 0.0043   lr: 5e-05  max_mem: 1632M
[11/22 06:14:26] d2.utils.events INFO:  eta: 0:14:02  iter: 9839  total_loss: 1.024  loss_ce: 0.1357  loss_objectness: 0.6069  loss_dice: 0.2665  loss_mask: 0.0332    time: 0.1650  last_time: 0.1678  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-05  max_mem: 1632M
[11/22 06:14:29] d2.utils.events INFO:  eta: 0:13:59  iter: 9859  total_loss: 1.056  loss_ce: 0.183  loss_objectness: 0.5905  loss_dice: 0.2494  loss_mask: 0.03233    time: 0.1650  last_time: 0.1636  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:14:32] d2.utils.events INFO:  eta: 0:13:56  iter: 9879  total_loss: 1.045  loss_ce: 0.1649  loss_objectness: 0.59  loss_dice: 0.2752  loss_mask: 0.03605    time: 0.1649  last_time: 0.1609  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:14:36] d2.utils.events INFO:  eta: 0:13:53  iter: 9899  total_loss: 1.062  loss_ce: 0.1437  loss_objectness: 0.6075  loss_dice: 0.2997  loss_mask: 0.03547    time: 0.1649  last_time: 0.1608  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1632M
[11/22 06:14:39] d2.utils.events INFO:  eta: 0:13:49  iter: 9919  total_loss: 1.025  loss_ce: 0.1291  loss_objectness: 0.5856  loss_dice: 0.2743  loss_mask: 0.03238    time: 0.1649  last_time: 0.1632  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-05  max_mem: 1632M
[11/22 06:14:42] d2.utils.events INFO:  eta: 0:13:46  iter: 9939  total_loss: 1.133  loss_ce: 0.1779  loss_objectness: 0.5942  loss_dice: 0.3208  loss_mask: 0.02371    time: 0.1649  last_time: 0.1661  data_time: 0.0029  last_data_time: 0.0037   lr: 5e-05  max_mem: 1632M
[11/22 06:14:45] d2.utils.events INFO:  eta: 0:13:43  iter: 9959  total_loss: 0.9904  loss_ce: 0.1651  loss_objectness: 0.564  loss_dice: 0.2403  loss_mask: 0.03015    time: 0.1649  last_time: 0.1629  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-05  max_mem: 1632M
[11/22 06:14:49] d2.utils.events INFO:  eta: 0:13:40  iter: 9979  total_loss: 1.01  loss_ce: 0.1132  loss_objectness: 0.5929  loss_dice: 0.2735  loss_mask: 0.02498    time: 0.1649  last_time: 0.1707  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-05  max_mem: 1632M
[11/22 06:14:52] fvcore.common.checkpoint INFO: Saving checkpoint to output/crack_model_turbo\model_0009999.pth
[11/22 06:14:52] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 06:14:52] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 06:14:52] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 06:14:52] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 06:14:52] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 06:14:52] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 06:14:58] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0776 s/iter. Eval: 0.0376 s/iter. Total: 0.1156 s/iter. ETA=0:00:12
[11/22 06:15:03] d2.evaluation.evaluator INFO: Inference done 85/120. Dataloading: 0.0004 s/iter. Inference: 0.0290 s/iter. Eval: 0.0427 s/iter. Total: 0.0720 s/iter. ETA=0:00:02
[11/22 06:15:06] d2.evaluation.evaluator INFO: Total inference time: 0:00:08.870139 (0.077132 s / iter per device, on 1 devices)
[11/22 06:15:06] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:03 (0.027519 s / iter per device, on 1 devices)
[11/22 06:15:06] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 06:15:06] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 06:15:06] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 06:15:06] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 06:15:06] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.05 seconds.
[11/22 06:15:06] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 06:15:06] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 06:15:06] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.633 | 15.369 | 5.210  | 0.549 | 13.916 | 41.546 |
[11/22 06:15:06] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 06:15:06] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 06:15:06] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 06:15:06] d2.evaluation.testing INFO: copypaste: 6.6331,15.3685,5.2100,0.5491,13.9164,41.5464
[11/22 06:15:06] d2.utils.events INFO:  eta: 0:13:36  iter: 9999  total_loss: 1.119  loss_ce: 0.1614  loss_objectness: 0.5933  loss_dice: 0.2984  loss_mask: 0.03674    time: 0.1649  last_time: 0.1627  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1632M
[11/22 06:15:09] d2.utils.events INFO:  eta: 0:13:33  iter: 10019  total_loss: 1.055  loss_ce: 0.1578  loss_objectness: 0.5768  loss_dice: 0.2602  loss_mask: 0.03077    time: 0.1649  last_time: 0.1592  data_time: 0.0031  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:15:13] d2.utils.events INFO:  eta: 0:13:30  iter: 10039  total_loss: 0.9915  loss_ce: 0.1609  loss_objectness: 0.5733  loss_dice: 0.2611  loss_mask: 0.02486    time: 0.1649  last_time: 0.1674  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:15:16] d2.utils.events INFO:  eta: 0:13:27  iter: 10059  total_loss: 0.9208  loss_ce: 0.1213  loss_objectness: 0.5493  loss_dice: 0.1818  loss_mask: 0.02929    time: 0.1649  last_time: 0.1622  data_time: 0.0030  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:15:19] d2.utils.events INFO:  eta: 0:13:24  iter: 10079  total_loss: 0.9574  loss_ce: 0.1175  loss_objectness: 0.5631  loss_dice: 0.2176  loss_mask: 0.02761    time: 0.1650  last_time: 0.1643  data_time: 0.0031  last_data_time: 0.0034   lr: 5e-06  max_mem: 1632M
[11/22 06:15:23] d2.utils.events INFO:  eta: 0:13:22  iter: 10099  total_loss: 0.8383  loss_ce: 0.07584  loss_objectness: 0.5348  loss_dice: 0.1836  loss_mask: 0.02722    time: 0.1650  last_time: 0.1670  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:15:26] d2.utils.events INFO:  eta: 0:13:19  iter: 10119  total_loss: 0.9071  loss_ce: 0.1016  loss_objectness: 0.5442  loss_dice: 0.2032  loss_mask: 0.02259    time: 0.1650  last_time: 0.1648  data_time: 0.0030  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:15:29] d2.utils.events INFO:  eta: 0:13:15  iter: 10139  total_loss: 0.902  loss_ce: 0.1288  loss_objectness: 0.5767  loss_dice: 0.1838  loss_mask: 0.02345    time: 0.1650  last_time: 0.1656  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:15:33] d2.utils.events INFO:  eta: 0:13:12  iter: 10159  total_loss: 0.7571  loss_ce: 0.06008  loss_objectness: 0.515  loss_dice: 0.152  loss_mask: 0.02354    time: 0.1650  last_time: 0.1617  data_time: 0.0027  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:15:36] d2.utils.events INFO:  eta: 0:13:09  iter: 10179  total_loss: 1.028  loss_ce: 0.1505  loss_objectness: 0.5725  loss_dice: 0.2407  loss_mask: 0.02461    time: 0.1650  last_time: 0.1657  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:15:39] d2.utils.events INFO:  eta: 0:13:06  iter: 10199  total_loss: 0.8452  loss_ce: 0.09419  loss_objectness: 0.5232  loss_dice: 0.1536  loss_mask: 0.02867    time: 0.1650  last_time: 0.1642  data_time: 0.0028  last_data_time: 0.0037   lr: 5e-06  max_mem: 1632M
[11/22 06:15:43] d2.utils.events INFO:  eta: 0:13:03  iter: 10219  total_loss: 0.9396  loss_ce: 0.1167  loss_objectness: 0.5496  loss_dice: 0.2119  loss_mask: 0.02529    time: 0.1650  last_time: 0.1632  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:15:46] d2.utils.events INFO:  eta: 0:13:00  iter: 10239  total_loss: 0.857  loss_ce: 0.07143  loss_objectness: 0.5385  loss_dice: 0.1805  loss_mask: 0.02512    time: 0.1650  last_time: 0.1640  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:15:49] d2.utils.events INFO:  eta: 0:12:57  iter: 10259  total_loss: 0.7713  loss_ce: 0.0816  loss_objectness: 0.5026  loss_dice: 0.1505  loss_mask: 0.02685    time: 0.1650  last_time: 0.1657  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:15:52] d2.utils.events INFO:  eta: 0:12:54  iter: 10279  total_loss: 0.8391  loss_ce: 0.08576  loss_objectness: 0.5309  loss_dice: 0.1672  loss_mask: 0.02926    time: 0.1650  last_time: 0.1661  data_time: 0.0030  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:15:56] d2.utils.events INFO:  eta: 0:12:50  iter: 10299  total_loss: 0.8587  loss_ce: 0.094  loss_objectness: 0.5275  loss_dice: 0.2024  loss_mask: 0.02325    time: 0.1650  last_time: 0.1630  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:15:59] d2.utils.events INFO:  eta: 0:12:47  iter: 10319  total_loss: 0.8175  loss_ce: 0.07824  loss_objectness: 0.5482  loss_dice: 0.1647  loss_mask: 0.02406    time: 0.1650  last_time: 0.1650  data_time: 0.0029  last_data_time: 0.0034   lr: 5e-06  max_mem: 1632M
[11/22 06:16:02] d2.utils.events INFO:  eta: 0:12:44  iter: 10339  total_loss: 0.8449  loss_ce: 0.1033  loss_objectness: 0.5084  loss_dice: 0.1831  loss_mask: 0.02635    time: 0.1650  last_time: 0.1646  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:16:06] d2.utils.events INFO:  eta: 0:12:41  iter: 10359  total_loss: 0.8034  loss_ce: 0.09636  loss_objectness: 0.5183  loss_dice: 0.1623  loss_mask: 0.02382    time: 0.1650  last_time: 0.1640  data_time: 0.0030  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:16:09] d2.utils.events INFO:  eta: 0:12:38  iter: 10379  total_loss: 0.7177  loss_ce: 0.05699  loss_objectness: 0.4857  loss_dice: 0.1477  loss_mask: 0.02815    time: 0.1650  last_time: 0.1645  data_time: 0.0028  last_data_time: 0.0036   lr: 5e-06  max_mem: 1632M
[11/22 06:16:13] d2.utils.events INFO:  eta: 0:12:35  iter: 10399  total_loss: 0.8423  loss_ce: 0.09729  loss_objectness: 0.5348  loss_dice: 0.1769  loss_mask: 0.02356    time: 0.1650  last_time: 0.1593  data_time: 0.0034  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:16:16] d2.utils.events INFO:  eta: 0:12:32  iter: 10419  total_loss: 0.7755  loss_ce: 0.07422  loss_objectness: 0.4956  loss_dice: 0.1676  loss_mask: 0.02422    time: 0.1650  last_time: 0.1702  data_time: 0.0031  last_data_time: 0.0035   lr: 5e-06  max_mem: 1632M
[11/22 06:16:19] d2.utils.events INFO:  eta: 0:12:29  iter: 10439  total_loss: 0.7684  loss_ce: 0.07825  loss_objectness: 0.5132  loss_dice: 0.1539  loss_mask: 0.02073    time: 0.1650  last_time: 0.1648  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:16:23] d2.utils.events INFO:  eta: 0:12:25  iter: 10459  total_loss: 0.7119  loss_ce: 0.05858  loss_objectness: 0.4979  loss_dice: 0.1379  loss_mask: 0.02886    time: 0.1650  last_time: 0.1591  data_time: 0.0028  last_data_time: 0.0021   lr: 5e-06  max_mem: 1632M
[11/22 06:16:26] d2.utils.events INFO:  eta: 0:12:22  iter: 10479  total_loss: 0.6984  loss_ce: 0.04783  loss_objectness: 0.4902  loss_dice: 0.1358  loss_mask: 0.02428    time: 0.1650  last_time: 0.1647  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:16:29] d2.utils.events INFO:  eta: 0:12:19  iter: 10499  total_loss: 0.8984  loss_ce: 0.157  loss_objectness: 0.5305  loss_dice: 0.1986  loss_mask: 0.02057    time: 0.1650  last_time: 0.1646  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-06  max_mem: 1632M
[11/22 06:16:32] d2.utils.events INFO:  eta: 0:12:15  iter: 10519  total_loss: 0.6946  loss_ce: 0.06306  loss_objectness: 0.4941  loss_dice: 0.1369  loss_mask: 0.02099    time: 0.1650  last_time: 0.1619  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:16:36] d2.utils.events INFO:  eta: 0:12:12  iter: 10539  total_loss: 0.7961  loss_ce: 0.07609  loss_objectness: 0.4984  loss_dice: 0.1609  loss_mask: 0.02436    time: 0.1650  last_time: 0.1612  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:16:39] d2.utils.events INFO:  eta: 0:12:09  iter: 10559  total_loss: 0.7407  loss_ce: 0.03092  loss_objectness: 0.4993  loss_dice: 0.1483  loss_mask: 0.02572    time: 0.1650  last_time: 0.1625  data_time: 0.0028  last_data_time: 0.0034   lr: 5e-06  max_mem: 1632M
[11/22 06:16:42] d2.utils.events INFO:  eta: 0:12:06  iter: 10579  total_loss: 0.8327  loss_ce: 0.1043  loss_objectness: 0.504  loss_dice: 0.1647  loss_mask: 0.02189    time: 0.1650  last_time: 0.1603  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:16:46] d2.utils.events INFO:  eta: 0:12:02  iter: 10599  total_loss: 0.8498  loss_ce: 0.09897  loss_objectness: 0.5483  loss_dice: 0.1613  loss_mask: 0.02469    time: 0.1650  last_time: 0.1640  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:16:49] d2.utils.events INFO:  eta: 0:11:59  iter: 10619  total_loss: 0.8283  loss_ce: 0.07915  loss_objectness: 0.5332  loss_dice: 0.1563  loss_mask: 0.02356    time: 0.1650  last_time: 0.1618  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:16:52] d2.utils.events INFO:  eta: 0:11:55  iter: 10639  total_loss: 0.7856  loss_ce: 0.07195  loss_objectness: 0.4991  loss_dice: 0.1434  loss_mask: 0.02058    time: 0.1650  last_time: 0.1711  data_time: 0.0030  last_data_time: 0.0043   lr: 5e-06  max_mem: 1632M
[11/22 06:16:55] d2.utils.events INFO:  eta: 0:11:52  iter: 10659  total_loss: 0.7016  loss_ce: 0.07637  loss_objectness: 0.4739  loss_dice: 0.1342  loss_mask: 0.02548    time: 0.1650  last_time: 0.1627  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:16:59] d2.utils.events INFO:  eta: 0:11:49  iter: 10679  total_loss: 0.754  loss_ce: 0.08231  loss_objectness: 0.484  loss_dice: 0.1449  loss_mask: 0.02916    time: 0.1650  last_time: 0.1626  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:17:02] d2.utils.events INFO:  eta: 0:11:45  iter: 10699  total_loss: 0.7172  loss_ce: 0.07627  loss_objectness: 0.4781  loss_dice: 0.1466  loss_mask: 0.02182    time: 0.1650  last_time: 0.1647  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-06  max_mem: 1632M
[11/22 06:17:05] d2.utils.events INFO:  eta: 0:11:42  iter: 10719  total_loss: 0.7533  loss_ce: 0.08281  loss_objectness: 0.5124  loss_dice: 0.1513  loss_mask: 0.0228    time: 0.1649  last_time: 0.1605  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:17:09] d2.utils.events INFO:  eta: 0:11:39  iter: 10739  total_loss: 0.7231  loss_ce: 0.05565  loss_objectness: 0.5097  loss_dice: 0.134  loss_mask: 0.02693    time: 0.1649  last_time: 0.1611  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:17:12] d2.utils.events INFO:  eta: 0:11:35  iter: 10759  total_loss: 0.7114  loss_ce: 0.06611  loss_objectness: 0.4977  loss_dice: 0.1371  loss_mask: 0.02525    time: 0.1649  last_time: 0.1679  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:17:15] d2.utils.events INFO:  eta: 0:11:32  iter: 10779  total_loss: 0.7269  loss_ce: 0.07406  loss_objectness: 0.489  loss_dice: 0.1516  loss_mask: 0.02702    time: 0.1649  last_time: 0.1630  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:17:18] d2.utils.events INFO:  eta: 0:11:29  iter: 10799  total_loss: 0.7677  loss_ce: 0.09403  loss_objectness: 0.4993  loss_dice: 0.1504  loss_mask: 0.02139    time: 0.1649  last_time: 0.1626  data_time: 0.0028  last_data_time: 0.0022   lr: 5e-06  max_mem: 1632M
[11/22 06:17:22] d2.utils.events INFO:  eta: 0:11:25  iter: 10819  total_loss: 0.7874  loss_ce: 0.07875  loss_objectness: 0.5101  loss_dice: 0.1528  loss_mask: 0.02177    time: 0.1649  last_time: 0.1620  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:17:25] d2.utils.events INFO:  eta: 0:11:22  iter: 10839  total_loss: 0.6912  loss_ce: 0.09006  loss_objectness: 0.4439  loss_dice: 0.1309  loss_mask: 0.02167    time: 0.1649  last_time: 0.1706  data_time: 0.0028  last_data_time: 0.0034   lr: 5e-06  max_mem: 1632M
[11/22 06:17:28] d2.utils.events INFO:  eta: 0:11:19  iter: 10859  total_loss: 0.6633  loss_ce: 0.05545  loss_objectness: 0.4675  loss_dice: 0.129  loss_mask: 0.02146    time: 0.1649  last_time: 0.1644  data_time: 0.0035  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:17:32] d2.utils.events INFO:  eta: 0:11:16  iter: 10879  total_loss: 0.7276  loss_ce: 0.08773  loss_objectness: 0.4818  loss_dice: 0.1601  loss_mask: 0.02395    time: 0.1649  last_time: 0.1616  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:17:35] d2.utils.events INFO:  eta: 0:11:13  iter: 10899  total_loss: 0.6844  loss_ce: 0.07105  loss_objectness: 0.4761  loss_dice: 0.1441  loss_mask: 0.02562    time: 0.1649  last_time: 0.1645  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:17:38] d2.utils.events INFO:  eta: 0:11:09  iter: 10919  total_loss: 0.7452  loss_ce: 0.07357  loss_objectness: 0.466  loss_dice: 0.1673  loss_mask: 0.02017    time: 0.1649  last_time: 0.1666  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:17:41] d2.utils.events INFO:  eta: 0:11:06  iter: 10939  total_loss: 0.7844  loss_ce: 0.07891  loss_objectness: 0.525  loss_dice: 0.1526  loss_mask: 0.02408    time: 0.1649  last_time: 0.1630  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:17:45] d2.utils.events INFO:  eta: 0:11:03  iter: 10959  total_loss: 0.77  loss_ce: 0.07685  loss_objectness: 0.492  loss_dice: 0.1418  loss_mask: 0.02373    time: 0.1649  last_time: 0.1610  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:17:48] d2.utils.events INFO:  eta: 0:10:59  iter: 10979  total_loss: 0.6781  loss_ce: 0.04094  loss_objectness: 0.4728  loss_dice: 0.133  loss_mask: 0.02284    time: 0.1649  last_time: 0.1635  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:17:51] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 06:17:51] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 06:17:51] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 06:17:51] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 06:17:51] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 06:17:51] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 06:17:56] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0361 s/iter. Eval: 0.0381 s/iter. Total: 0.0745 s/iter. ETA=0:00:08
[11/22 06:18:01] d2.evaluation.evaluator INFO: Inference done 93/120. Dataloading: 0.0004 s/iter. Inference: 0.0231 s/iter. Eval: 0.0384 s/iter. Total: 0.0620 s/iter. ETA=0:00:01
[11/22 06:18:04] d2.evaluation.evaluator INFO: Total inference time: 0:00:07.916217 (0.068837 s / iter per device, on 1 devices)
[11/22 06:18:04] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.022640 s / iter per device, on 1 devices)
[11/22 06:18:04] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 06:18:04] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 06:18:04] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 06:18:04] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 06:18:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.04 seconds.
[11/22 06:18:04] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 06:18:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 06:18:04] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 7.213 | 14.504 | 6.871  | 0.047 | 15.347 | 51.033 |
[11/22 06:18:04] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 06:18:04] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 06:18:04] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 06:18:04] d2.evaluation.testing INFO: copypaste: 7.2132,14.5043,6.8711,0.0467,15.3474,51.0333
[11/22 06:18:04] d2.utils.events INFO:  eta: 0:10:56  iter: 10999  total_loss: 0.6421  loss_ce: 0.0433  loss_objectness: 0.4494  loss_dice: 0.1221  loss_mask: 0.02248    time: 0.1649  last_time: 0.1708  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:18:07] d2.utils.events INFO:  eta: 0:10:53  iter: 11019  total_loss: 0.7712  loss_ce: 0.08738  loss_objectness: 0.5185  loss_dice: 0.1351  loss_mask: 0.02643    time: 0.1649  last_time: 0.1634  data_time: 0.0028  last_data_time: 0.0022   lr: 5e-06  max_mem: 1632M
[11/22 06:18:11] d2.utils.events INFO:  eta: 0:10:49  iter: 11039  total_loss: 0.7557  loss_ce: 0.06033  loss_objectness: 0.4875  loss_dice: 0.149  loss_mask: 0.02774    time: 0.1649  last_time: 0.1637  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:18:14] d2.utils.events INFO:  eta: 0:10:46  iter: 11059  total_loss: 0.7402  loss_ce: 0.08287  loss_objectness: 0.4673  loss_dice: 0.1394  loss_mask: 0.01739    time: 0.1649  last_time: 0.1611  data_time: 0.0028  last_data_time: 0.0021   lr: 5e-06  max_mem: 1632M
[11/22 06:18:17] d2.utils.events INFO:  eta: 0:10:42  iter: 11079  total_loss: 0.891  loss_ce: 0.1685  loss_objectness: 0.5191  loss_dice: 0.1564  loss_mask: 0.02177    time: 0.1649  last_time: 0.1696  data_time: 0.0030  last_data_time: 0.0051   lr: 5e-06  max_mem: 1632M
[11/22 06:18:20] d2.utils.events INFO:  eta: 0:10:39  iter: 11099  total_loss: 0.6914  loss_ce: 0.0445  loss_objectness: 0.457  loss_dice: 0.1365  loss_mask: 0.02511    time: 0.1649  last_time: 0.1638  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:18:24] d2.utils.events INFO:  eta: 0:10:35  iter: 11119  total_loss: 0.6897  loss_ce: 0.05539  loss_objectness: 0.4768  loss_dice: 0.1262  loss_mask: 0.02369    time: 0.1649  last_time: 0.1646  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:18:27] d2.utils.events INFO:  eta: 0:10:32  iter: 11139  total_loss: 0.7966  loss_ce: 0.1235  loss_objectness: 0.513  loss_dice: 0.159  loss_mask: 0.01973    time: 0.1649  last_time: 0.1637  data_time: 0.0029  last_data_time: 0.0045   lr: 5e-06  max_mem: 1632M
[11/22 06:18:30] d2.utils.events INFO:  eta: 0:10:29  iter: 11159  total_loss: 0.7493  loss_ce: 0.04749  loss_objectness: 0.5009  loss_dice: 0.1329  loss_mask: 0.02378    time: 0.1649  last_time: 0.1621  data_time: 0.0029  last_data_time: 0.0033   lr: 5e-06  max_mem: 1632M
[11/22 06:18:34] d2.utils.events INFO:  eta: 0:10:25  iter: 11179  total_loss: 0.7617  loss_ce: 0.08862  loss_objectness: 0.5118  loss_dice: 0.1483  loss_mask: 0.0242    time: 0.1649  last_time: 0.1632  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:18:37] d2.utils.events INFO:  eta: 0:10:22  iter: 11199  total_loss: 0.6886  loss_ce: 0.06975  loss_objectness: 0.4652  loss_dice: 0.1328  loss_mask: 0.02053    time: 0.1649  last_time: 0.1634  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-06  max_mem: 1632M
[11/22 06:18:40] d2.utils.events INFO:  eta: 0:10:18  iter: 11219  total_loss: 0.7625  loss_ce: 0.1101  loss_objectness: 0.4679  loss_dice: 0.1507  loss_mask: 0.02225    time: 0.1649  last_time: 0.1618  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:18:43] d2.utils.events INFO:  eta: 0:10:15  iter: 11239  total_loss: 0.7523  loss_ce: 0.07629  loss_objectness: 0.4922  loss_dice: 0.1309  loss_mask: 0.02327    time: 0.1649  last_time: 0.1669  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:18:47] d2.utils.events INFO:  eta: 0:10:12  iter: 11259  total_loss: 0.6991  loss_ce: 0.05154  loss_objectness: 0.443  loss_dice: 0.1275  loss_mask: 0.02421    time: 0.1649  last_time: 0.1641  data_time: 0.0031  last_data_time: 0.0035   lr: 5e-06  max_mem: 1632M
[11/22 06:18:50] d2.utils.events INFO:  eta: 0:10:08  iter: 11279  total_loss: 0.7374  loss_ce: 0.07554  loss_objectness: 0.4944  loss_dice: 0.1348  loss_mask: 0.01993    time: 0.1649  last_time: 0.1631  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-06  max_mem: 1632M
[11/22 06:18:53] d2.utils.events INFO:  eta: 0:10:05  iter: 11299  total_loss: 0.7782  loss_ce: 0.08063  loss_objectness: 0.5044  loss_dice: 0.1456  loss_mask: 0.02185    time: 0.1649  last_time: 0.1596  data_time: 0.0028  last_data_time: 0.0033   lr: 5e-06  max_mem: 1632M
[11/22 06:18:57] d2.utils.events INFO:  eta: 0:10:01  iter: 11319  total_loss: 0.6522  loss_ce: 0.0401  loss_objectness: 0.4597  loss_dice: 0.1199  loss_mask: 0.02678    time: 0.1649  last_time: 0.1630  data_time: 0.0026  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:19:00] d2.utils.events INFO:  eta: 0:09:58  iter: 11339  total_loss: 0.7154  loss_ce: 0.05436  loss_objectness: 0.4867  loss_dice: 0.1416  loss_mask: 0.01968    time: 0.1649  last_time: 0.1646  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:19:03] d2.utils.events INFO:  eta: 0:09:55  iter: 11359  total_loss: 0.7312  loss_ce: 0.1053  loss_objectness: 0.4877  loss_dice: 0.1354  loss_mask: 0.02366    time: 0.1649  last_time: 0.1659  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-06  max_mem: 1632M
[11/22 06:19:06] d2.utils.events INFO:  eta: 0:09:51  iter: 11379  total_loss: 0.6574  loss_ce: 0.04486  loss_objectness: 0.4712  loss_dice: 0.1206  loss_mask: 0.02094    time: 0.1649  last_time: 0.1619  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-06  max_mem: 1632M
[11/22 06:19:10] d2.utils.events INFO:  eta: 0:09:48  iter: 11399  total_loss: 0.7586  loss_ce: 0.07372  loss_objectness: 0.5125  loss_dice: 0.1552  loss_mask: 0.02082    time: 0.1649  last_time: 0.1639  data_time: 0.0029  last_data_time: 0.0042   lr: 5e-06  max_mem: 1632M
[11/22 06:19:13] d2.utils.events INFO:  eta: 0:09:44  iter: 11419  total_loss: 0.6606  loss_ce: 0.05636  loss_objectness: 0.4464  loss_dice: 0.1271  loss_mask: 0.02141    time: 0.1649  last_time: 0.1625  data_time: 0.0031  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:19:16] d2.utils.events INFO:  eta: 0:09:41  iter: 11439  total_loss: 0.6725  loss_ce: 0.03801  loss_objectness: 0.4825  loss_dice: 0.1162  loss_mask: 0.02659    time: 0.1649  last_time: 0.1660  data_time: 0.0029  last_data_time: 0.0045   lr: 5e-06  max_mem: 1632M
[11/22 06:19:20] d2.utils.events INFO:  eta: 0:09:38  iter: 11459  total_loss: 0.6772  loss_ce: 0.02476  loss_objectness: 0.472  loss_dice: 0.1285  loss_mask: 0.02475    time: 0.1649  last_time: 0.1667  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:19:23] d2.utils.events INFO:  eta: 0:09:35  iter: 11479  total_loss: 0.7068  loss_ce: 0.05059  loss_objectness: 0.4856  loss_dice: 0.1291  loss_mask: 0.02348    time: 0.1649  last_time: 0.1596  data_time: 0.0030  last_data_time: 0.0028   lr: 5e-06  max_mem: 1632M
[11/22 06:19:26] d2.utils.events INFO:  eta: 0:09:31  iter: 11499  total_loss: 0.6873  loss_ce: 0.07715  loss_objectness: 0.4426  loss_dice: 0.1144  loss_mask: 0.02225    time: 0.1649  last_time: 0.1604  data_time: 0.0028  last_data_time: 0.0035   lr: 5e-06  max_mem: 1632M
[11/22 06:19:29] d2.utils.events INFO:  eta: 0:09:28  iter: 11519  total_loss: 0.6801  loss_ce: 0.03143  loss_objectness: 0.4782  loss_dice: 0.13  loss_mask: 0.02029    time: 0.1649  last_time: 0.1625  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:19:33] d2.utils.events INFO:  eta: 0:09:25  iter: 11539  total_loss: 0.6497  loss_ce: 0.04486  loss_objectness: 0.4567  loss_dice: 0.1217  loss_mask: 0.02338    time: 0.1649  last_time: 0.1658  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:19:36] d2.utils.events INFO:  eta: 0:09:21  iter: 11559  total_loss: 0.7109  loss_ce: 0.0457  loss_objectness: 0.4988  loss_dice: 0.1289  loss_mask: 0.02414    time: 0.1649  last_time: 0.1628  data_time: 0.0028  last_data_time: 0.0032   lr: 5e-06  max_mem: 1632M
[11/22 06:19:39] d2.utils.events INFO:  eta: 0:09:18  iter: 11579  total_loss: 0.7475  loss_ce: 0.07841  loss_objectness: 0.4844  loss_dice: 0.141  loss_mask: 0.02001    time: 0.1649  last_time: 0.1633  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:19:43] d2.utils.events INFO:  eta: 0:09:15  iter: 11599  total_loss: 0.6407  loss_ce: 0.04392  loss_objectness: 0.4547  loss_dice: 0.1167  loss_mask: 0.01882    time: 0.1649  last_time: 0.1609  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:19:46] d2.utils.events INFO:  eta: 0:09:12  iter: 11619  total_loss: 0.6584  loss_ce: 0.04737  loss_objectness: 0.4357  loss_dice: 0.1435  loss_mask: 0.02232    time: 0.1649  last_time: 0.1611  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:19:49] d2.utils.events INFO:  eta: 0:09:08  iter: 11639  total_loss: 0.6422  loss_ce: 0.04439  loss_objectness: 0.4426  loss_dice: 0.1156  loss_mask: 0.02107    time: 0.1648  last_time: 0.1599  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:19:52] d2.utils.events INFO:  eta: 0:09:05  iter: 11659  total_loss: 0.6266  loss_ce: 0.02012  loss_objectness: 0.4322  loss_dice: 0.1092  loss_mask: 0.02602    time: 0.1648  last_time: 0.1629  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:19:56] d2.utils.events INFO:  eta: 0:09:02  iter: 11679  total_loss: 0.717  loss_ce: 0.07253  loss_objectness: 0.497  loss_dice: 0.1405  loss_mask: 0.01878    time: 0.1648  last_time: 0.1618  data_time: 0.0029  last_data_time: 0.0037   lr: 5e-06  max_mem: 1632M
[11/22 06:19:59] d2.utils.events INFO:  eta: 0:08:59  iter: 11699  total_loss: 0.7067  loss_ce: 0.05618  loss_objectness: 0.4807  loss_dice: 0.1314  loss_mask: 0.02562    time: 0.1648  last_time: 0.1617  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:20:02] d2.utils.events INFO:  eta: 0:08:56  iter: 11719  total_loss: 0.6735  loss_ce: 0.02743  loss_objectness: 0.4658  loss_dice: 0.1285  loss_mask: 0.02013    time: 0.1648  last_time: 0.1655  data_time: 0.0031  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:20:06] d2.utils.events INFO:  eta: 0:08:53  iter: 11739  total_loss: 0.65  loss_ce: 0.02439  loss_objectness: 0.4458  loss_dice: 0.1211  loss_mask: 0.02511    time: 0.1649  last_time: 0.1631  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:20:09] d2.utils.events INFO:  eta: 0:08:49  iter: 11759  total_loss: 0.6381  loss_ce: 0.03773  loss_objectness: 0.4385  loss_dice: 0.1183  loss_mask: 0.0196    time: 0.1649  last_time: 0.1606  data_time: 0.0033  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:20:12] d2.utils.events INFO:  eta: 0:08:46  iter: 11779  total_loss: 0.6615  loss_ce: 0.052  loss_objectness: 0.4838  loss_dice: 0.1423  loss_mask: 0.02057    time: 0.1648  last_time: 0.1625  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:20:16] d2.utils.events INFO:  eta: 0:08:43  iter: 11799  total_loss: 0.6332  loss_ce: 0.03699  loss_objectness: 0.4353  loss_dice: 0.1124  loss_mask: 0.02468    time: 0.1649  last_time: 0.1619  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:20:19] d2.utils.events INFO:  eta: 0:08:40  iter: 11819  total_loss: 0.6988  loss_ce: 0.05621  loss_objectness: 0.4861  loss_dice: 0.1365  loss_mask: 0.02016    time: 0.1648  last_time: 0.1629  data_time: 0.0031  last_data_time: 0.0033   lr: 5e-06  max_mem: 1632M
[11/22 06:20:22] d2.utils.events INFO:  eta: 0:08:36  iter: 11839  total_loss: 0.6406  loss_ce: 0.05317  loss_objectness: 0.4361  loss_dice: 0.1177  loss_mask: 0.02657    time: 0.1648  last_time: 0.1611  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:20:25] d2.utils.events INFO:  eta: 0:08:33  iter: 11859  total_loss: 0.5977  loss_ce: 0.03413  loss_objectness: 0.4358  loss_dice: 0.1144  loss_mask: 0.01992    time: 0.1648  last_time: 0.1585  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-06  max_mem: 1632M
[11/22 06:20:29] d2.utils.events INFO:  eta: 0:08:30  iter: 11879  total_loss: 0.6013  loss_ce: 0.01495  loss_objectness: 0.4416  loss_dice: 0.11  loss_mask: 0.02144    time: 0.1648  last_time: 0.1635  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:20:32] d2.utils.events INFO:  eta: 0:08:26  iter: 11899  total_loss: 0.6045  loss_ce: 0.02184  loss_objectness: 0.4394  loss_dice: 0.1108  loss_mask: 0.02059    time: 0.1648  last_time: 0.1635  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-06  max_mem: 1632M
[11/22 06:20:35] d2.utils.events INFO:  eta: 0:08:23  iter: 11919  total_loss: 0.7471  loss_ce: 0.09067  loss_objectness: 0.4884  loss_dice: 0.1448  loss_mask: 0.02471    time: 0.1648  last_time: 0.1594  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:20:39] d2.utils.events INFO:  eta: 0:08:20  iter: 11939  total_loss: 0.6359  loss_ce: 0.03013  loss_objectness: 0.4529  loss_dice: 0.1094  loss_mask: 0.02117    time: 0.1648  last_time: 0.1639  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:20:42] d2.utils.events INFO:  eta: 0:08:17  iter: 11959  total_loss: 0.617  loss_ce: 0.02488  loss_objectness: 0.4503  loss_dice: 0.1187  loss_mask: 0.02025    time: 0.1648  last_time: 0.1669  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:20:45] d2.utils.events INFO:  eta: 0:08:13  iter: 11979  total_loss: 0.6025  loss_ce: 0.02265  loss_objectness: 0.4209  loss_dice: 0.1085  loss_mask: 0.01932    time: 0.1648  last_time: 0.1618  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:20:49] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 06:20:49] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 06:20:49] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 06:20:49] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 06:20:49] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 06:20:49] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 06:20:53] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0214 s/iter. Eval: 0.0317 s/iter. Total: 0.0534 s/iter. ETA=0:00:05
[11/22 06:20:58] d2.evaluation.evaluator INFO: Inference done 102/120. Dataloading: 0.0004 s/iter. Inference: 0.0208 s/iter. Eval: 0.0337 s/iter. Total: 0.0549 s/iter. ETA=0:00:00
[11/22 06:21:00] d2.evaluation.evaluator INFO: Total inference time: 0:00:07.225856 (0.062834 s / iter per device, on 1 devices)
[11/22 06:21:00] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.020885 s / iter per device, on 1 devices)
[11/22 06:21:00] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 06:21:00] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 06:21:00] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 06:21:00] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 06:21:00] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.04 seconds.
[11/22 06:21:00] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 06:21:00] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 06:21:00] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 7.185 | 14.992 | 7.131  | 0.045 | 15.304 | 50.695 |
[11/22 06:21:00] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 06:21:00] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 06:21:00] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 06:21:00] d2.evaluation.testing INFO: copypaste: 7.1847,14.9916,7.1315,0.0450,15.3043,50.6953
[11/22 06:21:00] d2.utils.events INFO:  eta: 0:08:10  iter: 11999  total_loss: 0.6743  loss_ce: 0.06107  loss_objectness: 0.4746  loss_dice: 0.1264  loss_mask: 0.02132    time: 0.1648  last_time: 0.1661  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:21:04] d2.utils.events INFO:  eta: 0:08:07  iter: 12019  total_loss: 0.7194  loss_ce: 0.04956  loss_objectness: 0.4918  loss_dice: 0.1304  loss_mask: 0.02536    time: 0.1648  last_time: 0.1636  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:21:07] d2.utils.events INFO:  eta: 0:08:04  iter: 12039  total_loss: 0.6227  loss_ce: 0.04334  loss_objectness: 0.429  loss_dice: 0.1111  loss_mask: 0.01837    time: 0.1648  last_time: 0.1639  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:21:10] d2.utils.events INFO:  eta: 0:08:00  iter: 12059  total_loss: 0.6033  loss_ce: 0.01854  loss_objectness: 0.4333  loss_dice: 0.1091  loss_mask: 0.02118    time: 0.1648  last_time: 0.1614  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:21:13] d2.utils.events INFO:  eta: 0:07:57  iter: 12079  total_loss: 0.6877  loss_ce: 0.07154  loss_objectness: 0.4715  loss_dice: 0.1328  loss_mask: 0.02138    time: 0.1648  last_time: 0.1626  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:21:17] d2.utils.events INFO:  eta: 0:07:54  iter: 12099  total_loss: 0.6334  loss_ce: 0.03747  loss_objectness: 0.4597  loss_dice: 0.1145  loss_mask: 0.02429    time: 0.1648  last_time: 0.1631  data_time: 0.0028  last_data_time: 0.0036   lr: 5e-06  max_mem: 1632M
[11/22 06:21:20] d2.utils.events INFO:  eta: 0:07:51  iter: 12119  total_loss: 0.6195  loss_ce: 0.05658  loss_objectness: 0.4315  loss_dice: 0.1163  loss_mask: 0.02089    time: 0.1648  last_time: 0.1598  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:21:23] d2.utils.events INFO:  eta: 0:07:47  iter: 12139  total_loss: 0.5866  loss_ce: 0.02312  loss_objectness: 0.4283  loss_dice: 0.1075  loss_mask: 0.02044    time: 0.1648  last_time: 0.1665  data_time: 0.0029  last_data_time: 0.0043   lr: 5e-06  max_mem: 1632M
[11/22 06:21:27] d2.utils.events INFO:  eta: 0:07:44  iter: 12159  total_loss: 0.5844  loss_ce: 0.02547  loss_objectness: 0.4185  loss_dice: 0.107  loss_mask: 0.02476    time: 0.1648  last_time: 0.1669  data_time: 0.0030  last_data_time: 0.0031   lr: 5e-06  max_mem: 1632M
[11/22 06:21:30] d2.utils.events INFO:  eta: 0:07:41  iter: 12179  total_loss: 0.6654  loss_ce: 0.06612  loss_objectness: 0.4471  loss_dice: 0.1145  loss_mask: 0.02345    time: 0.1648  last_time: 0.1605  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:21:33] d2.utils.events INFO:  eta: 0:07:38  iter: 12199  total_loss: 0.6599  loss_ce: 0.02318  loss_objectness: 0.4637  loss_dice: 0.1232  loss_mask: 0.02268    time: 0.1648  last_time: 0.1644  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:21:37] d2.utils.events INFO:  eta: 0:07:34  iter: 12219  total_loss: 0.6639  loss_ce: 0.03996  loss_objectness: 0.4487  loss_dice: 0.1061  loss_mask: 0.0209    time: 0.1648  last_time: 0.1640  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:21:40] d2.utils.events INFO:  eta: 0:07:31  iter: 12239  total_loss: 0.643  loss_ce: 0.05289  loss_objectness: 0.4783  loss_dice: 0.1276  loss_mask: 0.01784    time: 0.1648  last_time: 0.1636  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:21:43] d2.utils.events INFO:  eta: 0:07:28  iter: 12259  total_loss: 0.6486  loss_ce: 0.05621  loss_objectness: 0.4281  loss_dice: 0.1072  loss_mask: 0.02252    time: 0.1648  last_time: 0.1660  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:21:46] d2.utils.events INFO:  eta: 0:07:25  iter: 12279  total_loss: 0.6052  loss_ce: 0.03105  loss_objectness: 0.4386  loss_dice: 0.1153  loss_mask: 0.01974    time: 0.1648  last_time: 0.1601  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:21:50] d2.utils.events INFO:  eta: 0:07:21  iter: 12299  total_loss: 0.6083  loss_ce: 0.03184  loss_objectness: 0.4207  loss_dice: 0.1097  loss_mask: 0.02701    time: 0.1648  last_time: 0.1587  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:21:53] d2.utils.events INFO:  eta: 0:07:18  iter: 12319  total_loss: 0.6097  loss_ce: 0.01781  loss_objectness: 0.4256  loss_dice: 0.1059  loss_mask: 0.01931    time: 0.1648  last_time: 0.1635  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:21:56] d2.utils.events INFO:  eta: 0:07:15  iter: 12339  total_loss: 0.6508  loss_ce: 0.05756  loss_objectness: 0.4289  loss_dice: 0.1118  loss_mask: 0.02551    time: 0.1648  last_time: 0.1625  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:21:59] d2.utils.events INFO:  eta: 0:07:11  iter: 12359  total_loss: 0.6136  loss_ce: 0.03833  loss_objectness: 0.4413  loss_dice: 0.1324  loss_mask: 0.01777    time: 0.1648  last_time: 0.1656  data_time: 0.0030  last_data_time: 0.0036   lr: 5e-06  max_mem: 1632M
[11/22 06:22:03] d2.utils.events INFO:  eta: 0:07:08  iter: 12379  total_loss: 0.6098  loss_ce: 0.02423  loss_objectness: 0.4551  loss_dice: 0.1024  loss_mask: 0.02116    time: 0.1648  last_time: 0.1644  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:22:06] d2.utils.events INFO:  eta: 0:07:05  iter: 12399  total_loss: 0.6066  loss_ce: 0.02756  loss_objectness: 0.4467  loss_dice: 0.1102  loss_mask: 0.0212    time: 0.1648  last_time: 0.1626  data_time: 0.0027  last_data_time: 0.0037   lr: 5e-06  max_mem: 1632M
[11/22 06:22:09] d2.utils.events INFO:  eta: 0:07:01  iter: 12419  total_loss: 0.6114  loss_ce: 0.04524  loss_objectness: 0.4425  loss_dice: 0.09963  loss_mask: 0.02062    time: 0.1648  last_time: 0.1612  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:22:13] d2.utils.events INFO:  eta: 0:06:58  iter: 12439  total_loss: 0.5577  loss_ce: 0.03523  loss_objectness: 0.4316  loss_dice: 0.1019  loss_mask: 0.0215    time: 0.1648  last_time: 0.1600  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:22:16] d2.utils.events INFO:  eta: 0:06:55  iter: 12459  total_loss: 0.614  loss_ce: 0.03487  loss_objectness: 0.4365  loss_dice: 0.1172  loss_mask: 0.02103    time: 0.1648  last_time: 0.1637  data_time: 0.0030  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:22:19] d2.utils.events INFO:  eta: 0:06:52  iter: 12479  total_loss: 0.6005  loss_ce: 0.03115  loss_objectness: 0.4321  loss_dice: 0.1207  loss_mask: 0.02132    time: 0.1648  last_time: 0.1670  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:22:22] d2.utils.events INFO:  eta: 0:06:48  iter: 12499  total_loss: 0.6093  loss_ce: 0.0453  loss_objectness: 0.4407  loss_dice: 0.1093  loss_mask: 0.01828    time: 0.1648  last_time: 0.1623  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-06  max_mem: 1632M
[11/22 06:22:26] d2.utils.events INFO:  eta: 0:06:45  iter: 12519  total_loss: 0.7137  loss_ce: 0.06171  loss_objectness: 0.4965  loss_dice: 0.1323  loss_mask: 0.02553    time: 0.1648  last_time: 0.1641  data_time: 0.0029  last_data_time: 0.0038   lr: 5e-06  max_mem: 1632M
[11/22 06:22:29] d2.utils.events INFO:  eta: 0:06:42  iter: 12539  total_loss: 0.5969  loss_ce: 0.02272  loss_objectness: 0.4355  loss_dice: 0.09966  loss_mask: 0.01805    time: 0.1648  last_time: 0.1663  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:22:32] d2.utils.events INFO:  eta: 0:06:39  iter: 12559  total_loss: 0.5707  loss_ce: 0.01415  loss_objectness: 0.4071  loss_dice: 0.09652  loss_mask: 0.02757    time: 0.1648  last_time: 0.1584  data_time: 0.0027  last_data_time: 0.0028   lr: 5e-06  max_mem: 1632M
[11/22 06:22:36] d2.utils.events INFO:  eta: 0:06:35  iter: 12579  total_loss: 0.6094  loss_ce: 0.01649  loss_objectness: 0.4418  loss_dice: 0.1146  loss_mask: 0.0243    time: 0.1648  last_time: 0.1653  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:22:39] d2.utils.events INFO:  eta: 0:06:32  iter: 12599  total_loss: 0.5911  loss_ce: 0.02964  loss_objectness: 0.4315  loss_dice: 0.1145  loss_mask: 0.0211    time: 0.1648  last_time: 0.1602  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:22:42] d2.utils.events INFO:  eta: 0:06:29  iter: 12619  total_loss: 0.6168  loss_ce: 0.0508  loss_objectness: 0.4259  loss_dice: 0.1004  loss_mask: 0.01535    time: 0.1648  last_time: 0.1644  data_time: 0.0028  last_data_time: 0.0032   lr: 5e-06  max_mem: 1632M
[11/22 06:22:45] d2.utils.events INFO:  eta: 0:06:26  iter: 12639  total_loss: 0.6443  loss_ce: 0.02139  loss_objectness: 0.4272  loss_dice: 0.1186  loss_mask: 0.02926    time: 0.1648  last_time: 0.1604  data_time: 0.0029  last_data_time: 0.0022   lr: 5e-06  max_mem: 1632M
[11/22 06:22:49] d2.utils.events INFO:  eta: 0:06:22  iter: 12659  total_loss: 0.6466  loss_ce: 0.03607  loss_objectness: 0.4563  loss_dice: 0.1207  loss_mask: 0.02119    time: 0.1648  last_time: 0.1620  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-06  max_mem: 1632M
[11/22 06:22:52] d2.utils.events INFO:  eta: 0:06:19  iter: 12679  total_loss: 0.5769  loss_ce: 0.02699  loss_objectness: 0.4267  loss_dice: 0.11  loss_mask: 0.02024    time: 0.1648  last_time: 0.1633  data_time: 0.0027  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:22:55] d2.utils.events INFO:  eta: 0:06:16  iter: 12699  total_loss: 0.5754  loss_ce: 0.01659  loss_objectness: 0.4124  loss_dice: 0.1019  loss_mask: 0.0249    time: 0.1648  last_time: 0.1638  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:22:59] d2.utils.events INFO:  eta: 0:06:12  iter: 12719  total_loss: 0.5575  loss_ce: 0.01137  loss_objectness: 0.4106  loss_dice: 0.09783  loss_mask: 0.01771    time: 0.1648  last_time: 0.1597  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:23:02] d2.utils.events INFO:  eta: 0:06:09  iter: 12739  total_loss: 0.6031  loss_ce: 0.03643  loss_objectness: 0.4442  loss_dice: 0.1064  loss_mask: 0.01617    time: 0.1648  last_time: 0.1600  data_time: 0.0028  last_data_time: 0.0020   lr: 5e-06  max_mem: 1632M
[11/22 06:23:05] d2.utils.events INFO:  eta: 0:06:06  iter: 12759  total_loss: 0.6536  loss_ce: 0.04102  loss_objectness: 0.4293  loss_dice: 0.102  loss_mask: 0.021    time: 0.1648  last_time: 0.1636  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:23:08] d2.utils.events INFO:  eta: 0:06:02  iter: 12779  total_loss: 0.7082  loss_ce: 0.03937  loss_objectness: 0.4666  loss_dice: 0.1228  loss_mask: 0.02502    time: 0.1648  last_time: 0.1635  data_time: 0.0030  last_data_time: 0.0043   lr: 5e-06  max_mem: 1632M
[11/22 06:23:12] d2.utils.events INFO:  eta: 0:05:59  iter: 12799  total_loss: 0.6494  loss_ce: 0.0347  loss_objectness: 0.4558  loss_dice: 0.1151  loss_mask: 0.0217    time: 0.1648  last_time: 0.1610  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:23:15] d2.utils.events INFO:  eta: 0:05:56  iter: 12819  total_loss: 0.5856  loss_ce: 0.01896  loss_objectness: 0.4351  loss_dice: 0.1026  loss_mask: 0.0166    time: 0.1648  last_time: 0.1631  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:23:18] d2.utils.events INFO:  eta: 0:05:53  iter: 12839  total_loss: 0.6458  loss_ce: 0.02958  loss_objectness: 0.4618  loss_dice: 0.1189  loss_mask: 0.02074    time: 0.1648  last_time: 0.1636  data_time: 0.0034  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:23:22] d2.utils.events INFO:  eta: 0:05:49  iter: 12859  total_loss: 0.6397  loss_ce: 0.0345  loss_objectness: 0.4544  loss_dice: 0.1077  loss_mask: 0.0211    time: 0.1648  last_time: 0.1614  data_time: 0.0030  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:23:25] d2.utils.events INFO:  eta: 0:05:46  iter: 12879  total_loss: 0.5693  loss_ce: 0.01943  loss_objectness: 0.3985  loss_dice: 0.1025  loss_mask: 0.01968    time: 0.1648  last_time: 0.1632  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:23:28] d2.utils.events INFO:  eta: 0:05:43  iter: 12899  total_loss: 0.5673  loss_ce: 0.01728  loss_objectness: 0.4219  loss_dice: 0.09362  loss_mask: 0.0217    time: 0.1648  last_time: 0.1632  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:23:31] d2.utils.events INFO:  eta: 0:05:39  iter: 12919  total_loss: 0.6057  loss_ce: 0.02646  loss_objectness: 0.4287  loss_dice: 0.1153  loss_mask: 0.01846    time: 0.1648  last_time: 0.1627  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:23:35] d2.utils.events INFO:  eta: 0:05:36  iter: 12939  total_loss: 0.5631  loss_ce: 0.015  loss_objectness: 0.4307  loss_dice: 0.1006  loss_mask: 0.02014    time: 0.1648  last_time: 0.1660  data_time: 0.0028  last_data_time: 0.0034   lr: 5e-06  max_mem: 1632M
[11/22 06:23:38] d2.utils.events INFO:  eta: 0:05:33  iter: 12959  total_loss: 0.5861  loss_ce: 0.02255  loss_objectness: 0.4367  loss_dice: 0.1199  loss_mask: 0.02162    time: 0.1648  last_time: 0.1601  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:23:41] d2.utils.events INFO:  eta: 0:05:30  iter: 12979  total_loss: 0.6233  loss_ce: 0.01955  loss_objectness: 0.4407  loss_dice: 0.106  loss_mask: 0.02184    time: 0.1648  last_time: 0.1655  data_time: 0.0029  last_data_time: 0.0033   lr: 5e-06  max_mem: 1632M
[11/22 06:23:45] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 06:23:45] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 06:23:45] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 06:23:45] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 06:23:45] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 06:23:45] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 06:23:49] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0209 s/iter. Eval: 0.0216 s/iter. Total: 0.0428 s/iter. ETA=0:00:04
[11/22 06:23:54] d2.evaluation.evaluator INFO: Inference done 114/120. Dataloading: 0.0004 s/iter. Inference: 0.0205 s/iter. Eval: 0.0277 s/iter. Total: 0.0487 s/iter. ETA=0:00:00
[11/22 06:23:55] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.411857 (0.055755 s / iter per device, on 1 devices)
[11/22 06:23:55] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.020552 s / iter per device, on 1 devices)
[11/22 06:23:55] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 06:23:55] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 06:23:55] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 06:23:56] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 06:23:56] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.05 seconds.
[11/22 06:23:56] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 06:23:56] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[11/22 06:23:56] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.887 | 13.591 | 6.108  | 0.046 | 14.279 | 51.185 |
[11/22 06:23:56] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 06:23:56] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 06:23:56] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 06:23:56] d2.evaluation.testing INFO: copypaste: 6.8872,13.5908,6.1081,0.0457,14.2791,51.1854
[11/22 06:23:56] d2.utils.events INFO:  eta: 0:05:26  iter: 12999  total_loss: 0.6358  loss_ce: 0.07162  loss_objectness: 0.4503  loss_dice: 0.1143  loss_mask: 0.02046    time: 0.1648  last_time: 0.1677  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:23:59] d2.utils.events INFO:  eta: 0:05:23  iter: 13019  total_loss: 0.6249  loss_ce: 0.02047  loss_objectness: 0.4498  loss_dice: 0.1049  loss_mask: 0.02234    time: 0.1648  last_time: 0.1678  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:24:02] d2.utils.events INFO:  eta: 0:05:20  iter: 13039  total_loss: 0.6296  loss_ce: 0.01662  loss_objectness: 0.4431  loss_dice: 0.1137  loss_mask: 0.01561    time: 0.1648  last_time: 0.1644  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:24:06] d2.utils.events INFO:  eta: 0:05:17  iter: 13059  total_loss: 0.6269  loss_ce: 0.05219  loss_objectness: 0.4207  loss_dice: 0.1098  loss_mask: 0.02323    time: 0.1648  last_time: 0.1616  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:24:09] d2.utils.events INFO:  eta: 0:05:13  iter: 13079  total_loss: 0.5706  loss_ce: 0.02103  loss_objectness: 0.4209  loss_dice: 0.1054  loss_mask: 0.01924    time: 0.1648  last_time: 0.1633  data_time: 0.0027  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:24:12] d2.utils.events INFO:  eta: 0:05:10  iter: 13099  total_loss: 0.6213  loss_ce: 0.007484  loss_objectness: 0.4179  loss_dice: 0.1153  loss_mask: 0.02498    time: 0.1647  last_time: 0.1621  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:24:15] d2.utils.events INFO:  eta: 0:05:07  iter: 13119  total_loss: 0.5685  loss_ce: 0.02196  loss_objectness: 0.4403  loss_dice: 0.09908  loss_mask: 0.01802    time: 0.1647  last_time: 0.1612  data_time: 0.0030  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:24:19] d2.utils.events INFO:  eta: 0:05:04  iter: 13139  total_loss: 0.5662  loss_ce: 0.01805  loss_objectness: 0.3946  loss_dice: 0.09799  loss_mask: 0.02251    time: 0.1647  last_time: 0.1590  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:24:22] d2.utils.events INFO:  eta: 0:05:00  iter: 13159  total_loss: 0.6288  loss_ce: 0.02356  loss_objectness: 0.4307  loss_dice: 0.1053  loss_mask: 0.01865    time: 0.1647  last_time: 0.1660  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-06  max_mem: 1632M
[11/22 06:24:25] d2.utils.events INFO:  eta: 0:04:57  iter: 13179  total_loss: 0.5457  loss_ce: 0.02158  loss_objectness: 0.4062  loss_dice: 0.09672  loss_mask: 0.01972    time: 0.1647  last_time: 0.1594  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:24:29] d2.utils.events INFO:  eta: 0:04:54  iter: 13199  total_loss: 0.67  loss_ce: 0.06579  loss_objectness: 0.48  loss_dice: 0.1181  loss_mask: 0.02124    time: 0.1647  last_time: 0.1596  data_time: 0.0028  last_data_time: 0.0033   lr: 5e-06  max_mem: 1632M
[11/22 06:24:32] d2.utils.events INFO:  eta: 0:04:50  iter: 13219  total_loss: 0.5854  loss_ce: 0.03613  loss_objectness: 0.4047  loss_dice: 0.09895  loss_mask: 0.02187    time: 0.1647  last_time: 0.1663  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:24:35] d2.utils.events INFO:  eta: 0:04:47  iter: 13239  total_loss: 0.6009  loss_ce: 0.01257  loss_objectness: 0.4185  loss_dice: 0.1052  loss_mask: 0.02215    time: 0.1647  last_time: 0.1661  data_time: 0.0029  last_data_time: 0.0045   lr: 5e-06  max_mem: 1632M
[11/22 06:24:38] d2.utils.events INFO:  eta: 0:04:44  iter: 13259  total_loss: 0.595  loss_ce: 0.01301  loss_objectness: 0.4267  loss_dice: 0.1183  loss_mask: 0.01979    time: 0.1647  last_time: 0.1631  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:24:42] d2.utils.events INFO:  eta: 0:04:41  iter: 13279  total_loss: 0.5443  loss_ce: 0.007507  loss_objectness: 0.3972  loss_dice: 0.09735  loss_mask: 0.01887    time: 0.1647  last_time: 0.1663  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:24:45] d2.utils.events INFO:  eta: 0:04:37  iter: 13299  total_loss: 0.5987  loss_ce: 0.02395  loss_objectness: 0.4373  loss_dice: 0.1088  loss_mask: 0.02033    time: 0.1647  last_time: 0.1623  data_time: 0.0035  last_data_time: 0.0034   lr: 5e-06  max_mem: 1632M
[11/22 06:24:48] d2.utils.events INFO:  eta: 0:04:34  iter: 13319  total_loss: 0.5803  loss_ce: 0.03381  loss_objectness: 0.4297  loss_dice: 0.1018  loss_mask: 0.02304    time: 0.1647  last_time: 0.1597  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:24:52] d2.utils.events INFO:  eta: 0:04:31  iter: 13339  total_loss: 0.5362  loss_ce: 0.02042  loss_objectness: 0.3944  loss_dice: 0.08626  loss_mask: 0.01949    time: 0.1647  last_time: 0.1616  data_time: 0.0028  last_data_time: 0.0022   lr: 5e-06  max_mem: 1632M
[11/22 06:24:55] d2.utils.events INFO:  eta: 0:04:28  iter: 13359  total_loss: 0.5436  loss_ce: 0.01105  loss_objectness: 0.4187  loss_dice: 0.09423  loss_mask: 0.01881    time: 0.1647  last_time: 0.1656  data_time: 0.0028  last_data_time: 0.0047   lr: 5e-06  max_mem: 1632M
[11/22 06:24:58] d2.utils.events INFO:  eta: 0:04:24  iter: 13379  total_loss: 0.5495  loss_ce: 0.02641  loss_objectness: 0.4087  loss_dice: 0.1039  loss_mask: 0.01756    time: 0.1647  last_time: 0.1640  data_time: 0.0030  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:25:01] d2.utils.events INFO:  eta: 0:04:21  iter: 13399  total_loss: 0.6023  loss_ce: 0.03279  loss_objectness: 0.4322  loss_dice: 0.09168  loss_mask: 0.02135    time: 0.1647  last_time: 0.1618  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:25:05] d2.utils.events INFO:  eta: 0:04:18  iter: 13419  total_loss: 0.5989  loss_ce: 0.01053  loss_objectness: 0.4339  loss_dice: 0.1088  loss_mask: 0.01924    time: 0.1647  last_time: 0.1635  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:25:08] d2.utils.events INFO:  eta: 0:04:15  iter: 13439  total_loss: 0.5879  loss_ce: 0.01607  loss_objectness: 0.4419  loss_dice: 0.113  loss_mask: 0.0206    time: 0.1647  last_time: 0.1633  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:25:11] d2.utils.events INFO:  eta: 0:04:11  iter: 13459  total_loss: 0.5577  loss_ce: 0.01883  loss_objectness: 0.3974  loss_dice: 0.09773  loss_mask: 0.01832    time: 0.1647  last_time: 0.1642  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:25:15] d2.utils.events INFO:  eta: 0:04:08  iter: 13479  total_loss: 0.6148  loss_ce: 0.04033  loss_objectness: 0.4253  loss_dice: 0.1051  loss_mask: 0.01685    time: 0.1647  last_time: 0.1621  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-06  max_mem: 1632M
[11/22 06:25:18] d2.utils.events INFO:  eta: 0:04:05  iter: 13499  total_loss: 0.6392  loss_ce: 0.0372  loss_objectness: 0.4299  loss_dice: 0.1156  loss_mask: 0.01884    time: 0.1647  last_time: 0.1670  data_time: 0.0028  last_data_time: 0.0032   lr: 5e-06  max_mem: 1632M
[11/22 06:25:21] d2.utils.events INFO:  eta: 0:04:02  iter: 13519  total_loss: 0.4558  loss_ce: 0.003833  loss_objectness: 0.3642  loss_dice: 0.0751  loss_mask: 0.02331    time: 0.1647  last_time: 0.1662  data_time: 0.0027  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:25:25] d2.utils.events INFO:  eta: 0:03:58  iter: 13539  total_loss: 0.549  loss_ce: 0.008898  loss_objectness: 0.4041  loss_dice: 0.09328  loss_mask: 0.01998    time: 0.1647  last_time: 0.1628  data_time: 0.0027  last_data_time: 0.0028   lr: 5e-06  max_mem: 1632M
[11/22 06:25:28] d2.utils.events INFO:  eta: 0:03:55  iter: 13559  total_loss: 0.5539  loss_ce: 0.03619  loss_objectness: 0.4152  loss_dice: 0.09552  loss_mask: 0.016    time: 0.1647  last_time: 0.1639  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:25:31] d2.utils.events INFO:  eta: 0:03:52  iter: 13579  total_loss: 0.5802  loss_ce: 0.01148  loss_objectness: 0.4037  loss_dice: 0.1094  loss_mask: 0.019    time: 0.1647  last_time: 0.1640  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:25:34] d2.utils.events INFO:  eta: 0:03:48  iter: 13599  total_loss: 0.5715  loss_ce: 0.01228  loss_objectness: 0.4056  loss_dice: 0.08928  loss_mask: 0.02209    time: 0.1647  last_time: 0.1619  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:25:38] d2.utils.events INFO:  eta: 0:03:45  iter: 13619  total_loss: 0.5459  loss_ce: 0.01892  loss_objectness: 0.4067  loss_dice: 0.1005  loss_mask: 0.01774    time: 0.1647  last_time: 0.1678  data_time: 0.0029  last_data_time: 0.0037   lr: 5e-06  max_mem: 1632M
[11/22 06:25:41] d2.utils.events INFO:  eta: 0:03:42  iter: 13639  total_loss: 0.6252  loss_ce: 0.02769  loss_objectness: 0.437  loss_dice: 0.1249  loss_mask: 0.01816    time: 0.1647  last_time: 0.1628  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:25:44] d2.utils.events INFO:  eta: 0:03:39  iter: 13659  total_loss: 0.5598  loss_ce: 0.006467  loss_objectness: 0.4108  loss_dice: 0.09884  loss_mask: 0.01929    time: 0.1647  last_time: 0.1634  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:25:47] d2.utils.events INFO:  eta: 0:03:35  iter: 13679  total_loss: 0.6067  loss_ce: 0.0266  loss_objectness: 0.4343  loss_dice: 0.108  loss_mask: 0.01878    time: 0.1647  last_time: 0.1604  data_time: 0.0028  last_data_time: 0.0034   lr: 5e-06  max_mem: 1632M
[11/22 06:25:51] d2.utils.events INFO:  eta: 0:03:32  iter: 13699  total_loss: 0.5718  loss_ce: 0.01725  loss_objectness: 0.4257  loss_dice: 0.09167  loss_mask: 0.02001    time: 0.1647  last_time: 0.1646  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:25:54] d2.utils.events INFO:  eta: 0:03:29  iter: 13719  total_loss: 0.5548  loss_ce: 0.02164  loss_objectness: 0.4292  loss_dice: 0.08995  loss_mask: 0.02457    time: 0.1647  last_time: 0.1646  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:25:57] d2.utils.events INFO:  eta: 0:03:26  iter: 13739  total_loss: 0.5791  loss_ce: 0.02033  loss_objectness: 0.4283  loss_dice: 0.1206  loss_mask: 0.01929    time: 0.1647  last_time: 0.1610  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:26:01] d2.utils.events INFO:  eta: 0:03:22  iter: 13759  total_loss: 0.5643  loss_ce: 0.01735  loss_objectness: 0.4301  loss_dice: 0.1037  loss_mask: 0.01904    time: 0.1647  last_time: 0.1622  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:26:04] d2.utils.events INFO:  eta: 0:03:19  iter: 13779  total_loss: 0.527  loss_ce: 0.02147  loss_objectness: 0.3868  loss_dice: 0.09921  loss_mask: 0.0212    time: 0.1647  last_time: 0.1653  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-06  max_mem: 1632M
[11/22 06:26:07] d2.utils.events INFO:  eta: 0:03:16  iter: 13799  total_loss: 0.5612  loss_ce: 0.02547  loss_objectness: 0.424  loss_dice: 0.09639  loss_mask: 0.01736    time: 0.1647  last_time: 0.1646  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:26:10] d2.utils.events INFO:  eta: 0:03:12  iter: 13819  total_loss: 0.5349  loss_ce: 0.01527  loss_objectness: 0.3935  loss_dice: 0.09848  loss_mask: 0.01715    time: 0.1647  last_time: 0.1589  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:26:14] d2.utils.events INFO:  eta: 0:03:09  iter: 13839  total_loss: 0.5355  loss_ce: 0.00908  loss_objectness: 0.4088  loss_dice: 0.09543  loss_mask: 0.01763    time: 0.1647  last_time: 0.1645  data_time: 0.0028  last_data_time: 0.0035   lr: 5e-06  max_mem: 1632M
[11/22 06:26:17] d2.utils.events INFO:  eta: 0:03:06  iter: 13859  total_loss: 0.4491  loss_ce: 0.001474  loss_objectness: 0.3395  loss_dice: 0.08286  loss_mask: 0.01811    time: 0.1647  last_time: 0.1643  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:26:20] d2.utils.events INFO:  eta: 0:03:03  iter: 13879  total_loss: 0.5782  loss_ce: 0.01945  loss_objectness: 0.3924  loss_dice: 0.1018  loss_mask: 0.02061    time: 0.1647  last_time: 0.1600  data_time: 0.0030  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:26:24] d2.utils.events INFO:  eta: 0:02:59  iter: 13899  total_loss: 0.5772  loss_ce: 0.04308  loss_objectness: 0.4153  loss_dice: 0.09205  loss_mask: 0.0186    time: 0.1647  last_time: 0.1745  data_time: 0.0030  last_data_time: 0.0039   lr: 5e-06  max_mem: 1632M
[11/22 06:26:27] d2.utils.events INFO:  eta: 0:02:56  iter: 13919  total_loss: 0.5401  loss_ce: 0.01228  loss_objectness: 0.3861  loss_dice: 0.09835  loss_mask: 0.02028    time: 0.1647  last_time: 0.1670  data_time: 0.0030  last_data_time: 0.0031   lr: 5e-06  max_mem: 1632M
[11/22 06:26:30] d2.utils.events INFO:  eta: 0:02:53  iter: 13939  total_loss: 0.5728  loss_ce: 0.02013  loss_objectness: 0.4184  loss_dice: 0.0997  loss_mask: 0.02116    time: 0.1647  last_time: 0.1625  data_time: 0.0031  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:26:34] d2.utils.events INFO:  eta: 0:02:50  iter: 13959  total_loss: 0.4614  loss_ce: 0.007136  loss_objectness: 0.3579  loss_dice: 0.08955  loss_mask: 0.02273    time: 0.1647  last_time: 0.1597  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:26:37] d2.utils.events INFO:  eta: 0:02:46  iter: 13979  total_loss: 0.5651  loss_ce: 0.00912  loss_objectness: 0.4265  loss_dice: 0.09312  loss_mask: 0.0233    time: 0.1647  last_time: 0.1660  data_time: 0.0026  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:26:40] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 06:26:40] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 06:26:40] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 06:26:40] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 06:26:40] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 06:26:40] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 06:26:45] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0320 s/iter. Eval: 0.0195 s/iter. Total: 0.0517 s/iter. ETA=0:00:05
[11/22 06:26:50] d2.evaluation.evaluator INFO: Inference done 119/120. Dataloading: 0.0003 s/iter. Inference: 0.0211 s/iter. Eval: 0.0253 s/iter. Total: 0.0467 s/iter. ETA=0:00:00
[11/22 06:26:51] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.193101 (0.053853 s / iter per device, on 1 devices)
[11/22 06:26:51] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.021072 s / iter per device, on 1 devices)
[11/22 06:26:51] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 06:26:51] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 06:26:51] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 06:26:51] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 06:26:51] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.04 seconds.
[11/22 06:26:51] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 06:26:51] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 06:26:51] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.665 | 13.112 | 6.096  | 0.034 | 14.030 | 51.524 |
[11/22 06:26:51] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 06:26:51] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 06:26:51] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 06:26:51] d2.evaluation.testing INFO: copypaste: 6.6647,13.1124,6.0956,0.0338,14.0298,51.5241
[11/22 06:26:51] d2.utils.events INFO:  eta: 0:02:43  iter: 13999  total_loss: 0.6851  loss_ce: 0.04582  loss_objectness: 0.4527  loss_dice: 0.1233  loss_mask: 0.01711    time: 0.1647  last_time: 0.1648  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-06  max_mem: 1632M
[11/22 06:26:54] d2.utils.events INFO:  eta: 0:02:40  iter: 14019  total_loss: 0.5859  loss_ce: 0.01628  loss_objectness: 0.4146  loss_dice: 0.1061  loss_mask: 0.01689    time: 0.1647  last_time: 0.1662  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:26:57] d2.utils.events INFO:  eta: 0:02:37  iter: 14039  total_loss: 0.6057  loss_ce: 0.01766  loss_objectness: 0.4146  loss_dice: 0.1007  loss_mask: 0.02032    time: 0.1647  last_time: 0.1621  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:27:01] d2.utils.events INFO:  eta: 0:02:33  iter: 14059  total_loss: 0.5193  loss_ce: 0.01039  loss_objectness: 0.3785  loss_dice: 0.0953  loss_mask: 0.0182    time: 0.1647  last_time: 0.1629  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:27:04] d2.utils.events INFO:  eta: 0:02:30  iter: 14079  total_loss: 0.5511  loss_ce: 0.003449  loss_objectness: 0.4351  loss_dice: 0.09846  loss_mask: 0.01855    time: 0.1647  last_time: 0.1588  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:27:07] d2.utils.events INFO:  eta: 0:02:27  iter: 14099  total_loss: 0.6266  loss_ce: 0.03446  loss_objectness: 0.4426  loss_dice: 0.1045  loss_mask: 0.01932    time: 0.1647  last_time: 0.1614  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:27:11] d2.utils.events INFO:  eta: 0:02:23  iter: 14119  total_loss: 0.569  loss_ce: 0.01022  loss_objectness: 0.4224  loss_dice: 0.0917  loss_mask: 0.01851    time: 0.1647  last_time: 0.1616  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:27:14] d2.utils.events INFO:  eta: 0:02:20  iter: 14139  total_loss: 0.4867  loss_ce: 0.01074  loss_objectness: 0.3771  loss_dice: 0.08217  loss_mask: 0.02074    time: 0.1647  last_time: 0.1631  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:27:17] d2.utils.events INFO:  eta: 0:02:17  iter: 14159  total_loss: 0.5551  loss_ce: 0.009403  loss_objectness: 0.4028  loss_dice: 0.09552  loss_mask: 0.02047    time: 0.1647  last_time: 0.1688  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:27:20] d2.utils.events INFO:  eta: 0:02:14  iter: 14179  total_loss: 0.5214  loss_ce: 0.02212  loss_objectness: 0.4041  loss_dice: 0.07814  loss_mask: 0.0154    time: 0.1647  last_time: 0.1630  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:27:24] d2.utils.events INFO:  eta: 0:02:10  iter: 14199  total_loss: 0.508  loss_ce: 0.008101  loss_objectness: 0.3852  loss_dice: 0.08884  loss_mask: 0.02132    time: 0.1647  last_time: 0.1629  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:27:27] d2.utils.events INFO:  eta: 0:02:07  iter: 14219  total_loss: 0.5755  loss_ce: 0.01567  loss_objectness: 0.4211  loss_dice: 0.1033  loss_mask: 0.01902    time: 0.1647  last_time: 0.1618  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:27:30] d2.utils.events INFO:  eta: 0:02:04  iter: 14239  total_loss: 0.5925  loss_ce: 0.01291  loss_objectness: 0.4395  loss_dice: 0.1099  loss_mask: 0.02084    time: 0.1647  last_time: 0.1633  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:27:34] d2.utils.events INFO:  eta: 0:02:00  iter: 14259  total_loss: 0.4805  loss_ce: 0.002422  loss_objectness: 0.3909  loss_dice: 0.0825  loss_mask: 0.02128    time: 0.1647  last_time: 0.1629  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:27:37] d2.utils.events INFO:  eta: 0:01:57  iter: 14279  total_loss: 0.6044  loss_ce: 0.02885  loss_objectness: 0.471  loss_dice: 0.08662  loss_mask: 0.01946    time: 0.1647  last_time: 0.1628  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-06  max_mem: 1632M
[11/22 06:27:40] d2.utils.events INFO:  eta: 0:01:54  iter: 14299  total_loss: 0.5305  loss_ce: 0.006043  loss_objectness: 0.3842  loss_dice: 0.1008  loss_mask: 0.01875    time: 0.1647  last_time: 0.1630  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:27:43] d2.utils.events INFO:  eta: 0:01:51  iter: 14319  total_loss: 0.5377  loss_ce: 0.004145  loss_objectness: 0.4006  loss_dice: 0.09575  loss_mask: 0.01939    time: 0.1647  last_time: 0.1602  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:27:47] d2.utils.events INFO:  eta: 0:01:47  iter: 14339  total_loss: 0.5822  loss_ce: 0.02153  loss_objectness: 0.4041  loss_dice: 0.106  loss_mask: 0.01854    time: 0.1647  last_time: 0.1621  data_time: 0.0027  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:27:50] d2.utils.events INFO:  eta: 0:01:44  iter: 14359  total_loss: 0.5504  loss_ce: 0.006395  loss_objectness: 0.3916  loss_dice: 0.09169  loss_mask: 0.01845    time: 0.1647  last_time: 0.1609  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:27:53] d2.utils.events INFO:  eta: 0:01:41  iter: 14379  total_loss: 0.5157  loss_ce: 0.002911  loss_objectness: 0.3939  loss_dice: 0.08695  loss_mask: 0.01991    time: 0.1647  last_time: 0.1642  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-06  max_mem: 1632M
[11/22 06:27:56] d2.utils.events INFO:  eta: 0:01:38  iter: 14399  total_loss: 0.5207  loss_ce: 0.005862  loss_objectness: 0.3923  loss_dice: 0.08613  loss_mask: 0.02254    time: 0.1647  last_time: 0.1607  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:28:00] d2.utils.events INFO:  eta: 0:01:34  iter: 14419  total_loss: 0.5096  loss_ce: 0.007551  loss_objectness: 0.3751  loss_dice: 0.08466  loss_mask: 0.01927    time: 0.1647  last_time: 0.1642  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:28:03] d2.utils.events INFO:  eta: 0:01:31  iter: 14439  total_loss: 0.5148  loss_ce: 0.006194  loss_objectness: 0.4012  loss_dice: 0.09537  loss_mask: 0.01817    time: 0.1647  last_time: 0.1614  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:28:06] d2.utils.events INFO:  eta: 0:01:28  iter: 14459  total_loss: 0.5347  loss_ce: 0.01504  loss_objectness: 0.4067  loss_dice: 0.08662  loss_mask: 0.01695    time: 0.1647  last_time: 0.1650  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-06  max_mem: 1632M
[11/22 06:28:10] d2.utils.events INFO:  eta: 0:01:24  iter: 14479  total_loss: 0.4954  loss_ce: 0.01115  loss_objectness: 0.3871  loss_dice: 0.08149  loss_mask: 0.01985    time: 0.1647  last_time: 0.1621  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:28:13] d2.utils.events INFO:  eta: 0:01:21  iter: 14499  total_loss: 0.5518  loss_ce: 0.01086  loss_objectness: 0.3931  loss_dice: 0.09184  loss_mask: 0.01942    time: 0.1647  last_time: 0.1628  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:28:16] d2.utils.events INFO:  eta: 0:01:18  iter: 14519  total_loss: 0.5793  loss_ce: 0.01985  loss_objectness: 0.4186  loss_dice: 0.09121  loss_mask: 0.01899    time: 0.1647  last_time: 0.1654  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:28:19] d2.utils.events INFO:  eta: 0:01:15  iter: 14539  total_loss: 0.5945  loss_ce: 0.01541  loss_objectness: 0.4191  loss_dice: 0.1125  loss_mask: 0.02036    time: 0.1646  last_time: 0.1621  data_time: 0.0029  last_data_time: 0.0022   lr: 5e-06  max_mem: 1632M
[11/22 06:28:23] d2.utils.events INFO:  eta: 0:01:11  iter: 14559  total_loss: 0.5615  loss_ce: 0.01086  loss_objectness: 0.4071  loss_dice: 0.1064  loss_mask: 0.01845    time: 0.1646  last_time: 0.1604  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:28:26] d2.utils.events INFO:  eta: 0:01:08  iter: 14579  total_loss: 0.5285  loss_ce: 0.0074  loss_objectness: 0.3877  loss_dice: 0.1093  loss_mask: 0.01667    time: 0.1646  last_time: 0.1644  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:28:29] d2.utils.events INFO:  eta: 0:01:05  iter: 14599  total_loss: 0.5541  loss_ce: 0.01412  loss_objectness: 0.402  loss_dice: 0.08966  loss_mask: 0.02141    time: 0.1646  last_time: 0.1694  data_time: 0.0029  last_data_time: 0.0037   lr: 5e-06  max_mem: 1632M
[11/22 06:28:33] d2.utils.events INFO:  eta: 0:01:02  iter: 14619  total_loss: 0.5619  loss_ce: 0.02694  loss_objectness: 0.4004  loss_dice: 0.102  loss_mask: 0.02099    time: 0.1646  last_time: 0.1632  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:28:36] d2.utils.events INFO:  eta: 0:00:58  iter: 14639  total_loss: 0.5414  loss_ce: 0.01468  loss_objectness: 0.374  loss_dice: 0.08745  loss_mask: 0.01703    time: 0.1646  last_time: 0.1609  data_time: 0.0027  last_data_time: 0.0029   lr: 5e-06  max_mem: 1632M
[11/22 06:28:39] d2.utils.events INFO:  eta: 0:00:55  iter: 14659  total_loss: 0.5102  loss_ce: 0.004951  loss_objectness: 0.3777  loss_dice: 0.08746  loss_mask: 0.01856    time: 0.1646  last_time: 0.1605  data_time: 0.0028  last_data_time: 0.0034   lr: 5e-06  max_mem: 1632M
[11/22 06:28:42] d2.utils.events INFO:  eta: 0:00:52  iter: 14679  total_loss: 0.5569  loss_ce: 0.01103  loss_objectness: 0.4271  loss_dice: 0.09225  loss_mask: 0.02103    time: 0.1646  last_time: 0.1625  data_time: 0.0028  last_data_time: 0.0037   lr: 5e-06  max_mem: 1632M
[11/22 06:28:46] d2.utils.events INFO:  eta: 0:00:48  iter: 14699  total_loss: 0.5725  loss_ce: 0.006855  loss_objectness: 0.4181  loss_dice: 0.09212  loss_mask: 0.0218    time: 0.1646  last_time: 0.1598  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:28:49] d2.utils.events INFO:  eta: 0:00:45  iter: 14719  total_loss: 0.5381  loss_ce: 0.01362  loss_objectness: 0.3864  loss_dice: 0.1009  loss_mask: 0.01578    time: 0.1646  last_time: 0.1627  data_time: 0.0028  last_data_time: 0.0034   lr: 5e-06  max_mem: 1632M
[11/22 06:28:52] d2.utils.events INFO:  eta: 0:00:42  iter: 14739  total_loss: 0.5065  loss_ce: 0.002644  loss_objectness: 0.3739  loss_dice: 0.07867  loss_mask: 0.01977    time: 0.1646  last_time: 0.1610  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1632M
[11/22 06:28:55] d2.utils.events INFO:  eta: 0:00:39  iter: 14759  total_loss: 0.5717  loss_ce: 0.02098  loss_objectness: 0.4078  loss_dice: 0.1141  loss_mask: 0.01896    time: 0.1646  last_time: 0.1674  data_time: 0.0029  last_data_time: 0.0021   lr: 5e-06  max_mem: 1632M
[11/22 06:28:59] d2.utils.events INFO:  eta: 0:00:35  iter: 14779  total_loss: 0.4771  loss_ce: 0.003332  loss_objectness: 0.3747  loss_dice: 0.07224  loss_mask: 0.01973    time: 0.1646  last_time: 0.1624  data_time: 0.0026  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:29:02] d2.utils.events INFO:  eta: 0:00:32  iter: 14799  total_loss: 0.5108  loss_ce: 0.006291  loss_objectness: 0.3891  loss_dice: 0.08625  loss_mask: 0.01712    time: 0.1646  last_time: 0.1599  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:29:05] d2.utils.events INFO:  eta: 0:00:29  iter: 14819  total_loss: 0.4709  loss_ce: 0.004059  loss_objectness: 0.3763  loss_dice: 0.08369  loss_mask: 0.01716    time: 0.1646  last_time: 0.1605  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-06  max_mem: 1632M
[11/22 06:29:09] d2.utils.events INFO:  eta: 0:00:26  iter: 14839  total_loss: 0.59  loss_ce: 0.01047  loss_objectness: 0.4109  loss_dice: 0.09927  loss_mask: 0.0191    time: 0.1646  last_time: 0.1604  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:29:12] d2.utils.events INFO:  eta: 0:00:22  iter: 14859  total_loss: 0.5788  loss_ce: 0.01351  loss_objectness: 0.429  loss_dice: 0.09881  loss_mask: 0.01896    time: 0.1646  last_time: 0.1622  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-06  max_mem: 1632M
[11/22 06:29:15] d2.utils.events INFO:  eta: 0:00:19  iter: 14879  total_loss: 0.5055  loss_ce: 0.01193  loss_objectness: 0.3849  loss_dice: 0.07809  loss_mask: 0.02227    time: 0.1646  last_time: 0.1605  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:29:18] d2.utils.events INFO:  eta: 0:00:16  iter: 14899  total_loss: 0.4954  loss_ce: 0.005784  loss_objectness: 0.3734  loss_dice: 0.07945  loss_mask: 0.0176    time: 0.1646  last_time: 0.1623  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:29:22] d2.utils.events INFO:  eta: 0:00:13  iter: 14919  total_loss: 0.5554  loss_ce: 0.00365  loss_objectness: 0.405  loss_dice: 0.09451  loss_mask: 0.01879    time: 0.1646  last_time: 0.1735  data_time: 0.0029  last_data_time: 0.0045   lr: 5e-06  max_mem: 1632M
[11/22 06:29:25] d2.utils.events INFO:  eta: 0:00:09  iter: 14939  total_loss: 0.4895  loss_ce: 0.003989  loss_objectness: 0.3609  loss_dice: 0.0843  loss_mask: 0.02233    time: 0.1646  last_time: 0.1640  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-06  max_mem: 1632M
[11/22 06:29:28] d2.utils.events INFO:  eta: 0:00:06  iter: 14959  total_loss: 0.491  loss_ce: 0.006317  loss_objectness: 0.3641  loss_dice: 0.08865  loss_mask: 0.01945    time: 0.1646  last_time: 0.1627  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1632M
[11/22 06:29:32] d2.utils.events INFO:  eta: 0:00:03  iter: 14979  total_loss: 0.5315  loss_ce: 0.01292  loss_objectness: 0.3937  loss_dice: 0.0899  loss_mask: 0.0149    time: 0.1646  last_time: 0.1619  data_time: 0.0028  last_data_time: 0.0033   lr: 5e-06  max_mem: 1632M
[11/22 06:29:35] fvcore.common.checkpoint INFO: Saving checkpoint to output/crack_model_turbo\model_0014999.pth
[11/22 06:29:35] fvcore.common.checkpoint INFO: Saving checkpoint to output/crack_model_turbo\model_final.pth
[11/22 06:29:37] d2.utils.events INFO:  eta: 0:00:00  iter: 14999  total_loss: 0.509  loss_ce: 0.008679  loss_objectness: 0.3869  loss_dice: 0.09184  loss_mask: 0.02072    time: 0.1646  last_time: 0.1625  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1632M
[11/22 06:29:37] d2.engine.hooks INFO: Overall training speed: 14998 iterations in 0:41:08 (0.1646 s / it)
[11/22 06:29:37] d2.engine.hooks INFO: Total training time: 0:44:24 (0:03:15 on hooks)
[11/22 06:29:37] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 06:29:37] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 06:29:37] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 06:29:37] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 06:29:37] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 06:29:37] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 06:29:41] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0360 s/iter. Eval: 0.0142 s/iter. Total: 0.0505 s/iter. ETA=0:00:05
[11/22 06:29:47] d2.evaluation.evaluator INFO: Total inference time: 0:00:05.933759 (0.051598 s / iter per device, on 1 devices)
[11/22 06:29:47] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.021204 s / iter per device, on 1 devices)
[11/22 06:29:47] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 06:29:47] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 06:29:47] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 06:29:47] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 06:29:47] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.03 seconds.
[11/22 06:29:47] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 06:29:47] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[11/22 06:29:47] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.431 | 12.473 | 5.859  | 0.043 | 13.707 | 51.758 |
[11/22 06:29:47] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 06:29:47] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 06:29:47] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 06:29:47] d2.evaluation.testing INFO: copypaste: 6.4311,12.4726,5.8588,0.0428,13.7070,51.7578
[11/22 07:12:26] detectron2 INFO: Rank of current process: 0. World size: 1
[11/22 07:12:27] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]
numpy                            2.2.6
detectron2                       0.6 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\detectron2
Compiler                         MSVC 195035718
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.9.1+cu126 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  True
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4060 (arch=8.9)
Driver version                   572.42
CUDA_HOME                        None - invalid!
Pillow                           12.0.0
torchvision                      0.24.1+cu126 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torchvision
torchvision arch flags           C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 194234444
  - Intel(R) oneAPI Math Kernel Library Version 2025.3-Product Build 20251007 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.7.1 (Git Hash 8d263e693366ef8db40acc569cc7d8edf644556d)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.6
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 91.0.2  (built against CUDA 12.9)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, COMMIT_SHA=5811a8d7da873dd699ff6687092c225caffcf1bb, CUDA_VERSION=12.6, CUDNN_VERSION=9.10.2, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/pytorch/.ci/pytorch/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, USE_XCCL=OFF, USE_XPU=OFF, 

[11/22 07:12:27] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sparse_inst_r50_giam_crack_gabor.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:49153', opts=['SOLVER.STEPS', '(10000,)', 'SOLVER.IMS_PER_BATCH', '8', 'SOLVER.BASE_LR', '0.00005', 'SOLVER.AMP.ENABLED', 'True', 'INPUT.MIN_SIZE_TRAIN', '(512,)', 'INPUT.MIN_SIZE_TEST', '512', 'OUTPUT_DIR', 'output/crack_model_turbo'])
[11/22 07:12:27] detectron2 INFO: Contents of args.config_file=configs/sparse_inst_r50_giam_crack_gabor.yaml:
# Configuration for SparseInst with ResNet-50 backbone for crack detection with Gabor Filtering
# Based on sparse_inst_r50_giam_crack.yaml

_BASE_: "Base-SparseInst.yaml"

MODEL:
  WEIGHTS: "pretrained_models/R-50.pkl"
  SPARSE_INST:
    DECODER:
      NUM_CLASSES: 1  # Only one class: crack
      NUM_MASKS: 100  # Maximum number of instances to detect
    DATASET_MAPPER: "GaborDatasetMapper" # Use the Gabor Filter Mapper

DATASETS:
  # Update these names after registering your dataset
  # Example: ("deepcracks_train",)
  TRAIN: ("deepcracks_train",)
  TEST: ("deepcracks_val",)

SOLVER:
  IMS_PER_BATCH: 16  # Reduced from 64 for smaller datasets, adjust based on GPU memory
  BASE_LR: 0.0001  # Slightly higher learning rate for fine-tuning
  STEPS: (10000, 15000)  # Adjust based on your dataset size
  MAX_ITER: 15000  # Adjust based on your dataset size
  WEIGHT_DECAY: 0.05
  # For smaller datasets, you might want to reduce learning rate schedule
  # STEPS: (5000, 10000)
  # MAX_ITER: 15000

INPUT:
  MIN_SIZE_TRAIN: (416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 853
  MIN_SIZE_TEST: 640
  MAX_SIZE_TEST: 853
  FORMAT: "RGB"
  MASK_FORMAT: "bitmask"

TEST:
  EVAL_PERIOD: 1000  # Evaluate every 1000 iterations

DATALOADER:
  NUM_WORKERS: 4  # Adjust based on your system

OUTPUT_DIR: "output/sparse_inst_r50_giam_crack_gabor"


[11/22 07:12:27] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - deepcracks_val
  TRAIN:
  - deepcracks_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: RGB
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 853
  MAX_SIZE_TRAIN: 853
  MIN_SIZE_TEST: 512
  MIN_SIZE_TRAIN:
  - 512
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_backbone
  CSPNET:
    NAME: darknet53
    NORM: ''
    OUT_FEATURES:
    - csp1
    - csp2
    - csp3
    - csp4
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: SparseInst
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  PVT:
    LINEAR: false
    NAME: b1
    OUT_FEATURES:
    - p2
    - p3
    - p4
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SPARSE_INST:
    CLS_THRESHOLD: 0.005
    DATASET_MAPPER: GaborDatasetMapper
    DECODER:
      GROUPS: 4
      INST:
        CONVS: 4
        DIM: 256
      KERNEL_DIM: 128
      MASK:
        CONVS: 4
        DIM: 256
      NAME: GroupIAMDecoder
      NUM_CLASSES: 1
      NUM_MASKS: 100
      OUTPUT_IAM: false
      SCALE_FACTOR: 2.0
    ENCODER:
      IN_FEATURES:
      - res3
      - res4
      - res5
      NAME: InstanceContextEncoder
      NORM: ''
      NUM_CHANNELS: 256
    LOSS:
      CLASS_WEIGHT: 2.0
      ITEMS:
      - labels
      - masks
      MASK_DICE_WEIGHT: 2.0
      MASK_PIXEL_WEIGHT: 5.0
      NAME: SparseInstCriterion
      OBJECTNESS_WEIGHT: 1.0
    MASK_THRESHOLD: 0.45
    MATCHER:
      ALPHA: 0.8
      BETA: 0.2
      NAME: SparseInstMatcher
    MAX_DETECTIONS: 100
  WEIGHTS: pretrained_models/R-50.pkl
OUTPUT_DIR: output/crack_model_turbo
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  AMSGRAD: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 15000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 10000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/22 07:12:27] detectron2 INFO: Full config saved to output/crack_model_turbo\config.yaml
[11/22 07:12:27] d2.utils.env INFO: Using a generated random seed 27265451
[11/22 07:12:27] d2.engine.defaults INFO: Model:
SparseInst(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (encoder): InstanceContextEncoder(
    (fpn_laterals): ModuleList(
      (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (fpn_outputs): ModuleList(
      (0-2): 3 x Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (ppm): PyramidPoolingModule(
      (stages): ModuleList(
        (0): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(2, 2))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(3, 3))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(6, 6))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (bottleneck): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (fusion): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
  )
  (decoder): GroupIAMDecoder(
    (inst_branch): GroupInstanceBranch(
      (inst_convs): Sequential(
        (0): Conv2d(258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU(inplace=True)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU(inplace=True)
      )
      (iam_conv): Conv2d(256, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)
      (fc): Linear(in_features=1024, out_features=1024, bias=True)
      (cls_score): Linear(in_features=1024, out_features=1, bias=True)
      (mask_kernel): Linear(in_features=1024, out_features=128, bias=True)
      (objectness): Linear(in_features=1024, out_features=1, bias=True)
    )
    (mask_branch): MaskBranch(
      (mask_convs): Sequential(
        (0): Conv2d(258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU(inplace=True)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU(inplace=True)
      )
      (projection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (criterion): SparseInstCriterion(
    (matcher): SparseInstMatcher()
  )
)
[11/22 07:12:27] sparseinst.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(512,), max_size=853, sample_style='choice')]
[11/22 07:12:27] d2.data.datasets.coco INFO: Loaded 382 images in COCO format from datasets/DeepCrack/annotations/train.json
[11/22 07:12:27] d2.data.build INFO: Removed 0 images with no usable annotations. 382 images left.
[11/22 07:12:27] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   crack    | 1250         |
|            |              |[0m
[11/22 07:12:27] d2.data.build INFO: Using training sampler TrainingSampler
[11/22 07:12:27] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 07:12:27] d2.data.common INFO: Serializing 382 elements to byte tensors and concatenating them all ...
[11/22 07:12:27] d2.data.common INFO: Serialized dataset takes 0.66 MiB
[11/22 07:12:27] d2.data.build INFO: Making batched data loader with batch_size=8
[11/22 07:12:27] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from pretrained_models/R-50.pkl ...
[11/22 07:12:27] fvcore.common.checkpoint INFO: [Checkpointer] Loading from pretrained_models/R-50.pkl ...
[11/22 07:12:27] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[11/22 07:12:27] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone - Total num: 54
[11/22 07:12:27] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mdecoder.inst_branch.cls_score.{bias, weight}[0m
[34mdecoder.inst_branch.fc.{bias, weight}[0m
[34mdecoder.inst_branch.iam_conv.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.0.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.2.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.4.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.6.{bias, weight}[0m
[34mdecoder.inst_branch.mask_kernel.{bias, weight}[0m
[34mdecoder.inst_branch.objectness.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.0.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.2.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.4.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.6.{bias, weight}[0m
[34mdecoder.mask_branch.projection.{bias, weight}[0m
[34mencoder.fpn_laterals.0.{bias, weight}[0m
[34mencoder.fpn_laterals.1.{bias, weight}[0m
[34mencoder.fpn_laterals.2.{bias, weight}[0m
[34mencoder.fpn_outputs.0.{bias, weight}[0m
[34mencoder.fpn_outputs.1.{bias, weight}[0m
[34mencoder.fpn_outputs.2.{bias, weight}[0m
[34mencoder.fusion.{bias, weight}[0m
[34mencoder.ppm.bottleneck.{bias, weight}[0m
[34mencoder.ppm.stages.0.1.{bias, weight}[0m
[34mencoder.ppm.stages.1.1.{bias, weight}[0m
[34mencoder.ppm.stages.2.1.{bias, weight}[0m
[34mencoder.ppm.stages.3.1.{bias, weight}[0m
[11/22 07:12:27] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[11/22 07:12:27] d2.engine.train_loop INFO: Starting training from iteration 0
[11/22 07:12:49] d2.utils.events INFO:  eta: 1:14:42  iter: 19  total_loss: 72.44  loss_ce: 2.44  loss_objectness: 0.7157  loss_dice: 1.96  loss_mask: 67.36    time: 0.3093  last_time: 0.3039  data_time: 0.7057  last_data_time: 0.0048   lr: 9.9905e-07  max_mem: 2549M
[11/22 07:12:55] d2.utils.events INFO:  eta: 1:14:52  iter: 39  total_loss: 7.658  loss_ce: 2.372  loss_objectness: 0.6974  loss_dice: 1.991  loss_mask: 2.606    time: 0.3051  last_time: 0.3029  data_time: 0.0048  last_data_time: 0.0049   lr: 1.998e-06  max_mem: 2549M
[11/22 07:13:01] d2.utils.events INFO:  eta: 1:14:55  iter: 59  total_loss: 7.228  loss_ce: 2.31  loss_objectness: 0.6544  loss_dice: 1.999  loss_mask: 2.249    time: 0.3041  last_time: 0.3004  data_time: 0.0049  last_data_time: 0.0052   lr: 2.997e-06  max_mem: 2555M
[11/22 07:13:08] d2.utils.events INFO:  eta: 1:14:55  iter: 79  total_loss: 5.993  loss_ce: 2.262  loss_objectness: 0.5949  loss_dice: 1.997  loss_mask: 1.116    time: 0.3040  last_time: 0.3061  data_time: 0.0051  last_data_time: 0.0050   lr: 3.9961e-06  max_mem: 2556M
[11/22 07:13:14] d2.utils.events INFO:  eta: 1:14:49  iter: 99  total_loss: 5.441  loss_ce: 2.182  loss_objectness: 0.5443  loss_dice: 1.935  loss_mask: 0.791    time: 0.3035  last_time: 0.3019  data_time: 0.0048  last_data_time: 0.0047   lr: 4.9951e-06  max_mem: 2556M
[11/22 07:13:20] d2.utils.events INFO:  eta: 1:14:48  iter: 119  total_loss: 5.02  loss_ce: 2.098  loss_objectness: 0.4659  loss_dice: 1.925  loss_mask: 0.5712    time: 0.3038  last_time: 0.3035  data_time: 0.0055  last_data_time: 0.0063   lr: 5.9941e-06  max_mem: 2556M
[11/22 07:13:26] d2.utils.events INFO:  eta: 1:14:50  iter: 139  total_loss: 4.7  loss_ce: 1.983  loss_objectness: 0.4043  loss_dice: 1.849  loss_mask: 0.4999    time: 0.3038  last_time: 0.3047  data_time: 0.0055  last_data_time: 0.0061   lr: 6.993e-06  max_mem: 2557M
[11/22 07:13:32] d2.utils.events INFO:  eta: 1:14:48  iter: 159  total_loss: 4.304  loss_ce: 1.816  loss_objectness: 0.3606  loss_dice: 1.763  loss_mask: 0.3729    time: 0.3038  last_time: 0.3031  data_time: 0.0053  last_data_time: 0.0052   lr: 7.9921e-06  max_mem: 2557M
[11/22 07:13:38] d2.utils.events INFO:  eta: 1:14:45  iter: 179  total_loss: 3.991  loss_ce: 1.55  loss_objectness: 0.331  loss_dice: 1.729  loss_mask: 0.3516    time: 0.3038  last_time: 0.3046  data_time: 0.0055  last_data_time: 0.0055   lr: 8.9911e-06  max_mem: 2557M
[11/22 07:13:44] d2.utils.events INFO:  eta: 1:14:42  iter: 199  total_loss: 3.488  loss_ce: 1.162  loss_objectness: 0.3044  loss_dice: 1.679  loss_mask: 0.3221    time: 0.3039  last_time: 0.3089  data_time: 0.0054  last_data_time: 0.0044   lr: 9.99e-06  max_mem: 2557M
[11/22 07:13:50] d2.utils.events INFO:  eta: 1:14:41  iter: 219  total_loss: 3.122  loss_ce: 0.8908  loss_objectness: 0.3317  loss_dice: 1.627  loss_mask: 0.2877    time: 0.3046  last_time: 0.3046  data_time: 0.0056  last_data_time: 0.0056   lr: 1.0989e-05  max_mem: 2557M
[11/22 07:13:56] d2.utils.events INFO:  eta: 1:14:36  iter: 239  total_loss: 3.019  loss_ce: 0.8124  loss_objectness: 0.3123  loss_dice: 1.64  loss_mask: 0.2712    time: 0.3045  last_time: 0.3020  data_time: 0.0054  last_data_time: 0.0047   lr: 1.1988e-05  max_mem: 2557M
[11/22 07:14:02] d2.utils.events INFO:  eta: 1:14:29  iter: 259  total_loss: 2.925  loss_ce: 0.7483  loss_objectness: 0.3502  loss_dice: 1.593  loss_mask: 0.233    time: 0.3044  last_time: 0.3067  data_time: 0.0051  last_data_time: 0.0045   lr: 1.2987e-05  max_mem: 2557M
[11/22 07:14:09] d2.utils.events INFO:  eta: 1:14:23  iter: 279  total_loss: 2.754  loss_ce: 0.6056  loss_objectness: 0.3371  loss_dice: 1.605  loss_mask: 0.2329    time: 0.3044  last_time: 0.3002  data_time: 0.0054  last_data_time: 0.0044   lr: 1.3986e-05  max_mem: 2557M
[11/22 07:14:15] d2.utils.events INFO:  eta: 1:14:19  iter: 299  total_loss: 2.697  loss_ce: 0.5269  loss_objectness: 0.3811  loss_dice: 1.553  loss_mask: 0.223    time: 0.3044  last_time: 0.3028  data_time: 0.0054  last_data_time: 0.0060   lr: 1.4985e-05  max_mem: 2557M
[11/22 07:14:21] d2.utils.events INFO:  eta: 1:14:13  iter: 319  total_loss: 2.639  loss_ce: 0.4957  loss_objectness: 0.3721  loss_dice: 1.514  loss_mask: 0.2232    time: 0.3044  last_time: 0.3029  data_time: 0.0054  last_data_time: 0.0048   lr: 1.5984e-05  max_mem: 2557M
[11/22 07:14:27] d2.utils.events INFO:  eta: 1:14:07  iter: 339  total_loss: 2.599  loss_ce: 0.4966  loss_objectness: 0.3878  loss_dice: 1.488  loss_mask: 0.2257    time: 0.3043  last_time: 0.3028  data_time: 0.0054  last_data_time: 0.0048   lr: 1.6983e-05  max_mem: 2557M
[11/22 07:14:33] d2.utils.events INFO:  eta: 1:14:01  iter: 359  total_loss: 2.468  loss_ce: 0.4731  loss_objectness: 0.4184  loss_dice: 1.413  loss_mask: 0.1924    time: 0.3043  last_time: 0.3021  data_time: 0.0053  last_data_time: 0.0048   lr: 1.7982e-05  max_mem: 2557M
[11/22 07:14:39] d2.utils.events INFO:  eta: 1:13:55  iter: 379  total_loss: 2.475  loss_ce: 0.4404  loss_objectness: 0.3542  loss_dice: 1.515  loss_mask: 0.1952    time: 0.3042  last_time: 0.3009  data_time: 0.0054  last_data_time: 0.0049   lr: 1.8981e-05  max_mem: 2557M
[11/22 07:14:45] d2.utils.events INFO:  eta: 1:13:50  iter: 399  total_loss: 2.469  loss_ce: 0.4411  loss_objectness: 0.3928  loss_dice: 1.462  loss_mask: 0.1802    time: 0.3043  last_time: 0.3047  data_time: 0.0053  last_data_time: 0.0055   lr: 1.998e-05  max_mem: 2557M
[11/22 07:14:51] d2.utils.events INFO:  eta: 1:13:44  iter: 419  total_loss: 2.436  loss_ce: 0.4651  loss_objectness: 0.4469  loss_dice: 1.323  loss_mask: 0.1829    time: 0.3042  last_time: 0.3009  data_time: 0.0052  last_data_time: 0.0043   lr: 2.0979e-05  max_mem: 2557M
[11/22 07:14:57] d2.utils.events INFO:  eta: 1:13:37  iter: 439  total_loss: 2.537  loss_ce: 0.5229  loss_objectness: 0.4046  loss_dice: 1.416  loss_mask: 0.206    time: 0.3042  last_time: 0.3014  data_time: 0.0052  last_data_time: 0.0042   lr: 2.1978e-05  max_mem: 2557M
[11/22 07:15:03] d2.utils.events INFO:  eta: 1:13:31  iter: 459  total_loss: 2.389  loss_ce: 0.4385  loss_objectness: 0.4185  loss_dice: 1.343  loss_mask: 0.1543    time: 0.3041  last_time: 0.3050  data_time: 0.0055  last_data_time: 0.0059   lr: 2.2977e-05  max_mem: 2557M
[11/22 07:15:09] d2.utils.events INFO:  eta: 1:13:25  iter: 479  total_loss: 2.342  loss_ce: 0.4346  loss_objectness: 0.4617  loss_dice: 1.271  loss_mask: 0.1467    time: 0.3041  last_time: 0.3047  data_time: 0.0053  last_data_time: 0.0057   lr: 2.3976e-05  max_mem: 2557M
[11/22 07:15:15] d2.utils.events INFO:  eta: 1:13:19  iter: 499  total_loss: 2.374  loss_ce: 0.4428  loss_objectness: 0.476  loss_dice: 1.274  loss_mask: 0.1524    time: 0.3041  last_time: 0.3015  data_time: 0.0053  last_data_time: 0.0051   lr: 2.4975e-05  max_mem: 2557M
[11/22 07:15:22] d2.utils.events INFO:  eta: 1:13:12  iter: 519  total_loss: 2.385  loss_ce: 0.5162  loss_objectness: 0.45  loss_dice: 1.313  loss_mask: 0.1457    time: 0.3040  last_time: 0.3006  data_time: 0.0052  last_data_time: 0.0052   lr: 2.5974e-05  max_mem: 2557M
[11/22 07:15:28] d2.utils.events INFO:  eta: 1:13:06  iter: 539  total_loss: 2.42  loss_ce: 0.4756  loss_objectness: 0.4866  loss_dice: 1.245  loss_mask: 0.1409    time: 0.3040  last_time: 0.3037  data_time: 0.0053  last_data_time: 0.0068   lr: 2.6973e-05  max_mem: 2557M
[11/22 07:15:34] d2.utils.events INFO:  eta: 1:13:00  iter: 559  total_loss: 2.31  loss_ce: 0.4665  loss_objectness: 0.4847  loss_dice: 1.243  loss_mask: 0.1211    time: 0.3040  last_time: 0.3022  data_time: 0.0053  last_data_time: 0.0054   lr: 2.7972e-05  max_mem: 2557M
[11/22 07:15:40] d2.utils.events INFO:  eta: 1:12:54  iter: 579  total_loss: 2.322  loss_ce: 0.4618  loss_objectness: 0.5183  loss_dice: 1.16  loss_mask: 0.1333    time: 0.3040  last_time: 0.2997  data_time: 0.0053  last_data_time: 0.0045   lr: 2.8971e-05  max_mem: 2557M
[11/22 07:15:46] d2.utils.events INFO:  eta: 1:12:48  iter: 599  total_loss: 2.272  loss_ce: 0.4525  loss_objectness: 0.5035  loss_dice: 1.195  loss_mask: 0.1117    time: 0.3039  last_time: 0.3045  data_time: 0.0054  last_data_time: 0.0068   lr: 2.997e-05  max_mem: 2557M
[11/22 07:15:52] d2.utils.events INFO:  eta: 1:12:41  iter: 619  total_loss: 2.324  loss_ce: 0.4865  loss_objectness: 0.5253  loss_dice: 1.156  loss_mask: 0.1564    time: 0.3039  last_time: 0.3004  data_time: 0.0053  last_data_time: 0.0047   lr: 3.0969e-05  max_mem: 2557M
[11/22 07:15:58] d2.utils.events INFO:  eta: 1:12:35  iter: 639  total_loss: 2.266  loss_ce: 0.4669  loss_objectness: 0.5222  loss_dice: 1.193  loss_mask: 0.1145    time: 0.3039  last_time: 0.3020  data_time: 0.0053  last_data_time: 0.0054   lr: 3.1968e-05  max_mem: 2557M
[11/22 07:16:04] d2.utils.events INFO:  eta: 1:12:29  iter: 659  total_loss: 2.34  loss_ce: 0.5186  loss_objectness: 0.5649  loss_dice: 1.065  loss_mask: 0.1377    time: 0.3039  last_time: 0.3019  data_time: 0.0051  last_data_time: 0.0060   lr: 3.2967e-05  max_mem: 2557M
[11/22 07:16:10] d2.utils.events INFO:  eta: 1:12:22  iter: 679  total_loss: 2.401  loss_ce: 0.4778  loss_objectness: 0.5125  loss_dice: 1.257  loss_mask: 0.163    time: 0.3038  last_time: 0.3048  data_time: 0.0051  last_data_time: 0.0044   lr: 3.3966e-05  max_mem: 2557M
[11/22 07:16:16] d2.utils.events INFO:  eta: 1:12:16  iter: 699  total_loss: 2.491  loss_ce: 0.5548  loss_objectness: 0.5083  loss_dice: 1.24  loss_mask: 0.1782    time: 0.3038  last_time: 0.3052  data_time: 0.0053  last_data_time: 0.0047   lr: 3.4965e-05  max_mem: 2557M
[11/22 07:16:22] d2.utils.events INFO:  eta: 1:12:10  iter: 719  total_loss: 2.321  loss_ce: 0.4966  loss_objectness: 0.5034  loss_dice: 1.191  loss_mask: 0.1246    time: 0.3038  last_time: 0.3119  data_time: 0.0055  last_data_time: 0.0057   lr: 3.5964e-05  max_mem: 2569M
[11/22 07:16:28] d2.utils.events INFO:  eta: 1:12:05  iter: 739  total_loss: 2.168  loss_ce: 0.4619  loss_objectness: 0.5869  loss_dice: 1.022  loss_mask: 0.1102    time: 0.3039  last_time: 0.3063  data_time: 0.0058  last_data_time: 0.0070   lr: 3.6963e-05  max_mem: 2569M
[11/22 07:16:35] d2.utils.events INFO:  eta: 1:11:59  iter: 759  total_loss: 2.258  loss_ce: 0.4826  loss_objectness: 0.5492  loss_dice: 1.063  loss_mask: 0.1266    time: 0.3040  last_time: 0.3047  data_time: 0.0054  last_data_time: 0.0047   lr: 3.7962e-05  max_mem: 2569M
[11/22 07:16:41] d2.utils.events INFO:  eta: 1:11:52  iter: 779  total_loss: 2.161  loss_ce: 0.4618  loss_objectness: 0.5618  loss_dice: 1.017  loss_mask: 0.1205    time: 0.3039  last_time: 0.3020  data_time: 0.0053  last_data_time: 0.0050   lr: 3.8961e-05  max_mem: 2569M
[11/22 07:16:47] d2.utils.events INFO:  eta: 1:11:46  iter: 799  total_loss: 2.202  loss_ce: 0.4693  loss_objectness: 0.5692  loss_dice: 1  loss_mask: 0.1199    time: 0.3039  last_time: 0.3037  data_time: 0.0050  last_data_time: 0.0048   lr: 3.996e-05  max_mem: 2569M
[11/22 07:16:53] d2.utils.events INFO:  eta: 1:11:40  iter: 819  total_loss: 2.141  loss_ce: 0.4728  loss_objectness: 0.5731  loss_dice: 0.9747  loss_mask: 0.09962    time: 0.3039  last_time: 0.3008  data_time: 0.0056  last_data_time: 0.0045   lr: 4.0959e-05  max_mem: 2569M
[11/22 07:16:59] d2.utils.events INFO:  eta: 1:11:34  iter: 839  total_loss: 2.126  loss_ce: 0.4628  loss_objectness: 0.5808  loss_dice: 1.007  loss_mask: 0.09938    time: 0.3039  last_time: 0.3019  data_time: 0.0051  last_data_time: 0.0059   lr: 4.1958e-05  max_mem: 2569M
[11/22 07:17:05] d2.utils.events INFO:  eta: 1:11:28  iter: 859  total_loss: 2.18  loss_ce: 0.4664  loss_objectness: 0.5698  loss_dice: 1.051  loss_mask: 0.09016    time: 0.3039  last_time: 0.3137  data_time: 0.0054  last_data_time: 0.0058   lr: 4.2957e-05  max_mem: 2572M
[11/22 07:17:11] d2.utils.events INFO:  eta: 1:11:22  iter: 879  total_loss: 2.23  loss_ce: 0.5107  loss_objectness: 0.571  loss_dice: 1.046  loss_mask: 0.1229    time: 0.3039  last_time: 0.3026  data_time: 0.0054  last_data_time: 0.0052   lr: 4.3956e-05  max_mem: 2572M
[11/22 07:17:17] d2.utils.events INFO:  eta: 1:11:15  iter: 899  total_loss: 2.18  loss_ce: 0.4975  loss_objectness: 0.5779  loss_dice: 0.9737  loss_mask: 0.1174    time: 0.3039  last_time: 0.3054  data_time: 0.0051  last_data_time: 0.0052   lr: 4.4955e-05  max_mem: 2572M
[11/22 07:17:23] d2.utils.events INFO:  eta: 1:11:10  iter: 919  total_loss: 2.183  loss_ce: 0.4815  loss_objectness: 0.5639  loss_dice: 1.014  loss_mask: 0.08954    time: 0.3039  last_time: 0.2999  data_time: 0.0055  last_data_time: 0.0048   lr: 4.5954e-05  max_mem: 2572M
[11/22 07:17:29] d2.utils.events INFO:  eta: 1:11:03  iter: 939  total_loss: 2.195  loss_ce: 0.4836  loss_objectness: 0.5837  loss_dice: 1.007  loss_mask: 0.09213    time: 0.3039  last_time: 0.3041  data_time: 0.0053  last_data_time: 0.0061   lr: 4.6953e-05  max_mem: 2572M
[11/22 07:17:35] d2.utils.events INFO:  eta: 1:10:57  iter: 959  total_loss: 2.139  loss_ce: 0.4337  loss_objectness: 0.5796  loss_dice: 0.9862  loss_mask: 0.09749    time: 0.3039  last_time: 0.3023  data_time: 0.0053  last_data_time: 0.0048   lr: 4.7952e-05  max_mem: 2572M
[11/22 07:17:41] d2.utils.events INFO:  eta: 1:10:51  iter: 979  total_loss: 2.183  loss_ce: 0.4803  loss_objectness: 0.6041  loss_dice: 0.9435  loss_mask: 0.1231    time: 0.3038  last_time: 0.3032  data_time: 0.0052  last_data_time: 0.0046   lr: 4.8951e-05  max_mem: 2572M
[11/22 07:17:48] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 07:17:48] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   crack    | 376          |
|            |              |[0m
[11/22 07:17:48] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 07:17:48] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 07:17:48] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 07:17:48] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 07:17:48] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 07:17:54] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0227 s/iter. Eval: 0.0537 s/iter. Total: 0.0767 s/iter. ETA=0:00:08
[11/22 07:17:59] d2.evaluation.evaluator INFO: Inference done 73/120. Dataloading: 0.0004 s/iter. Inference: 0.0250 s/iter. Eval: 0.0549 s/iter. Total: 0.0804 s/iter. ETA=0:00:03
[11/22 07:18:04] d2.evaluation.evaluator INFO: Total inference time: 0:00:10.361330 (0.090099 s / iter per device, on 1 devices)
[11/22 07:18:04] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.025833 s / iter per device, on 1 devices)
[11/22 07:18:04] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 07:18:04] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 07:18:04] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 07:18:05] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 07:18:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.07 seconds.
[11/22 07:18:05] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 07:18:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 07:18:05] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 3.914 | 11.788 | 2.570  | 0.010 | 8.550 | 26.844 |
[11/22 07:18:05] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 07:18:05] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 07:18:05] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 07:18:05] d2.evaluation.testing INFO: copypaste: 3.9140,11.7876,2.5699,0.0097,8.5504,26.8440
[11/22 07:18:05] d2.utils.events INFO:  eta: 1:10:45  iter: 999  total_loss: 2.145  loss_ce: 0.4841  loss_objectness: 0.5936  loss_dice: 0.9806  loss_mask: 0.0971    time: 0.3038  last_time: 0.3018  data_time: 0.0052  last_data_time: 0.0045   lr: 4.995e-05  max_mem: 2572M
[11/22 07:18:11] d2.utils.events INFO:  eta: 1:10:40  iter: 1019  total_loss: 2.139  loss_ce: 0.484  loss_objectness: 0.5731  loss_dice: 1.011  loss_mask: 0.08519    time: 0.3041  last_time: 0.3085  data_time: 0.0061  last_data_time: 0.0063   lr: 5e-05  max_mem: 2572M
[11/22 07:18:17] d2.utils.events INFO:  eta: 1:10:34  iter: 1039  total_loss: 2.062  loss_ce: 0.4685  loss_objectness: 0.616  loss_dice: 0.8925  loss_mask: 0.09271    time: 0.3040  last_time: 0.3022  data_time: 0.0054  last_data_time: 0.0046   lr: 5e-05  max_mem: 2572M
[11/22 07:18:23] d2.utils.events INFO:  eta: 1:10:28  iter: 1059  total_loss: 2.061  loss_ce: 0.4861  loss_objectness: 0.609  loss_dice: 0.8927  loss_mask: 0.09122    time: 0.3040  last_time: 0.3138  data_time: 0.0054  last_data_time: 0.0062   lr: 5e-05  max_mem: 2572M
[11/22 07:18:29] d2.utils.events INFO:  eta: 1:10:22  iter: 1079  total_loss: 2.144  loss_ce: 0.487  loss_objectness: 0.6054  loss_dice: 0.9414  loss_mask: 0.09007    time: 0.3041  last_time: 0.3006  data_time: 0.0059  last_data_time: 0.0044   lr: 5e-05  max_mem: 2572M
[11/22 07:18:36] d2.utils.events INFO:  eta: 1:10:16  iter: 1099  total_loss: 2.109  loss_ce: 0.4648  loss_objectness: 0.5978  loss_dice: 0.9349  loss_mask: 0.1031    time: 0.3040  last_time: 0.2994  data_time: 0.0053  last_data_time: 0.0045   lr: 5e-05  max_mem: 2572M
[11/22 07:18:42] d2.utils.events INFO:  eta: 1:10:10  iter: 1119  total_loss: 2.053  loss_ce: 0.4641  loss_objectness: 0.5868  loss_dice: 0.8602  loss_mask: 0.08381    time: 0.3040  last_time: 0.3008  data_time: 0.0055  last_data_time: 0.0050   lr: 5e-05  max_mem: 2572M
[11/22 07:18:48] d2.utils.events INFO:  eta: 1:10:03  iter: 1139  total_loss: 2.099  loss_ce: 0.4871  loss_objectness: 0.6218  loss_dice: 0.8815  loss_mask: 0.08159    time: 0.3040  last_time: 0.3064  data_time: 0.0052  last_data_time: 0.0059   lr: 5e-05  max_mem: 2572M
[11/22 07:18:54] d2.utils.events INFO:  eta: 1:09:57  iter: 1159  total_loss: 2.205  loss_ce: 0.5022  loss_objectness: 0.6054  loss_dice: 0.957  loss_mask: 0.1051    time: 0.3040  last_time: 0.2996  data_time: 0.0054  last_data_time: 0.0056   lr: 5e-05  max_mem: 2572M
[11/22 07:19:00] d2.utils.events INFO:  eta: 1:09:51  iter: 1179  total_loss: 2.04  loss_ce: 0.4605  loss_objectness: 0.6009  loss_dice: 0.9245  loss_mask: 0.08288    time: 0.3041  last_time: 0.2984  data_time: 0.0057  last_data_time: 0.0047   lr: 5e-05  max_mem: 2572M
[11/22 07:19:06] d2.utils.events INFO:  eta: 1:09:44  iter: 1199  total_loss: 2.046  loss_ce: 0.485  loss_objectness: 0.6164  loss_dice: 0.8653  loss_mask: 0.09508    time: 0.3040  last_time: 0.2993  data_time: 0.0050  last_data_time: 0.0043   lr: 5e-05  max_mem: 2572M
[11/22 07:19:12] d2.utils.events INFO:  eta: 1:09:37  iter: 1219  total_loss: 2.103  loss_ce: 0.4813  loss_objectness: 0.6181  loss_dice: 0.9006  loss_mask: 0.102    time: 0.3040  last_time: 0.3015  data_time: 0.0054  last_data_time: 0.0044   lr: 5e-05  max_mem: 2572M
[11/22 07:19:18] d2.utils.events INFO:  eta: 1:09:30  iter: 1239  total_loss: 2.057  loss_ce: 0.4277  loss_objectness: 0.6073  loss_dice: 0.8625  loss_mask: 0.07165    time: 0.3039  last_time: 0.3049  data_time: 0.0052  last_data_time: 0.0056   lr: 5e-05  max_mem: 2572M
[11/22 07:19:24] d2.utils.events INFO:  eta: 1:09:24  iter: 1259  total_loss: 2.057  loss_ce: 0.4625  loss_objectness: 0.6152  loss_dice: 0.839  loss_mask: 0.08828    time: 0.3039  last_time: 0.3002  data_time: 0.0053  last_data_time: 0.0053   lr: 5e-05  max_mem: 2572M
[11/22 07:19:30] d2.utils.events INFO:  eta: 1:09:18  iter: 1279  total_loss: 2.095  loss_ce: 0.4813  loss_objectness: 0.6129  loss_dice: 0.9083  loss_mask: 0.07223    time: 0.3039  last_time: 0.3056  data_time: 0.0053  last_data_time: 0.0046   lr: 5e-05  max_mem: 2572M
[11/22 07:19:36] d2.utils.events INFO:  eta: 1:09:11  iter: 1299  total_loss: 2.024  loss_ce: 0.4691  loss_objectness: 0.65  loss_dice: 0.7784  loss_mask: 0.09246    time: 0.3038  last_time: 0.3038  data_time: 0.0053  last_data_time: 0.0050   lr: 5e-05  max_mem: 2572M
[11/22 07:19:42] d2.utils.events INFO:  eta: 1:09:04  iter: 1319  total_loss: 2.001  loss_ce: 0.449  loss_objectness: 0.6279  loss_dice: 0.8581  loss_mask: 0.08914    time: 0.3038  last_time: 0.3016  data_time: 0.0052  last_data_time: 0.0051   lr: 5e-05  max_mem: 2572M
[11/22 07:19:48] d2.utils.events INFO:  eta: 1:08:58  iter: 1339  total_loss: 2.029  loss_ce: 0.4666  loss_objectness: 0.6254  loss_dice: 0.8676  loss_mask: 0.08081    time: 0.3038  last_time: 0.3033  data_time: 0.0054  last_data_time: 0.0041   lr: 5e-05  max_mem: 2572M
[11/22 07:19:54] d2.utils.events INFO:  eta: 1:08:51  iter: 1359  total_loss: 1.935  loss_ce: 0.432  loss_objectness: 0.6363  loss_dice: 0.7795  loss_mask: 0.0721    time: 0.3037  last_time: 0.3009  data_time: 0.0053  last_data_time: 0.0053   lr: 5e-05  max_mem: 2572M
[11/22 07:20:00] d2.utils.events INFO:  eta: 1:08:45  iter: 1379  total_loss: 1.991  loss_ce: 0.4798  loss_objectness: 0.6287  loss_dice: 0.8026  loss_mask: 0.06903    time: 0.3038  last_time: 0.3082  data_time: 0.0058  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 07:20:07] d2.utils.events INFO:  eta: 1:08:39  iter: 1399  total_loss: 1.994  loss_ce: 0.4676  loss_objectness: 0.615  loss_dice: 0.852  loss_mask: 0.07832    time: 0.3038  last_time: 0.2987  data_time: 0.0056  last_data_time: 0.0048   lr: 5e-05  max_mem: 2572M
[11/22 07:20:13] d2.utils.events INFO:  eta: 1:08:33  iter: 1419  total_loss: 1.962  loss_ce: 0.4433  loss_objectness: 0.6205  loss_dice: 0.7869  loss_mask: 0.06195    time: 0.3037  last_time: 0.3002  data_time: 0.0054  last_data_time: 0.0044   lr: 5e-05  max_mem: 2572M
[11/22 07:20:19] d2.utils.events INFO:  eta: 1:08:26  iter: 1439  total_loss: 1.978  loss_ce: 0.4672  loss_objectness: 0.6219  loss_dice: 0.8038  loss_mask: 0.07807    time: 0.3037  last_time: 0.3047  data_time: 0.0056  last_data_time: 0.0060   lr: 5e-05  max_mem: 2572M
[11/22 07:20:25] d2.utils.events INFO:  eta: 1:08:20  iter: 1459  total_loss: 2.012  loss_ce: 0.4663  loss_objectness: 0.6415  loss_dice: 0.7772  loss_mask: 0.07438    time: 0.3037  last_time: 0.2981  data_time: 0.0054  last_data_time: 0.0046   lr: 5e-05  max_mem: 2572M
[11/22 07:20:31] d2.utils.events INFO:  eta: 1:08:14  iter: 1479  total_loss: 1.988  loss_ce: 0.4632  loss_objectness: 0.6411  loss_dice: 0.7462  loss_mask: 0.08738    time: 0.3037  last_time: 0.2999  data_time: 0.0052  last_data_time: 0.0046   lr: 5e-05  max_mem: 2572M
[11/22 07:20:37] d2.utils.events INFO:  eta: 1:08:08  iter: 1499  total_loss: 1.913  loss_ce: 0.4248  loss_objectness: 0.6337  loss_dice: 0.7502  loss_mask: 0.0868    time: 0.3036  last_time: 0.3005  data_time: 0.0054  last_data_time: 0.0051   lr: 5e-05  max_mem: 2572M
[11/22 07:20:43] d2.utils.events INFO:  eta: 1:08:01  iter: 1519  total_loss: 1.964  loss_ce: 0.4501  loss_objectness: 0.6427  loss_dice: 0.7984  loss_mask: 0.07013    time: 0.3036  last_time: 0.3017  data_time: 0.0052  last_data_time: 0.0050   lr: 5e-05  max_mem: 2572M
[11/22 07:20:49] d2.utils.events INFO:  eta: 1:07:55  iter: 1539  total_loss: 1.971  loss_ce: 0.4654  loss_objectness: 0.6247  loss_dice: 0.7857  loss_mask: 0.07896    time: 0.3036  last_time: 0.2985  data_time: 0.0053  last_data_time: 0.0048   lr: 5e-05  max_mem: 2572M
[11/22 07:20:55] d2.utils.events INFO:  eta: 1:07:47  iter: 1559  total_loss: 1.918  loss_ce: 0.4469  loss_objectness: 0.6475  loss_dice: 0.6875  loss_mask: 0.07326    time: 0.3035  last_time: 0.2991  data_time: 0.0053  last_data_time: 0.0046   lr: 5e-05  max_mem: 2572M
[11/22 07:21:01] d2.utils.events INFO:  eta: 1:07:41  iter: 1579  total_loss: 1.962  loss_ce: 0.4525  loss_objectness: 0.6248  loss_dice: 0.8726  loss_mask: 0.06097    time: 0.3035  last_time: 0.2986  data_time: 0.0056  last_data_time: 0.0042   lr: 5e-05  max_mem: 2572M
[11/22 07:21:07] d2.utils.events INFO:  eta: 1:07:34  iter: 1599  total_loss: 1.882  loss_ce: 0.4353  loss_objectness: 0.6431  loss_dice: 0.7256  loss_mask: 0.06172    time: 0.3035  last_time: 0.2997  data_time: 0.0052  last_data_time: 0.0053   lr: 5e-05  max_mem: 2572M
[11/22 07:21:13] d2.utils.events INFO:  eta: 1:07:27  iter: 1619  total_loss: 1.89  loss_ce: 0.4377  loss_objectness: 0.637  loss_dice: 0.7607  loss_mask: 0.07173    time: 0.3035  last_time: 0.3006  data_time: 0.0053  last_data_time: 0.0058   lr: 5e-05  max_mem: 2572M
[11/22 07:21:19] d2.utils.events INFO:  eta: 1:07:21  iter: 1639  total_loss: 1.918  loss_ce: 0.4586  loss_objectness: 0.6158  loss_dice: 0.7221  loss_mask: 0.06249    time: 0.3034  last_time: 0.3036  data_time: 0.0055  last_data_time: 0.0055   lr: 5e-05  max_mem: 2572M
[11/22 07:21:25] d2.utils.events INFO:  eta: 1:07:15  iter: 1659  total_loss: 1.881  loss_ce: 0.4475  loss_objectness: 0.6469  loss_dice: 0.6673  loss_mask: 0.06467    time: 0.3035  last_time: 0.3167  data_time: 0.0058  last_data_time: 0.0066   lr: 5e-05  max_mem: 2572M
[11/22 07:21:31] d2.utils.events INFO:  eta: 1:07:10  iter: 1679  total_loss: 1.874  loss_ce: 0.4338  loss_objectness: 0.6532  loss_dice: 0.6906  loss_mask: 0.06273    time: 0.3035  last_time: 0.3045  data_time: 0.0057  last_data_time: 0.0051   lr: 5e-05  max_mem: 2572M
[11/22 07:21:37] d2.utils.events INFO:  eta: 1:07:03  iter: 1699  total_loss: 1.879  loss_ce: 0.4442  loss_objectness: 0.6453  loss_dice: 0.6845  loss_mask: 0.06661    time: 0.3035  last_time: 0.3011  data_time: 0.0055  last_data_time: 0.0056   lr: 5e-05  max_mem: 2572M
[11/22 07:21:43] d2.utils.events INFO:  eta: 1:06:56  iter: 1719  total_loss: 1.838  loss_ce: 0.445  loss_objectness: 0.6477  loss_dice: 0.6844  loss_mask: 0.07142    time: 0.3035  last_time: 0.3004  data_time: 0.0051  last_data_time: 0.0057   lr: 5e-05  max_mem: 2572M
[11/22 07:21:49] d2.utils.events INFO:  eta: 1:06:49  iter: 1739  total_loss: 1.835  loss_ce: 0.4514  loss_objectness: 0.6455  loss_dice: 0.67  loss_mask: 0.05735    time: 0.3035  last_time: 0.3019  data_time: 0.0050  last_data_time: 0.0054   lr: 5e-05  max_mem: 2572M
[11/22 07:21:55] d2.utils.events INFO:  eta: 1:06:42  iter: 1759  total_loss: 1.77  loss_ce: 0.4159  loss_objectness: 0.6522  loss_dice: 0.6546  loss_mask: 0.07043    time: 0.3034  last_time: 0.3070  data_time: 0.0049  last_data_time: 0.0055   lr: 5e-05  max_mem: 2572M
[11/22 07:22:02] d2.utils.events INFO:  eta: 1:06:35  iter: 1779  total_loss: 1.899  loss_ce: 0.4597  loss_objectness: 0.6403  loss_dice: 0.7059  loss_mask: 0.06742    time: 0.3034  last_time: 0.3034  data_time: 0.0055  last_data_time: 0.0059   lr: 5e-05  max_mem: 2572M
[11/22 07:22:08] d2.utils.events INFO:  eta: 1:06:29  iter: 1799  total_loss: 1.869  loss_ce: 0.4394  loss_objectness: 0.6502  loss_dice: 0.7159  loss_mask: 0.06275    time: 0.3034  last_time: 0.3014  data_time: 0.0053  last_data_time: 0.0057   lr: 5e-05  max_mem: 2572M
[11/22 07:22:14] d2.utils.events INFO:  eta: 1:06:22  iter: 1819  total_loss: 1.801  loss_ce: 0.4325  loss_objectness: 0.6607  loss_dice: 0.6896  loss_mask: 0.07134    time: 0.3034  last_time: 0.3023  data_time: 0.0053  last_data_time: 0.0053   lr: 5e-05  max_mem: 2572M
[11/22 07:22:20] d2.utils.events INFO:  eta: 1:06:16  iter: 1839  total_loss: 1.859  loss_ce: 0.461  loss_objectness: 0.6428  loss_dice: 0.7015  loss_mask: 0.0597    time: 0.3034  last_time: 0.3017  data_time: 0.0056  last_data_time: 0.0059   lr: 5e-05  max_mem: 2572M
[11/22 07:22:26] d2.utils.events INFO:  eta: 1:06:09  iter: 1859  total_loss: 1.791  loss_ce: 0.4375  loss_objectness: 0.6463  loss_dice: 0.6207  loss_mask: 0.06573    time: 0.3034  last_time: 0.3064  data_time: 0.0053  last_data_time: 0.0061   lr: 5e-05  max_mem: 2572M
[11/22 07:22:32] d2.utils.events INFO:  eta: 1:06:02  iter: 1879  total_loss: 1.854  loss_ce: 0.4345  loss_objectness: 0.6527  loss_dice: 0.6716  loss_mask: 0.06167    time: 0.3034  last_time: 0.3007  data_time: 0.0055  last_data_time: 0.0046   lr: 5e-05  max_mem: 2572M
[11/22 07:22:38] d2.utils.events INFO:  eta: 1:05:56  iter: 1899  total_loss: 1.734  loss_ce: 0.4473  loss_objectness: 0.6568  loss_dice: 0.5808  loss_mask: 0.05934    time: 0.3033  last_time: 0.2996  data_time: 0.0053  last_data_time: 0.0053   lr: 5e-05  max_mem: 2572M
[11/22 07:22:44] d2.utils.events INFO:  eta: 1:05:49  iter: 1919  total_loss: 1.858  loss_ce: 0.4533  loss_objectness: 0.6508  loss_dice: 0.6848  loss_mask: 0.05848    time: 0.3033  last_time: 0.3013  data_time: 0.0053  last_data_time: 0.0053   lr: 5e-05  max_mem: 2572M
[11/22 07:22:50] d2.utils.events INFO:  eta: 1:05:43  iter: 1939  total_loss: 1.818  loss_ce: 0.4226  loss_objectness: 0.647  loss_dice: 0.6063  loss_mask: 0.07376    time: 0.3033  last_time: 0.3003  data_time: 0.0053  last_data_time: 0.0057   lr: 5e-05  max_mem: 2572M
[11/22 07:22:56] d2.utils.events INFO:  eta: 1:05:36  iter: 1959  total_loss: 1.749  loss_ce: 0.4356  loss_objectness: 0.6423  loss_dice: 0.5697  loss_mask: 0.0627    time: 0.3033  last_time: 0.3025  data_time: 0.0053  last_data_time: 0.0048   lr: 5e-05  max_mem: 2572M
[11/22 07:23:02] d2.utils.events INFO:  eta: 1:05:29  iter: 1979  total_loss: 1.861  loss_ce: 0.4292  loss_objectness: 0.644  loss_dice: 0.6579  loss_mask: 0.07229    time: 0.3033  last_time: 0.3002  data_time: 0.0057  last_data_time: 0.0053   lr: 5e-05  max_mem: 2572M
[11/22 07:23:08] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 07:23:08] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 07:23:08] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 07:23:08] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 07:23:08] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 07:23:08] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 07:23:14] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0222 s/iter. Eval: 0.0549 s/iter. Total: 0.0774 s/iter. ETA=0:00:08
[11/22 07:23:19] d2.evaluation.evaluator INFO: Inference done 73/120. Dataloading: 0.0004 s/iter. Inference: 0.0253 s/iter. Eval: 0.0550 s/iter. Total: 0.0807 s/iter. ETA=0:00:03
[11/22 07:23:24] d2.evaluation.evaluator INFO: Total inference time: 0:00:10.292823 (0.089503 s / iter per device, on 1 devices)
[11/22 07:23:24] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.025841 s / iter per device, on 1 devices)
[11/22 07:23:24] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 07:23:24] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 07:23:24] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 07:23:24] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 07:23:24] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.06 seconds.
[11/22 07:23:24] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 07:23:24] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 07:23:24] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.447 | 13.900 | 6.166  | 0.043 | 13.473 | 43.291 |
[11/22 07:23:24] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 07:23:24] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 07:23:24] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 07:23:24] d2.evaluation.testing INFO: copypaste: 6.4467,13.8998,6.1658,0.0429,13.4728,43.2911
[11/22 07:23:24] d2.utils.events INFO:  eta: 1:05:23  iter: 1999  total_loss: 1.824  loss_ce: 0.449  loss_objectness: 0.6588  loss_dice: 0.6668  loss_mask: 0.06537    time: 0.3032  last_time: 0.3006  data_time: 0.0054  last_data_time: 0.0060   lr: 5e-05  max_mem: 2572M
[11/22 07:23:30] d2.utils.events INFO:  eta: 1:05:16  iter: 2019  total_loss: 1.836  loss_ce: 0.4451  loss_objectness: 0.6449  loss_dice: 0.6881  loss_mask: 0.05515    time: 0.3033  last_time: 0.3006  data_time: 0.0054  last_data_time: 0.0045   lr: 5e-05  max_mem: 2572M
[11/22 07:23:36] d2.utils.events INFO:  eta: 1:05:10  iter: 2039  total_loss: 1.723  loss_ce: 0.4223  loss_objectness: 0.6654  loss_dice: 0.5698  loss_mask: 0.06012    time: 0.3033  last_time: 0.3026  data_time: 0.0056  last_data_time: 0.0053   lr: 5e-05  max_mem: 2572M
[11/22 07:23:42] d2.utils.events INFO:  eta: 1:05:04  iter: 2059  total_loss: 1.794  loss_ce: 0.4114  loss_objectness: 0.6406  loss_dice: 0.6471  loss_mask: 0.05786    time: 0.3033  last_time: 0.3022  data_time: 0.0053  last_data_time: 0.0055   lr: 5e-05  max_mem: 2572M
[11/22 07:23:49] d2.utils.events INFO:  eta: 1:04:58  iter: 2079  total_loss: 1.746  loss_ce: 0.4261  loss_objectness: 0.6467  loss_dice: 0.6186  loss_mask: 0.05159    time: 0.3033  last_time: 0.3036  data_time: 0.0055  last_data_time: 0.0059   lr: 5e-05  max_mem: 2572M
[11/22 07:23:55] d2.utils.events INFO:  eta: 1:04:51  iter: 2099  total_loss: 1.824  loss_ce: 0.4579  loss_objectness: 0.6489  loss_dice: 0.6519  loss_mask: 0.07059    time: 0.3032  last_time: 0.3027  data_time: 0.0051  last_data_time: 0.0065   lr: 5e-05  max_mem: 2572M
[11/22 07:24:01] d2.utils.events INFO:  eta: 1:04:44  iter: 2119  total_loss: 1.729  loss_ce: 0.4335  loss_objectness: 0.6408  loss_dice: 0.5473  loss_mask: 0.05988    time: 0.3032  last_time: 0.3028  data_time: 0.0052  last_data_time: 0.0048   lr: 5e-05  max_mem: 2572M
[11/22 07:24:07] d2.utils.events INFO:  eta: 1:04:38  iter: 2139  total_loss: 1.85  loss_ce: 0.4572  loss_objectness: 0.6364  loss_dice: 0.6699  loss_mask: 0.05292    time: 0.3032  last_time: 0.3007  data_time: 0.0056  last_data_time: 0.0066   lr: 5e-05  max_mem: 2572M
[11/22 07:24:13] d2.utils.events INFO:  eta: 1:04:31  iter: 2159  total_loss: 1.705  loss_ce: 0.4218  loss_objectness: 0.657  loss_dice: 0.5627  loss_mask: 0.05794    time: 0.3032  last_time: 0.3038  data_time: 0.0051  last_data_time: 0.0060   lr: 5e-05  max_mem: 2572M
[11/22 07:24:19] d2.utils.events INFO:  eta: 1:04:25  iter: 2179  total_loss: 1.762  loss_ce: 0.4173  loss_objectness: 0.6549  loss_dice: 0.5964  loss_mask: 0.0622    time: 0.3032  last_time: 0.3122  data_time: 0.0053  last_data_time: 0.0066   lr: 5e-05  max_mem: 2572M
[11/22 07:24:25] d2.utils.events INFO:  eta: 1:04:19  iter: 2199  total_loss: 1.751  loss_ce: 0.4191  loss_objectness: 0.6281  loss_dice: 0.6114  loss_mask: 0.05096    time: 0.3032  last_time: 0.3004  data_time: 0.0054  last_data_time: 0.0043   lr: 5e-05  max_mem: 2572M
[11/22 07:24:31] d2.utils.events INFO:  eta: 1:04:13  iter: 2219  total_loss: 1.637  loss_ce: 0.3909  loss_objectness: 0.6434  loss_dice: 0.5246  loss_mask: 0.04697    time: 0.3032  last_time: 0.2992  data_time: 0.0055  last_data_time: 0.0053   lr: 5e-05  max_mem: 2572M
[11/22 07:24:37] d2.utils.events INFO:  eta: 1:04:07  iter: 2239  total_loss: 1.663  loss_ce: 0.4194  loss_objectness: 0.644  loss_dice: 0.5602  loss_mask: 0.05735    time: 0.3032  last_time: 0.2997  data_time: 0.0056  last_data_time: 0.0044   lr: 5e-05  max_mem: 2572M
[11/22 07:24:43] d2.utils.events INFO:  eta: 1:04:01  iter: 2259  total_loss: 1.657  loss_ce: 0.3823  loss_objectness: 0.6564  loss_dice: 0.5493  loss_mask: 0.05737    time: 0.3032  last_time: 0.3036  data_time: 0.0051  last_data_time: 0.0058   lr: 5e-05  max_mem: 2572M
[11/22 07:24:49] d2.utils.events INFO:  eta: 1:03:55  iter: 2279  total_loss: 1.646  loss_ce: 0.4232  loss_objectness: 0.6451  loss_dice: 0.5096  loss_mask: 0.05319    time: 0.3032  last_time: 0.2984  data_time: 0.0053  last_data_time: 0.0049   lr: 5e-05  max_mem: 2572M
[11/22 07:24:55] d2.utils.events INFO:  eta: 1:03:49  iter: 2299  total_loss: 1.807  loss_ce: 0.4112  loss_objectness: 0.6484  loss_dice: 0.6571  loss_mask: 0.04461    time: 0.3031  last_time: 0.3001  data_time: 0.0057  last_data_time: 0.0059   lr: 5e-05  max_mem: 2572M
[11/22 07:25:01] d2.utils.events INFO:  eta: 1:03:43  iter: 2319  total_loss: 1.685  loss_ce: 0.4091  loss_objectness: 0.6462  loss_dice: 0.5404  loss_mask: 0.05049    time: 0.3031  last_time: 0.2993  data_time: 0.0053  last_data_time: 0.0049   lr: 5e-05  max_mem: 2572M
[11/22 07:25:07] d2.utils.events INFO:  eta: 1:03:37  iter: 2339  total_loss: 1.597  loss_ce: 0.3876  loss_objectness: 0.6404  loss_dice: 0.5105  loss_mask: 0.05108    time: 0.3031  last_time: 0.2998  data_time: 0.0053  last_data_time: 0.0059   lr: 5e-05  max_mem: 2572M
[11/22 07:25:13] d2.utils.events INFO:  eta: 1:03:31  iter: 2359  total_loss: 1.706  loss_ce: 0.3854  loss_objectness: 0.6456  loss_dice: 0.5604  loss_mask: 0.04961    time: 0.3031  last_time: 0.3012  data_time: 0.0053  last_data_time: 0.0053   lr: 5e-05  max_mem: 2572M
[11/22 07:25:19] d2.utils.events INFO:  eta: 1:03:24  iter: 2379  total_loss: 1.611  loss_ce: 0.4004  loss_objectness: 0.6408  loss_dice: 0.5115  loss_mask: 0.05373    time: 0.3031  last_time: 0.3036  data_time: 0.0053  last_data_time: 0.0059   lr: 5e-05  max_mem: 2572M
[11/22 07:25:25] d2.utils.events INFO:  eta: 1:03:18  iter: 2399  total_loss: 1.69  loss_ce: 0.4087  loss_objectness: 0.652  loss_dice: 0.5691  loss_mask: 0.04844    time: 0.3031  last_time: 0.2995  data_time: 0.0053  last_data_time: 0.0055   lr: 5e-05  max_mem: 2572M
[11/22 07:25:31] d2.utils.events INFO:  eta: 1:03:12  iter: 2419  total_loss: 1.625  loss_ce: 0.3761  loss_objectness: 0.6221  loss_dice: 0.5302  loss_mask: 0.04236    time: 0.3031  last_time: 0.3043  data_time: 0.0054  last_data_time: 0.0056   lr: 5e-05  max_mem: 2572M
[11/22 07:25:37] d2.utils.events INFO:  eta: 1:03:06  iter: 2439  total_loss: 1.701  loss_ce: 0.4183  loss_objectness: 0.65  loss_dice: 0.5762  loss_mask: 0.0478    time: 0.3031  last_time: 0.3010  data_time: 0.0052  last_data_time: 0.0052   lr: 5e-05  max_mem: 2572M
[11/22 07:25:43] d2.utils.events INFO:  eta: 1:03:00  iter: 2459  total_loss: 1.683  loss_ce: 0.4366  loss_objectness: 0.6471  loss_dice: 0.5409  loss_mask: 0.05406    time: 0.3030  last_time: 0.3029  data_time: 0.0053  last_data_time: 0.0050   lr: 5e-05  max_mem: 2572M
[11/22 07:25:49] d2.utils.events INFO:  eta: 1:02:53  iter: 2479  total_loss: 1.647  loss_ce: 0.4066  loss_objectness: 0.648  loss_dice: 0.521  loss_mask: 0.04943    time: 0.3030  last_time: 0.3016  data_time: 0.0052  last_data_time: 0.0064   lr: 5e-05  max_mem: 2572M
[11/22 07:25:55] d2.utils.events INFO:  eta: 1:02:48  iter: 2499  total_loss: 1.602  loss_ce: 0.3911  loss_objectness: 0.625  loss_dice: 0.5095  loss_mask: 0.04617    time: 0.3030  last_time: 0.2999  data_time: 0.0054  last_data_time: 0.0045   lr: 5e-05  max_mem: 2572M
[11/22 07:26:01] d2.utils.events INFO:  eta: 1:02:42  iter: 2519  total_loss: 1.618  loss_ce: 0.3823  loss_objectness: 0.6416  loss_dice: 0.5439  loss_mask: 0.05078    time: 0.3030  last_time: 0.3015  data_time: 0.0053  last_data_time: 0.0057   lr: 5e-05  max_mem: 2572M
[11/22 07:26:08] d2.utils.events INFO:  eta: 1:02:36  iter: 2539  total_loss: 1.647  loss_ce: 0.4185  loss_objectness: 0.6572  loss_dice: 0.5402  loss_mask: 0.04713    time: 0.3030  last_time: 0.3028  data_time: 0.0052  last_data_time: 0.0056   lr: 5e-05  max_mem: 2572M
[11/22 07:26:14] d2.utils.events INFO:  eta: 1:02:30  iter: 2559  total_loss: 1.703  loss_ce: 0.446  loss_objectness: 0.6444  loss_dice: 0.4946  loss_mask: 0.05593    time: 0.3030  last_time: 0.3004  data_time: 0.0054  last_data_time: 0.0047   lr: 5e-05  max_mem: 2572M
[11/22 07:26:20] d2.utils.events INFO:  eta: 1:02:24  iter: 2579  total_loss: 1.619  loss_ce: 0.3853  loss_objectness: 0.6202  loss_dice: 0.5182  loss_mask: 0.04934    time: 0.3030  last_time: 0.2994  data_time: 0.0053  last_data_time: 0.0044   lr: 5e-05  max_mem: 2572M
[11/22 07:26:26] d2.utils.events INFO:  eta: 1:02:18  iter: 2599  total_loss: 1.558  loss_ce: 0.3734  loss_objectness: 0.641  loss_dice: 0.4907  loss_mask: 0.05059    time: 0.3030  last_time: 0.3060  data_time: 0.0054  last_data_time: 0.0060   lr: 5e-05  max_mem: 2572M
[11/22 07:26:32] d2.utils.events INFO:  eta: 1:02:12  iter: 2619  total_loss: 1.698  loss_ce: 0.4297  loss_objectness: 0.6512  loss_dice: 0.5804  loss_mask: 0.04998    time: 0.3030  last_time: 0.3035  data_time: 0.0056  last_data_time: 0.0059   lr: 5e-05  max_mem: 2572M
[11/22 07:26:38] d2.utils.events INFO:  eta: 1:02:06  iter: 2639  total_loss: 1.659  loss_ce: 0.4027  loss_objectness: 0.6506  loss_dice: 0.5394  loss_mask: 0.0567    time: 0.3030  last_time: 0.3033  data_time: 0.0055  last_data_time: 0.0062   lr: 5e-05  max_mem: 2572M
[11/22 07:26:44] d2.utils.events INFO:  eta: 1:01:59  iter: 2659  total_loss: 1.656  loss_ce: 0.3941  loss_objectness: 0.6417  loss_dice: 0.5473  loss_mask: 0.04915    time: 0.3029  last_time: 0.3044  data_time: 0.0054  last_data_time: 0.0057   lr: 5e-05  max_mem: 2572M
[11/22 07:26:50] d2.utils.events INFO:  eta: 1:01:53  iter: 2679  total_loss: 1.614  loss_ce: 0.3727  loss_objectness: 0.623  loss_dice: 0.5162  loss_mask: 0.04181    time: 0.3029  last_time: 0.3024  data_time: 0.0054  last_data_time: 0.0044   lr: 5e-05  max_mem: 2572M
[11/22 07:26:56] d2.utils.events INFO:  eta: 1:01:47  iter: 2699  total_loss: 1.678  loss_ce: 0.3508  loss_objectness: 0.6457  loss_dice: 0.5537  loss_mask: 0.06673    time: 0.3029  last_time: 0.3023  data_time: 0.0054  last_data_time: 0.0057   lr: 5e-05  max_mem: 2572M
[11/22 07:27:02] d2.utils.events INFO:  eta: 1:01:41  iter: 2719  total_loss: 1.622  loss_ce: 0.3774  loss_objectness: 0.6397  loss_dice: 0.5318  loss_mask: 0.04869    time: 0.3029  last_time: 0.2978  data_time: 0.0051  last_data_time: 0.0049   lr: 5e-05  max_mem: 2572M
[11/22 07:27:08] d2.utils.events INFO:  eta: 1:01:35  iter: 2739  total_loss: 1.721  loss_ce: 0.41  loss_objectness: 0.6337  loss_dice: 0.5883  loss_mask: 0.04412    time: 0.3029  last_time: 0.3000  data_time: 0.0053  last_data_time: 0.0055   lr: 5e-05  max_mem: 2572M
[11/22 07:27:14] d2.utils.events INFO:  eta: 1:01:29  iter: 2759  total_loss: 1.638  loss_ce: 0.3557  loss_objectness: 0.6492  loss_dice: 0.5815  loss_mask: 0.04701    time: 0.3029  last_time: 0.3028  data_time: 0.0054  last_data_time: 0.0065   lr: 5e-05  max_mem: 2572M
[11/22 07:27:20] d2.utils.events INFO:  eta: 1:01:23  iter: 2779  total_loss: 1.552  loss_ce: 0.3872  loss_objectness: 0.642  loss_dice: 0.4661  loss_mask: 0.05182    time: 0.3029  last_time: 0.3015  data_time: 0.0055  last_data_time: 0.0043   lr: 5e-05  max_mem: 2572M
[11/22 07:27:26] d2.utils.events INFO:  eta: 1:01:17  iter: 2799  total_loss: 1.52  loss_ce: 0.3735  loss_objectness: 0.6337  loss_dice: 0.4808  loss_mask: 0.04002    time: 0.3029  last_time: 0.3064  data_time: 0.0053  last_data_time: 0.0059   lr: 5e-05  max_mem: 2572M
[11/22 07:27:32] d2.utils.events INFO:  eta: 1:01:11  iter: 2819  total_loss: 1.56  loss_ce: 0.3856  loss_objectness: 0.6452  loss_dice: 0.458  loss_mask: 0.04563    time: 0.3029  last_time: 0.2993  data_time: 0.0054  last_data_time: 0.0050   lr: 5e-05  max_mem: 2572M
[11/22 07:27:38] d2.utils.events INFO:  eta: 1:01:05  iter: 2839  total_loss: 1.493  loss_ce: 0.3549  loss_objectness: 0.6312  loss_dice: 0.4576  loss_mask: 0.04342    time: 0.3029  last_time: 0.3037  data_time: 0.0054  last_data_time: 0.0057   lr: 5e-05  max_mem: 2572M
[11/22 07:27:44] d2.utils.events INFO:  eta: 1:00:59  iter: 2859  total_loss: 1.615  loss_ce: 0.3527  loss_objectness: 0.648  loss_dice: 0.5528  loss_mask: 0.04217    time: 0.3028  last_time: 0.2997  data_time: 0.0054  last_data_time: 0.0056   lr: 5e-05  max_mem: 2572M
[11/22 07:27:50] d2.utils.events INFO:  eta: 1:00:52  iter: 2879  total_loss: 1.567  loss_ce: 0.3505  loss_objectness: 0.6387  loss_dice: 0.5066  loss_mask: 0.04633    time: 0.3028  last_time: 0.2993  data_time: 0.0054  last_data_time: 0.0047   lr: 5e-05  max_mem: 2572M
[11/22 07:27:56] d2.utils.events INFO:  eta: 1:00:46  iter: 2899  total_loss: 1.547  loss_ce: 0.3639  loss_objectness: 0.6219  loss_dice: 0.4739  loss_mask: 0.0449    time: 0.3028  last_time: 0.3044  data_time: 0.0050  last_data_time: 0.0051   lr: 5e-05  max_mem: 2572M
[11/22 07:28:02] d2.utils.events INFO:  eta: 1:00:40  iter: 2919  total_loss: 1.502  loss_ce: 0.3622  loss_objectness: 0.6467  loss_dice: 0.4401  loss_mask: 0.04479    time: 0.3028  last_time: 0.2982  data_time: 0.0053  last_data_time: 0.0048   lr: 5e-05  max_mem: 2572M
[11/22 07:28:08] d2.utils.events INFO:  eta: 1:00:34  iter: 2939  total_loss: 1.518  loss_ce: 0.3483  loss_objectness: 0.6237  loss_dice: 0.4647  loss_mask: 0.04142    time: 0.3028  last_time: 0.3016  data_time: 0.0054  last_data_time: 0.0062   lr: 5e-05  max_mem: 2572M
[11/22 07:28:15] d2.utils.events INFO:  eta: 1:00:28  iter: 2959  total_loss: 1.459  loss_ce: 0.3235  loss_objectness: 0.6404  loss_dice: 0.4349  loss_mask: 0.04174    time: 0.3028  last_time: 0.3004  data_time: 0.0052  last_data_time: 0.0054   lr: 5e-05  max_mem: 2572M
[11/22 07:28:21] d2.utils.events INFO:  eta: 1:00:22  iter: 2979  total_loss: 1.516  loss_ce: 0.3691  loss_objectness: 0.6341  loss_dice: 0.4593  loss_mask: 0.04349    time: 0.3028  last_time: 0.2993  data_time: 0.0051  last_data_time: 0.0045   lr: 5e-05  max_mem: 2572M
[11/22 07:28:27] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 07:28:27] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 07:28:27] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 07:28:27] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 07:28:27] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 07:28:27] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 07:28:33] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0223 s/iter. Eval: 0.0573 s/iter. Total: 0.0800 s/iter. ETA=0:00:08
[11/22 07:28:38] d2.evaluation.evaluator INFO: Inference done 74/120. Dataloading: 0.0004 s/iter. Inference: 0.0252 s/iter. Eval: 0.0550 s/iter. Total: 0.0806 s/iter. ETA=0:00:03
[11/22 07:28:42] d2.evaluation.evaluator INFO: Total inference time: 0:00:10.308344 (0.089638 s / iter per device, on 1 devices)
[11/22 07:28:42] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.026070 s / iter per device, on 1 devices)
[11/22 07:28:42] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 07:28:42] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 07:28:42] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 07:28:43] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 07:28:43] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.05 seconds.
[11/22 07:28:43] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 07:28:43] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 07:28:43] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.462 | 14.645 | 6.526  | 0.030 | 13.831 | 43.169 |
[11/22 07:28:43] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 07:28:43] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 07:28:43] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 07:28:43] d2.evaluation.testing INFO: copypaste: 6.4621,14.6452,6.5257,0.0295,13.8315,43.1690
[11/22 07:28:43] d2.utils.events INFO:  eta: 1:00:16  iter: 2999  total_loss: 1.451  loss_ce: 0.3236  loss_objectness: 0.6411  loss_dice: 0.4338  loss_mask: 0.0435    time: 0.3028  last_time: 0.3007  data_time: 0.0053  last_data_time: 0.0051   lr: 5e-05  max_mem: 2572M
[11/22 07:28:49] d2.utils.events INFO:  eta: 1:00:10  iter: 3019  total_loss: 1.471  loss_ce: 0.3235  loss_objectness: 0.6278  loss_dice: 0.4473  loss_mask: 0.04141    time: 0.3028  last_time: 0.3011  data_time: 0.0053  last_data_time: 0.0054   lr: 5e-05  max_mem: 2572M
[11/22 07:28:55] d2.utils.events INFO:  eta: 1:00:04  iter: 3039  total_loss: 1.442  loss_ce: 0.3261  loss_objectness: 0.6138  loss_dice: 0.4405  loss_mask: 0.04532    time: 0.3028  last_time: 0.3005  data_time: 0.0054  last_data_time: 0.0050   lr: 5e-05  max_mem: 2572M
[11/22 07:29:01] d2.utils.events INFO:  eta: 0:59:58  iter: 3059  total_loss: 1.438  loss_ce: 0.3366  loss_objectness: 0.6409  loss_dice: 0.4036  loss_mask: 0.03994    time: 0.3028  last_time: 0.2998  data_time: 0.0053  last_data_time: 0.0048   lr: 5e-05  max_mem: 2572M
[11/22 07:29:07] d2.utils.events INFO:  eta: 0:59:51  iter: 3079  total_loss: 1.444  loss_ce: 0.3415  loss_objectness: 0.6282  loss_dice: 0.4264  loss_mask: 0.04324    time: 0.3028  last_time: 0.2989  data_time: 0.0054  last_data_time: 0.0052   lr: 5e-05  max_mem: 2572M
[11/22 07:29:13] d2.utils.events INFO:  eta: 0:59:45  iter: 3099  total_loss: 1.491  loss_ce: 0.3372  loss_objectness: 0.6473  loss_dice: 0.46  loss_mask: 0.04612    time: 0.3028  last_time: 0.2996  data_time: 0.0053  last_data_time: 0.0045   lr: 5e-05  max_mem: 2572M
[11/22 07:29:19] d2.utils.events INFO:  eta: 0:59:40  iter: 3119  total_loss: 1.644  loss_ce: 0.3208  loss_objectness: 0.6265  loss_dice: 0.6129  loss_mask: 0.04455    time: 0.3028  last_time: 0.3097  data_time: 0.0054  last_data_time: 0.0054   lr: 5e-05  max_mem: 2572M
[11/22 07:29:25] d2.utils.events INFO:  eta: 0:59:34  iter: 3139  total_loss: 1.459  loss_ce: 0.3303  loss_objectness: 0.6319  loss_dice: 0.4226  loss_mask: 0.04563    time: 0.3028  last_time: 0.3021  data_time: 0.0056  last_data_time: 0.0055   lr: 5e-05  max_mem: 2572M
[11/22 07:34:31] d2.utils.events INFO:  eta: 0:59:28  iter: 3159  total_loss: 1.436  loss_ce: 0.3335  loss_objectness: 0.6229  loss_dice: 0.4035  loss_mask: 0.041    time: 0.4055  last_time: 0.3431  data_time: 0.0121  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 07:34:38] d2.utils.events INFO:  eta: 0:59:23  iter: 3179  total_loss: 1.416  loss_ce: 0.3191  loss_objectness: 0.6371  loss_dice: 0.4396  loss_mask: 0.04287    time: 0.4049  last_time: 0.3060  data_time: 0.0057  last_data_time: 0.0049   lr: 5e-05  max_mem: 2572M
[11/22 07:34:44] d2.utils.events INFO:  eta: 0:59:17  iter: 3199  total_loss: 1.541  loss_ce: 0.2968  loss_objectness: 0.6227  loss_dice: 0.4922  loss_mask: 0.04886    time: 0.4043  last_time: 0.3041  data_time: 0.0056  last_data_time: 0.0065   lr: 5e-05  max_mem: 2572M
[11/22 07:34:50] d2.utils.events INFO:  eta: 0:59:11  iter: 3219  total_loss: 1.422  loss_ce: 0.3236  loss_objectness: 0.624  loss_dice: 0.4409  loss_mask: 0.04334    time: 0.4037  last_time: 0.3047  data_time: 0.0056  last_data_time: 0.0054   lr: 5e-05  max_mem: 2572M
[11/22 07:34:56] d2.utils.events INFO:  eta: 0:59:06  iter: 3239  total_loss: 1.496  loss_ce: 0.3308  loss_objectness: 0.6291  loss_dice: 0.4689  loss_mask: 0.04391    time: 0.4031  last_time: 0.3059  data_time: 0.0052  last_data_time: 0.0040   lr: 5e-05  max_mem: 2572M
[11/22 07:35:02] d2.utils.events INFO:  eta: 0:59:00  iter: 3259  total_loss: 1.543  loss_ce: 0.3328  loss_objectness: 0.6505  loss_dice: 0.4744  loss_mask: 0.04087    time: 0.4025  last_time: 0.3036  data_time: 0.0054  last_data_time: 0.0053   lr: 5e-05  max_mem: 2572M
[11/22 07:35:08] d2.utils.events INFO:  eta: 0:58:54  iter: 3279  total_loss: 1.507  loss_ce: 0.3318  loss_objectness: 0.6412  loss_dice: 0.4793  loss_mask: 0.04167    time: 0.4019  last_time: 0.3105  data_time: 0.0050  last_data_time: 0.0055   lr: 5e-05  max_mem: 2572M
[11/22 07:35:14] d2.utils.events INFO:  eta: 0:58:49  iter: 3299  total_loss: 1.491  loss_ce: 0.3375  loss_objectness: 0.6381  loss_dice: 0.454  loss_mask: 0.04475    time: 0.4013  last_time: 0.3365  data_time: 0.0059  last_data_time: 0.0071   lr: 5e-05  max_mem: 2572M
[11/22 20:27:28] d2.utils.events INFO:  eta: 0:58:43  iter: 3319  total_loss: 1.381  loss_ce: 0.3077  loss_objectness: 0.6387  loss_dice: 0.4135  loss_mask: 0.04023    time: 14.3709  last_time: 0.3976  data_time: 0.0126  last_data_time: 0.0432   lr: 5e-05  max_mem: 2572M
[11/22 20:27:35] d2.utils.events INFO:  eta: 0:58:38  iter: 3339  total_loss: 1.413  loss_ce: 0.3241  loss_objectness: 0.6362  loss_dice: 0.4213  loss_mask: 0.04066    time: 14.2869  last_time: 0.3140  data_time: 0.0077  last_data_time: 0.0061   lr: 5e-05  max_mem: 2572M
[11/22 20:27:42] d2.utils.events INFO:  eta: 0:58:34  iter: 3359  total_loss: 1.362  loss_ce: 0.3136  loss_objectness: 0.6354  loss_dice: 0.3772  loss_mask: 0.03821    time: 14.2038  last_time: 0.3207  data_time: 0.0090  last_data_time: 0.0066   lr: 5e-05  max_mem: 2572M
[11/22 20:27:49] d2.utils.events INFO:  eta: 0:58:29  iter: 3379  total_loss: 1.496  loss_ce: 0.3015  loss_objectness: 0.641  loss_dice: 0.4588  loss_mask: 0.04188    time: 14.1216  last_time: 0.3224  data_time: 0.0069  last_data_time: 0.0093   lr: 5e-05  max_mem: 2572M
[11/22 20:27:55] d2.utils.events INFO:  eta: 0:58:24  iter: 3399  total_loss: 1.384  loss_ce: 0.2911  loss_objectness: 0.622  loss_dice: 0.4185  loss_mask: 0.04404    time: 14.0403  last_time: 0.3172  data_time: 0.0060  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 20:28:01] d2.utils.events INFO:  eta: 0:58:19  iter: 3419  total_loss: 1.428  loss_ce: 0.2889  loss_objectness: 0.6289  loss_dice: 0.4486  loss_mask: 0.04081    time: 13.9600  last_time: 0.3148  data_time: 0.0063  last_data_time: 0.0064   lr: 5e-05  max_mem: 2572M
[11/22 20:28:08] d2.utils.events INFO:  eta: 0:58:14  iter: 3439  total_loss: 1.461  loss_ce: 0.3209  loss_objectness: 0.629  loss_dice: 0.423  loss_mask: 0.03731    time: 13.8806  last_time: 0.3139  data_time: 0.0063  last_data_time: 0.0062   lr: 5e-05  max_mem: 2572M
[11/22 20:28:14] d2.utils.events INFO:  eta: 0:58:10  iter: 3459  total_loss: 1.35  loss_ce: 0.2916  loss_objectness: 0.6324  loss_dice: 0.3742  loss_mask: 0.04297    time: 13.8021  last_time: 0.3061  data_time: 0.0057  last_data_time: 0.0048   lr: 5e-05  max_mem: 2572M
[11/22 20:28:20] d2.utils.events INFO:  eta: 0:58:06  iter: 3479  total_loss: 1.452  loss_ce: 0.3245  loss_objectness: 0.6232  loss_dice: 0.404  loss_mask: 0.04605    time: 13.7245  last_time: 0.3089  data_time: 0.0059  last_data_time: 0.0056   lr: 5e-05  max_mem: 2572M
[11/22 20:28:26] d2.utils.events INFO:  eta: 0:58:01  iter: 3499  total_loss: 1.353  loss_ce: 0.2931  loss_objectness: 0.6292  loss_dice: 0.3794  loss_mask: 0.03905    time: 13.6479  last_time: 0.3140  data_time: 0.0063  last_data_time: 0.0076   lr: 5e-05  max_mem: 2572M
[11/22 20:28:32] d2.utils.events INFO:  eta: 0:57:57  iter: 3519  total_loss: 1.334  loss_ce: 0.2806  loss_objectness: 0.6219  loss_dice: 0.366  loss_mask: 0.03776    time: 13.5720  last_time: 0.3018  data_time: 0.0057  last_data_time: 0.0054   lr: 5e-05  max_mem: 2572M
[11/22 20:28:38] d2.utils.events INFO:  eta: 0:57:53  iter: 3539  total_loss: 1.385  loss_ce: 0.3093  loss_objectness: 0.6299  loss_dice: 0.3829  loss_mask: 0.04579    time: 13.4970  last_time: 0.3084  data_time: 0.0057  last_data_time: 0.0049   lr: 5e-05  max_mem: 2572M
[11/22 20:28:45] d2.utils.events INFO:  eta: 0:57:48  iter: 3559  total_loss: 1.353  loss_ce: 0.2759  loss_objectness: 0.6327  loss_dice: 0.36  loss_mask: 0.03569    time: 13.4229  last_time: 0.3044  data_time: 0.0063  last_data_time: 0.0056   lr: 5e-05  max_mem: 2572M
[11/22 20:28:51] d2.utils.events INFO:  eta: 0:57:44  iter: 3579  total_loss: 1.364  loss_ce: 0.2892  loss_objectness: 0.6192  loss_dice: 0.4068  loss_mask: 0.03401    time: 13.3496  last_time: 0.3044  data_time: 0.0057  last_data_time: 0.0055   lr: 5e-05  max_mem: 2572M
[11/22 20:28:57] d2.utils.events INFO:  eta: 0:57:39  iter: 3599  total_loss: 1.411  loss_ce: 0.3073  loss_objectness: 0.6103  loss_dice: 0.3946  loss_mask: 0.03718    time: 13.2771  last_time: 0.3078  data_time: 0.0056  last_data_time: 0.0043   lr: 5e-05  max_mem: 2572M
[11/22 20:29:03] d2.utils.events INFO:  eta: 0:57:33  iter: 3619  total_loss: 1.292  loss_ce: 0.2645  loss_objectness: 0.6257  loss_dice: 0.3641  loss_mask: 0.04214    time: 13.2054  last_time: 0.3065  data_time: 0.0053  last_data_time: 0.0056   lr: 5e-05  max_mem: 2572M
[11/22 20:29:09] d2.utils.events INFO:  eta: 0:57:27  iter: 3639  total_loss: 1.319  loss_ce: 0.2661  loss_objectness: 0.6249  loss_dice: 0.364  loss_mask: 0.04285    time: 13.1344  last_time: 0.3044  data_time: 0.0052  last_data_time: 0.0041   lr: 5e-05  max_mem: 2572M
[11/22 20:29:16] d2.utils.events INFO:  eta: 0:57:23  iter: 3659  total_loss: 1.381  loss_ce: 0.303  loss_objectness: 0.6295  loss_dice: 0.4088  loss_mask: 0.03667    time: 13.0644  last_time: 0.3052  data_time: 0.0061  last_data_time: 0.0064   lr: 5e-05  max_mem: 2572M
[11/22 20:29:22] d2.utils.events INFO:  eta: 0:57:19  iter: 3679  total_loss: 1.317  loss_ce: 0.2593  loss_objectness: 0.6127  loss_dice: 0.378  loss_mask: 0.03486    time: 12.9951  last_time: 0.3040  data_time: 0.0058  last_data_time: 0.0058   lr: 5e-05  max_mem: 2572M
[11/22 20:29:29] d2.utils.events INFO:  eta: 0:57:16  iter: 3699  total_loss: 1.458  loss_ce: 0.322  loss_objectness: 0.6331  loss_dice: 0.4238  loss_mask: 0.04198    time: 12.9266  last_time: 0.3083  data_time: 0.0083  last_data_time: 0.0064   lr: 5e-05  max_mem: 2572M
[11/22 20:29:35] d2.utils.events INFO:  eta: 0:57:11  iter: 3719  total_loss: 1.303  loss_ce: 0.274  loss_objectness: 0.6085  loss_dice: 0.3535  loss_mask: 0.04556    time: 12.8587  last_time: 0.3042  data_time: 0.0056  last_data_time: 0.0047   lr: 5e-05  max_mem: 2572M
[11/22 20:29:41] d2.utils.events INFO:  eta: 0:57:07  iter: 3739  total_loss: 1.347  loss_ce: 0.3081  loss_objectness: 0.6033  loss_dice: 0.3857  loss_mask: 0.03994    time: 12.7916  last_time: 0.3023  data_time: 0.0055  last_data_time: 0.0051   lr: 5e-05  max_mem: 2572M
[11/22 20:29:47] d2.utils.events INFO:  eta: 0:57:02  iter: 3759  total_loss: 1.312  loss_ce: 0.2407  loss_objectness: 0.6261  loss_dice: 0.3502  loss_mask: 0.0328    time: 12.7251  last_time: 0.3059  data_time: 0.0054  last_data_time: 0.0058   lr: 5e-05  max_mem: 2572M
[11/22 20:29:53] d2.utils.events INFO:  eta: 0:56:57  iter: 3779  total_loss: 1.324  loss_ce: 0.2626  loss_objectness: 0.6198  loss_dice: 0.3618  loss_mask: 0.03504    time: 12.6593  last_time: 0.3039  data_time: 0.0055  last_data_time: 0.0056   lr: 5e-05  max_mem: 2572M
[11/22 20:29:59] d2.utils.events INFO:  eta: 0:56:52  iter: 3799  total_loss: 1.305  loss_ce: 0.2578  loss_objectness: 0.6138  loss_dice: 0.36  loss_mask: 0.04062    time: 12.5943  last_time: 0.3036  data_time: 0.0055  last_data_time: 0.0062   lr: 5e-05  max_mem: 2572M
[11/22 20:30:05] d2.utils.events INFO:  eta: 0:56:47  iter: 3819  total_loss: 1.312  loss_ce: 0.2601  loss_objectness: 0.623  loss_dice: 0.4113  loss_mask: 0.0338    time: 12.5299  last_time: 0.3052  data_time: 0.0054  last_data_time: 0.0065   lr: 5e-05  max_mem: 2572M
[11/22 20:30:11] d2.utils.events INFO:  eta: 0:56:41  iter: 3839  total_loss: 1.33  loss_ce: 0.2612  loss_objectness: 0.626  loss_dice: 0.3871  loss_mask: 0.03301    time: 12.4662  last_time: 0.3012  data_time: 0.0054  last_data_time: 0.0048   lr: 5e-05  max_mem: 2572M
[11/22 20:30:18] d2.utils.events INFO:  eta: 0:56:35  iter: 3859  total_loss: 1.308  loss_ce: 0.2633  loss_objectness: 0.6146  loss_dice: 0.397  loss_mask: 0.03475    time: 12.4031  last_time: 0.3018  data_time: 0.0054  last_data_time: 0.0047   lr: 5e-05  max_mem: 2572M
[11/22 20:30:24] d2.utils.events INFO:  eta: 0:56:30  iter: 3879  total_loss: 1.198  loss_ce: 0.2408  loss_objectness: 0.6085  loss_dice: 0.3198  loss_mask: 0.03843    time: 12.3407  last_time: 0.3006  data_time: 0.0053  last_data_time: 0.0048   lr: 5e-05  max_mem: 2572M
[11/22 20:30:30] d2.utils.events INFO:  eta: 0:56:25  iter: 3899  total_loss: 1.274  loss_ce: 0.261  loss_objectness: 0.6203  loss_dice: 0.3527  loss_mask: 0.03116    time: 12.2790  last_time: 0.3068  data_time: 0.0053  last_data_time: 0.0055   lr: 5e-05  max_mem: 2572M
[11/22 20:30:36] d2.utils.events INFO:  eta: 0:56:19  iter: 3919  total_loss: 1.271  loss_ce: 0.2827  loss_objectness: 0.5959  loss_dice: 0.3408  loss_mask: 0.03673    time: 12.2179  last_time: 0.3051  data_time: 0.0057  last_data_time: 0.0059   lr: 5e-05  max_mem: 2572M
[11/22 20:30:42] d2.utils.events INFO:  eta: 0:56:13  iter: 3939  total_loss: 1.28  loss_ce: 0.2676  loss_objectness: 0.622  loss_dice: 0.3591  loss_mask: 0.03826    time: 12.1574  last_time: 0.3068  data_time: 0.0053  last_data_time: 0.0049   lr: 5e-05  max_mem: 2572M
[11/22 20:30:48] d2.utils.events INFO:  eta: 0:56:08  iter: 3959  total_loss: 1.337  loss_ce: 0.3052  loss_objectness: 0.6241  loss_dice: 0.3553  loss_mask: 0.0328    time: 12.0975  last_time: 0.3039  data_time: 0.0056  last_data_time: 0.0054   lr: 5e-05  max_mem: 2572M
[11/22 20:30:54] d2.utils.events INFO:  eta: 0:56:02  iter: 3979  total_loss: 1.206  loss_ce: 0.2361  loss_objectness: 0.5905  loss_dice: 0.3208  loss_mask: 0.03738    time: 12.0382  last_time: 0.3034  data_time: 0.0054  last_data_time: 0.0056   lr: 5e-05  max_mem: 2572M
[11/22 20:31:01] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 20:31:01] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 20:31:01] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 20:31:01] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 20:31:01] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 20:31:01] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 20:31:16] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0004 s/iter. Inference: 0.0238 s/iter. Eval: 0.0571 s/iter. Total: 0.0814 s/iter. ETA=0:00:08
[11/22 20:31:21] d2.evaluation.evaluator INFO: Inference done 72/120. Dataloading: 0.0005 s/iter. Inference: 0.0262 s/iter. Eval: 0.0557 s/iter. Total: 0.0824 s/iter. ETA=0:00:03
[11/22 20:31:26] d2.evaluation.evaluator INFO: Total inference time: 0:00:10.881779 (0.094624 s / iter per device, on 1 devices)
[11/22 20:31:26] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:03 (0.027552 s / iter per device, on 1 devices)
[11/22 20:31:26] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 20:31:26] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 20:31:26] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 20:31:27] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 20:31:27] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.06 seconds.
[11/22 20:31:27] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 20:31:27] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 20:31:27] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.267 | 14.898 | 5.534  | 0.067 | 13.729 | 46.070 |
[11/22 20:31:27] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 20:31:27] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 20:31:27] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 20:31:27] d2.evaluation.testing INFO: copypaste: 6.2670,14.8976,5.5344,0.0675,13.7291,46.0704
[11/22 20:31:27] d2.utils.events INFO:  eta: 0:55:58  iter: 3999  total_loss: 1.376  loss_ce: 0.2556  loss_objectness: 0.6396  loss_dice: 0.4016  loss_mask: 0.04629    time: 11.9795  last_time: 0.3216  data_time: 0.0058  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 20:31:33] d2.utils.events INFO:  eta: 0:55:53  iter: 4019  total_loss: 1.359  loss_ce: 0.2776  loss_objectness: 0.6229  loss_dice: 0.4196  loss_mask: 0.04106    time: 11.9215  last_time: 0.3048  data_time: 0.0057  last_data_time: 0.0054   lr: 5e-05  max_mem: 2572M
[11/22 20:31:39] d2.utils.events INFO:  eta: 0:55:48  iter: 4039  total_loss: 1.29  loss_ce: 0.2588  loss_objectness: 0.6086  loss_dice: 0.3702  loss_mask: 0.03737    time: 11.8640  last_time: 0.3147  data_time: 0.0054  last_data_time: 0.0061   lr: 5e-05  max_mem: 2572M
[11/22 20:31:45] d2.utils.events INFO:  eta: 0:55:43  iter: 4059  total_loss: 1.354  loss_ce: 0.2483  loss_objectness: 0.6179  loss_dice: 0.3878  loss_mask: 0.03736    time: 11.8070  last_time: 0.3067  data_time: 0.0057  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 20:31:51] d2.utils.events INFO:  eta: 0:55:37  iter: 4079  total_loss: 1.191  loss_ce: 0.2131  loss_objectness: 0.6073  loss_dice: 0.3021  loss_mask: 0.04016    time: 11.7506  last_time: 0.3226  data_time: 0.0053  last_data_time: 0.0059   lr: 5e-05  max_mem: 2572M
[11/22 20:31:58] d2.utils.events INFO:  eta: 0:55:32  iter: 4099  total_loss: 1.327  loss_ce: 0.2629  loss_objectness: 0.6125  loss_dice: 0.3751  loss_mask: 0.02923    time: 11.6948  last_time: 0.3063  data_time: 0.0072  last_data_time: 0.0052   lr: 5e-05  max_mem: 2572M
[11/22 20:32:04] d2.utils.events INFO:  eta: 0:55:28  iter: 4119  total_loss: 1.205  loss_ce: 0.2484  loss_objectness: 0.595  loss_dice: 0.3248  loss_mask: 0.03124    time: 11.6395  last_time: 0.3088  data_time: 0.0056  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 20:32:10] d2.utils.events INFO:  eta: 0:55:24  iter: 4139  total_loss: 1.205  loss_ce: 0.2237  loss_objectness: 0.6074  loss_dice: 0.3546  loss_mask: 0.03612    time: 11.5847  last_time: 0.3143  data_time: 0.0054  last_data_time: 0.0058   lr: 5e-05  max_mem: 2572M
[11/22 20:32:17] d2.utils.events INFO:  eta: 0:55:18  iter: 4159  total_loss: 1.269  loss_ce: 0.2327  loss_objectness: 0.6189  loss_dice: 0.3722  loss_mask: 0.03887    time: 11.5305  last_time: 0.3284  data_time: 0.0058  last_data_time: 0.0060   lr: 5e-05  max_mem: 2572M
[11/22 20:32:23] d2.utils.events INFO:  eta: 0:55:13  iter: 4179  total_loss: 1.263  loss_ce: 0.2327  loss_objectness: 0.6118  loss_dice: 0.375  loss_mask: 0.04338    time: 11.4769  last_time: 0.3324  data_time: 0.0058  last_data_time: 0.0060   lr: 5e-05  max_mem: 2572M
[11/22 20:32:30] d2.utils.events INFO:  eta: 0:55:10  iter: 4199  total_loss: 1.289  loss_ce: 0.231  loss_objectness: 0.6015  loss_dice: 0.3719  loss_mask: 0.04097    time: 11.4239  last_time: 0.3459  data_time: 0.0077  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 20:32:37] d2.utils.events INFO:  eta: 0:55:07  iter: 4219  total_loss: 1.195  loss_ce: 0.2048  loss_objectness: 0.6193  loss_dice: 0.3216  loss_mask: 0.03947    time: 11.3713  last_time: 0.3238  data_time: 0.0063  last_data_time: 0.0049   lr: 5e-05  max_mem: 2572M
[11/22 20:32:43] d2.utils.events INFO:  eta: 0:55:04  iter: 4239  total_loss: 1.307  loss_ce: 0.2432  loss_objectness: 0.622  loss_dice: 0.4276  loss_mask: 0.03777    time: 11.3192  last_time: 0.3260  data_time: 0.0062  last_data_time: 0.0071   lr: 5e-05  max_mem: 2572M
[11/22 20:32:50] d2.utils.events INFO:  eta: 0:55:01  iter: 4259  total_loss: 1.289  loss_ce: 0.2486  loss_objectness: 0.6144  loss_dice: 0.4013  loss_mask: 0.03672    time: 11.2675  last_time: 0.3302  data_time: 0.0059  last_data_time: 0.0067   lr: 5e-05  max_mem: 2572M
[11/22 20:32:56] d2.utils.events INFO:  eta: 0:54:59  iter: 4279  total_loss: 1.232  loss_ce: 0.2368  loss_objectness: 0.6173  loss_dice: 0.3434  loss_mask: 0.03611    time: 11.2164  last_time: 0.3287  data_time: 0.0059  last_data_time: 0.0065   lr: 5e-05  max_mem: 2572M
[11/22 20:33:03] d2.utils.events INFO:  eta: 0:54:55  iter: 4299  total_loss: 1.219  loss_ce: 0.2206  loss_objectness: 0.6145  loss_dice: 0.3263  loss_mask: 0.03852    time: 11.1657  last_time: 0.3254  data_time: 0.0055  last_data_time: 0.0056   lr: 5e-05  max_mem: 2572M
[11/22 20:33:10] d2.utils.events INFO:  eta: 0:54:49  iter: 4319  total_loss: 1.165  loss_ce: 0.2233  loss_objectness: 0.6055  loss_dice: 0.3185  loss_mask: 0.03789    time: 11.1155  last_time: 0.3270  data_time: 0.0057  last_data_time: 0.0056   lr: 5e-05  max_mem: 2572M
[11/22 20:33:16] d2.utils.events INFO:  eta: 0:54:45  iter: 4339  total_loss: 1.224  loss_ce: 0.2341  loss_objectness: 0.624  loss_dice: 0.3205  loss_mask: 0.03666    time: 11.0658  last_time: 0.3238  data_time: 0.0056  last_data_time: 0.0052   lr: 5e-05  max_mem: 2572M
[11/22 20:33:23] d2.utils.events INFO:  eta: 0:54:40  iter: 4359  total_loss: 1.283  loss_ce: 0.244  loss_objectness: 0.6235  loss_dice: 0.3959  loss_mask: 0.03176    time: 11.0165  last_time: 0.3304  data_time: 0.0061  last_data_time: 0.0070   lr: 5e-05  max_mem: 2572M
[11/22 20:33:29] d2.utils.events INFO:  eta: 0:54:34  iter: 4379  total_loss: 1.253  loss_ce: 0.2275  loss_objectness: 0.6145  loss_dice: 0.3471  loss_mask: 0.03835    time: 10.9677  last_time: 0.3370  data_time: 0.0072  last_data_time: 0.0072   lr: 5e-05  max_mem: 2572M
[11/22 20:33:36] d2.utils.events INFO:  eta: 0:54:30  iter: 4399  total_loss: 1.161  loss_ce: 0.2058  loss_objectness: 0.6081  loss_dice: 0.3011  loss_mask: 0.03671    time: 10.9193  last_time: 0.3275  data_time: 0.0058  last_data_time: 0.0062   lr: 5e-05  max_mem: 2572M
[11/22 20:33:43] d2.utils.events INFO:  eta: 0:54:24  iter: 4419  total_loss: 1.201  loss_ce: 0.2106  loss_objectness: 0.6003  loss_dice: 0.356  loss_mask: 0.03929    time: 10.8714  last_time: 0.3254  data_time: 0.0056  last_data_time: 0.0066   lr: 5e-05  max_mem: 2572M
[11/22 20:33:49] d2.utils.events INFO:  eta: 0:54:18  iter: 4439  total_loss: 1.395  loss_ce: 0.282  loss_objectness: 0.6285  loss_dice: 0.4003  loss_mask: 0.04505    time: 10.8239  last_time: 0.3449  data_time: 0.0059  last_data_time: 0.0054   lr: 5e-05  max_mem: 2572M
[11/22 20:33:56] d2.utils.events INFO:  eta: 0:54:15  iter: 4459  total_loss: 1.237  loss_ce: 0.2469  loss_objectness: 0.6159  loss_dice: 0.3373  loss_mask: 0.03798    time: 10.7768  last_time: 0.3290  data_time: 0.0056  last_data_time: 0.0056   lr: 5e-05  max_mem: 2572M
[11/22 20:34:02] d2.utils.events INFO:  eta: 0:54:15  iter: 4479  total_loss: 1.244  loss_ce: 0.2469  loss_objectness: 0.6088  loss_dice: 0.3286  loss_mask: 0.0401    time: 10.7301  last_time: 0.3248  data_time: 0.0057  last_data_time: 0.0050   lr: 5e-05  max_mem: 2572M
[11/22 20:34:09] d2.utils.events INFO:  eta: 0:54:12  iter: 4499  total_loss: 1.232  loss_ce: 0.2385  loss_objectness: 0.612  loss_dice: 0.3429  loss_mask: 0.03203    time: 10.6839  last_time: 0.3246  data_time: 0.0058  last_data_time: 0.0052   lr: 5e-05  max_mem: 2572M
[11/22 20:34:15] d2.utils.events INFO:  eta: 0:54:12  iter: 4519  total_loss: 1.296  loss_ce: 0.2608  loss_objectness: 0.6001  loss_dice: 0.3594  loss_mask: 0.03488    time: 10.6380  last_time: 0.3256  data_time: 0.0056  last_data_time: 0.0059   lr: 5e-05  max_mem: 2572M
[11/22 20:34:22] d2.utils.events INFO:  eta: 0:54:20  iter: 4539  total_loss: 1.212  loss_ce: 0.2149  loss_objectness: 0.6229  loss_dice: 0.3279  loss_mask: 0.03638    time: 10.5926  last_time: 0.3246  data_time: 0.0056  last_data_time: 0.0050   lr: 5e-05  max_mem: 2572M
[11/22 20:34:28] d2.utils.events INFO:  eta: 0:54:27  iter: 4559  total_loss: 1.226  loss_ce: 0.2076  loss_objectness: 0.6096  loss_dice: 0.3442  loss_mask: 0.03235    time: 10.5475  last_time: 0.3241  data_time: 0.0058  last_data_time: 0.0058   lr: 5e-05  max_mem: 2572M
[11/22 20:34:35] d2.utils.events INFO:  eta: 0:54:39  iter: 4579  total_loss: 1.115  loss_ce: 0.1993  loss_objectness: 0.6032  loss_dice: 0.2616  loss_mask: 0.03548    time: 10.5029  last_time: 0.3165  data_time: 0.0061  last_data_time: 0.0058   lr: 5e-05  max_mem: 2572M
[11/22 20:34:41] d2.utils.events INFO:  eta: 0:54:42  iter: 4599  total_loss: 1.149  loss_ce: 0.2194  loss_objectness: 0.5889  loss_dice: 0.2973  loss_mask: 0.03159    time: 10.4585  last_time: 0.3001  data_time: 0.0059  last_data_time: 0.0053   lr: 5e-05  max_mem: 2572M
[11/22 20:34:47] d2.utils.events INFO:  eta: 0:54:42  iter: 4619  total_loss: 1.238  loss_ce: 0.2344  loss_objectness: 0.5991  loss_dice: 0.3334  loss_mask: 0.03126    time: 10.4146  last_time: 0.3302  data_time: 0.0056  last_data_time: 0.0063   lr: 5e-05  max_mem: 2572M
[11/22 20:34:54] d2.utils.events INFO:  eta: 0:54:47  iter: 4639  total_loss: 1.085  loss_ce: 0.1749  loss_objectness: 0.5852  loss_dice: 0.2757  loss_mask: 0.03473    time: 10.3710  last_time: 0.3165  data_time: 0.0073  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 20:35:00] d2.utils.events INFO:  eta: 0:54:38  iter: 4659  total_loss: 1.227  loss_ce: 0.2126  loss_objectness: 0.6078  loss_dice: 0.3589  loss_mask: 0.02967    time: 10.3279  last_time: 0.3345  data_time: 0.0064  last_data_time: 0.0057   lr: 5e-05  max_mem: 2572M
[11/22 20:35:07] d2.utils.events INFO:  eta: 0:54:40  iter: 4679  total_loss: 1.13  loss_ce: 0.1899  loss_objectness: 0.6014  loss_dice: 0.2985  loss_mask: 0.03162    time: 10.2851  last_time: 0.3317  data_time: 0.0058  last_data_time: 0.0055   lr: 5e-05  max_mem: 2572M
[11/22 20:35:13] d2.utils.events INFO:  eta: 0:54:54  iter: 4699  total_loss: 1.137  loss_ce: 0.2006  loss_objectness: 0.5939  loss_dice: 0.3025  loss_mask: 0.03374    time: 10.2428  last_time: 0.3288  data_time: 0.0060  last_data_time: 0.0062   lr: 5e-05  max_mem: 2572M
[11/22 20:35:20] d2.utils.events INFO:  eta: 0:55:07  iter: 4719  total_loss: 1.175  loss_ce: 0.2115  loss_objectness: 0.5706  loss_dice: 0.329  loss_mask: 0.03325    time: 10.2007  last_time: 0.3149  data_time: 0.0057  last_data_time: 0.0063   lr: 5e-05  max_mem: 2572M
[11/22 20:35:26] d2.utils.events INFO:  eta: 0:55:07  iter: 4739  total_loss: 1.226  loss_ce: 0.2069  loss_objectness: 0.6148  loss_dice: 0.343  loss_mask: 0.03325    time: 10.1590  last_time: 0.3088  data_time: 0.0067  last_data_time: 0.0054   lr: 5e-05  max_mem: 2572M
[11/22 20:35:33] d2.utils.events INFO:  eta: 0:55:03  iter: 4759  total_loss: 1.193  loss_ce: 0.1941  loss_objectness: 0.6141  loss_dice: 0.3277  loss_mask: 0.03393    time: 10.1177  last_time: 0.3125  data_time: 0.0061  last_data_time: 0.0062   lr: 5e-05  max_mem: 2572M
[11/22 20:35:39] d2.utils.events INFO:  eta: 0:54:57  iter: 4779  total_loss: 1.086  loss_ce: 0.164  loss_objectness: 0.5958  loss_dice: 0.2924  loss_mask: 0.03205    time: 10.0766  last_time: 0.3041  data_time: 0.0055  last_data_time: 0.0050   lr: 5e-05  max_mem: 2572M
[11/22 20:35:45] d2.utils.events INFO:  eta: 0:54:51  iter: 4799  total_loss: 1.131  loss_ce: 0.1718  loss_objectness: 0.5925  loss_dice: 0.3581  loss_mask: 0.03546    time: 10.0359  last_time: 0.3518  data_time: 0.0055  last_data_time: 0.0080   lr: 5e-05  max_mem: 2572M
[11/22 20:35:52] d2.utils.events INFO:  eta: 0:54:48  iter: 4819  total_loss: 1.162  loss_ce: 0.1934  loss_objectness: 0.6187  loss_dice: 0.3255  loss_mask: 0.03629    time: 9.9956  last_time: 0.3334  data_time: 0.0062  last_data_time: 0.0054   lr: 5e-05  max_mem: 2572M
[11/22 20:35:58] d2.utils.events INFO:  eta: 0:54:45  iter: 4839  total_loss: 1.175  loss_ce: 0.2266  loss_objectness: 0.6201  loss_dice: 0.304  loss_mask: 0.03322    time: 9.9556  last_time: 0.3216  data_time: 0.0077  last_data_time: 0.0055   lr: 5e-05  max_mem: 2572M
[11/22 20:36:04] d2.utils.events INFO:  eta: 0:54:39  iter: 4859  total_loss: 1.145  loss_ce: 0.1909  loss_objectness: 0.5891  loss_dice: 0.315  loss_mask: 0.03506    time: 9.9159  last_time: 0.3129  data_time: 0.0057  last_data_time: 0.0053   lr: 5e-05  max_mem: 2572M
[11/22 20:36:11] d2.utils.events INFO:  eta: 0:54:33  iter: 4879  total_loss: 1.081  loss_ce: 0.1863  loss_objectness: 0.5804  loss_dice: 0.2942  loss_mask: 0.03287    time: 9.8765  last_time: 0.3097  data_time: 0.0058  last_data_time: 0.0055   lr: 5e-05  max_mem: 2572M
[11/22 20:36:17] d2.utils.events INFO:  eta: 0:54:27  iter: 4899  total_loss: 1.066  loss_ce: 0.1976  loss_objectness: 0.5739  loss_dice: 0.2806  loss_mask: 0.02891    time: 9.8375  last_time: 0.3071  data_time: 0.0056  last_data_time: 0.0063   lr: 5e-05  max_mem: 2572M
[11/22 20:36:23] d2.utils.events INFO:  eta: 0:54:20  iter: 4919  total_loss: 1.07  loss_ce: 0.1736  loss_objectness: 0.5905  loss_dice: 0.267  loss_mask: 0.02832    time: 9.7987  last_time: 0.3186  data_time: 0.0058  last_data_time: 0.0053   lr: 5e-05  max_mem: 2572M
[11/22 20:36:30] d2.utils.events INFO:  eta: 0:54:16  iter: 4939  total_loss: 0.9948  loss_ce: 0.1667  loss_objectness: 0.567  loss_dice: 0.2459  loss_mask: 0.03281    time: 9.7604  last_time: 0.3185  data_time: 0.0066  last_data_time: 0.0058   lr: 5e-05  max_mem: 2572M
[11/22 20:36:36] d2.utils.events INFO:  eta: 0:54:10  iter: 4959  total_loss: 1.111  loss_ce: 0.187  loss_objectness: 0.5924  loss_dice: 0.2828  loss_mask: 0.02996    time: 9.7223  last_time: 0.3107  data_time: 0.0057  last_data_time: 0.0052   lr: 5e-05  max_mem: 2572M
[11/22 20:36:42] d2.utils.events INFO:  eta: 0:54:04  iter: 4979  total_loss: 1.021  loss_ce: 0.172  loss_objectness: 0.5771  loss_dice: 0.2581  loss_mask: 0.02572    time: 9.6845  last_time: 0.3251  data_time: 0.0058  last_data_time: 0.0049   lr: 5e-05  max_mem: 2572M
[11/22 20:36:49] fvcore.common.checkpoint INFO: Saving checkpoint to output/crack_model_turbo\model_0004999.pth
[11/22 20:36:49] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 20:36:49] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 20:36:49] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 20:36:49] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 20:36:49] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 20:36:49] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 20:37:00] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0004 s/iter. Inference: 0.0237 s/iter. Eval: 0.0602 s/iter. Total: 0.0842 s/iter. ETA=0:00:09
[11/22 20:37:05] d2.evaluation.evaluator INFO: Inference done 62/120. Dataloading: 0.0005 s/iter. Inference: 0.0372 s/iter. Eval: 0.0597 s/iter. Total: 0.0976 s/iter. ETA=0:00:05
[11/22 20:37:10] d2.evaluation.evaluator INFO: Inference done 120/120. Dataloading: 0.0006 s/iter. Inference: 0.0314 s/iter. Eval: 0.0601 s/iter. Total: 0.0922 s/iter. ETA=0:00:00
[11/22 20:37:11] d2.evaluation.evaluator INFO: Total inference time: 0:00:11.761050 (0.102270 s / iter per device, on 1 devices)
[11/22 20:37:11] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:03 (0.031414 s / iter per device, on 1 devices)
[11/22 20:37:11] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 20:37:11] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 20:37:11] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 20:37:12] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 20:37:12] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.08 seconds.
[11/22 20:37:12] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 20:37:12] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 20:37:12] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.652 | 14.498 | 6.008  | 0.298 | 13.255 | 49.886 |
[11/22 20:37:12] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 20:37:12] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 20:37:12] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 20:37:12] d2.evaluation.testing INFO: copypaste: 6.6517,14.4981,6.0079,0.2980,13.2551,49.8857
[11/22 20:37:12] d2.utils.events INFO:  eta: 0:53:57  iter: 4999  total_loss: 1.023  loss_ce: 0.1532  loss_objectness: 0.5773  loss_dice: 0.2835  loss_mask: 0.02636    time: 9.6470  last_time: 0.3312  data_time: 0.0058  last_data_time: 0.0053   lr: 5e-05  max_mem: 2572M
[11/22 20:37:18] d2.utils.events INFO:  eta: 0:53:51  iter: 5019  total_loss: 1.089  loss_ce: 0.176  loss_objectness: 0.5878  loss_dice: 0.3044  loss_mask: 0.03054    time: 9.6098  last_time: 0.3125  data_time: 0.0094  last_data_time: 0.0067   lr: 5e-05  max_mem: 2572M
[11/22 20:37:25] d2.utils.events INFO:  eta: 0:53:46  iter: 5039  total_loss: 1.06  loss_ce: 0.163  loss_objectness: 0.5847  loss_dice: 0.2672  loss_mask: 0.02817    time: 9.5729  last_time: 0.3133  data_time: 0.0074  last_data_time: 0.0072   lr: 5e-05  max_mem: 2572M
[11/22 20:37:31] d2.utils.events INFO:  eta: 0:53:40  iter: 5059  total_loss: 1.002  loss_ce: 0.1505  loss_objectness: 0.5733  loss_dice: 0.2568  loss_mask: 0.03022    time: 9.5363  last_time: 0.3073  data_time: 0.0060  last_data_time: 0.0065   lr: 5e-05  max_mem: 2572M
[11/22 20:37:37] d2.utils.events INFO:  eta: 0:53:33  iter: 5079  total_loss: 1.072  loss_ce: 0.1684  loss_objectness: 0.5883  loss_dice: 0.2611  loss_mask: 0.02684    time: 9.5000  last_time: 0.3097  data_time: 0.0054  last_data_time: 0.0046   lr: 5e-05  max_mem: 2572M
[11/22 20:37:48] d2.utils.events INFO:  eta: 0:53:29  iter: 5099  total_loss: 1.1  loss_ce: 0.1869  loss_objectness: 0.5809  loss_dice: 0.298  loss_mask: 0.03236    time: 9.4648  last_time: 0.6975  data_time: 0.0063  last_data_time: 0.0070   lr: 5e-05  max_mem: 2572M
[11/22 20:38:02] d2.utils.events INFO:  eta: 0:53:26  iter: 5119  total_loss: 1.036  loss_ce: 0.1481  loss_objectness: 0.5809  loss_dice: 0.2705  loss_mask: 0.0337    time: 9.4306  last_time: 0.7094  data_time: 0.0068  last_data_time: 0.0070   lr: 5e-05  max_mem: 2572M
[11/22 20:38:17] d2.utils.events INFO:  eta: 0:53:22  iter: 5139  total_loss: 1.065  loss_ce: 0.1753  loss_objectness: 0.5905  loss_dice: 0.3013  loss_mask: 0.03432    time: 9.3967  last_time: 0.7139  data_time: 0.0073  last_data_time: 0.0066   lr: 5e-05  max_mem: 2572M
[11/22 20:38:29] d2.utils.events INFO:  eta: 0:53:16  iter: 5159  total_loss: 1.195  loss_ce: 0.2514  loss_objectness: 0.6029  loss_dice: 0.3202  loss_mask: 0.03318    time: 9.3626  last_time: 0.4098  data_time: 0.0066  last_data_time: 0.0065   lr: 5e-05  max_mem: 2572M
[11/22 20:38:41] d2.utils.events INFO:  eta: 0:53:10  iter: 5179  total_loss: 1.21  loss_ce: 0.2293  loss_objectness: 0.6208  loss_dice: 0.3447  loss_mask: 0.03794    time: 9.3288  last_time: 0.7801  data_time: 0.0069  last_data_time: 0.0086   lr: 5e-05  max_mem: 2572M
[11/22 20:38:57] d2.utils.events INFO:  eta: 0:53:04  iter: 5199  total_loss: 1.137  loss_ce: 0.1798  loss_objectness: 0.6092  loss_dice: 0.3014  loss_mask: 0.03906    time: 9.2959  last_time: 0.7858  data_time: 0.0085  last_data_time: 0.0107   lr: 5e-05  max_mem: 2572M
[11/22 20:39:12] d2.utils.events INFO:  eta: 0:52:57  iter: 5219  total_loss: 1.093  loss_ce: 0.1647  loss_objectness: 0.5977  loss_dice: 0.3005  loss_mask: 0.02845    time: 9.2633  last_time: 0.8043  data_time: 0.0091  last_data_time: 0.0082   lr: 5e-05  max_mem: 2572M
[11/22 20:39:28] d2.utils.events INFO:  eta: 0:52:51  iter: 5239  total_loss: 1.1  loss_ce: 0.1614  loss_objectness: 0.6051  loss_dice: 0.3104  loss_mask: 0.03728    time: 9.2309  last_time: 0.7838  data_time: 0.0077  last_data_time: 0.0069   lr: 5e-05  max_mem: 2572M
[11/22 20:39:44] d2.utils.events INFO:  eta: 0:52:45  iter: 5259  total_loss: 1.127  loss_ce: 0.1693  loss_objectness: 0.5918  loss_dice: 0.3252  loss_mask: 0.02815    time: 9.1988  last_time: 0.7722  data_time: 0.0085  last_data_time: 0.0077   lr: 5e-05  max_mem: 2572M
[11/22 20:39:59] d2.utils.events INFO:  eta: 0:52:40  iter: 5279  total_loss: 1.061  loss_ce: 0.1646  loss_objectness: 0.583  loss_dice: 0.2902  loss_mask: 0.03467    time: 9.1669  last_time: 0.7436  data_time: 0.0077  last_data_time: 0.0063   lr: 5e-05  max_mem: 2572M
[11/22 20:40:15] d2.utils.events INFO:  eta: 0:52:34  iter: 5299  total_loss: 1.112  loss_ce: 0.1879  loss_objectness: 0.5912  loss_dice: 0.2995  loss_mask: 0.03018    time: 9.1352  last_time: 0.7759  data_time: 0.0090  last_data_time: 0.0072   lr: 5e-05  max_mem: 2572M
[11/22 20:40:28] d2.utils.events INFO:  eta: 0:52:29  iter: 5319  total_loss: 1.098  loss_ce: 0.1536  loss_objectness: 0.6054  loss_dice: 0.3028  loss_mask: 0.0284    time: 9.1033  last_time: 0.3218  data_time: 0.0086  last_data_time: 0.0060   lr: 5e-05  max_mem: 2572M
[11/22 20:40:34] d2.utils.events INFO:  eta: 0:52:21  iter: 5339  total_loss: 0.9998  loss_ce: 0.1206  loss_objectness: 0.569  loss_dice: 0.2617  loss_mask: 0.03104    time: 9.0704  last_time: 0.3133  data_time: 0.0066  last_data_time: 0.0060   lr: 5e-05  max_mem: 2572M
[11/22 20:40:48] d2.utils.events INFO:  eta: 0:52:16  iter: 5359  total_loss: 1.139  loss_ce: 0.1775  loss_objectness: 0.5861  loss_dice: 0.2918  loss_mask: 0.03031    time: 9.0391  last_time: 0.8197  data_time: 0.0075  last_data_time: 0.0095   lr: 5e-05  max_mem: 2572M
[11/22 20:41:04] d2.utils.events INFO:  eta: 0:52:09  iter: 5379  total_loss: 1.103  loss_ce: 0.1546  loss_objectness: 0.5934  loss_dice: 0.3072  loss_mask: 0.0323    time: 9.0085  last_time: 0.8232  data_time: 0.0083  last_data_time: 0.0072   lr: 5e-05  max_mem: 2572M
[11/22 20:41:20] d2.utils.events INFO:  eta: 0:52:06  iter: 5399  total_loss: 1.042  loss_ce: 0.1427  loss_objectness: 0.602  loss_dice: 0.2853  loss_mask: 0.03003    time: 8.9781  last_time: 0.8342  data_time: 0.0089  last_data_time: 0.0091   lr: 5e-05  max_mem: 2572M
[11/22 20:41:35] d2.utils.events INFO:  eta: 0:52:03  iter: 5419  total_loss: 1.022  loss_ce: 0.1614  loss_objectness: 0.5619  loss_dice: 0.2657  loss_mask: 0.02837    time: 8.9477  last_time: 0.7546  data_time: 0.0083  last_data_time: 0.0075   lr: 5e-05  max_mem: 2572M
[11/22 20:41:51] d2.utils.events INFO:  eta: 0:51:58  iter: 5439  total_loss: 1.073  loss_ce: 0.1463  loss_objectness: 0.5835  loss_dice: 0.2846  loss_mask: 0.03225    time: 8.9177  last_time: 0.8042  data_time: 0.0083  last_data_time: 0.0094   lr: 5e-05  max_mem: 2572M
[11/22 20:42:06] d2.utils.events INFO:  eta: 0:51:56  iter: 5459  total_loss: 1.049  loss_ce: 0.1465  loss_objectness: 0.5764  loss_dice: 0.2934  loss_mask: 0.02971    time: 8.8878  last_time: 0.7741  data_time: 0.0086  last_data_time: 0.0075   lr: 5e-05  max_mem: 2572M
[11/22 20:42:22] d2.utils.events INFO:  eta: 0:52:01  iter: 5479  total_loss: 1.076  loss_ce: 0.1591  loss_objectness: 0.5965  loss_dice: 0.2682  loss_mask: 0.03188    time: 8.8583  last_time: 0.7978  data_time: 0.0082  last_data_time: 0.0084   lr: 5e-05  max_mem: 2572M
[11/22 20:42:38] d2.utils.events INFO:  eta: 0:52:09  iter: 5499  total_loss: 1.018  loss_ce: 0.1324  loss_objectness: 0.5787  loss_dice: 0.2573  loss_mask: 0.02803    time: 8.8289  last_time: 0.8543  data_time: 0.0100  last_data_time: 0.0352   lr: 5e-05  max_mem: 2572M
[11/22 20:42:53] d2.utils.events INFO:  eta: 0:52:13  iter: 5519  total_loss: 1.069  loss_ce: 0.1417  loss_objectness: 0.5895  loss_dice: 0.3077  loss_mask: 0.03666    time: 8.7997  last_time: 0.7710  data_time: 0.0089  last_data_time: 0.0060   lr: 5e-05  max_mem: 2572M
[11/22 20:43:09] d2.utils.events INFO:  eta: 0:52:29  iter: 5539  total_loss: 1.046  loss_ce: 0.167  loss_objectness: 0.5856  loss_dice: 0.2755  loss_mask: 0.02683    time: 8.7707  last_time: 0.8022  data_time: 0.0082  last_data_time: 0.0097   lr: 5e-05  max_mem: 2572M
[11/22 20:43:25] d2.utils.events INFO:  eta: 0:52:56  iter: 5559  total_loss: 0.8871  loss_ce: 0.0904  loss_objectness: 0.5514  loss_dice: 0.2169  loss_mask: 0.03132    time: 8.7420  last_time: 0.8144  data_time: 0.0089  last_data_time: 0.0102   lr: 5e-05  max_mem: 2572M
[11/22 20:43:41] d2.utils.events INFO:  eta: 0:53:20  iter: 5579  total_loss: 1.074  loss_ce: 0.1656  loss_objectness: 0.5967  loss_dice: 0.2917  loss_mask: 0.02684    time: 8.7136  last_time: 0.7837  data_time: 0.0085  last_data_time: 0.0073   lr: 5e-05  max_mem: 2572M
[11/22 20:43:56] d2.utils.events INFO:  eta: 0:55:31  iter: 5599  total_loss: 1.144  loss_ce: 0.1739  loss_objectness: 0.6059  loss_dice: 0.3043  loss_mask: 0.03378    time: 8.6852  last_time: 0.7992  data_time: 0.0084  last_data_time: 0.0059   lr: 5e-05  max_mem: 2572M
[11/22 20:44:12] d2.utils.events INFO:  eta: 1:09:21  iter: 5619  total_loss: 1.046  loss_ce: 0.1495  loss_objectness: 0.5851  loss_dice: 0.3003  loss_mask: 0.0315    time: 8.6570  last_time: 0.7876  data_time: 0.0095  last_data_time: 0.0085   lr: 5e-05  max_mem: 2572M
[11/22 20:44:27] d2.utils.events INFO:  eta: 1:42:26  iter: 5639  total_loss: 1.002  loss_ce: 0.1139  loss_objectness: 0.5929  loss_dice: 0.2862  loss_mask: 0.028    time: 8.6291  last_time: 0.8099  data_time: 0.0083  last_data_time: 0.0083   lr: 5e-05  max_mem: 2572M
[11/22 20:44:43] d2.utils.events INFO:  eta: 1:46:19  iter: 5659  total_loss: 0.963  loss_ce: 0.1264  loss_objectness: 0.5657  loss_dice: 0.2376  loss_mask: 0.0331    time: 8.6014  last_time: 0.7397  data_time: 0.0081  last_data_time: 0.0072   lr: 5e-05  max_mem: 2572M
[11/22 20:44:59] d2.utils.events INFO:  eta: 1:48:44  iter: 5679  total_loss: 1.041  loss_ce: 0.146  loss_objectness: 0.572  loss_dice: 0.2929  loss_mask: 0.02917    time: 8.5739  last_time: 0.8029  data_time: 0.0085  last_data_time: 0.0077   lr: 5e-05  max_mem: 2572M
[11/22 20:45:16] d2.utils.events INFO:  eta: 1:50:11  iter: 5699  total_loss: 0.9749  loss_ce: 0.1206  loss_objectness: 0.5728  loss_dice: 0.2584  loss_mask: 0.02664    time: 8.5467  last_time: 0.8074  data_time: 0.0085  last_data_time: 0.0093   lr: 5e-05  max_mem: 2572M
[11/22 20:45:31] d2.utils.events INFO:  eta: 1:51:21  iter: 5719  total_loss: 0.9746  loss_ce: 0.1456  loss_objectness: 0.5619  loss_dice: 0.2473  loss_mask: 0.02806    time: 8.5196  last_time: 0.7724  data_time: 0.0083  last_data_time: 0.0066   lr: 5e-05  max_mem: 2572M
[11/22 20:45:47] d2.utils.events INFO:  eta: 1:53:25  iter: 5739  total_loss: 0.9485  loss_ce: 0.1282  loss_objectness: 0.562  loss_dice: 0.2415  loss_mask: 0.03013    time: 8.4926  last_time: 0.8246  data_time: 0.0083  last_data_time: 0.0073   lr: 5e-05  max_mem: 2572M
[11/22 20:46:03] d2.utils.events INFO:  eta: 1:53:54  iter: 5759  total_loss: 0.9584  loss_ce: 0.1199  loss_objectness: 0.5567  loss_dice: 0.2454  loss_mask: 0.02891    time: 8.4659  last_time: 0.7814  data_time: 0.0087  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 20:46:19] d2.utils.events INFO:  eta: 1:54:50  iter: 5779  total_loss: 0.9957  loss_ce: 0.1371  loss_objectness: 0.5841  loss_dice: 0.2434  loss_mask: 0.02767    time: 8.4393  last_time: 0.8045  data_time: 0.0084  last_data_time: 0.0075   lr: 5e-05  max_mem: 2572M
[11/22 20:46:32] d2.utils.events INFO:  eta: 1:55:08  iter: 5799  total_loss: 0.9669  loss_ce: 0.1245  loss_objectness: 0.5596  loss_dice: 0.2543  loss_mask: 0.02759    time: 8.4125  last_time: 0.5883  data_time: 0.0076  last_data_time: 0.0077   lr: 5e-05  max_mem: 2572M
[11/22 20:46:44] d2.utils.events INFO:  eta: 1:54:53  iter: 5819  total_loss: 0.9406  loss_ce: 0.1265  loss_objectness: 0.5498  loss_dice: 0.2264  loss_mask: 0.02893    time: 8.3856  last_time: 0.5893  data_time: 0.0073  last_data_time: 0.0069   lr: 5e-05  max_mem: 2572M
[11/22 20:46:56] d2.utils.events INFO:  eta: 1:54:38  iter: 5839  total_loss: 1.068  loss_ce: 0.1654  loss_objectness: 0.5864  loss_dice: 0.2513  loss_mask: 0.02708    time: 8.3589  last_time: 0.5887  data_time: 0.0076  last_data_time: 0.0078   lr: 5e-05  max_mem: 2572M
[11/22 20:47:07] d2.utils.events INFO:  eta: 1:54:23  iter: 5859  total_loss: 1.088  loss_ce: 0.1532  loss_objectness: 0.5905  loss_dice: 0.3117  loss_mask: 0.02924    time: 8.3324  last_time: 0.6005  data_time: 0.0072  last_data_time: 0.0081   lr: 5e-05  max_mem: 2572M
[11/22 20:47:19] d2.utils.events INFO:  eta: 1:54:08  iter: 5879  total_loss: 0.9785  loss_ce: 0.1285  loss_objectness: 0.5702  loss_dice: 0.2365  loss_mask: 0.03024    time: 8.3060  last_time: 0.5973  data_time: 0.0070  last_data_time: 0.0075   lr: 5e-05  max_mem: 2572M
[11/22 20:47:31] d2.utils.events INFO:  eta: 1:53:53  iter: 5899  total_loss: 1.086  loss_ce: 0.1592  loss_objectness: 0.5908  loss_dice: 0.2943  loss_mask: 0.02831    time: 8.2798  last_time: 0.5670  data_time: 0.0071  last_data_time: 0.0063   lr: 5e-05  max_mem: 2572M
[11/22 20:47:43] d2.utils.events INFO:  eta: 1:53:38  iter: 5919  total_loss: 1.059  loss_ce: 0.1547  loss_objectness: 0.5804  loss_dice: 0.2758  loss_mask: 0.03053    time: 8.2538  last_time: 0.5915  data_time: 0.0073  last_data_time: 0.0059   lr: 5e-05  max_mem: 2572M
[11/22 20:47:55] d2.utils.events INFO:  eta: 1:53:23  iter: 5939  total_loss: 0.9738  loss_ce: 0.1145  loss_objectness: 0.5857  loss_dice: 0.2478  loss_mask: 0.02955    time: 8.2280  last_time: 0.6197  data_time: 0.0074  last_data_time: 0.0067   lr: 5e-05  max_mem: 2572M
[11/22 20:48:07] d2.utils.events INFO:  eta: 1:53:08  iter: 5959  total_loss: 1.014  loss_ce: 0.1177  loss_objectness: 0.5831  loss_dice: 0.2862  loss_mask: 0.03171    time: 8.2024  last_time: 0.6033  data_time: 0.0077  last_data_time: 0.0077   lr: 5e-05  max_mem: 2572M
[11/22 20:48:18] d2.utils.events INFO:  eta: 1:52:53  iter: 5979  total_loss: 0.9443  loss_ce: 0.121  loss_objectness: 0.5806  loss_dice: 0.2194  loss_mask: 0.02764    time: 8.1770  last_time: 0.5955  data_time: 0.0072  last_data_time: 0.0075   lr: 5e-05  max_mem: 2572M
[11/22 20:48:30] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 20:48:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 20:48:30] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 20:48:30] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 20:48:30] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 20:48:30] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 20:48:39] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0005 s/iter. Inference: 0.0416 s/iter. Eval: 0.0588 s/iter. Total: 0.1009 s/iter. ETA=0:00:10
[11/22 20:48:44] d2.evaluation.evaluator INFO: Inference done 58/120. Dataloading: 0.0006 s/iter. Inference: 0.0427 s/iter. Eval: 0.0640 s/iter. Total: 0.1073 s/iter. ETA=0:00:06
[11/22 20:48:49] d2.evaluation.evaluator INFO: Inference done 106/120. Dataloading: 0.0006 s/iter. Inference: 0.0431 s/iter. Eval: 0.0622 s/iter. Total: 0.1059 s/iter. ETA=0:00:01
[11/22 20:48:51] d2.evaluation.evaluator INFO: Total inference time: 0:00:13.432542 (0.116805 s / iter per device, on 1 devices)
[11/22 20:48:51] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:04 (0.043235 s / iter per device, on 1 devices)
[11/22 20:48:52] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 20:48:52] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 20:48:52] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 20:48:52] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 20:48:52] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.08 seconds.
[11/22 20:48:52] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 20:48:52] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 20:48:52] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.364 | 13.317 | 6.095  | 0.324 | 12.607 | 45.055 |
[11/22 20:48:52] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 20:48:52] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 20:48:52] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 20:48:52] d2.evaluation.testing INFO: copypaste: 6.3644,13.3167,6.0949,0.3243,12.6074,45.0554
[11/22 20:48:52] d2.utils.events INFO:  eta: 1:52:38  iter: 5999  total_loss: 0.9094  loss_ce: 0.116  loss_objectness: 0.5607  loss_dice: 0.2198  loss_mask: 0.02667    time: 8.1517  last_time: 0.6027  data_time: 0.0074  last_data_time: 0.0081   lr: 5e-05  max_mem: 2572M
[11/22 20:49:04] d2.utils.events INFO:  eta: 1:52:23  iter: 6019  total_loss: 0.9557  loss_ce: 0.1063  loss_objectness: 0.5612  loss_dice: 0.2436  loss_mask: 0.0278    time: 8.1266  last_time: 0.6602  data_time: 0.0073  last_data_time: 0.0079   lr: 5e-05  max_mem: 2572M
[11/22 20:49:18] d2.utils.events INFO:  eta: 1:52:08  iter: 6039  total_loss: 0.9552  loss_ce: 0.1202  loss_objectness: 0.5655  loss_dice: 0.2361  loss_mask: 0.02594    time: 8.1020  last_time: 0.6845  data_time: 0.0077  last_data_time: 0.0065   lr: 5e-05  max_mem: 2572M
[11/22 20:49:32] d2.utils.events INFO:  eta: 1:52:18  iter: 6059  total_loss: 0.9968  loss_ce: 0.1305  loss_objectness: 0.5693  loss_dice: 0.2726  loss_mask: 0.03196    time: 8.0776  last_time: 0.7475  data_time: 0.0076  last_data_time: 0.0072   lr: 5e-05  max_mem: 2572M
[11/22 20:49:47] d2.utils.events INFO:  eta: 1:52:25  iter: 6079  total_loss: 0.9293  loss_ce: 0.1204  loss_objectness: 0.5493  loss_dice: 0.2372  loss_mask: 0.02875    time: 8.0535  last_time: 0.7376  data_time: 0.0085  last_data_time: 0.0086   lr: 5e-05  max_mem: 2572M
[11/22 20:50:02] d2.utils.events INFO:  eta: 1:52:17  iter: 6099  total_loss: 0.9735  loss_ce: 0.1147  loss_objectness: 0.5744  loss_dice: 0.263  loss_mask: 0.02821    time: 8.0295  last_time: 0.7462  data_time: 0.0079  last_data_time: 0.0090   lr: 5e-05  max_mem: 2572M
[11/22 20:50:17] d2.utils.events INFO:  eta: 1:52:15  iter: 6119  total_loss: 0.9774  loss_ce: 0.1244  loss_objectness: 0.5514  loss_dice: 0.255  loss_mask: 0.02516    time: 8.0058  last_time: 0.7675  data_time: 0.0079  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 20:50:32] d2.utils.events INFO:  eta: 1:52:06  iter: 6139  total_loss: 0.9989  loss_ce: 0.1194  loss_objectness: 0.5767  loss_dice: 0.2575  loss_mask: 0.02769    time: 7.9821  last_time: 0.7555  data_time: 0.0078  last_data_time: 0.0088   lr: 5e-05  max_mem: 2572M
[11/22 20:50:47] d2.utils.events INFO:  eta: 1:51:51  iter: 6159  total_loss: 0.8822  loss_ce: 0.08592  loss_objectness: 0.5386  loss_dice: 0.2146  loss_mask: 0.02619    time: 7.9586  last_time: 0.7134  data_time: 0.0071  last_data_time: 0.0063   lr: 5e-05  max_mem: 2572M
[11/22 20:50:59] d2.utils.events INFO:  eta: 1:51:29  iter: 6179  total_loss: 0.9713  loss_ce: 0.08683  loss_objectness: 0.5587  loss_dice: 0.2687  loss_mask: 0.02925    time: 7.9348  last_time: 0.5851  data_time: 0.0073  last_data_time: 0.0063   lr: 5e-05  max_mem: 2572M
[11/22 20:51:11] d2.utils.events INFO:  eta: 1:50:46  iter: 6199  total_loss: 0.9005  loss_ce: 0.08463  loss_objectness: 0.5643  loss_dice: 0.2332  loss_mask: 0.02643    time: 7.9111  last_time: 0.5956  data_time: 0.0072  last_data_time: 0.0071   lr: 5e-05  max_mem: 2572M
[11/22 20:51:23] d2.utils.events INFO:  eta: 1:50:06  iter: 6219  total_loss: 0.8701  loss_ce: 0.1075  loss_objectness: 0.5413  loss_dice: 0.2019  loss_mask: 0.02598    time: 7.8876  last_time: 0.6101  data_time: 0.0084  last_data_time: 0.0083   lr: 5e-05  max_mem: 2572M
[11/22 20:51:36] d2.utils.events INFO:  eta: 1:49:06  iter: 6239  total_loss: 0.8685  loss_ce: 0.07966  loss_objectness: 0.5501  loss_dice: 0.2256  loss_mask: 0.02651    time: 7.8643  last_time: 0.6168  data_time: 0.0078  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 20:51:48] d2.utils.events INFO:  eta: 1:48:15  iter: 6259  total_loss: 0.9454  loss_ce: 0.08976  loss_objectness: 0.5677  loss_dice: 0.273  loss_mask: 0.02684    time: 7.8411  last_time: 0.6021  data_time: 0.0076  last_data_time: 0.0065   lr: 5e-05  max_mem: 2572M
[11/22 20:52:00] d2.utils.events INFO:  eta: 1:47:28  iter: 6279  total_loss: 0.878  loss_ce: 0.1039  loss_objectness: 0.5342  loss_dice: 0.2033  loss_mask: 0.02741    time: 7.8181  last_time: 0.6148  data_time: 0.0075  last_data_time: 0.0070   lr: 5e-05  max_mem: 2572M
[11/22 20:52:12] d2.utils.events INFO:  eta: 1:46:10  iter: 6299  total_loss: 0.955  loss_ce: 0.1176  loss_objectness: 0.5668  loss_dice: 0.2538  loss_mask: 0.0291    time: 7.7952  last_time: 0.6393  data_time: 0.0073  last_data_time: 0.0073   lr: 5e-05  max_mem: 2572M
[11/22 20:52:25] d2.utils.events INFO:  eta: 1:45:47  iter: 6319  total_loss: 0.9383  loss_ce: 0.09338  loss_objectness: 0.57  loss_dice: 0.2373  loss_mask: 0.02756    time: 7.7725  last_time: 0.6063  data_time: 0.0077  last_data_time: 0.0069   lr: 5e-05  max_mem: 2572M
[11/22 20:52:37] d2.utils.events INFO:  eta: 1:45:32  iter: 6339  total_loss: 0.9481  loss_ce: 0.1148  loss_objectness: 0.56  loss_dice: 0.2521  loss_mask: 0.02807    time: 7.7499  last_time: 0.6503  data_time: 0.0075  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 20:52:50] d2.utils.events INFO:  eta: 1:44:38  iter: 6359  total_loss: 0.9419  loss_ce: 0.06921  loss_objectness: 0.5764  loss_dice: 0.2399  loss_mask: 0.02728    time: 7.7275  last_time: 0.6295  data_time: 0.0077  last_data_time: 0.0069   lr: 5e-05  max_mem: 2572M
[11/22 20:53:03] d2.utils.events INFO:  eta: 1:41:30  iter: 6379  total_loss: 0.9932  loss_ce: 0.1158  loss_objectness: 0.577  loss_dice: 0.2562  loss_mask: 0.02842    time: 7.7053  last_time: 0.6142  data_time: 0.0072  last_data_time: 0.0063   lr: 5e-05  max_mem: 2572M
[11/22 20:53:15] d2.utils.events INFO:  eta: 1:39:10  iter: 6399  total_loss: 0.9381  loss_ce: 0.1099  loss_objectness: 0.5754  loss_dice: 0.2245  loss_mask: 0.02955    time: 7.6832  last_time: 0.7120  data_time: 0.0073  last_data_time: 0.0081   lr: 5e-05  max_mem: 2572M
[11/22 20:53:30] d2.utils.events INFO:  eta: 1:39:14  iter: 6419  total_loss: 0.9149  loss_ce: 0.09453  loss_objectness: 0.5561  loss_dice: 0.255  loss_mask: 0.02843    time: 7.6615  last_time: 0.7256  data_time: 0.0075  last_data_time: 0.0070   lr: 5e-05  max_mem: 2572M
[11/22 20:53:45] d2.utils.events INFO:  eta: 1:39:11  iter: 6439  total_loss: 0.9329  loss_ce: 0.1011  loss_objectness: 0.5679  loss_dice: 0.2251  loss_mask: 0.02651    time: 7.6400  last_time: 0.7590  data_time: 0.0071  last_data_time: 0.0073   lr: 5e-05  max_mem: 2572M
[11/22 20:53:59] d2.utils.events INFO:  eta: 1:38:52  iter: 6459  total_loss: 0.9107  loss_ce: 0.08263  loss_objectness: 0.5471  loss_dice: 0.2271  loss_mask: 0.02636    time: 7.6186  last_time: 0.7153  data_time: 0.0071  last_data_time: 0.0092   lr: 5e-05  max_mem: 2572M
[11/22 20:54:14] d2.utils.events INFO:  eta: 1:38:38  iter: 6479  total_loss: 0.9409  loss_ce: 0.1023  loss_objectness: 0.5628  loss_dice: 0.2586  loss_mask: 0.02952    time: 7.5974  last_time: 0.7416  data_time: 0.0076  last_data_time: 0.0083   lr: 5e-05  max_mem: 2572M
[11/22 20:54:29] d2.utils.events INFO:  eta: 1:38:18  iter: 6499  total_loss: 0.9635  loss_ce: 0.1251  loss_objectness: 0.571  loss_dice: 0.26  loss_mask: 0.02732    time: 7.5763  last_time: 0.7367  data_time: 0.0078  last_data_time: 0.0085   lr: 5e-05  max_mem: 2572M
[11/22 20:54:42] d2.utils.events INFO:  eta: 1:36:46  iter: 6519  total_loss: 1.073  loss_ce: 0.1576  loss_objectness: 0.5756  loss_dice: 0.2686  loss_mask: 0.03067    time: 7.5550  last_time: 0.6130  data_time: 0.0070  last_data_time: 0.0069   lr: 5e-05  max_mem: 2572M
[11/22 20:54:54] d2.utils.events INFO:  eta: 1:33:13  iter: 6539  total_loss: 1.033  loss_ce: 0.1502  loss_objectness: 0.5867  loss_dice: 0.2596  loss_mask: 0.03263    time: 7.5338  last_time: 0.6192  data_time: 0.0077  last_data_time: 0.0066   lr: 5e-05  max_mem: 2572M
[11/22 20:55:06] d2.utils.events INFO:  eta: 1:30:39  iter: 6559  total_loss: 1.038  loss_ce: 0.1536  loss_objectness: 0.5922  loss_dice: 0.2784  loss_mask: 0.03396    time: 7.5126  last_time: 0.6046  data_time: 0.0073  last_data_time: 0.0077   lr: 5e-05  max_mem: 2572M
[11/22 20:55:18] d2.utils.events INFO:  eta: 1:28:46  iter: 6579  total_loss: 0.9406  loss_ce: 0.1075  loss_objectness: 0.5549  loss_dice: 0.2465  loss_mask: 0.03074    time: 7.4917  last_time: 0.6051  data_time: 0.0077  last_data_time: 0.0084   lr: 5e-05  max_mem: 2572M
[11/22 20:55:31] d2.utils.events INFO:  eta: 1:27:18  iter: 6599  total_loss: 0.9606  loss_ce: 0.1136  loss_objectness: 0.5722  loss_dice: 0.233  loss_mask: 0.02815    time: 7.4708  last_time: 0.6117  data_time: 0.0087  last_data_time: 0.0072   lr: 5e-05  max_mem: 2572M
[11/22 20:55:43] d2.utils.events INFO:  eta: 1:26:50  iter: 6619  total_loss: 0.8917  loss_ce: 0.09797  loss_objectness: 0.5611  loss_dice: 0.2315  loss_mask: 0.03019    time: 7.4501  last_time: 0.6683  data_time: 0.0072  last_data_time: 0.0066   lr: 5e-05  max_mem: 2572M
[11/22 20:55:58] d2.utils.events INFO:  eta: 1:26:38  iter: 6639  total_loss: 0.8866  loss_ce: 0.0804  loss_objectness: 0.5615  loss_dice: 0.2132  loss_mask: 0.02823    time: 7.4298  last_time: 0.7009  data_time: 0.0075  last_data_time: 0.0076   lr: 5e-05  max_mem: 2572M
[11/22 20:56:12] d2.utils.events INFO:  eta: 1:26:25  iter: 6659  total_loss: 0.9469  loss_ce: 0.07704  loss_objectness: 0.5662  loss_dice: 0.2378  loss_mask: 0.03101    time: 7.4097  last_time: 0.7329  data_time: 0.0072  last_data_time: 0.0075   lr: 5e-05  max_mem: 2572M
[11/22 20:56:27] d2.utils.events INFO:  eta: 1:26:13  iter: 6679  total_loss: 0.8487  loss_ce: 0.08414  loss_objectness: 0.5492  loss_dice: 0.224  loss_mask: 0.03187    time: 7.3897  last_time: 0.7247  data_time: 0.0078  last_data_time: 0.0075   lr: 5e-05  max_mem: 2572M
[11/22 20:56:41] d2.utils.events INFO:  eta: 1:26:01  iter: 6699  total_loss: 0.8959  loss_ce: 0.1007  loss_objectness: 0.5494  loss_dice: 0.2097  loss_mask: 0.02827    time: 7.3698  last_time: 0.7203  data_time: 0.0077  last_data_time: 0.0072   lr: 5e-05  max_mem: 2572M
[11/22 20:56:56] d2.utils.events INFO:  eta: 1:25:48  iter: 6719  total_loss: 0.8816  loss_ce: 0.09661  loss_objectness: 0.5444  loss_dice: 0.2171  loss_mask: 0.02592    time: 7.3500  last_time: 0.7177  data_time: 0.0070  last_data_time: 0.0076   lr: 5e-05  max_mem: 2572M
[11/22 20:57:10] d2.utils.events INFO:  eta: 1:25:36  iter: 6739  total_loss: 0.8779  loss_ce: 0.09055  loss_objectness: 0.5516  loss_dice: 0.2121  loss_mask: 0.02725    time: 7.3303  last_time: 0.7299  data_time: 0.0078  last_data_time: 0.0078   lr: 5e-05  max_mem: 2572M
[11/22 20:57:22] d2.utils.events INFO:  eta: 1:25:06  iter: 6759  total_loss: 0.8596  loss_ce: 0.08054  loss_objectness: 0.5417  loss_dice: 0.217  loss_mask: 0.02711    time: 7.3105  last_time: 0.6131  data_time: 0.0073  last_data_time: 0.0073   lr: 5e-05  max_mem: 2572M
[11/22 20:57:35] d2.utils.events INFO:  eta: 1:24:46  iter: 6779  total_loss: 0.9027  loss_ce: 0.09169  loss_objectness: 0.5502  loss_dice: 0.2264  loss_mask: 0.02488    time: 7.2907  last_time: 0.6126  data_time: 0.0074  last_data_time: 0.0081   lr: 5e-05  max_mem: 2572M
[11/22 20:57:47] d2.utils.events INFO:  eta: 1:24:33  iter: 6799  total_loss: 0.8247  loss_ce: 0.08016  loss_objectness: 0.5388  loss_dice: 0.1995  loss_mask: 0.02531    time: 7.2711  last_time: 0.6204  data_time: 0.0074  last_data_time: 0.0066   lr: 5e-05  max_mem: 2572M
[11/22 20:57:59] d2.utils.events INFO:  eta: 1:24:25  iter: 6819  total_loss: 0.8888  loss_ce: 0.1055  loss_objectness: 0.5364  loss_dice: 0.2016  loss_mask: 0.02397    time: 7.2515  last_time: 0.6149  data_time: 0.0075  last_data_time: 0.0070   lr: 5e-05  max_mem: 2572M
[11/22 20:58:11] d2.utils.events INFO:  eta: 1:24:13  iter: 6839  total_loss: 0.9761  loss_ce: 0.09136  loss_objectness: 0.5749  loss_dice: 0.2846  loss_mask: 0.02953    time: 7.2321  last_time: 0.5922  data_time: 0.0071  last_data_time: 0.0065   lr: 5e-05  max_mem: 2572M
[11/22 20:58:24] d2.utils.events INFO:  eta: 1:24:02  iter: 6859  total_loss: 0.905  loss_ce: 0.102  loss_objectness: 0.5547  loss_dice: 0.2219  loss_mask: 0.02864    time: 7.2128  last_time: 0.6009  data_time: 0.0071  last_data_time: 0.0073   lr: 5e-05  max_mem: 2572M
[11/22 20:58:36] d2.utils.events INFO:  eta: 1:23:51  iter: 6879  total_loss: 0.952  loss_ce: 0.1008  loss_objectness: 0.5778  loss_dice: 0.2382  loss_mask: 0.02913    time: 7.1936  last_time: 0.6134  data_time: 0.0085  last_data_time: 0.0079   lr: 5e-05  max_mem: 2572M
[11/22 20:58:48] d2.utils.events INFO:  eta: 1:23:40  iter: 6899  total_loss: 0.9005  loss_ce: 0.07801  loss_objectness: 0.5745  loss_dice: 0.2419  loss_mask: 0.02932    time: 7.1745  last_time: 0.6078  data_time: 0.0072  last_data_time: 0.0076   lr: 5e-05  max_mem: 2572M
[11/22 20:59:00] d2.utils.events INFO:  eta: 1:23:28  iter: 6919  total_loss: 0.9251  loss_ce: 0.1146  loss_objectness: 0.5577  loss_dice: 0.2197  loss_mask: 0.02543    time: 7.1555  last_time: 0.6107  data_time: 0.0073  last_data_time: 0.0057   lr: 5e-05  max_mem: 2572M
[11/22 20:59:13] d2.utils.events INFO:  eta: 1:23:19  iter: 6939  total_loss: 0.9257  loss_ce: 0.09156  loss_objectness: 0.5588  loss_dice: 0.2183  loss_mask: 0.03159    time: 7.1367  last_time: 0.6193  data_time: 0.0073  last_data_time: 0.0067   lr: 5e-05  max_mem: 2572M
[11/22 20:59:25] d2.utils.events INFO:  eta: 1:23:07  iter: 6959  total_loss: 1.09  loss_ce: 0.1475  loss_objectness: 0.5912  loss_dice: 0.2922  loss_mask: 0.03117    time: 7.1179  last_time: 0.6155  data_time: 0.0076  last_data_time: 0.0063   lr: 5e-05  max_mem: 2572M
[11/22 20:59:38] d2.utils.events INFO:  eta: 1:23:09  iter: 6979  total_loss: 1.041  loss_ce: 0.1335  loss_objectness: 0.6154  loss_dice: 0.2838  loss_mask: 0.03603    time: 7.0995  last_time: 0.7146  data_time: 0.0077  last_data_time: 0.0075   lr: 5e-05  max_mem: 2572M
[11/22 20:59:53] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 20:59:53] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 20:59:53] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 20:59:53] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 20:59:53] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 20:59:53] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 21:00:00] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0004 s/iter. Inference: 0.0533 s/iter. Eval: 0.0701 s/iter. Total: 0.1238 s/iter. ETA=0:00:13
[11/22 21:00:05] d2.evaluation.evaluator INFO: Inference done 54/120. Dataloading: 0.0007 s/iter. Inference: 0.0531 s/iter. Eval: 0.0657 s/iter. Total: 0.1195 s/iter. ETA=0:00:07
[11/22 21:00:10] d2.evaluation.evaluator INFO: Inference done 99/120. Dataloading: 0.0007 s/iter. Inference: 0.0522 s/iter. Eval: 0.0628 s/iter. Total: 0.1158 s/iter. ETA=0:00:02
[11/22 21:00:14] d2.evaluation.evaluator INFO: Total inference time: 0:00:14.392947 (0.125156 s / iter per device, on 1 devices)
[11/22 21:00:14] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:06 (0.052369 s / iter per device, on 1 devices)
[11/22 21:00:14] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 21:00:14] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 21:00:14] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 21:00:14] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 21:00:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.06 seconds.
[11/22 21:00:14] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 21:00:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 21:00:14] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 5.872 | 12.105 | 6.264  | 0.335 | 11.783 | 41.483 |
[11/22 21:00:14] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 21:00:14] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 21:00:14] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 21:00:14] d2.evaluation.testing INFO: copypaste: 5.8724,12.1054,6.2644,0.3348,11.7831,41.4831
[11/22 21:00:14] d2.utils.events INFO:  eta: 1:23:14  iter: 6999  total_loss: 0.9745  loss_ce: 0.1075  loss_objectness: 0.5752  loss_dice: 0.2553  loss_mask: 0.03143    time: 7.0812  last_time: 0.7233  data_time: 0.0074  last_data_time: 0.0089   lr: 5e-05  max_mem: 2572M
[11/22 21:00:29] d2.utils.events INFO:  eta: 1:23:21  iter: 7019  total_loss: 0.9824  loss_ce: 0.1144  loss_objectness: 0.5887  loss_dice: 0.266  loss_mask: 0.02801    time: 7.0631  last_time: 0.7170  data_time: 0.0082  last_data_time: 0.0062   lr: 5e-05  max_mem: 2572M
[11/22 21:00:44] d2.utils.events INFO:  eta: 1:23:11  iter: 7039  total_loss: 1.006  loss_ce: 0.08795  loss_objectness: 0.5897  loss_dice: 0.2807  loss_mask: 0.0286    time: 7.0451  last_time: 0.7282  data_time: 0.0077  last_data_time: 0.0062   lr: 5e-05  max_mem: 2572M
[11/22 21:00:58] d2.utils.events INFO:  eta: 1:22:58  iter: 7059  total_loss: 1.03  loss_ce: 0.129  loss_objectness: 0.5841  loss_dice: 0.2599  loss_mask: 0.02821    time: 7.0272  last_time: 0.7396  data_time: 0.0077  last_data_time: 0.0066   lr: 5e-05  max_mem: 2572M
[11/22 21:01:13] d2.utils.events INFO:  eta: 1:22:46  iter: 7079  total_loss: 0.9291  loss_ce: 0.08725  loss_objectness: 0.5588  loss_dice: 0.2399  loss_mask: 0.02864    time: 7.0094  last_time: 0.7285  data_time: 0.0073  last_data_time: 0.0088   lr: 5e-05  max_mem: 2572M
[11/22 21:01:27] d2.utils.events INFO:  eta: 1:22:33  iter: 7099  total_loss: 0.9131  loss_ce: 0.07144  loss_objectness: 0.5558  loss_dice: 0.2374  loss_mask: 0.02369    time: 6.9917  last_time: 0.7221  data_time: 0.0081  last_data_time: 0.0062   lr: 5e-05  max_mem: 2572M
[11/22 21:01:42] d2.utils.events INFO:  eta: 1:22:21  iter: 7119  total_loss: 0.9129  loss_ce: 0.08443  loss_objectness: 0.5554  loss_dice: 0.2354  loss_mask: 0.02789    time: 6.9741  last_time: 0.7298  data_time: 0.0075  last_data_time: 0.0077   lr: 5e-05  max_mem: 2572M
[11/22 21:01:55] d2.utils.events INFO:  eta: 1:21:55  iter: 7139  total_loss: 0.9516  loss_ce: 0.08766  loss_objectness: 0.5605  loss_dice: 0.2442  loss_mask: 0.02789    time: 6.9564  last_time: 0.6196  data_time: 0.0074  last_data_time: 0.0100   lr: 5e-05  max_mem: 2572M
[11/22 21:02:07] d2.utils.events INFO:  eta: 1:21:24  iter: 7159  total_loss: 0.9687  loss_ce: 0.0908  loss_objectness: 0.5727  loss_dice: 0.2669  loss_mask: 0.03643    time: 6.9387  last_time: 0.6003  data_time: 0.0076  last_data_time: 0.0070   lr: 5e-05  max_mem: 2572M
[11/22 21:02:20] d2.utils.events INFO:  eta: 1:21:11  iter: 7179  total_loss: 0.9843  loss_ce: 0.0905  loss_objectness: 0.5808  loss_dice: 0.2609  loss_mask: 0.02738    time: 6.9211  last_time: 0.6140  data_time: 0.0072  last_data_time: 0.0074   lr: 5e-05  max_mem: 2572M
[11/22 21:02:32] d2.utils.events INFO:  eta: 1:21:01  iter: 7199  total_loss: 0.8247  loss_ce: 0.05834  loss_objectness: 0.5337  loss_dice: 0.1973  loss_mask: 0.02953    time: 6.9035  last_time: 0.6101  data_time: 0.0072  last_data_time: 0.0082   lr: 5e-05  max_mem: 2572M
[11/22 21:02:44] d2.utils.events INFO:  eta: 1:20:50  iter: 7219  total_loss: 0.8965  loss_ce: 0.07035  loss_objectness: 0.5561  loss_dice: 0.2265  loss_mask: 0.02618    time: 6.8861  last_time: 0.6108  data_time: 0.0074  last_data_time: 0.0082   lr: 5e-05  max_mem: 2572M
[11/22 21:02:56] d2.utils.events INFO:  eta: 1:20:37  iter: 7239  total_loss: 0.794  loss_ce: 0.06349  loss_objectness: 0.5221  loss_dice: 0.1919  loss_mask: 0.02381    time: 6.8688  last_time: 0.6040  data_time: 0.0074  last_data_time: 0.0081   lr: 5e-05  max_mem: 2572M
[11/22 21:03:09] d2.utils.events INFO:  eta: 1:20:24  iter: 7259  total_loss: 0.8722  loss_ce: 0.088  loss_objectness: 0.5439  loss_dice: 0.2145  loss_mask: 0.02616    time: 6.8515  last_time: 0.6043  data_time: 0.0076  last_data_time: 0.0073   lr: 5e-05  max_mem: 2572M
[11/22 21:03:21] d2.utils.events INFO:  eta: 1:20:12  iter: 7279  total_loss: 0.852  loss_ce: 0.07734  loss_objectness: 0.5325  loss_dice: 0.2253  loss_mask: 0.0273    time: 6.8344  last_time: 0.7276  data_time: 0.0073  last_data_time: 0.0082   lr: 5e-05  max_mem: 2572M
[11/22 21:03:35] d2.utils.events INFO:  eta: 1:20:17  iter: 7299  total_loss: 0.9139  loss_ce: 0.08484  loss_objectness: 0.5582  loss_dice: 0.2157  loss_mask: 0.02455    time: 6.8176  last_time: 0.7127  data_time: 0.0077  last_data_time: 0.0096   lr: 5e-05  max_mem: 2572M
[11/22 21:03:50] d2.utils.events INFO:  eta: 1:20:31  iter: 7319  total_loss: 0.8942  loss_ce: 0.08456  loss_objectness: 0.551  loss_dice: 0.2204  loss_mask: 0.03068    time: 6.8010  last_time: 0.7482  data_time: 0.0077  last_data_time: 0.0083   lr: 5e-05  max_mem: 2572M
[11/22 21:04:05] d2.utils.events INFO:  eta: 1:20:34  iter: 7339  total_loss: 0.8136  loss_ce: 0.04504  loss_objectness: 0.5439  loss_dice: 0.1893  loss_mask: 0.02328    time: 6.7845  last_time: 0.7669  data_time: 0.0077  last_data_time: 0.0079   lr: 5e-05  max_mem: 2572M
[11/22 21:04:20] d2.utils.events INFO:  eta: 1:21:56  iter: 7359  total_loss: 0.8684  loss_ce: 0.06373  loss_objectness: 0.5375  loss_dice: 0.224  loss_mask: 0.02629    time: 6.7681  last_time: 0.7745  data_time: 0.0074  last_data_time: 0.0085   lr: 5e-05  max_mem: 2572M
[11/22 21:04:35] d2.utils.events INFO:  eta: 1:24:25  iter: 7379  total_loss: 0.8397  loss_ce: 0.0692  loss_objectness: 0.5433  loss_dice: 0.2052  loss_mask: 0.02324    time: 6.7517  last_time: 0.7265  data_time: 0.0073  last_data_time: 0.0069   lr: 5e-05  max_mem: 2572M
[11/22 21:04:50] d2.utils.events INFO:  eta: 1:25:13  iter: 7399  total_loss: 0.8336  loss_ce: 0.04526  loss_objectness: 0.5513  loss_dice: 0.2052  loss_mask: 0.02928    time: 6.7355  last_time: 0.7424  data_time: 0.0071  last_data_time: 0.0071   lr: 5e-05  max_mem: 2572M
[11/22 21:05:04] d2.utils.events INFO:  eta: 1:25:00  iter: 7419  total_loss: 0.8375  loss_ce: 0.07294  loss_objectness: 0.5494  loss_dice: 0.2098  loss_mask: 0.02478    time: 6.7193  last_time: 0.7311  data_time: 0.0077  last_data_time: 0.0086   lr: 5e-05  max_mem: 2572M
[11/22 21:05:17] d2.utils.events INFO:  eta: 1:23:28  iter: 7439  total_loss: 0.8743  loss_ce: 0.0997  loss_objectness: 0.5461  loss_dice: 0.21  loss_mask: 0.02638    time: 6.7030  last_time: 0.6138  data_time: 0.0070  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 21:05:30] d2.utils.events INFO:  eta: 1:20:03  iter: 7459  total_loss: 0.9508  loss_ce: 0.08637  loss_objectness: 0.5659  loss_dice: 0.2554  loss_mask: 0.02649    time: 6.6867  last_time: 0.6158  data_time: 0.0076  last_data_time: 0.0094   lr: 5e-05  max_mem: 2572M
[11/22 21:05:42] d2.utils.events INFO:  eta: 1:18:34  iter: 7479  total_loss: 0.839  loss_ce: 0.06647  loss_objectness: 0.5462  loss_dice: 0.2376  loss_mask: 0.03157    time: 6.6704  last_time: 0.6157  data_time: 0.0073  last_data_time: 0.0061   lr: 5e-05  max_mem: 2572M
[11/22 21:05:54] d2.utils.events INFO:  eta: 1:17:59  iter: 7499  total_loss: 0.8067  loss_ce: 0.07352  loss_objectness: 0.5452  loss_dice: 0.2011  loss_mask: 0.02645    time: 6.6543  last_time: 0.5959  data_time: 0.0076  last_data_time: 0.0076   lr: 5e-05  max_mem: 2572M
[11/22 21:06:06] d2.utils.events INFO:  eta: 1:17:45  iter: 7519  total_loss: 0.8633  loss_ce: 0.06132  loss_objectness: 0.5536  loss_dice: 0.2257  loss_mask: 0.02522    time: 6.6382  last_time: 0.5982  data_time: 0.0070  last_data_time: 0.0067   lr: 5e-05  max_mem: 2572M
[11/22 21:06:19] d2.utils.events INFO:  eta: 1:17:31  iter: 7539  total_loss: 0.8882  loss_ce: 0.1082  loss_objectness: 0.5513  loss_dice: 0.2183  loss_mask: 0.02645    time: 6.6222  last_time: 0.5959  data_time: 0.0072  last_data_time: 0.0067   lr: 5e-05  max_mem: 2572M
[11/22 21:06:31] d2.utils.events INFO:  eta: 1:17:22  iter: 7559  total_loss: 0.9163  loss_ce: 0.06341  loss_objectness: 0.5779  loss_dice: 0.2419  loss_mask: 0.03209    time: 6.6063  last_time: 0.6053  data_time: 0.0077  last_data_time: 0.0065   lr: 5e-05  max_mem: 2572M
[11/22 21:06:43] d2.utils.events INFO:  eta: 1:17:10  iter: 7579  total_loss: 0.8577  loss_ce: 0.09018  loss_objectness: 0.5532  loss_dice: 0.2171  loss_mask: 0.02478    time: 6.5905  last_time: 0.6230  data_time: 0.0075  last_data_time: 0.0092   lr: 5e-05  max_mem: 2572M
[11/22 21:06:56] d2.utils.events INFO:  eta: 1:17:01  iter: 7599  total_loss: 0.9973  loss_ce: 0.08942  loss_objectness: 0.5709  loss_dice: 0.2615  loss_mask: 0.03809    time: 6.5748  last_time: 0.6160  data_time: 0.0074  last_data_time: 0.0075   lr: 5e-05  max_mem: 2572M
[11/22 21:07:08] d2.utils.events INFO:  eta: 1:16:45  iter: 7619  total_loss: 0.9127  loss_ce: 0.08753  loss_objectness: 0.564  loss_dice: 0.2321  loss_mask: 0.02815    time: 6.5591  last_time: 0.6178  data_time: 0.0070  last_data_time: 0.0067   lr: 5e-05  max_mem: 2572M
[11/22 21:07:20] d2.utils.events INFO:  eta: 1:16:20  iter: 7639  total_loss: 0.866  loss_ce: 0.06096  loss_objectness: 0.548  loss_dice: 0.2257  loss_mask: 0.02639    time: 6.5436  last_time: 0.6444  data_time: 0.0073  last_data_time: 0.0092   lr: 5e-05  max_mem: 2572M
[11/22 21:07:33] d2.utils.events INFO:  eta: 1:16:01  iter: 7659  total_loss: 0.8227  loss_ce: 0.06404  loss_objectness: 0.5405  loss_dice: 0.2054  loss_mask: 0.02535    time: 6.5281  last_time: 0.6176  data_time: 0.0078  last_data_time: 0.0070   lr: 5e-05  max_mem: 2572M
[11/22 21:07:45] d2.utils.events INFO:  eta: 1:15:44  iter: 7679  total_loss: 0.8878  loss_ce: 0.07631  loss_objectness: 0.5312  loss_dice: 0.196  loss_mask: 0.02539    time: 6.5127  last_time: 0.6279  data_time: 0.0075  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 21:07:57] d2.utils.events INFO:  eta: 1:15:28  iter: 7699  total_loss: 0.8365  loss_ce: 0.0604  loss_objectness: 0.5236  loss_dice: 0.1977  loss_mask: 0.02478    time: 6.4974  last_time: 0.6114  data_time: 0.0083  last_data_time: 0.0082   lr: 5e-05  max_mem: 2572M
[11/22 21:08:10] d2.utils.events INFO:  eta: 1:15:12  iter: 7719  total_loss: 0.772  loss_ce: 0.04633  loss_objectness: 0.512  loss_dice: 0.1775  loss_mask: 0.02436    time: 6.4821  last_time: 0.6192  data_time: 0.0078  last_data_time: 0.0071   lr: 5e-05  max_mem: 2572M
[11/22 21:08:22] d2.utils.events INFO:  eta: 1:14:58  iter: 7739  total_loss: 0.8717  loss_ce: 0.06152  loss_objectness: 0.5318  loss_dice: 0.2124  loss_mask: 0.02214    time: 6.4670  last_time: 0.6087  data_time: 0.0076  last_data_time: 0.0086   lr: 5e-05  max_mem: 2572M
[11/22 21:08:34] d2.utils.events INFO:  eta: 1:14:45  iter: 7759  total_loss: 0.7478  loss_ce: 0.04921  loss_objectness: 0.5081  loss_dice: 0.1581  loss_mask: 0.02624    time: 6.4519  last_time: 0.6095  data_time: 0.0076  last_data_time: 0.0074   lr: 5e-05  max_mem: 2572M
[11/22 21:08:47] d2.utils.events INFO:  eta: 1:14:35  iter: 7779  total_loss: 0.7724  loss_ce: 0.04354  loss_objectness: 0.5039  loss_dice: 0.1862  loss_mask: 0.02261    time: 6.4370  last_time: 0.6996  data_time: 0.0081  last_data_time: 0.0083   lr: 5e-05  max_mem: 2572M
[11/22 21:09:01] d2.utils.events INFO:  eta: 1:14:27  iter: 7799  total_loss: 0.7771  loss_ce: 0.05396  loss_objectness: 0.5275  loss_dice: 0.177  loss_mask: 0.02395    time: 6.4222  last_time: 0.7233  data_time: 0.0076  last_data_time: 0.0070   lr: 5e-05  max_mem: 2572M
[11/22 21:09:15] d2.utils.events INFO:  eta: 1:14:19  iter: 7819  total_loss: 0.7466  loss_ce: 0.04196  loss_objectness: 0.5031  loss_dice: 0.1767  loss_mask: 0.02218    time: 6.4076  last_time: 0.7356  data_time: 0.0082  last_data_time: 0.0074   lr: 5e-05  max_mem: 2572M
[11/22 21:09:30] d2.utils.events INFO:  eta: 1:14:12  iter: 7839  total_loss: 0.6973  loss_ce: 0.01206  loss_objectness: 0.5005  loss_dice: 0.1591  loss_mask: 0.02063    time: 6.3931  last_time: 0.7197  data_time: 0.0073  last_data_time: 0.0079   lr: 5e-05  max_mem: 2572M
[11/22 21:09:45] d2.utils.events INFO:  eta: 1:14:06  iter: 7859  total_loss: 0.7709  loss_ce: 0.04286  loss_objectness: 0.5088  loss_dice: 0.1863  loss_mask: 0.02303    time: 6.3787  last_time: 0.7155  data_time: 0.0074  last_data_time: 0.0070   lr: 5e-05  max_mem: 2572M
[11/22 21:09:59] d2.utils.events INFO:  eta: 1:14:03  iter: 7879  total_loss: 0.6951  loss_ce: 0.04072  loss_objectness: 0.5023  loss_dice: 0.1636  loss_mask: 0.02161    time: 6.3644  last_time: 0.7119  data_time: 0.0074  last_data_time: 0.0081   lr: 5e-05  max_mem: 2572M
[11/22 21:10:14] d2.utils.events INFO:  eta: 1:14:03  iter: 7899  total_loss: 0.7708  loss_ce: 0.05337  loss_objectness: 0.5046  loss_dice: 0.185  loss_mask: 0.02278    time: 6.3501  last_time: 0.7395  data_time: 0.0078  last_data_time: 0.0076   lr: 5e-05  max_mem: 2572M
[11/22 21:10:28] d2.utils.events INFO:  eta: 1:14:10  iter: 7919  total_loss: 0.7045  loss_ce: 0.0229  loss_objectness: 0.501  loss_dice: 0.157  loss_mask: 0.0231    time: 6.3359  last_time: 0.7046  data_time: 0.0076  last_data_time: 0.0089   lr: 5e-05  max_mem: 2572M
[11/22 21:10:42] d2.utils.events INFO:  eta: 1:14:24  iter: 7939  total_loss: 0.7838  loss_ce: 0.0395  loss_objectness: 0.5194  loss_dice: 0.1945  loss_mask: 0.02215    time: 6.3217  last_time: 0.6053  data_time: 0.0073  last_data_time: 0.0069   lr: 5e-05  max_mem: 2572M
[11/22 21:10:55] d2.utils.events INFO:  eta: 1:14:12  iter: 7959  total_loss: 0.696  loss_ce: 0.04633  loss_objectness: 0.4628  loss_dice: 0.1428  loss_mask: 0.02359    time: 6.3074  last_time: 0.6345  data_time: 0.0074  last_data_time: 0.0073   lr: 5e-05  max_mem: 2572M
[11/22 21:11:07] d2.utils.events INFO:  eta: 1:13:39  iter: 7979  total_loss: 0.7549  loss_ce: 0.04025  loss_objectness: 0.4936  loss_dice: 0.1801  loss_mask: 0.02449    time: 6.2931  last_time: 0.6274  data_time: 0.0077  last_data_time: 0.0061   lr: 5e-05  max_mem: 2572M
[11/22 21:11:20] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 21:11:20] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 21:11:20] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 21:11:20] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 21:11:20] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 21:11:20] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 21:11:28] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0004 s/iter. Inference: 0.0463 s/iter. Eval: 0.0639 s/iter. Total: 0.1106 s/iter. ETA=0:00:12
[11/22 21:11:33] d2.evaluation.evaluator INFO: Inference done 61/120. Dataloading: 0.0006 s/iter. Inference: 0.0459 s/iter. Eval: 0.0548 s/iter. Total: 0.1013 s/iter. ETA=0:00:05
[11/22 21:11:38] d2.evaluation.evaluator INFO: Inference done 113/120. Dataloading: 0.0006 s/iter. Inference: 0.0458 s/iter. Eval: 0.0526 s/iter. Total: 0.0991 s/iter. ETA=0:00:00
[11/22 21:11:39] d2.evaluation.evaluator INFO: Total inference time: 0:00:12.530613 (0.108962 s / iter per device, on 1 devices)
[11/22 21:11:39] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.045699 s / iter per device, on 1 devices)
[11/22 21:11:39] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 21:11:39] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 21:11:39] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 21:11:40] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 21:11:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.07 seconds.
[11/22 21:11:40] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 21:11:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 21:11:40] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.528 | 13.178 | 6.325  | 0.074 | 12.448 | 51.826 |
[11/22 21:11:40] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 21:11:40] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 21:11:40] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 21:11:40] d2.evaluation.testing INFO: copypaste: 6.5280,13.1783,6.3248,0.0743,12.4475,51.8257
[11/22 21:11:40] d2.utils.events INFO:  eta: 1:13:15  iter: 7999  total_loss: 0.7093  loss_ce: 0.03804  loss_objectness: 0.4882  loss_dice: 0.1594  loss_mask: 0.02043    time: 6.2790  last_time: 0.6293  data_time: 0.0073  last_data_time: 0.0073   lr: 5e-05  max_mem: 2572M
[11/22 21:11:52] d2.utils.events INFO:  eta: 1:12:57  iter: 8019  total_loss: 0.7246  loss_ce: 0.04938  loss_objectness: 0.5139  loss_dice: 0.1716  loss_mask: 0.02229    time: 6.2649  last_time: 0.6273  data_time: 0.0078  last_data_time: 0.0080   lr: 5e-05  max_mem: 2572M
[11/22 21:12:05] d2.utils.events INFO:  eta: 1:12:35  iter: 8039  total_loss: 0.763  loss_ce: 0.05152  loss_objectness: 0.5095  loss_dice: 0.1726  loss_mask: 0.02396    time: 6.2508  last_time: 0.6255  data_time: 0.0076  last_data_time: 0.0073   lr: 5e-05  max_mem: 2572M
[11/22 21:12:17] d2.utils.events INFO:  eta: 1:12:18  iter: 8059  total_loss: 0.7186  loss_ce: 0.01868  loss_objectness: 0.498  loss_dice: 0.1779  loss_mask: 0.02444    time: 6.2368  last_time: 0.6222  data_time: 0.0075  last_data_time: 0.0075   lr: 5e-05  max_mem: 2572M
[11/22 21:12:30] d2.utils.events INFO:  eta: 1:12:02  iter: 8079  total_loss: 0.8369  loss_ce: 0.0584  loss_objectness: 0.5253  loss_dice: 0.2089  loss_mask: 0.02199    time: 6.2229  last_time: 0.6160  data_time: 0.0078  last_data_time: 0.0072   lr: 5e-05  max_mem: 2572M
[11/22 21:12:42] d2.utils.events INFO:  eta: 1:11:45  iter: 8099  total_loss: 0.8138  loss_ce: 0.03008  loss_objectness: 0.554  loss_dice: 0.1985  loss_mask: 0.0226    time: 6.2091  last_time: 0.6132  data_time: 0.0078  last_data_time: 0.0074   lr: 5e-05  max_mem: 2572M
[11/22 21:12:54] d2.utils.events INFO:  eta: 1:11:23  iter: 8119  total_loss: 0.8052  loss_ce: 0.0578  loss_objectness: 0.5209  loss_dice: 0.1729  loss_mask: 0.02754    time: 6.1953  last_time: 0.6034  data_time: 0.0081  last_data_time: 0.0074   lr: 5e-05  max_mem: 2572M
[11/22 21:13:06] d2.utils.events INFO:  eta: 1:11:08  iter: 8139  total_loss: 0.9544  loss_ce: 0.1003  loss_objectness: 0.5533  loss_dice: 0.2407  loss_mask: 0.0241    time: 6.1816  last_time: 0.6121  data_time: 0.0076  last_data_time: 0.0072   lr: 5e-05  max_mem: 2572M
[11/22 21:13:19] d2.utils.events INFO:  eta: 1:10:56  iter: 8159  total_loss: 0.8178  loss_ce: 0.08145  loss_objectness: 0.5298  loss_dice: 0.1843  loss_mask: 0.02873    time: 6.1679  last_time: 0.6158  data_time: 0.0074  last_data_time: 0.0073   lr: 5e-05  max_mem: 2572M
[11/22 21:13:31] d2.utils.events INFO:  eta: 1:10:44  iter: 8179  total_loss: 0.8054  loss_ce: 0.05544  loss_objectness: 0.5199  loss_dice: 0.194  loss_mask: 0.02893    time: 6.1544  last_time: 0.6350  data_time: 0.0075  last_data_time: 0.0075   lr: 5e-05  max_mem: 2572M
[11/22 21:13:43] d2.utils.events INFO:  eta: 1:10:32  iter: 8199  total_loss: 0.8114  loss_ce: 0.06214  loss_objectness: 0.5334  loss_dice: 0.1874  loss_mask: 0.02378    time: 6.1408  last_time: 0.6202  data_time: 0.0076  last_data_time: 0.0085   lr: 5e-05  max_mem: 2572M
[11/22 21:13:56] d2.utils.events INFO:  eta: 1:10:20  iter: 8219  total_loss: 0.8219  loss_ce: 0.0526  loss_objectness: 0.528  loss_dice: 0.1911  loss_mask: 0.02319    time: 6.1274  last_time: 0.7005  data_time: 0.0078  last_data_time: 0.0058   lr: 5e-05  max_mem: 2572M
[11/22 21:14:10] d2.utils.events INFO:  eta: 1:10:16  iter: 8239  total_loss: 0.791  loss_ce: 0.06096  loss_objectness: 0.5057  loss_dice: 0.1807  loss_mask: 0.02089    time: 6.1143  last_time: 0.7090  data_time: 0.0074  last_data_time: 0.0057   lr: 5e-05  max_mem: 2572M
[11/22 21:14:25] d2.utils.events INFO:  eta: 1:10:11  iter: 8259  total_loss: 0.7082  loss_ce: 0.03445  loss_objectness: 0.4815  loss_dice: 0.1507  loss_mask: 0.02373    time: 6.1012  last_time: 0.7519  data_time: 0.0075  last_data_time: 0.0079   lr: 5e-05  max_mem: 2572M
[11/22 21:14:40] d2.utils.events INFO:  eta: 1:10:01  iter: 8279  total_loss: 0.6888  loss_ce: 0.02508  loss_objectness: 0.5028  loss_dice: 0.1364  loss_mask: 0.01746    time: 6.0883  last_time: 0.7532  data_time: 0.0080  last_data_time: 0.0120   lr: 5e-05  max_mem: 2572M
[11/22 21:14:55] d2.utils.events INFO:  eta: 1:09:49  iter: 8299  total_loss: 0.6683  loss_ce: 0.01999  loss_objectness: 0.4738  loss_dice: 0.1355  loss_mask: 0.02431    time: 6.0754  last_time: 0.7458  data_time: 0.0070  last_data_time: 0.0092   lr: 5e-05  max_mem: 2572M
[11/22 21:15:10] d2.utils.events INFO:  eta: 1:09:36  iter: 8319  total_loss: 0.7827  loss_ce: 0.05418  loss_objectness: 0.4995  loss_dice: 0.1721  loss_mask: 0.02283    time: 6.0626  last_time: 0.7681  data_time: 0.0073  last_data_time: 0.0069   lr: 5e-05  max_mem: 2572M
[11/22 21:15:25] d2.utils.events INFO:  eta: 1:09:24  iter: 8339  total_loss: 0.8841  loss_ce: 0.04684  loss_objectness: 0.5404  loss_dice: 0.2318  loss_mask: 0.02566    time: 6.0499  last_time: 0.7825  data_time: 0.0073  last_data_time: 0.0074   lr: 5e-05  max_mem: 2572M
[11/22 21:15:40] d2.utils.events INFO:  eta: 1:09:11  iter: 8359  total_loss: 0.7516  loss_ce: 0.0412  loss_objectness: 0.5054  loss_dice: 0.1603  loss_mask: 0.02119    time: 6.0373  last_time: 0.7521  data_time: 0.0074  last_data_time: 0.0073   lr: 5e-05  max_mem: 2572M
[11/22 21:15:55] d2.utils.events INFO:  eta: 1:08:59  iter: 8379  total_loss: 0.7392  loss_ce: 0.0502  loss_objectness: 0.4864  loss_dice: 0.1652  loss_mask: 0.02134    time: 6.0246  last_time: 0.7729  data_time: 0.0074  last_data_time: 0.0090   lr: 5e-05  max_mem: 2572M
[11/22 21:16:10] d2.utils.events INFO:  eta: 1:08:46  iter: 8399  total_loss: 0.7669  loss_ce: 0.04422  loss_objectness: 0.5142  loss_dice: 0.1771  loss_mask: 0.02415    time: 6.0121  last_time: 0.7360  data_time: 0.0080  last_data_time: 0.0069   lr: 5e-05  max_mem: 2572M
[11/22 21:16:25] d2.utils.events INFO:  eta: 1:08:34  iter: 8419  total_loss: 0.6997  loss_ce: 0.02164  loss_objectness: 0.4736  loss_dice: 0.1528  loss_mask: 0.0231    time: 5.9996  last_time: 0.7238  data_time: 0.0077  last_data_time: 0.0093   lr: 5e-05  max_mem: 2572M
[11/22 21:16:38] d2.utils.events INFO:  eta: 1:08:21  iter: 8439  total_loss: 0.7357  loss_ce: 0.0354  loss_objectness: 0.5002  loss_dice: 0.1717  loss_mask: 0.02289    time: 5.9869  last_time: 0.6116  data_time: 0.0073  last_data_time: 0.0069   lr: 5e-05  max_mem: 2572M
[11/22 21:16:51] d2.utils.events INFO:  eta: 1:08:11  iter: 8459  total_loss: 0.6881  loss_ce: 0.02572  loss_objectness: 0.4903  loss_dice: 0.1408  loss_mask: 0.01955    time: 5.9742  last_time: 0.6276  data_time: 0.0078  last_data_time: 0.0072   lr: 5e-05  max_mem: 2572M
[11/22 21:17:03] d2.utils.events INFO:  eta: 1:07:59  iter: 8479  total_loss: 0.6863  loss_ce: 0.02366  loss_objectness: 0.4733  loss_dice: 0.1395  loss_mask: 0.02169    time: 5.9616  last_time: 0.6162  data_time: 0.0072  last_data_time: 0.0066   lr: 5e-05  max_mem: 2572M
[11/22 21:17:15] d2.utils.events INFO:  eta: 1:07:47  iter: 8499  total_loss: 0.6681  loss_ce: 0.02202  loss_objectness: 0.4729  loss_dice: 0.1373  loss_mask: 0.01906    time: 5.9490  last_time: 0.6318  data_time: 0.0076  last_data_time: 0.0074   lr: 5e-05  max_mem: 2572M
[11/22 21:17:28] d2.utils.events INFO:  eta: 1:07:35  iter: 8519  total_loss: 0.6668  loss_ce: 0.02558  loss_objectness: 0.475  loss_dice: 0.1408  loss_mask: 0.0191    time: 5.9365  last_time: 0.6223  data_time: 0.0077  last_data_time: 0.0076   lr: 5e-05  max_mem: 2572M
[11/22 21:17:40] d2.utils.events INFO:  eta: 1:07:24  iter: 8539  total_loss: 0.6481  loss_ce: 0.01919  loss_objectness: 0.4708  loss_dice: 0.1457  loss_mask: 0.02091    time: 5.9240  last_time: 0.6298  data_time: 0.0075  last_data_time: 0.0072   lr: 5e-05  max_mem: 2572M
[11/22 21:17:52] d2.utils.events INFO:  eta: 1:07:13  iter: 8559  total_loss: 0.5914  loss_ce: 0.009397  loss_objectness: 0.4333  loss_dice: 0.1227  loss_mask: 0.02163    time: 5.9116  last_time: 0.6211  data_time: 0.0076  last_data_time: 0.0058   lr: 5e-05  max_mem: 2572M
[11/22 21:18:07] d2.utils.events INFO:  eta: 1:07:07  iter: 8579  total_loss: 0.6358  loss_ce: 0.01568  loss_objectness: 0.4623  loss_dice: 0.1337  loss_mask: 0.01764    time: 5.8995  last_time: 0.7311  data_time: 0.0073  last_data_time: 0.0071   lr: 5e-05  max_mem: 2572M
[11/22 21:18:22] d2.utils.events INFO:  eta: 1:07:01  iter: 8599  total_loss: 0.6169  loss_ce: 0.02074  loss_objectness: 0.4613  loss_dice: 0.1174  loss_mask: 0.02015    time: 5.8875  last_time: 0.7481  data_time: 0.0077  last_data_time: 0.0064   lr: 5e-05  max_mem: 2572M
[11/22 21:18:37] d2.utils.events INFO:  eta: 1:06:57  iter: 8619  total_loss: 0.6696  loss_ce: 0.01941  loss_objectness: 0.4782  loss_dice: 0.1484  loss_mask: 0.02007    time: 5.8756  last_time: 0.7637  data_time: 0.0074  last_data_time: 0.0061   lr: 5e-05  max_mem: 2572M
[11/22 21:18:52] d2.utils.events INFO:  eta: 1:06:55  iter: 8639  total_loss: 0.7225  loss_ce: 0.02735  loss_objectness: 0.4896  loss_dice: 0.1652  loss_mask: 0.02144    time: 5.8638  last_time: 0.7182  data_time: 0.0076  last_data_time: 0.0051   lr: 5e-05  max_mem: 2572M
[11/22 21:19:07] d2.utils.events INFO:  eta: 1:06:58  iter: 8659  total_loss: 0.7179  loss_ce: 0.01195  loss_objectness: 0.5024  loss_dice: 0.148  loss_mask: 0.02007    time: 5.8519  last_time: 0.7585  data_time: 0.0072  last_data_time: 0.0079   lr: 5e-05  max_mem: 2572M
[11/22 21:19:22] d2.utils.events INFO:  eta: 1:07:18  iter: 8679  total_loss: 0.7534  loss_ce: 0.04269  loss_objectness: 0.4945  loss_dice: 0.1691  loss_mask: 0.02207    time: 5.8402  last_time: 0.7337  data_time: 0.0077  last_data_time: 0.0079   lr: 5e-05  max_mem: 2572M
[11/22 21:19:37] d2.utils.events INFO:  eta: 1:11:10  iter: 8699  total_loss: 0.6781  loss_ce: 0.03774  loss_objectness: 0.485  loss_dice: 0.1441  loss_mask: 0.02184    time: 5.8285  last_time: 0.7449  data_time: 0.0075  last_data_time: 0.0069   lr: 5e-05  max_mem: 2572M
[11/22 21:19:52] d2.utils.events INFO:  eta: 1:12:46  iter: 8719  total_loss: 0.8368  loss_ce: 0.06498  loss_objectness: 0.5458  loss_dice: 0.2033  loss_mask: 0.02727    time: 5.8168  last_time: 0.7336  data_time: 0.0073  last_data_time: 0.0086   lr: 5e-05  max_mem: 2572M
[11/22 21:20:07] d2.utils.events INFO:  eta: 1:13:31  iter: 8739  total_loss: 0.8497  loss_ce: 0.05609  loss_objectness: 0.5508  loss_dice: 0.2087  loss_mask: 0.02737    time: 5.8052  last_time: 0.7341  data_time: 0.0078  last_data_time: 0.0062   lr: 5e-05  max_mem: 2572M
[11/22 21:20:21] d2.utils.events INFO:  eta: 1:13:56  iter: 8759  total_loss: 0.9262  loss_ce: 0.07861  loss_objectness: 0.5758  loss_dice: 0.2281  loss_mask: 0.02768    time: 5.7936  last_time: 0.7635  data_time: 0.0075  last_data_time: 0.0089   lr: 5e-05  max_mem: 2572M
[11/22 21:20:35] d2.utils.events INFO:  eta: 1:13:55  iter: 8779  total_loss: 0.9345  loss_ce: 0.07085  loss_objectness: 0.5754  loss_dice: 0.2227  loss_mask: 0.02757    time: 5.7820  last_time: 0.6347  data_time: 0.0076  last_data_time: 0.0078   lr: 5e-05  max_mem: 2572M
[11/22 21:20:48] d2.utils.events INFO:  eta: 1:13:38  iter: 8799  total_loss: 0.8205  loss_ce: 0.05956  loss_objectness: 0.5349  loss_dice: 0.2167  loss_mask: 0.02656    time: 5.7703  last_time: 0.6205  data_time: 0.0079  last_data_time: 0.0122   lr: 5e-05  max_mem: 2572M
[11/22 21:21:00] d2.utils.events INFO:  eta: 1:12:52  iter: 8819  total_loss: 0.7596  loss_ce: 0.04009  loss_objectness: 0.5221  loss_dice: 0.176  loss_mask: 0.02524    time: 5.7586  last_time: 0.6192  data_time: 0.0076  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 21:21:13] d2.utils.events INFO:  eta: 1:11:23  iter: 8839  total_loss: 0.8358  loss_ce: 0.05009  loss_objectness: 0.5566  loss_dice: 0.1983  loss_mask: 0.0247    time: 5.7470  last_time: 0.6372  data_time: 0.0071  last_data_time: 0.0074   lr: 5e-05  max_mem: 2572M
[11/22 21:21:25] d2.utils.events INFO:  eta: 1:06:14  iter: 8859  total_loss: 0.7936  loss_ce: 0.03131  loss_objectness: 0.5368  loss_dice: 0.1867  loss_mask: 0.02558    time: 5.7354  last_time: 0.6355  data_time: 0.0075  last_data_time: 0.0075   lr: 5e-05  max_mem: 2572M
[11/22 21:21:39] d2.utils.events INFO:  eta: 1:05:37  iter: 8879  total_loss: 0.7994  loss_ce: 0.04798  loss_objectness: 0.5347  loss_dice: 0.2057  loss_mask: 0.02078    time: 5.7241  last_time: 0.7348  data_time: 0.0079  last_data_time: 0.0077   lr: 5e-05  max_mem: 2572M
[11/22 21:21:54] d2.utils.events INFO:  eta: 1:05:24  iter: 8899  total_loss: 0.7853  loss_ce: 0.02982  loss_objectness: 0.526  loss_dice: 0.1894  loss_mask: 0.02463    time: 5.7128  last_time: 0.7300  data_time: 0.0075  last_data_time: 0.0083   lr: 5e-05  max_mem: 2572M
[11/22 21:22:09] d2.utils.events INFO:  eta: 1:05:11  iter: 8919  total_loss: 0.7948  loss_ce: 0.03499  loss_objectness: 0.544  loss_dice: 0.1991  loss_mask: 0.02306    time: 5.7017  last_time: 0.7670  data_time: 0.0071  last_data_time: 0.0078   lr: 5e-05  max_mem: 2572M
[11/22 21:22:24] d2.utils.events INFO:  eta: 1:05:10  iter: 8939  total_loss: 0.6856  loss_ce: 0.02779  loss_objectness: 0.4817  loss_dice: 0.1434  loss_mask: 0.02345    time: 5.6906  last_time: 0.7559  data_time: 0.0074  last_data_time: 0.0076   lr: 5e-05  max_mem: 2572M
[11/22 21:22:39] d2.utils.events INFO:  eta: 1:09:55  iter: 8959  total_loss: 0.7462  loss_ce: 0.04267  loss_objectness: 0.5159  loss_dice: 0.1718  loss_mask: 0.02304    time: 5.6796  last_time: 0.7662  data_time: 0.0075  last_data_time: 0.0097   lr: 5e-05  max_mem: 2572M
[11/22 21:22:54] d2.utils.events INFO:  eta: 1:11:07  iter: 8979  total_loss: 0.8212  loss_ce: 0.04498  loss_objectness: 0.5462  loss_dice: 0.2153  loss_mask: 0.0216    time: 5.6686  last_time: 0.7985  data_time: 0.0075  last_data_time: 0.0095   lr: 5e-05  max_mem: 2572M
[11/22 21:23:09] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 21:23:09] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 21:23:09] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 21:23:09] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 21:23:09] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 21:23:09] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 21:23:17] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0005 s/iter. Inference: 0.0513 s/iter. Eval: 0.0543 s/iter. Total: 0.1062 s/iter. ETA=0:00:11
[11/22 21:23:22] d2.evaluation.evaluator INFO: Inference done 63/120. Dataloading: 0.0006 s/iter. Inference: 0.0522 s/iter. Eval: 0.0459 s/iter. Total: 0.0988 s/iter. ETA=0:00:05
[11/22 21:23:27] d2.evaluation.evaluator INFO: Inference done 112/120. Dataloading: 0.0007 s/iter. Inference: 0.0524 s/iter. Eval: 0.0477 s/iter. Total: 0.1008 s/iter. ETA=0:00:00
[11/22 21:23:29] d2.evaluation.evaluator INFO: Total inference time: 0:00:12.809818 (0.111390 s / iter per device, on 1 devices)
[11/22 21:23:29] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:06 (0.052617 s / iter per device, on 1 devices)
[11/22 21:23:29] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 21:23:29] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 21:23:29] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 21:23:29] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 21:23:29] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.07 seconds.
[11/22 21:23:29] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 21:23:29] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 21:23:29] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.667 | 13.296 | 6.315  | 0.198 | 13.652 | 49.096 |
[11/22 21:23:29] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 21:23:29] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 21:23:29] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 21:23:29] d2.evaluation.testing INFO: copypaste: 6.6670,13.2956,6.3151,0.1984,13.6522,49.0958
[11/22 21:23:29] d2.utils.events INFO:  eta: 1:11:27  iter: 8999  total_loss: 0.7762  loss_ce: 0.03008  loss_objectness: 0.5163  loss_dice: 0.1814  loss_mask: 0.02368    time: 5.6577  last_time: 0.7448  data_time: 0.0081  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 21:23:44] d2.utils.events INFO:  eta: 1:11:46  iter: 9019  total_loss: 0.734  loss_ce: 0.0262  loss_objectness: 0.5099  loss_dice: 0.1636  loss_mask: 0.02467    time: 5.6469  last_time: 0.6993  data_time: 0.0082  last_data_time: 0.0074   lr: 5e-05  max_mem: 2572M
[11/22 21:23:59] d2.utils.events INFO:  eta: 1:11:48  iter: 9039  total_loss: 0.7706  loss_ce: 0.04336  loss_objectness: 0.514  loss_dice: 0.1845  loss_mask: 0.0221    time: 5.6360  last_time: 0.7376  data_time: 0.0078  last_data_time: 0.0082   lr: 5e-05  max_mem: 2572M
[11/22 21:24:13] d2.utils.events INFO:  eta: 1:11:43  iter: 9059  total_loss: 0.7753  loss_ce: 0.02948  loss_objectness: 0.5163  loss_dice: 0.1825  loss_mask: 0.02319    time: 5.6251  last_time: 0.7242  data_time: 0.0073  last_data_time: 0.0061   lr: 5e-05  max_mem: 2572M
[11/22 21:24:27] d2.utils.events INFO:  eta: 1:11:30  iter: 9079  total_loss: 0.7237  loss_ce: 0.02515  loss_objectness: 0.5011  loss_dice: 0.1716  loss_mask: 0.02304    time: 5.6143  last_time: 0.6502  data_time: 0.0082  last_data_time: 0.0072   lr: 5e-05  max_mem: 2572M
[11/22 21:24:40] d2.utils.events INFO:  eta: 1:11:16  iter: 9099  total_loss: 0.9253  loss_ce: 0.07918  loss_objectness: 0.5765  loss_dice: 0.2639  loss_mask: 0.02492    time: 5.6033  last_time: 0.6388  data_time: 0.0077  last_data_time: 0.0081   lr: 5e-05  max_mem: 2572M
[11/22 21:24:52] d2.utils.events INFO:  eta: 1:11:01  iter: 9119  total_loss: 0.8632  loss_ce: 0.05234  loss_objectness: 0.557  loss_dice: 0.2173  loss_mask: 0.02864    time: 5.5924  last_time: 0.6184  data_time: 0.0078  last_data_time: 0.0061   lr: 5e-05  max_mem: 2572M
[11/22 21:25:05] d2.utils.events INFO:  eta: 1:10:47  iter: 9139  total_loss: 0.8315  loss_ce: 0.06276  loss_objectness: 0.5411  loss_dice: 0.2002  loss_mask: 0.02521    time: 5.5815  last_time: 0.6189  data_time: 0.0077  last_data_time: 0.0073   lr: 5e-05  max_mem: 2572M
[11/22 21:25:17] d2.utils.events INFO:  eta: 1:10:32  iter: 9159  total_loss: 0.7954  loss_ce: 0.03701  loss_objectness: 0.5304  loss_dice: 0.1988  loss_mask: 0.02452    time: 5.5707  last_time: 0.6208  data_time: 0.0075  last_data_time: 0.0080   lr: 5e-05  max_mem: 2572M
[11/22 21:25:30] d2.utils.events INFO:  eta: 1:10:18  iter: 9179  total_loss: 0.7131  loss_ce: 0.02838  loss_objectness: 0.4895  loss_dice: 0.1583  loss_mask: 0.02562    time: 5.5599  last_time: 0.6295  data_time: 0.0078  last_data_time: 0.0087   lr: 5e-05  max_mem: 2572M
[11/22 21:25:42] d2.utils.events INFO:  eta: 1:10:03  iter: 9199  total_loss: 0.7646  loss_ce: 0.01923  loss_objectness: 0.5139  loss_dice: 0.1914  loss_mask: 0.02288    time: 5.5492  last_time: 0.6285  data_time: 0.0075  last_data_time: 0.0065   lr: 5e-05  max_mem: 2572M
[11/22 21:25:55] d2.utils.events INFO:  eta: 1:09:49  iter: 9219  total_loss: 0.8054  loss_ce: 0.03407  loss_objectness: 0.5022  loss_dice: 0.2021  loss_mask: 0.02359    time: 5.5385  last_time: 0.6348  data_time: 0.0078  last_data_time: 0.0069   lr: 5e-05  max_mem: 2572M
[11/22 21:26:07] d2.utils.events INFO:  eta: 1:09:34  iter: 9239  total_loss: 0.7889  loss_ce: 0.04553  loss_objectness: 0.5197  loss_dice: 0.1646  loss_mask: 0.0224    time: 5.5279  last_time: 0.6372  data_time: 0.0079  last_data_time: 0.0073   lr: 5e-05  max_mem: 2572M
[11/22 21:26:20] d2.utils.events INFO:  eta: 1:09:10  iter: 9259  total_loss: 0.7471  loss_ce: 0.03747  loss_objectness: 0.5008  loss_dice: 0.1501  loss_mask: 0.02128    time: 5.5173  last_time: 0.6317  data_time: 0.0076  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 21:26:33] d2.utils.events INFO:  eta: 1:08:32  iter: 9279  total_loss: 0.7222  loss_ce: 0.03926  loss_objectness: 0.5022  loss_dice: 0.1718  loss_mask: 0.0183    time: 5.5067  last_time: 0.6309  data_time: 0.0076  last_data_time: 0.0083   lr: 5e-05  max_mem: 2572M
[11/22 21:26:45] d2.utils.events INFO:  eta: 1:07:42  iter: 9299  total_loss: 0.7163  loss_ce: 0.02969  loss_objectness: 0.4948  loss_dice: 0.1495  loss_mask: 0.02346    time: 5.4963  last_time: 0.6375  data_time: 0.0076  last_data_time: 0.0060   lr: 5e-05  max_mem: 2572M
[11/22 21:26:57] d2.utils.events INFO:  eta: 1:06:53  iter: 9319  total_loss: 0.6766  loss_ce: 0.03249  loss_objectness: 0.4501  loss_dice: 0.1444  loss_mask: 0.0233    time: 5.4858  last_time: 0.6416  data_time: 0.0079  last_data_time: 0.0079   lr: 5e-05  max_mem: 2572M
[11/22 21:27:10] d2.utils.events INFO:  eta: 1:04:16  iter: 9339  total_loss: 0.692  loss_ce: 0.04778  loss_objectness: 0.4855  loss_dice: 0.1447  loss_mask: 0.02256    time: 5.4754  last_time: 0.6219  data_time: 0.0079  last_data_time: 0.0075   lr: 5e-05  max_mem: 2572M
[11/22 21:27:23] d2.utils.events INFO:  eta: 1:01:08  iter: 9359  total_loss: 0.7145  loss_ce: 0.0261  loss_objectness: 0.5035  loss_dice: 0.1522  loss_mask: 0.02239    time: 5.4650  last_time: 0.6569  data_time: 0.0081  last_data_time: 0.0147   lr: 5e-05  max_mem: 2572M
[11/22 21:27:37] d2.utils.events INFO:  eta: 1:00:42  iter: 9379  total_loss: 0.6567  loss_ce: 0.0317  loss_objectness: 0.4573  loss_dice: 0.1342  loss_mask: 0.02128    time: 5.4549  last_time: 0.7947  data_time: 0.0087  last_data_time: 0.0089   lr: 5e-05  max_mem: 2572M
[11/22 21:27:52] d2.utils.events INFO:  eta: 1:00:29  iter: 9399  total_loss: 0.6364  loss_ce: 0.01257  loss_objectness: 0.4764  loss_dice: 0.1338  loss_mask: 0.02172    time: 5.4449  last_time: 0.7839  data_time: 0.0073  last_data_time: 0.0077   lr: 5e-05  max_mem: 2572M
[11/22 21:28:08] d2.utils.events INFO:  eta: 1:00:16  iter: 9419  total_loss: 0.6603  loss_ce: 0.02599  loss_objectness: 0.4729  loss_dice: 0.1404  loss_mask: 0.02084    time: 5.4350  last_time: 0.7789  data_time: 0.0078  last_data_time: 0.0066   lr: 5e-05  max_mem: 2572M
[11/22 21:28:24] d2.utils.events INFO:  eta: 1:00:32  iter: 9439  total_loss: 0.6911  loss_ce: 0.01681  loss_objectness: 0.4847  loss_dice: 0.1512  loss_mask: 0.02113    time: 5.4251  last_time: 0.7566  data_time: 0.0074  last_data_time: 0.0058   lr: 5e-05  max_mem: 2572M
[11/22 21:28:39] d2.utils.events INFO:  eta: 1:04:13  iter: 9459  total_loss: 0.6867  loss_ce: 0.02634  loss_objectness: 0.4998  loss_dice: 0.1512  loss_mask: 0.02366    time: 5.4153  last_time: 0.7608  data_time: 0.0073  last_data_time: 0.0074   lr: 5e-05  max_mem: 2572M
[11/22 21:28:54] d2.utils.events INFO:  eta: 1:05:19  iter: 9479  total_loss: 0.6632  loss_ce: 0.01485  loss_objectness: 0.4667  loss_dice: 0.1405  loss_mask: 0.02036    time: 5.4055  last_time: 0.6825  data_time: 0.0075  last_data_time: 0.0068   lr: 5e-05  max_mem: 2572M
[11/22 21:29:10] d2.utils.events INFO:  eta: 1:05:33  iter: 9499  total_loss: 0.7005  loss_ce: 0.02778  loss_objectness: 0.4719  loss_dice: 0.1449  loss_mask: 0.02008    time: 5.3958  last_time: 0.8077  data_time: 0.0080  last_data_time: 0.0137   lr: 5e-05  max_mem: 2572M
[11/22 21:29:26] d2.utils.events INFO:  eta: 1:05:52  iter: 9519  total_loss: 0.7756  loss_ce: 0.03723  loss_objectness: 0.5065  loss_dice: 0.1906  loss_mask: 0.02385    time: 5.3861  last_time: 0.7895  data_time: 0.0076  last_data_time: 0.0064   lr: 5e-05  max_mem: 2572M
[11/22 21:29:41] d2.utils.events INFO:  eta: 1:05:57  iter: 9539  total_loss: 0.884  loss_ce: 0.04922  loss_objectness: 0.5277  loss_dice: 0.2131  loss_mask: 0.02629    time: 5.3764  last_time: 0.7688  data_time: 0.0075  last_data_time: 0.0078   lr: 5e-05  max_mem: 2572M
[11/22 21:29:57] d2.utils.events INFO:  eta: 1:06:04  iter: 9559  total_loss: 0.7337  loss_ce: 0.04752  loss_objectness: 0.5015  loss_dice: 0.1761  loss_mask: 0.01926    time: 5.3668  last_time: 0.7771  data_time: 0.0077  last_data_time: 0.0074   lr: 5e-05  max_mem: 2572M
[11/22 21:30:12] d2.utils.events INFO:  eta: 1:06:02  iter: 9579  total_loss: 0.7017  loss_ce: 0.0343  loss_objectness: 0.4849  loss_dice: 0.1492  loss_mask: 0.02081    time: 5.3572  last_time: 0.7689  data_time: 0.0075  last_data_time: 0.0066   lr: 5e-05  max_mem: 2572M
[11/22 21:30:27] d2.utils.events INFO:  eta: 1:05:41  iter: 9599  total_loss: 0.7255  loss_ce: 0.04337  loss_objectness: 0.5132  loss_dice: 0.1694  loss_mask: 0.02296    time: 5.3475  last_time: 0.6308  data_time: 0.0081  last_data_time: 0.0065   lr: 5e-05  max_mem: 2572M
[11/22 21:30:39] d2.utils.events INFO:  eta: 1:05:07  iter: 9619  total_loss: 0.7648  loss_ce: 0.03627  loss_objectness: 0.5078  loss_dice: 0.1824  loss_mask: 0.02599    time: 5.3377  last_time: 0.6550  data_time: 0.0077  last_data_time: 0.0074   lr: 5e-05  max_mem: 2572M
[11/22 21:30:52] d2.utils.events INFO:  eta: 1:04:35  iter: 9639  total_loss: 0.6749  loss_ce: 0.02083  loss_objectness: 0.474  loss_dice: 0.1432  loss_mask: 0.01917    time: 5.3280  last_time: 0.6235  data_time: 0.0078  last_data_time: 0.0078   lr: 5e-05  max_mem: 2572M
[11/22 21:31:05] d2.utils.events INFO:  eta: 1:03:54  iter: 9659  total_loss: 0.619  loss_ce: 0.009166  loss_objectness: 0.4535  loss_dice: 0.1352  loss_mask: 0.02012    time: 5.3183  last_time: 0.6268  data_time: 0.0075  last_data_time: 0.0074   lr: 5e-05  max_mem: 2572M
[11/22 21:31:18] d2.utils.events INFO:  eta: 1:03:05  iter: 9679  total_loss: 0.6164  loss_ce: 0.02132  loss_objectness: 0.4574  loss_dice: 0.1473  loss_mask: 0.02314    time: 5.3086  last_time: 0.6456  data_time: 0.0081  last_data_time: 0.0087   lr: 5e-05  max_mem: 2572M
[11/22 21:31:30] d2.utils.events INFO:  eta: 1:01:47  iter: 9699  total_loss: 0.7236  loss_ce: 0.0365  loss_objectness: 0.4906  loss_dice: 0.1814  loss_mask: 0.01777    time: 5.2989  last_time: 0.6315  data_time: 0.0085  last_data_time: 0.0073   lr: 5e-05  max_mem: 2572M
[11/22 21:31:43] d2.utils.events INFO:  eta: 0:57:42  iter: 9719  total_loss: 0.6879  loss_ce: 0.04077  loss_objectness: 0.4831  loss_dice: 0.1381  loss_mask: 0.0189    time: 5.2893  last_time: 0.6527  data_time: 0.0075  last_data_time: 0.0084   lr: 5e-05  max_mem: 2572M
[11/22 21:31:56] d2.utils.events INFO:  eta: 0:56:56  iter: 9739  total_loss: 0.6486  loss_ce: 0.01503  loss_objectness: 0.4551  loss_dice: 0.1417  loss_mask: 0.01981    time: 5.2798  last_time: 0.6317  data_time: 0.0076  last_data_time: 0.0084   lr: 5e-05  max_mem: 2572M
[11/22 21:32:08] d2.utils.events INFO:  eta: 0:56:23  iter: 9759  total_loss: 0.7726  loss_ce: 0.05076  loss_objectness: 0.4972  loss_dice: 0.1793  loss_mask: 0.02064    time: 5.2703  last_time: 0.6494  data_time: 0.0079  last_data_time: 0.0075   lr: 5e-05  max_mem: 2572M
[11/22 21:32:21] d2.utils.events INFO:  eta: 0:56:07  iter: 9779  total_loss: 1.169  loss_ce: 0.09002  loss_objectness: 0.6393  loss_dice: 0.3379  loss_mask: 0.03772    time: 5.2608  last_time: 0.6580  data_time: 0.0075  last_data_time: 0.0072   lr: 5e-05  max_mem: 2572M
[11/22 21:32:34] d2.utils.events INFO:  eta: 0:55:58  iter: 9799  total_loss: 1.242  loss_ce: 0.1504  loss_objectness: 0.6437  loss_dice: 0.3995  loss_mask: 0.04591    time: 5.2514  last_time: 0.6368  data_time: 0.0082  last_data_time: 0.0078   lr: 5e-05  max_mem: 2572M
[11/22 21:32:47] d2.utils.events INFO:  eta: 0:55:52  iter: 9819  total_loss: 1.056  loss_ce: 0.1321  loss_objectness: 0.6006  loss_dice: 0.2843  loss_mask: 0.0367    time: 5.2420  last_time: 0.6354  data_time: 0.0082  last_data_time: 0.0080   lr: 5e-05  max_mem: 2572M
[11/22 21:33:00] d2.utils.events INFO:  eta: 0:55:43  iter: 9839  total_loss: 1.014  loss_ce: 0.09188  loss_objectness: 0.5979  loss_dice: 0.302  loss_mask: 0.03638    time: 5.2326  last_time: 0.6400  data_time: 0.0078  last_data_time: 0.0072   lr: 5e-05  max_mem: 2572M
[11/22 21:33:12] d2.utils.events INFO:  eta: 0:55:30  iter: 9859  total_loss: 1.016  loss_ce: 0.06499  loss_objectness: 0.5935  loss_dice: 0.2834  loss_mask: 0.03505    time: 5.2233  last_time: 0.6109  data_time: 0.0081  last_data_time: 0.0072   lr: 5e-05  max_mem: 2572M
[11/22 21:33:26] d2.utils.events INFO:  eta: 0:55:17  iter: 9879  total_loss: 0.9586  loss_ce: 0.06862  loss_objectness: 0.5889  loss_dice: 0.2501  loss_mask: 0.03001    time: 5.2141  last_time: 0.7644  data_time: 0.0085  last_data_time: 0.0071   lr: 5e-05  max_mem: 2572M
[11/22 21:33:42] d2.utils.events INFO:  eta: 0:55:04  iter: 9899  total_loss: 0.7961  loss_ce: 0.03411  loss_objectness: 0.5332  loss_dice: 0.1933  loss_mask: 0.02661    time: 5.2051  last_time: 0.7814  data_time: 0.0075  last_data_time: 0.0077   lr: 5e-05  max_mem: 2572M
[11/22 21:33:57] d2.utils.events INFO:  eta: 0:54:51  iter: 9919  total_loss: 0.8556  loss_ce: 0.03775  loss_objectness: 0.5325  loss_dice: 0.2102  loss_mask: 0.02595    time: 5.1962  last_time: 0.7779  data_time: 0.0078  last_data_time: 0.0092   lr: 5e-05  max_mem: 2572M
[11/22 21:34:12] d2.utils.events INFO:  eta: 0:54:38  iter: 9939  total_loss: 0.7058  loss_ce: 0.0383  loss_objectness: 0.4905  loss_dice: 0.1651  loss_mask: 0.02204    time: 5.1873  last_time: 0.7614  data_time: 0.0075  last_data_time: 0.0071   lr: 5e-05  max_mem: 2572M
[11/22 21:34:28] d2.utils.events INFO:  eta: 0:54:25  iter: 9959  total_loss: 0.717  loss_ce: 0.02239  loss_objectness: 0.4895  loss_dice: 0.1464  loss_mask: 0.02535    time: 5.1784  last_time: 0.7677  data_time: 0.0072  last_data_time: 0.0065   lr: 5e-05  max_mem: 2572M
[11/22 21:34:44] d2.utils.events INFO:  eta: 0:54:12  iter: 9979  total_loss: 0.7353  loss_ce: 0.02352  loss_objectness: 0.5095  loss_dice: 0.1673  loss_mask: 0.02205    time: 5.1696  last_time: 0.7838  data_time: 0.0086  last_data_time: 0.0079   lr: 5e-05  max_mem: 2572M
[11/22 21:34:59] fvcore.common.checkpoint INFO: Saving checkpoint to output/crack_model_turbo\model_0009999.pth
[11/22 21:34:59] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 21:34:59] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 21:34:59] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 21:34:59] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 21:34:59] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 21:34:59] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 21:35:08] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0006 s/iter. Inference: 0.0482 s/iter. Eval: 0.0706 s/iter. Total: 0.1194 s/iter. ETA=0:00:13
[11/22 21:35:13] d2.evaluation.evaluator INFO: Inference done 59/120. Dataloading: 0.0006 s/iter. Inference: 0.0517 s/iter. Eval: 0.0550 s/iter. Total: 0.1073 s/iter. ETA=0:00:06
[11/22 21:35:18] d2.evaluation.evaluator INFO: Inference done 105/120. Dataloading: 0.0009 s/iter. Inference: 0.0525 s/iter. Eval: 0.0555 s/iter. Total: 0.1090 s/iter. ETA=0:00:01
[11/22 21:35:21] d2.evaluation.evaluator INFO: Total inference time: 0:00:13.984319 (0.121603 s / iter per device, on 1 devices)
[11/22 21:35:21] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:06 (0.053268 s / iter per device, on 1 devices)
[11/22 21:35:21] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 21:35:21] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 21:35:21] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 21:35:22] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 21:35:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.09 seconds.
[11/22 21:35:22] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 21:35:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 21:35:22] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 7.403 | 14.519 | 6.754  | 0.307 | 15.366 | 53.264 |
[11/22 21:35:22] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 21:35:22] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 21:35:22] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 21:35:22] d2.evaluation.testing INFO: copypaste: 7.4026,14.5188,6.7539,0.3069,15.3663,53.2636
[11/22 21:35:22] d2.utils.events INFO:  eta: 0:54:00  iter: 9999  total_loss: 0.7051  loss_ce: 0.02371  loss_objectness: 0.4823  loss_dice: 0.148  loss_mask: 0.022    time: 5.1608  last_time: 0.7501  data_time: 0.0075  last_data_time: 0.0058   lr: 5e-05  max_mem: 2572M
[11/22 21:35:37] d2.utils.events INFO:  eta: 0:53:46  iter: 10019  total_loss: 0.6528  loss_ce: 0.01054  loss_objectness: 0.466  loss_dice: 0.1423  loss_mask: 0.02045    time: 5.1520  last_time: 0.7739  data_time: 0.0082  last_data_time: 0.0076   lr: 5e-06  max_mem: 2572M
[11/22 21:35:52] d2.utils.events INFO:  eta: 0:53:33  iter: 10039  total_loss: 0.6409  loss_ce: 0.02473  loss_objectness: 0.4392  loss_dice: 0.1333  loss_mask: 0.02093    time: 5.1433  last_time: 0.7493  data_time: 0.0081  last_data_time: 0.0076   lr: 5e-06  max_mem: 2572M
[11/22 21:36:08] d2.utils.events INFO:  eta: 0:53:21  iter: 10059  total_loss: 0.5672  loss_ce: 0.006772  loss_objectness: 0.4273  loss_dice: 0.1177  loss_mask: 0.02087    time: 5.1346  last_time: 0.7544  data_time: 0.0071  last_data_time: 0.0067   lr: 5e-06  max_mem: 2572M
[11/22 21:36:22] d2.utils.events INFO:  eta: 0:53:07  iter: 10079  total_loss: 0.607  loss_ce: 0.00936  loss_objectness: 0.4483  loss_dice: 0.1239  loss_mask: 0.01763    time: 5.1258  last_time: 0.6363  data_time: 0.0074  last_data_time: 0.0063   lr: 5e-06  max_mem: 2572M
[11/22 21:36:35] d2.utils.events INFO:  eta: 0:52:52  iter: 10099  total_loss: 0.6599  loss_ce: 0.01933  loss_objectness: 0.4378  loss_dice: 0.1593  loss_mask: 0.01885    time: 5.1169  last_time: 0.6385  data_time: 0.0077  last_data_time: 0.0084   lr: 5e-06  max_mem: 2572M
[11/22 21:36:47] d2.utils.events INFO:  eta: 0:52:39  iter: 10119  total_loss: 0.5632  loss_ce: 0.008793  loss_objectness: 0.4194  loss_dice: 0.1083  loss_mask: 0.01902    time: 5.1081  last_time: 0.6467  data_time: 0.0076  last_data_time: 0.0073   lr: 5e-06  max_mem: 2572M
[11/22 21:37:00] d2.utils.events INFO:  eta: 0:52:28  iter: 10139  total_loss: 0.5686  loss_ce: 0.007402  loss_objectness: 0.426  loss_dice: 0.1155  loss_mask: 0.02118    time: 5.0992  last_time: 0.6492  data_time: 0.0080  last_data_time: 0.0079   lr: 5e-06  max_mem: 2572M
[11/22 21:37:13] d2.utils.events INFO:  eta: 0:52:19  iter: 10159  total_loss: 0.56  loss_ce: 0.004482  loss_objectness: 0.4284  loss_dice: 0.1109  loss_mask: 0.01856    time: 5.0905  last_time: 0.6403  data_time: 0.0077  last_data_time: 0.0065   lr: 5e-06  max_mem: 2572M
[11/22 21:37:26] d2.utils.events INFO:  eta: 0:52:08  iter: 10179  total_loss: 0.5675  loss_ce: 0.009738  loss_objectness: 0.4238  loss_dice: 0.1069  loss_mask: 0.02261    time: 5.0817  last_time: 0.6557  data_time: 0.0076  last_data_time: 0.0072   lr: 5e-06  max_mem: 2572M
[11/22 21:37:39] d2.utils.events INFO:  eta: 0:52:01  iter: 10199  total_loss: 0.5317  loss_ce: 0.01257  loss_objectness: 0.4146  loss_dice: 0.1011  loss_mask: 0.01715    time: 5.0730  last_time: 0.6406  data_time: 0.0081  last_data_time: 0.0084   lr: 5e-06  max_mem: 2572M
[11/22 21:37:52] d2.utils.events INFO:  eta: 0:51:48  iter: 10219  total_loss: 0.5978  loss_ce: 0.006356  loss_objectness: 0.4407  loss_dice: 0.1242  loss_mask: 0.01891    time: 5.0644  last_time: 0.6370  data_time: 0.0075  last_data_time: 0.0067   lr: 5e-06  max_mem: 2572M
[11/22 21:38:05] d2.utils.events INFO:  eta: 0:51:47  iter: 10239  total_loss: 0.5449  loss_ce: 0.007186  loss_objectness: 0.4198  loss_dice: 0.1012  loss_mask: 0.01802    time: 5.0558  last_time: 0.7437  data_time: 0.0081  last_data_time: 0.0076   lr: 5e-06  max_mem: 2572M
[11/22 21:38:20] d2.utils.events INFO:  eta: 0:51:47  iter: 10259  total_loss: 0.5384  loss_ce: 0.004448  loss_objectness: 0.3973  loss_dice: 0.09537  loss_mask: 0.01747    time: 5.0474  last_time: 0.7522  data_time: 0.0081  last_data_time: 0.0084   lr: 5e-06  max_mem: 2572M
[11/22 21:38:36] d2.utils.events INFO:  eta: 0:51:53  iter: 10279  total_loss: 0.519  loss_ce: 0.002661  loss_objectness: 0.3951  loss_dice: 0.08996  loss_mask: 0.01754    time: 5.0391  last_time: 0.7871  data_time: 0.0087  last_data_time: 0.0075   lr: 5e-06  max_mem: 2572M
[11/22 21:38:51] d2.utils.events INFO:  eta: 0:53:38  iter: 10299  total_loss: 0.5369  loss_ce: 0.007649  loss_objectness: 0.4196  loss_dice: 0.1013  loss_mask: 0.01903    time: 5.0308  last_time: 0.7746  data_time: 0.0074  last_data_time: 0.0059   lr: 5e-06  max_mem: 2572M
[11/22 21:39:06] d2.utils.events INFO:  eta: 0:55:54  iter: 10319  total_loss: 0.5603  loss_ce: 0.0135  loss_objectness: 0.4114  loss_dice: 0.102  loss_mask: 0.01664    time: 5.0225  last_time: 0.7470  data_time: 0.0076  last_data_time: 0.0068   lr: 5e-06  max_mem: 2572M
[11/22 21:39:22] d2.utils.events INFO:  eta: 0:56:46  iter: 10339  total_loss: 0.5055  loss_ce: 0.007031  loss_objectness: 0.3938  loss_dice: 0.09563  loss_mask: 0.01829    time: 5.0143  last_time: 0.7526  data_time: 0.0076  last_data_time: 0.0077   lr: 5e-06  max_mem: 2572M
[11/22 21:39:37] d2.utils.events INFO:  eta: 0:57:15  iter: 10359  total_loss: 0.568  loss_ce: 0.006451  loss_objectness: 0.4137  loss_dice: 0.101  loss_mask: 0.01828    time: 5.0061  last_time: 0.7520  data_time: 0.0077  last_data_time: 0.0067   lr: 5e-06  max_mem: 2572M
[11/22 21:39:52] d2.utils.events INFO:  eta: 0:57:18  iter: 10379  total_loss: 0.5443  loss_ce: 0.00437  loss_objectness: 0.4204  loss_dice: 0.09045  loss_mask: 0.01793    time: 4.9979  last_time: 0.7741  data_time: 0.0076  last_data_time: 0.0067   lr: 5e-06  max_mem: 2572M
[11/22 21:40:08] d2.utils.events INFO:  eta: 0:56:58  iter: 10399  total_loss: 0.5502  loss_ce: 0.01136  loss_objectness: 0.4211  loss_dice: 0.092  loss_mask: 0.01953    time: 4.9898  last_time: 0.7835  data_time: 0.0080  last_data_time: 0.0099   lr: 5e-06  max_mem: 2572M
[11/22 21:40:23] d2.utils.events INFO:  eta: 0:56:44  iter: 10419  total_loss: 0.4969  loss_ce: 0.001739  loss_objectness: 0.3797  loss_dice: 0.08903  loss_mask: 0.01625    time: 4.9817  last_time: 0.7848  data_time: 0.0080  last_data_time: 0.0068   lr: 5e-06  max_mem: 2572M
[11/22 21:40:39] d2.utils.events INFO:  eta: 0:56:26  iter: 10439  total_loss: 0.5321  loss_ce: 0.009476  loss_objectness: 0.4177  loss_dice: 0.09048  loss_mask: 0.01715    time: 4.9736  last_time: 0.7707  data_time: 0.0075  last_data_time: 0.0072   lr: 5e-06  max_mem: 2572M
[11/22 21:40:54] d2.utils.events INFO:  eta: 0:56:06  iter: 10459  total_loss: 0.5018  loss_ce: 0.003178  loss_objectness: 0.3935  loss_dice: 0.0842  loss_mask: 0.01808    time: 4.9656  last_time: 0.7756  data_time: 0.0079  last_data_time: 0.0078   lr: 5e-06  max_mem: 2572M
[11/22 21:41:10] d2.utils.events INFO:  eta: 0:55:54  iter: 10479  total_loss: 0.5239  loss_ce: 0.006961  loss_objectness: 0.4048  loss_dice: 0.09076  loss_mask: 0.01799    time: 4.9576  last_time: 0.7709  data_time: 0.0078  last_data_time: 0.0089   lr: 5e-06  max_mem: 2572M
[11/22 21:41:25] d2.utils.events INFO:  eta: 0:55:35  iter: 10499  total_loss: 0.5024  loss_ce: 0.003758  loss_objectness: 0.3806  loss_dice: 0.0865  loss_mask: 0.01618    time: 4.9496  last_time: 0.6762  data_time: 0.0078  last_data_time: 0.0059   lr: 5e-06  max_mem: 2572M
[11/22 21:41:39] d2.utils.events INFO:  eta: 0:55:07  iter: 10519  total_loss: 0.4578  loss_ce: 0.00142  loss_objectness: 0.364  loss_dice: 0.07756  loss_mask: 0.01725    time: 4.9415  last_time: 0.7369  data_time: 0.0079  last_data_time: 0.0095   lr: 5e-06  max_mem: 2572M
[11/22 21:41:54] d2.utils.events INFO:  eta: 0:54:43  iter: 10539  total_loss: 0.5194  loss_ce: 0.007181  loss_objectness: 0.4094  loss_dice: 0.09217  loss_mask: 0.02    time: 4.9336  last_time: 0.7554  data_time: 0.0075  last_data_time: 0.0059   lr: 5e-06  max_mem: 2572M
[11/22 21:42:09] d2.utils.events INFO:  eta: 0:54:22  iter: 10559  total_loss: 0.4785  loss_ce: 0.003718  loss_objectness: 0.3705  loss_dice: 0.08267  loss_mask: 0.01888    time: 4.9256  last_time: 0.7360  data_time: 0.0075  last_data_time: 0.0074   lr: 5e-06  max_mem: 2572M
[11/22 21:42:22] d2.utils.events INFO:  eta: 0:53:36  iter: 10579  total_loss: 0.4863  loss_ce: 0.001857  loss_objectness: 0.39  loss_dice: 0.07857  loss_mask: 0.01684    time: 4.9176  last_time: 0.6515  data_time: 0.0078  last_data_time: 0.0080   lr: 5e-06  max_mem: 2572M
[11/22 21:42:35] d2.utils.events INFO:  eta: 0:52:40  iter: 10599  total_loss: 0.6157  loss_ce: 0.00896  loss_objectness: 0.4251  loss_dice: 0.09749  loss_mask: 0.01707    time: 4.9095  last_time: 0.6571  data_time: 0.0077  last_data_time: 0.0089   lr: 5e-06  max_mem: 2572M
[11/22 21:42:49] d2.utils.events INFO:  eta: 0:52:26  iter: 10619  total_loss: 0.5087  loss_ce: 0.003156  loss_objectness: 0.4102  loss_dice: 0.08321  loss_mask: 0.01682    time: 4.9015  last_time: 0.6606  data_time: 0.0076  last_data_time: 0.0065   lr: 5e-06  max_mem: 2572M
[11/22 21:43:02] d2.utils.events INFO:  eta: 0:52:12  iter: 10639  total_loss: 0.5006  loss_ce: 0.00843  loss_objectness: 0.3847  loss_dice: 0.08111  loss_mask: 0.01748    time: 4.8935  last_time: 0.6552  data_time: 0.0075  last_data_time: 0.0061   lr: 5e-06  max_mem: 2572M
[11/22 21:43:15] d2.utils.events INFO:  eta: 0:51:57  iter: 10659  total_loss: 0.5117  loss_ce: 0.001074  loss_objectness: 0.3906  loss_dice: 0.08964  loss_mask: 0.01701    time: 4.8856  last_time: 0.6579  data_time: 0.0073  last_data_time: 0.0061   lr: 5e-06  max_mem: 2572M
[11/22 21:43:28] d2.utils.events INFO:  eta: 0:51:43  iter: 10679  total_loss: 0.5063  loss_ce: 0.002073  loss_objectness: 0.3828  loss_dice: 0.08293  loss_mask: 0.01614    time: 4.8777  last_time: 0.6468  data_time: 0.0076  last_data_time: 0.0064   lr: 5e-06  max_mem: 2572M
[11/22 21:43:41] d2.utils.events INFO:  eta: 0:51:28  iter: 10699  total_loss: 0.4968  loss_ce: 0.007058  loss_objectness: 0.3899  loss_dice: 0.07946  loss_mask: 0.01655    time: 4.8698  last_time: 0.6502  data_time: 0.0075  last_data_time: 0.0081   lr: 5e-06  max_mem: 2572M
[11/22 21:43:54] d2.utils.events INFO:  eta: 0:51:14  iter: 10719  total_loss: 0.5487  loss_ce: 0.003119  loss_objectness: 0.4156  loss_dice: 0.08011  loss_mask: 0.01737    time: 4.8619  last_time: 0.6525  data_time: 0.0076  last_data_time: 0.0100   lr: 5e-06  max_mem: 2572M
[11/22 21:44:07] d2.utils.events INFO:  eta: 0:51:00  iter: 10739  total_loss: 0.4876  loss_ce: 0.0003852  loss_objectness: 0.3761  loss_dice: 0.08109  loss_mask: 0.0184    time: 4.8541  last_time: 0.6624  data_time: 0.0077  last_data_time: 0.0081   lr: 5e-06  max_mem: 2572M
[11/22 21:44:20] d2.utils.events INFO:  eta: 0:50:45  iter: 10759  total_loss: 0.5011  loss_ce: 0.002668  loss_objectness: 0.3981  loss_dice: 0.08213  loss_mask: 0.01601    time: 4.8463  last_time: 0.6766  data_time: 0.0075  last_data_time: 0.0086   lr: 5e-06  max_mem: 2572M
[11/22 21:44:33] d2.utils.events INFO:  eta: 0:50:31  iter: 10779  total_loss: 0.5061  loss_ce: 0.003209  loss_objectness: 0.4025  loss_dice: 0.08152  loss_mask: 0.01736    time: 4.8385  last_time: 0.6527  data_time: 0.0079  last_data_time: 0.0073   lr: 5e-06  max_mem: 2572M
[11/22 21:44:46] d2.utils.events INFO:  eta: 0:50:17  iter: 10799  total_loss: 0.4535  loss_ce: 0.002475  loss_objectness: 0.3575  loss_dice: 0.07392  loss_mask: 0.01669    time: 4.8307  last_time: 0.6552  data_time: 0.0071  last_data_time: 0.0076   lr: 5e-06  max_mem: 2572M
[11/22 21:44:59] d2.utils.events INFO:  eta: 0:50:02  iter: 10819  total_loss: 0.5089  loss_ce: 0.00233  loss_objectness: 0.3932  loss_dice: 0.08072  loss_mask: 0.01624    time: 4.8230  last_time: 0.6463  data_time: 0.0073  last_data_time: 0.0084   lr: 5e-06  max_mem: 2572M
[11/22 21:45:13] d2.utils.events INFO:  eta: 0:49:48  iter: 10839  total_loss: 0.5285  loss_ce: 0.002613  loss_objectness: 0.3892  loss_dice: 0.09711  loss_mask: 0.01692    time: 4.8153  last_time: 0.6589  data_time: 0.0076  last_data_time: 0.0079   lr: 5e-06  max_mem: 2572M
[11/22 21:45:26] d2.utils.events INFO:  eta: 0:49:33  iter: 10859  total_loss: 0.4906  loss_ce: 0.002387  loss_objectness: 0.375  loss_dice: 0.0793  loss_mask: 0.01756    time: 4.8076  last_time: 0.6555  data_time: 0.0076  last_data_time: 0.0078   lr: 5e-06  max_mem: 2572M
[11/22 21:45:39] d2.utils.events INFO:  eta: 0:49:03  iter: 10879  total_loss: 0.5056  loss_ce: 0.004069  loss_objectness: 0.3891  loss_dice: 0.08534  loss_mask: 0.01812    time: 4.8000  last_time: 0.6340  data_time: 0.0074  last_data_time: 0.0069   lr: 5e-06  max_mem: 2572M
[11/22 21:45:52] d2.utils.events INFO:  eta: 0:47:08  iter: 10899  total_loss: 0.4573  loss_ce: 0.001421  loss_objectness: 0.3573  loss_dice: 0.07157  loss_mask: 0.01648    time: 4.7924  last_time: 0.6356  data_time: 0.0076  last_data_time: 0.0070   lr: 5e-06  max_mem: 2572M
[11/22 21:46:04] d2.utils.events INFO:  eta: 0:45:21  iter: 10919  total_loss: 0.4798  loss_ce: 0.00104  loss_objectness: 0.3848  loss_dice: 0.07346  loss_mask: 0.01895    time: 4.7848  last_time: 0.6540  data_time: 0.0080  last_data_time: 0.0090   lr: 5e-06  max_mem: 2572M
[11/22 21:46:17] d2.utils.events INFO:  eta: 0:44:53  iter: 10939  total_loss: 0.5003  loss_ce: 0.003632  loss_objectness: 0.3894  loss_dice: 0.08272  loss_mask: 0.01812    time: 4.7772  last_time: 0.6316  data_time: 0.0071  last_data_time: 0.0062   lr: 5e-06  max_mem: 2572M
[11/22 21:46:29] d2.utils.events INFO:  eta: 0:44:32  iter: 10959  total_loss: 0.5027  loss_ce: 0.003923  loss_objectness: 0.3932  loss_dice: 0.07297  loss_mask: 0.01738    time: 4.7696  last_time: 0.6144  data_time: 0.0134  last_data_time: 0.0098   lr: 5e-06  max_mem: 2572M
[11/22 21:46:42] d2.utils.events INFO:  eta: 0:44:15  iter: 10979  total_loss: 0.4952  loss_ce: 0.001176  loss_objectness: 0.3831  loss_dice: 0.0739  loss_mask: 0.01695    time: 4.7620  last_time: 0.6032  data_time: 0.0076  last_data_time: 0.0057   lr: 5e-06  max_mem: 2572M
[11/22 21:46:54] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 21:46:54] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 21:46:54] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 21:46:54] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 21:46:54] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 21:46:55] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 21:47:08] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0007 s/iter. Inference: 0.0447 s/iter. Eval: 0.0302 s/iter. Total: 0.0755 s/iter. ETA=0:00:08
[11/22 21:47:13] d2.evaluation.evaluator INFO: Inference done 75/120. Dataloading: 0.0007 s/iter. Inference: 0.0470 s/iter. Eval: 0.0302 s/iter. Total: 0.0780 s/iter. ETA=0:00:03
[11/22 21:47:18] d2.evaluation.evaluator INFO: Total inference time: 0:00:10.652380 (0.092629 s / iter per device, on 1 devices)
[11/22 21:47:18] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.047964 s / iter per device, on 1 devices)
[11/22 21:47:19] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 21:47:19] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 21:47:19] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 21:47:19] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 21:47:19] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.05 seconds.
[11/22 21:47:19] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 21:47:19] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 21:47:19] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.805 | 13.522 | 6.410  | 0.082 | 13.931 | 52.070 |
[11/22 21:47:19] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 21:47:19] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 21:47:19] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 21:47:19] d2.evaluation.testing INFO: copypaste: 6.8052,13.5222,6.4101,0.0815,13.9308,52.0699
[11/22 21:47:19] d2.utils.events INFO:  eta: 0:43:56  iter: 10999  total_loss: 0.5222  loss_ce: 0.002156  loss_objectness: 0.3999  loss_dice: 0.07982  loss_mask: 0.01629    time: 4.7545  last_time: 0.6325  data_time: 0.0083  last_data_time: 0.0082   lr: 5e-06  max_mem: 2572M
[11/22 21:47:34] d2.utils.events INFO:  eta: 0:43:43  iter: 11019  total_loss: 0.5047  loss_ce: 0.004688  loss_objectness: 0.4035  loss_dice: 0.07657  loss_mask: 0.02131    time: 4.7472  last_time: 0.7649  data_time: 0.0077  last_data_time: 0.0074   lr: 5e-06  max_mem: 2572M
[11/22 21:47:48] d2.utils.events INFO:  eta: 0:43:30  iter: 11039  total_loss: 0.4723  loss_ce: 0.002628  loss_objectness: 0.3733  loss_dice: 0.07957  loss_mask: 0.01655    time: 4.7400  last_time: 0.7582  data_time: 0.0080  last_data_time: 0.0073   lr: 5e-06  max_mem: 2572M
[11/22 21:48:04] d2.utils.events INFO:  eta: 0:43:16  iter: 11059  total_loss: 0.4311  loss_ce: 0.0004384  loss_objectness: 0.3371  loss_dice: 0.07117  loss_mask: 0.01946    time: 4.7328  last_time: 0.7459  data_time: 0.0080  last_data_time: 0.0082   lr: 5e-06  max_mem: 2572M
[11/22 21:48:19] d2.utils.events INFO:  eta: 0:43:05  iter: 11079  total_loss: 0.4493  loss_ce: 0.001663  loss_objectness: 0.3618  loss_dice: 0.07503  loss_mask: 0.01595    time: 4.7256  last_time: 0.7974  data_time: 0.0080  last_data_time: 0.0114   lr: 5e-06  max_mem: 2572M
[11/22 21:48:34] d2.utils.events INFO:  eta: 0:42:56  iter: 11099  total_loss: 0.4625  loss_ce: 0.005231  loss_objectness: 0.368  loss_dice: 0.07142  loss_mask: 0.0174    time: 4.7185  last_time: 0.7916  data_time: 0.0076  last_data_time: 0.0078   lr: 5e-06  max_mem: 2572M
[11/22 21:48:50] d2.utils.events INFO:  eta: 0:42:49  iter: 11119  total_loss: 0.4326  loss_ce: 0.0009554  loss_objectness: 0.3442  loss_dice: 0.06291  loss_mask: 0.01641    time: 4.7114  last_time: 0.7863  data_time: 0.0077  last_data_time: 0.0074   lr: 5e-06  max_mem: 2572M
[11/22 21:49:05] d2.utils.events INFO:  eta: 0:42:44  iter: 11139  total_loss: 0.4466  loss_ce: 0.001134  loss_objectness: 0.354  loss_dice: 0.06528  loss_mask: 0.01747    time: 4.7043  last_time: 0.7454  data_time: 0.0078  last_data_time: 0.0069   lr: 5e-06  max_mem: 2572M
[11/22 21:49:20] d2.utils.events INFO:  eta: 0:42:51  iter: 11159  total_loss: 0.5048  loss_ce: 0.006843  loss_objectness: 0.3906  loss_dice: 0.08672  loss_mask: 0.01746    time: 4.6972  last_time: 0.7765  data_time: 0.0082  last_data_time: 0.0091   lr: 5e-06  max_mem: 2572M
[11/22 21:49:36] d2.utils.events INFO:  eta: 0:44:45  iter: 11179  total_loss: 0.4967  loss_ce: 0.0009395  loss_objectness: 0.3909  loss_dice: 0.0826  loss_mask: 0.01549    time: 4.6902  last_time: 0.7854  data_time: 0.0076  last_data_time: 0.0074   lr: 5e-06  max_mem: 2572M
[11/22 21:49:51] d2.utils.events INFO:  eta: 0:45:29  iter: 11199  total_loss: 0.4741  loss_ce: 0.00232  loss_objectness: 0.3782  loss_dice: 0.07435  loss_mask: 0.01395    time: 4.6832  last_time: 0.7993  data_time: 0.0084  last_data_time: 0.0085   lr: 5e-06  max_mem: 2572M
[11/22 21:50:06] d2.utils.events INFO:  eta: 0:45:46  iter: 11219  total_loss: 0.4757  loss_ce: 0.002548  loss_objectness: 0.3717  loss_dice: 0.0812  loss_mask: 0.01766    time: 4.6762  last_time: 0.7449  data_time: 0.0080  last_data_time: 0.0063   lr: 5e-06  max_mem: 2572M
[11/22 21:50:21] d2.utils.events INFO:  eta: 0:45:51  iter: 11239  total_loss: 0.4791  loss_ce: 0.001983  loss_objectness: 0.3656  loss_dice: 0.08379  loss_mask: 0.01605    time: 4.6692  last_time: 0.7670  data_time: 0.0080  last_data_time: 0.0068   lr: 5e-06  max_mem: 2572M
[11/22 21:50:36] d2.utils.events INFO:  eta: 0:45:32  iter: 11259  total_loss: 0.4519  loss_ce: 0.0006942  loss_objectness: 0.3545  loss_dice: 0.07003  loss_mask: 0.01795    time: 4.6622  last_time: 0.7306  data_time: 0.0076  last_data_time: 0.0092   lr: 5e-06  max_mem: 2572M
[11/22 21:50:49] d2.utils.events INFO:  eta: 0:44:54  iter: 11279  total_loss: 0.4958  loss_ce: 0.001877  loss_objectness: 0.379  loss_dice: 0.07228  loss_mask: 0.01747    time: 4.6551  last_time: 0.6343  data_time: 0.0078  last_data_time: 0.0063   lr: 5e-06  max_mem: 2572M
[11/22 21:51:01] d2.utils.events INFO:  eta: 0:43:59  iter: 11299  total_loss: 0.4777  loss_ce: 0.001609  loss_objectness: 0.3834  loss_dice: 0.08305  loss_mask: 0.01558    time: 4.6480  last_time: 0.6463  data_time: 0.0078  last_data_time: 0.0088   lr: 5e-06  max_mem: 2572M
[11/22 21:51:14] d2.utils.events INFO:  eta: 0:41:53  iter: 11319  total_loss: 0.4946  loss_ce: 0.001189  loss_objectness: 0.375  loss_dice: 0.06913  loss_mask: 0.01832    time: 4.6409  last_time: 0.6592  data_time: 0.0078  last_data_time: 0.0067   lr: 5e-06  max_mem: 2572M
[11/22 21:51:27] d2.utils.events INFO:  eta: 0:40:40  iter: 11339  total_loss: 0.4549  loss_ce: 0.001527  loss_objectness: 0.3481  loss_dice: 0.07373  loss_mask: 0.01598    time: 4.6338  last_time: 0.6407  data_time: 0.0087  last_data_time: 0.0080   lr: 5e-06  max_mem: 2572M
[11/22 21:51:40] d2.utils.events INFO:  eta: 0:40:13  iter: 11359  total_loss: 0.4642  loss_ce: 0.002574  loss_objectness: 0.365  loss_dice: 0.07224  loss_mask: 0.01667    time: 4.6268  last_time: 0.6365  data_time: 0.0091  last_data_time: 0.0070   lr: 5e-06  max_mem: 2572M
[11/22 21:51:53] d2.utils.events INFO:  eta: 0:39:55  iter: 11379  total_loss: 0.4839  loss_ce: 0.001124  loss_objectness: 0.3744  loss_dice: 0.0797  loss_mask: 0.01612    time: 4.6198  last_time: 0.6540  data_time: 0.0076  last_data_time: 0.0074   lr: 5e-06  max_mem: 2572M
[11/22 21:52:06] d2.utils.events INFO:  eta: 0:39:39  iter: 11399  total_loss: 0.45  loss_ce: 0.0008448  loss_objectness: 0.3577  loss_dice: 0.07119  loss_mask: 0.01592    time: 4.6129  last_time: 0.7081  data_time: 0.0073  last_data_time: 0.0049   lr: 5e-06  max_mem: 2572M
[11/22 21:52:21] d2.utils.events INFO:  eta: 0:39:26  iter: 11419  total_loss: 0.4989  loss_ce: 0.002493  loss_objectness: 0.3791  loss_dice: 0.07911  loss_mask: 0.01616    time: 4.6061  last_time: 0.7713  data_time: 0.0080  last_data_time: 0.0103   lr: 5e-06  max_mem: 2572M
[11/22 21:52:37] d2.utils.events INFO:  eta: 0:39:13  iter: 11439  total_loss: 0.4827  loss_ce: 0.001426  loss_objectness: 0.3874  loss_dice: 0.06901  loss_mask: 0.01617    time: 4.5994  last_time: 0.7957  data_time: 0.0090  last_data_time: 0.0065   lr: 5e-06  max_mem: 2572M
[11/22 21:52:52] d2.utils.events INFO:  eta: 0:39:00  iter: 11459  total_loss: 0.5009  loss_ce: 0.002547  loss_objectness: 0.3756  loss_dice: 0.08128  loss_mask: 0.01685    time: 4.5927  last_time: 0.7795  data_time: 0.0076  last_data_time: 0.0061   lr: 5e-06  max_mem: 2572M
[11/22 21:53:08] d2.utils.events INFO:  eta: 0:38:46  iter: 11479  total_loss: 0.4164  loss_ce: 0.0006  loss_objectness: 0.3371  loss_dice: 0.06757  loss_mask: 0.01656    time: 4.5861  last_time: 0.7524  data_time: 0.0077  last_data_time: 0.0079   lr: 5e-06  max_mem: 2572M
[11/22 21:53:23] d2.utils.events INFO:  eta: 0:38:33  iter: 11499  total_loss: 0.4637  loss_ce: 0.001696  loss_objectness: 0.3742  loss_dice: 0.08041  loss_mask: 0.01568    time: 4.5794  last_time: 0.7566  data_time: 0.0077  last_data_time: 0.0082   lr: 5e-06  max_mem: 2572M
[11/22 21:53:38] d2.utils.events INFO:  eta: 0:38:20  iter: 11519  total_loss: 0.4697  loss_ce: 0.0009551  loss_objectness: 0.3682  loss_dice: 0.07113  loss_mask: 0.01636    time: 4.5728  last_time: 0.7762  data_time: 0.0076  last_data_time: 0.0073   lr: 5e-06  max_mem: 2572M
[11/22 21:53:54] d2.utils.events INFO:  eta: 0:38:07  iter: 11539  total_loss: 0.4579  loss_ce: 0.001841  loss_objectness: 0.3497  loss_dice: 0.07843  loss_mask: 0.01753    time: 4.5662  last_time: 0.7669  data_time: 0.0080  last_data_time: 0.0081   lr: 5e-06  max_mem: 2572M
[11/22 21:54:09] d2.utils.events INFO:  eta: 0:37:53  iter: 11559  total_loss: 0.4328  loss_ce: 0.0005898  loss_objectness: 0.3521  loss_dice: 0.06702  loss_mask: 0.01641    time: 4.5597  last_time: 0.7810  data_time: 0.0078  last_data_time: 0.0061   lr: 5e-06  max_mem: 2572M
[11/22 21:54:25] d2.utils.events INFO:  eta: 0:37:42  iter: 11579  total_loss: 0.4545  loss_ce: 0.00128  loss_objectness: 0.352  loss_dice: 0.07545  loss_mask: 0.01528    time: 4.5531  last_time: 0.7739  data_time: 0.0080  last_data_time: 0.0059   lr: 5e-06  max_mem: 2572M
[11/22 21:54:41] d2.utils.events INFO:  eta: 0:37:33  iter: 11599  total_loss: 0.486  loss_ce: 0.001867  loss_objectness: 0.3836  loss_dice: 0.07709  loss_mask: 0.01581    time: 4.5466  last_time: 0.7884  data_time: 0.0075  last_data_time: 0.0068   lr: 5e-06  max_mem: 2572M
[11/22 21:54:56] d2.utils.events INFO:  eta: 0:37:33  iter: 11619  total_loss: 0.4948  loss_ce: 0.002399  loss_objectness: 0.363  loss_dice: 0.0887  loss_mask: 0.01494    time: 4.5401  last_time: 0.8092  data_time: 0.0085  last_data_time: 0.0071   lr: 5e-06  max_mem: 2572M
[11/22 21:55:12] d2.utils.events INFO:  eta: 0:38:48  iter: 11639  total_loss: 0.4314  loss_ce: 0.001334  loss_objectness: 0.3294  loss_dice: 0.07486  loss_mask: 0.01588    time: 4.5337  last_time: 0.7708  data_time: 0.0079  last_data_time: 0.0114   lr: 5e-06  max_mem: 2572M
[11/22 21:55:27] d2.utils.events INFO:  eta: 0:39:45  iter: 11659  total_loss: 0.4665  loss_ce: 0.004114  loss_objectness: 0.3617  loss_dice: 0.08016  loss_mask: 0.01722    time: 4.5272  last_time: 0.7623  data_time: 0.0076  last_data_time: 0.0082   lr: 5e-06  max_mem: 2572M
[11/22 21:55:42] d2.utils.events INFO:  eta: 0:40:20  iter: 11679  total_loss: 0.4676  loss_ce: 0.001267  loss_objectness: 0.3573  loss_dice: 0.07329  loss_mask: 0.01719    time: 4.5208  last_time: 0.7547  data_time: 0.0078  last_data_time: 0.0081   lr: 5e-06  max_mem: 2572M
[11/22 21:55:57] d2.utils.events INFO:  eta: 0:40:25  iter: 11699  total_loss: 0.4215  loss_ce: 0.0006947  loss_objectness: 0.3312  loss_dice: 0.06841  loss_mask: 0.01732    time: 4.5143  last_time: 0.7776  data_time: 0.0075  last_data_time: 0.0079   lr: 5e-06  max_mem: 2572M
[11/22 21:56:13] d2.utils.events INFO:  eta: 0:40:29  iter: 11719  total_loss: 0.4783  loss_ce: 0.000414  loss_objectness: 0.3713  loss_dice: 0.07356  loss_mask: 0.01596    time: 4.5079  last_time: 0.7620  data_time: 0.0079  last_data_time: 0.0069   lr: 5e-06  max_mem: 2572M
[11/22 21:56:28] d2.utils.events INFO:  eta: 0:40:26  iter: 11739  total_loss: 0.4594  loss_ce: 0.001172  loss_objectness: 0.3583  loss_dice: 0.07561  loss_mask: 0.01648    time: 4.5015  last_time: 0.7600  data_time: 0.0071  last_data_time: 0.0081   lr: 5e-06  max_mem: 2572M
[11/22 21:56:40] d2.utils.events INFO:  eta: 0:40:11  iter: 11759  total_loss: 0.4835  loss_ce: 0.003509  loss_objectness: 0.3815  loss_dice: 0.08756  loss_mask: 0.01644    time: 4.4949  last_time: 0.6451  data_time: 0.0076  last_data_time: 0.0077   lr: 5e-06  max_mem: 2572M
[11/22 21:56:53] d2.utils.events INFO:  eta: 0:39:56  iter: 11779  total_loss: 0.4219  loss_ce: 0.0009678  loss_objectness: 0.34  loss_dice: 0.06155  loss_mask: 0.01578    time: 4.4884  last_time: 0.6684  data_time: 0.0076  last_data_time: 0.0079   lr: 5e-06  max_mem: 2572M
[11/22 21:57:06] d2.utils.events INFO:  eta: 0:39:42  iter: 11799  total_loss: 0.4388  loss_ce: 0.001149  loss_objectness: 0.3541  loss_dice: 0.0707  loss_mask: 0.01542    time: 4.4819  last_time: 0.6394  data_time: 0.0074  last_data_time: 0.0064   lr: 5e-06  max_mem: 2572M
[11/22 21:57:19] d2.utils.events INFO:  eta: 0:39:27  iter: 11819  total_loss: 0.4667  loss_ce: 0.0008229  loss_objectness: 0.3641  loss_dice: 0.08091  loss_mask: 0.01718    time: 4.4754  last_time: 0.6436  data_time: 0.0075  last_data_time: 0.0081   lr: 5e-06  max_mem: 2572M
[11/22 21:57:32] d2.utils.events INFO:  eta: 0:39:12  iter: 11839  total_loss: 0.4627  loss_ce: 0.00103  loss_objectness: 0.3661  loss_dice: 0.06857  loss_mask: 0.01465    time: 4.4689  last_time: 0.6546  data_time: 0.0081  last_data_time: 0.0070   lr: 5e-06  max_mem: 2572M
[11/22 21:57:45] d2.utils.events INFO:  eta: 0:38:57  iter: 11859  total_loss: 0.4951  loss_ce: 0.0009307  loss_objectness: 0.3367  loss_dice: 0.0686  loss_mask: 0.01712    time: 4.4625  last_time: 0.6573  data_time: 0.0077  last_data_time: 0.0070   lr: 5e-06  max_mem: 2572M
[11/22 21:57:58] d2.utils.events INFO:  eta: 0:38:42  iter: 11879  total_loss: 0.4365  loss_ce: 0.0005929  loss_objectness: 0.3455  loss_dice: 0.07099  loss_mask: 0.01637    time: 4.4561  last_time: 0.6470  data_time: 0.0079  last_data_time: 0.0080   lr: 5e-06  max_mem: 2572M
[11/22 21:58:11] d2.utils.events INFO:  eta: 0:38:27  iter: 11899  total_loss: 0.4293  loss_ce: 0.001235  loss_objectness: 0.36  loss_dice: 0.06106  loss_mask: 0.01346    time: 4.4497  last_time: 0.6241  data_time: 0.0078  last_data_time: 0.0074   lr: 5e-06  max_mem: 2572M
[11/22 21:58:24] d2.utils.events INFO:  eta: 0:38:12  iter: 11919  total_loss: 0.446  loss_ce: 0.0006631  loss_objectness: 0.3672  loss_dice: 0.07223  loss_mask: 0.01563    time: 4.4433  last_time: 0.6451  data_time: 0.0095  last_data_time: 0.0051   lr: 5e-06  max_mem: 2572M
[11/22 21:58:37] d2.utils.events INFO:  eta: 0:37:57  iter: 11939  total_loss: 0.4356  loss_ce: 0.0007806  loss_objectness: 0.3372  loss_dice: 0.06612  loss_mask: 0.01636    time: 4.4369  last_time: 0.6481  data_time: 0.0071  last_data_time: 0.0070   lr: 5e-06  max_mem: 2572M
[11/22 21:58:50] d2.utils.events INFO:  eta: 0:37:42  iter: 11959  total_loss: 0.4579  loss_ce: 0.001503  loss_objectness: 0.3602  loss_dice: 0.08082  loss_mask: 0.01489    time: 4.4306  last_time: 0.6477  data_time: 0.0078  last_data_time: 0.0087   lr: 5e-06  max_mem: 2572M
[11/22 21:59:03] d2.utils.events INFO:  eta: 0:37:28  iter: 11979  total_loss: 0.4584  loss_ce: 0.000809  loss_objectness: 0.3535  loss_dice: 0.06764  loss_mask: 0.01526    time: 4.4242  last_time: 0.6519  data_time: 0.0081  last_data_time: 0.0080   lr: 5e-06  max_mem: 2572M
[11/22 21:59:17] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 21:59:17] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 21:59:17] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 21:59:17] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 21:59:17] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 21:59:17] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 21:59:25] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0006 s/iter. Inference: 0.0446 s/iter. Eval: 0.0176 s/iter. Total: 0.0628 s/iter. ETA=0:00:06
[11/22 21:59:30] d2.evaluation.evaluator INFO: Inference done 78/120. Dataloading: 0.0007 s/iter. Inference: 0.0506 s/iter. Eval: 0.0227 s/iter. Total: 0.0740 s/iter. ETA=0:00:03
[11/22 21:59:35] d2.evaluation.evaluator INFO: Total inference time: 0:00:10.405788 (0.090485 s / iter per device, on 1 devices)
[11/22 21:59:35] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.052122 s / iter per device, on 1 devices)
[11/22 21:59:35] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 21:59:35] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 21:59:35] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 21:59:35] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 21:59:35] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.05 seconds.
[11/22 21:59:35] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 21:59:35] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 21:59:35] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.817 | 13.459 | 7.114  | 0.053 | 13.640 | 51.427 |
[11/22 21:59:35] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 21:59:35] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 21:59:35] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 21:59:35] d2.evaluation.testing INFO: copypaste: 6.8166,13.4595,7.1140,0.0531,13.6404,51.4266
[11/22 21:59:35] d2.utils.events INFO:  eta: 0:37:17  iter: 11999  total_loss: 0.4433  loss_ce: 0.0004623  loss_objectness: 0.3446  loss_dice: 0.0627  loss_mask: 0.01634    time: 4.4181  last_time: 0.7227  data_time: 0.0071  last_data_time: 0.0072   lr: 5e-06  max_mem: 2572M
[11/22 21:59:51] d2.utils.events INFO:  eta: 0:37:06  iter: 12019  total_loss: 0.4807  loss_ce: 0.001606  loss_objectness: 0.3665  loss_dice: 0.07705  loss_mask: 0.01728    time: 4.4121  last_time: 0.8154  data_time: 0.0090  last_data_time: 0.0090   lr: 5e-06  max_mem: 2572M
[11/22 22:00:07] d2.utils.events INFO:  eta: 0:36:52  iter: 12039  total_loss: 0.4508  loss_ce: 0.0004509  loss_objectness: 0.3552  loss_dice: 0.07119  loss_mask: 0.01865    time: 4.4060  last_time: 0.7491  data_time: 0.0084  last_data_time: 0.0080   lr: 5e-06  max_mem: 2572M
[11/22 22:00:22] d2.utils.events INFO:  eta: 0:36:37  iter: 12059  total_loss: 0.4282  loss_ce: 0.0006227  loss_objectness: 0.3205  loss_dice: 0.07474  loss_mask: 0.01648    time: 4.4000  last_time: 0.7985  data_time: 0.0083  last_data_time: 0.0085   lr: 5e-06  max_mem: 2572M
[11/22 22:00:38] d2.utils.events INFO:  eta: 0:36:23  iter: 12079  total_loss: 0.4268  loss_ce: 0.0007069  loss_objectness: 0.3435  loss_dice: 0.06169  loss_mask: 0.0143    time: 4.3940  last_time: 0.7629  data_time: 0.0086  last_data_time: 0.0073   lr: 5e-06  max_mem: 2572M
[11/22 22:00:53] d2.utils.events INFO:  eta: 0:36:07  iter: 12099  total_loss: 0.4875  loss_ce: 0.0005352  loss_objectness: 0.372  loss_dice: 0.0739  loss_mask: 0.01643    time: 4.3880  last_time: 0.7889  data_time: 0.0083  last_data_time: 0.0072   lr: 5e-06  max_mem: 2572M
[11/22 22:01:09] d2.utils.events INFO:  eta: 0:35:53  iter: 12119  total_loss: 0.4441  loss_ce: 0.00103  loss_objectness: 0.3458  loss_dice: 0.07723  loss_mask: 0.0146    time: 4.3821  last_time: 0.7640  data_time: 0.0083  last_data_time: 0.0066   lr: 5e-06  max_mem: 2572M
[11/22 22:01:24] d2.utils.events INFO:  eta: 0:35:45  iter: 12139  total_loss: 0.4201  loss_ce: 0.0006374  loss_objectness: 0.3295  loss_dice: 0.06113  loss_mask: 0.01543    time: 4.3761  last_time: 0.8015  data_time: 0.0083  last_data_time: 0.0085   lr: 5e-06  max_mem: 2572M
[11/22 22:01:40] d2.utils.events INFO:  eta: 0:35:31  iter: 12159  total_loss: 0.4402  loss_ce: 0.0005167  loss_objectness: 0.3524  loss_dice: 0.06751  loss_mask: 0.01528    time: 4.3702  last_time: 0.8008  data_time: 0.0078  last_data_time: 0.0076   lr: 5e-06  max_mem: 2572M
[11/22 22:01:56] d2.utils.events INFO:  eta: 0:35:16  iter: 12179  total_loss: 0.4533  loss_ce: 0.00153  loss_objectness: 0.3574  loss_dice: 0.07074  loss_mask: 0.01357    time: 4.3643  last_time: 0.7807  data_time: 0.0087  last_data_time: 0.0077   lr: 5e-06  max_mem: 2572M
[11/22 22:02:11] d2.utils.events INFO:  eta: 0:35:00  iter: 12199  total_loss: 0.4063  loss_ce: 0.000163  loss_objectness: 0.3262  loss_dice: 0.0597  loss_mask: 0.01477    time: 4.3585  last_time: 0.8149  data_time: 0.0081  last_data_time: 0.0102   lr: 5e-06  max_mem: 2572M
[11/22 22:02:27] d2.utils.events INFO:  eta: 0:34:48  iter: 12219  total_loss: 0.4184  loss_ce: 0.0004814  loss_objectness: 0.3205  loss_dice: 0.07334  loss_mask: 0.01573    time: 4.3526  last_time: 0.7911  data_time: 0.0078  last_data_time: 0.0076   lr: 5e-06  max_mem: 2572M
[11/22 22:02:43] d2.utils.events INFO:  eta: 0:34:34  iter: 12239  total_loss: 0.4064  loss_ce: 0.0007906  loss_objectness: 0.3151  loss_dice: 0.07592  loss_mask: 0.01632    time: 4.3468  last_time: 0.7928  data_time: 0.0078  last_data_time: 0.0072   lr: 5e-06  max_mem: 2572M
[11/22 22:02:59] d2.utils.events INFO:  eta: 0:34:22  iter: 12259  total_loss: 0.4019  loss_ce: 0.0005376  loss_objectness: 0.3252  loss_dice: 0.06361  loss_mask: 0.01547    time: 4.3410  last_time: 0.7836  data_time: 0.0081  last_data_time: 0.0083   lr: 5e-06  max_mem: 2572M
[11/22 22:03:14] d2.utils.events INFO:  eta: 0:34:16  iter: 12279  total_loss: 0.4294  loss_ce: 0.0007054  loss_objectness: 0.3379  loss_dice: 0.07559  loss_mask: 0.01532    time: 4.3352  last_time: 0.7818  data_time: 0.0078  last_data_time: 0.0121   lr: 5e-06  max_mem: 2572M
[11/22 22:03:30] d2.utils.events INFO:  eta: 0:34:09  iter: 12299  total_loss: 0.4689  loss_ce: 0.0005673  loss_objectness: 0.3528  loss_dice: 0.07795  loss_mask: 0.01712    time: 4.3294  last_time: 0.7773  data_time: 0.0081  last_data_time: 0.0059   lr: 5e-06  max_mem: 2572M
[11/22 22:03:45] d2.utils.events INFO:  eta: 0:33:59  iter: 12319  total_loss: 0.4324  loss_ce: 0.0004928  loss_objectness: 0.314  loss_dice: 0.06656  loss_mask: 0.01365    time: 4.3236  last_time: 0.7447  data_time: 0.0078  last_data_time: 0.0082   lr: 5e-06  max_mem: 2572M
[11/22 22:04:00] d2.utils.events INFO:  eta: 0:33:47  iter: 12339  total_loss: 0.436  loss_ce: 0.001117  loss_objectness: 0.3348  loss_dice: 0.07553  loss_mask: 0.01574    time: 4.3178  last_time: 0.7620  data_time: 0.0079  last_data_time: 0.0073   lr: 5e-06  max_mem: 2572M
[11/22 22:04:15] d2.utils.events INFO:  eta: 0:33:32  iter: 12359  total_loss: 0.4438  loss_ce: 0.0003797  loss_objectness: 0.3379  loss_dice: 0.06674  loss_mask: 0.01463    time: 4.3121  last_time: 0.7529  data_time: 0.0075  last_data_time: 0.0083   lr: 5e-06  max_mem: 2572M
[11/22 22:04:29] d2.utils.events INFO:  eta: 0:33:17  iter: 12379  total_loss: 0.4377  loss_ce: 0.0006034  loss_objectness: 0.3713  loss_dice: 0.05535  loss_mask: 0.01351    time: 4.3062  last_time: 0.6410  data_time: 0.0077  last_data_time: 0.0065   lr: 5e-06  max_mem: 2572M
[11/22 22:04:42] d2.utils.events INFO:  eta: 0:33:02  iter: 12399  total_loss: 0.4603  loss_ce: 0.0004292  loss_objectness: 0.3434  loss_dice: 0.06492  loss_mask: 0.01726    time: 4.3003  last_time: 0.6508  data_time: 0.0074  last_data_time: 0.0094   lr: 5e-06  max_mem: 2572M
[11/22 22:04:55] d2.utils.events INFO:  eta: 0:32:46  iter: 12419  total_loss: 0.432  loss_ce: 0.0007984  loss_objectness: 0.3369  loss_dice: 0.06689  loss_mask: 0.01616    time: 4.2944  last_time: 0.6231  data_time: 0.0078  last_data_time: 0.0091   lr: 5e-06  max_mem: 2572M
[11/22 22:05:08] d2.utils.events INFO:  eta: 0:32:27  iter: 12439  total_loss: 0.4219  loss_ce: 0.0001712  loss_objectness: 0.3365  loss_dice: 0.06802  loss_mask: 0.01357    time: 4.2886  last_time: 0.6782  data_time: 0.0078  last_data_time: 0.0092   lr: 5e-06  max_mem: 2572M
[11/22 22:05:21] d2.utils.events INFO:  eta: 0:32:08  iter: 12459  total_loss: 0.4579  loss_ce: 0.001068  loss_objectness: 0.3511  loss_dice: 0.07213  loss_mask: 0.01449    time: 4.2827  last_time: 0.6597  data_time: 0.0079  last_data_time: 0.0072   lr: 5e-06  max_mem: 2572M
[11/22 22:05:34] d2.utils.events INFO:  eta: 0:31:44  iter: 12479  total_loss: 0.4255  loss_ce: 0.0003709  loss_objectness: 0.3278  loss_dice: 0.0677  loss_mask: 0.01433    time: 4.2769  last_time: 0.6552  data_time: 0.0077  last_data_time: 0.0078   lr: 5e-06  max_mem: 2572M
[11/22 22:05:47] d2.utils.events INFO:  eta: 0:31:22  iter: 12499  total_loss: 0.4267  loss_ce: 0.0006888  loss_objectness: 0.3329  loss_dice: 0.0727  loss_mask: 0.01563    time: 4.2711  last_time: 0.6580  data_time: 0.0078  last_data_time: 0.0102   lr: 5e-06  max_mem: 2572M
[11/22 22:06:02] d2.utils.events INFO:  eta: 0:31:06  iter: 12519  total_loss: 0.4041  loss_ce: 0.0003804  loss_objectness: 0.3132  loss_dice: 0.05998  loss_mask: 0.01524    time: 4.2654  last_time: 0.7742  data_time: 0.0073  last_data_time: 0.0061   lr: 5e-06  max_mem: 2572M
[11/22 22:06:18] d2.utils.events INFO:  eta: 0:30:54  iter: 12539  total_loss: 0.425  loss_ce: 0.0003497  loss_objectness: 0.334  loss_dice: 0.06623  loss_mask: 0.0147    time: 4.2599  last_time: 0.8063  data_time: 0.0072  last_data_time: 0.0064   lr: 5e-06  max_mem: 2572M
[11/22 22:06:33] d2.utils.events INFO:  eta: 0:30:37  iter: 12559  total_loss: 0.4547  loss_ce: 0.0005177  loss_objectness: 0.3586  loss_dice: 0.0702  loss_mask: 0.01599    time: 4.2544  last_time: 0.8104  data_time: 0.0073  last_data_time: 0.0082   lr: 5e-06  max_mem: 2572M
[11/22 22:06:49] d2.utils.events INFO:  eta: 0:30:23  iter: 12579  total_loss: 0.4075  loss_ce: 0.0009443  loss_objectness: 0.3109  loss_dice: 0.06088  loss_mask: 0.01562    time: 4.2489  last_time: 0.8168  data_time: 0.0076  last_data_time: 0.0077   lr: 5e-06  max_mem: 2572M
[11/22 22:07:05] d2.utils.events INFO:  eta: 0:30:10  iter: 12599  total_loss: 0.4425  loss_ce: 0.0004996  loss_objectness: 0.3525  loss_dice: 0.06974  loss_mask: 0.01447    time: 4.2434  last_time: 0.8174  data_time: 0.0071  last_data_time: 0.0059   lr: 5e-06  max_mem: 2572M
[11/22 22:07:22] d2.utils.events INFO:  eta: 0:29:55  iter: 12619  total_loss: 0.4341  loss_ce: 0.000447  loss_objectness: 0.335  loss_dice: 0.06587  loss_mask: 0.01549    time: 4.2380  last_time: 0.8111  data_time: 0.0078  last_data_time: 0.0102   lr: 5e-06  max_mem: 2572M
[11/22 22:07:38] d2.utils.events INFO:  eta: 0:29:40  iter: 12639  total_loss: 0.4396  loss_ce: 0.0006203  loss_objectness: 0.3466  loss_dice: 0.06559  loss_mask: 0.01626    time: 4.2325  last_time: 0.8168  data_time: 0.0082  last_data_time: 0.0075   lr: 5e-06  max_mem: 2572M
[11/22 22:07:54] d2.utils.events INFO:  eta: 0:29:26  iter: 12659  total_loss: 0.4708  loss_ce: 0.000729  loss_objectness: 0.3648  loss_dice: 0.07417  loss_mask: 0.01563    time: 4.2271  last_time: 0.8115  data_time: 0.0080  last_data_time: 0.0084   lr: 5e-06  max_mem: 2572M
[11/22 22:08:10] d2.utils.events INFO:  eta: 0:29:14  iter: 12679  total_loss: 0.4537  loss_ce: 0.0008063  loss_objectness: 0.3348  loss_dice: 0.07312  loss_mask: 0.01473    time: 4.2217  last_time: 0.7856  data_time: 0.0079  last_data_time: 0.0085   lr: 5e-06  max_mem: 2572M
[11/22 22:08:27] d2.utils.events INFO:  eta: 0:29:04  iter: 12699  total_loss: 0.3878  loss_ce: 0.000333  loss_objectness: 0.3165  loss_dice: 0.05573  loss_mask: 0.01437    time: 4.2164  last_time: 0.7818  data_time: 0.0076  last_data_time: 0.0073   lr: 5e-06  max_mem: 2572M
[11/22 22:08:43] d2.utils.events INFO:  eta: 0:28:52  iter: 12719  total_loss: 0.4322  loss_ce: 0.0004829  loss_objectness: 0.3495  loss_dice: 0.06845  loss_mask: 0.01504    time: 4.2110  last_time: 0.8211  data_time: 0.0081  last_data_time: 0.0066   lr: 5e-06  max_mem: 2572M
[11/22 22:08:59] d2.utils.events INFO:  eta: 0:28:42  iter: 12739  total_loss: 0.4196  loss_ce: 0.0002735  loss_objectness: 0.3388  loss_dice: 0.07012  loss_mask: 0.01473    time: 4.2057  last_time: 0.8349  data_time: 0.0079  last_data_time: 0.0070   lr: 5e-06  max_mem: 2572M
[11/22 22:09:15] d2.utils.events INFO:  eta: 0:28:34  iter: 12759  total_loss: 0.436  loss_ce: 0.001701  loss_objectness: 0.3365  loss_dice: 0.06829  loss_mask: 0.01501    time: 4.2004  last_time: 0.8238  data_time: 0.0076  last_data_time: 0.0064   lr: 5e-06  max_mem: 2572M
[11/22 22:09:32] d2.utils.events INFO:  eta: 0:28:27  iter: 12779  total_loss: 0.4458  loss_ce: 0.0003107  loss_objectness: 0.3239  loss_dice: 0.06605  loss_mask: 0.01528    time: 4.1951  last_time: 0.8167  data_time: 0.0078  last_data_time: 0.0084   lr: 5e-06  max_mem: 2572M
[11/22 22:09:48] d2.utils.events INFO:  eta: 0:28:18  iter: 12799  total_loss: 0.3967  loss_ce: 0.0001778  loss_objectness: 0.3178  loss_dice: 0.06066  loss_mask: 0.01363    time: 4.1898  last_time: 0.8238  data_time: 0.0081  last_data_time: 0.0088   lr: 5e-06  max_mem: 2572M
[11/22 22:10:04] d2.utils.events INFO:  eta: 0:28:08  iter: 12819  total_loss: 0.4332  loss_ce: 0.0001509  loss_objectness: 0.3379  loss_dice: 0.05681  loss_mask: 0.01624    time: 4.1845  last_time: 0.7875  data_time: 0.0075  last_data_time: 0.0092   lr: 5e-06  max_mem: 2572M
[11/22 22:10:20] d2.utils.events INFO:  eta: 0:28:00  iter: 12839  total_loss: 0.4329  loss_ce: 0.001114  loss_objectness: 0.3379  loss_dice: 0.07085  loss_mask: 0.01552    time: 4.1793  last_time: 0.8186  data_time: 0.0076  last_data_time: 0.0086   lr: 5e-06  max_mem: 2572M
[11/22 22:10:36] d2.utils.events INFO:  eta: 0:27:49  iter: 12859  total_loss: 0.434  loss_ce: 0.0007599  loss_objectness: 0.3256  loss_dice: 0.06657  loss_mask: 0.01673    time: 4.1740  last_time: 0.7922  data_time: 0.0080  last_data_time: 0.0089   lr: 5e-06  max_mem: 2572M
[11/22 22:10:51] d2.utils.events INFO:  eta: 0:27:36  iter: 12879  total_loss: 0.4708  loss_ce: 0.0004004  loss_objectness: 0.3319  loss_dice: 0.07104  loss_mask: 0.01434    time: 4.1687  last_time: 0.6505  data_time: 0.0077  last_data_time: 0.0089   lr: 5e-06  max_mem: 2572M
[11/22 22:11:04] d2.utils.events INFO:  eta: 0:27:20  iter: 12899  total_loss: 0.4076  loss_ce: 0.0002156  loss_objectness: 0.3181  loss_dice: 0.06071  loss_mask: 0.01403    time: 4.1632  last_time: 0.6286  data_time: 0.0080  last_data_time: 0.0083   lr: 5e-06  max_mem: 2572M
[11/22 22:11:17] d2.utils.events INFO:  eta: 0:27:05  iter: 12919  total_loss: 0.4219  loss_ce: 0.0008933  loss_objectness: 0.3341  loss_dice: 0.06325  loss_mask: 0.01443    time: 4.1578  last_time: 0.6611  data_time: 0.0075  last_data_time: 0.0081   lr: 5e-06  max_mem: 2572M
[11/22 22:11:30] d2.utils.events INFO:  eta: 0:26:49  iter: 12939  total_loss: 0.4514  loss_ce: 0.0004882  loss_objectness: 0.351  loss_dice: 0.07017  loss_mask: 0.01427    time: 4.1523  last_time: 0.6348  data_time: 0.0084  last_data_time: 0.0079   lr: 5e-06  max_mem: 2572M
[11/22 22:11:43] d2.utils.events INFO:  eta: 0:26:34  iter: 12959  total_loss: 0.3905  loss_ce: 0.0004189  loss_objectness: 0.3183  loss_dice: 0.05936  loss_mask: 0.01373    time: 4.1469  last_time: 0.6539  data_time: 0.0078  last_data_time: 0.0080   lr: 5e-06  max_mem: 2572M
[11/22 22:11:58] d2.utils.events INFO:  eta: 0:26:18  iter: 12979  total_loss: 0.4136  loss_ce: 0.0003742  loss_objectness: 0.3322  loss_dice: 0.06142  loss_mask: 0.0139    time: 4.1417  last_time: 0.7599  data_time: 0.0074  last_data_time: 0.0063   lr: 5e-06  max_mem: 2572M
[11/22 22:12:13] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 22:12:13] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 22:12:13] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 22:12:13] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 22:12:13] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 22:12:13] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 22:12:20] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0004 s/iter. Inference: 0.0422 s/iter. Eval: 0.0106 s/iter. Total: 0.0532 s/iter. ETA=0:00:05
[11/22 22:12:25] d2.evaluation.evaluator INFO: Inference done 83/120. Dataloading: 0.0006 s/iter. Inference: 0.0498 s/iter. Eval: 0.0182 s/iter. Total: 0.0687 s/iter. ETA=0:00:02
[11/22 22:12:30] d2.evaluation.evaluator INFO: Total inference time: 0:00:09.827632 (0.085458 s / iter per device, on 1 devices)
[11/22 22:12:30] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:06 (0.052219 s / iter per device, on 1 devices)
[11/22 22:12:30] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 22:12:30] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 22:12:30] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 22:12:30] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 22:12:30] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.04 seconds.
[11/22 22:12:30] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 22:12:30] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[11/22 22:12:30] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.401 | 13.146 | 6.736  | 0.055 | 12.733 | 51.688 |
[11/22 22:12:30] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 22:12:30] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 22:12:30] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 22:12:30] d2.evaluation.testing INFO: copypaste: 6.4006,13.1459,6.7363,0.0555,12.7326,51.6878
[11/22 22:12:30] d2.utils.events INFO:  eta: 0:26:03  iter: 12999  total_loss: 0.41  loss_ce: 0.0002392  loss_objectness: 0.3282  loss_dice: 0.06023  loss_mask: 0.01588    time: 4.1365  last_time: 0.7811  data_time: 0.0079  last_data_time: 0.0064   lr: 5e-06  max_mem: 2572M
[11/22 22:12:46] d2.utils.events INFO:  eta: 0:25:47  iter: 13019  total_loss: 0.3717  loss_ce: 0.0002872  loss_objectness: 0.2965  loss_dice: 0.05533  loss_mask: 0.01394    time: 4.1313  last_time: 0.7436  data_time: 0.0075  last_data_time: 0.0064   lr: 5e-06  max_mem: 2572M
[11/22 22:13:02] d2.utils.events INFO:  eta: 0:25:33  iter: 13039  total_loss: 0.4422  loss_ce: 0.0005781  loss_objectness: 0.3383  loss_dice: 0.07837  loss_mask: 0.01447    time: 4.1262  last_time: 0.8087  data_time: 0.0075  last_data_time: 0.0077   lr: 5e-06  max_mem: 2572M
[11/22 22:13:18] d2.utils.events INFO:  eta: 0:25:18  iter: 13059  total_loss: 0.4323  loss_ce: 0.0003371  loss_objectness: 0.3415  loss_dice: 0.06581  loss_mask: 0.01348    time: 4.1211  last_time: 0.7766  data_time: 0.0078  last_data_time: 0.0085   lr: 5e-06  max_mem: 2572M
[11/22 22:13:33] d2.utils.events INFO:  eta: 0:25:02  iter: 13079  total_loss: 0.4046  loss_ce: 0.0001714  loss_objectness: 0.3157  loss_dice: 0.06074  loss_mask: 0.0135    time: 4.1160  last_time: 0.7597  data_time: 0.0078  last_data_time: 0.0079   lr: 5e-06  max_mem: 2572M
[11/22 22:13:49] d2.utils.events INFO:  eta: 0:24:48  iter: 13099  total_loss: 0.409  loss_ce: 0.0003746  loss_objectness: 0.3151  loss_dice: 0.06292  loss_mask: 0.01394    time: 4.1109  last_time: 0.7838  data_time: 0.0077  last_data_time: 0.0079   lr: 5e-06  max_mem: 2572M
[11/22 22:14:05] d2.utils.events INFO:  eta: 0:24:33  iter: 13119  total_loss: 0.3923  loss_ce: 0.0004604  loss_objectness: 0.317  loss_dice: 0.06507  loss_mask: 0.01362    time: 4.1059  last_time: 0.8086  data_time: 0.0074  last_data_time: 0.0080   lr: 5e-06  max_mem: 2572M
[11/22 22:14:21] d2.utils.events INFO:  eta: 0:24:19  iter: 13139  total_loss: 0.4255  loss_ce: 0.0002606  loss_objectness: 0.3449  loss_dice: 0.06593  loss_mask: 0.01391    time: 4.1008  last_time: 0.8168  data_time: 0.0078  last_data_time: 0.0097   lr: 5e-06  max_mem: 2572M
[11/22 22:14:36] d2.utils.events INFO:  eta: 0:24:02  iter: 13159  total_loss: 0.4479  loss_ce: 0.0002444  loss_objectness: 0.3439  loss_dice: 0.0642  loss_mask: 0.01375    time: 4.0958  last_time: 0.8030  data_time: 0.0074  last_data_time: 0.0065   lr: 5e-06  max_mem: 2572M
[11/22 22:14:52] d2.utils.events INFO:  eta: 0:23:48  iter: 13179  total_loss: 0.4141  loss_ce: 0.0002734  loss_objectness: 0.3299  loss_dice: 0.06288  loss_mask: 0.01375    time: 4.0908  last_time: 0.8220  data_time: 0.0079  last_data_time: 0.0076   lr: 5e-06  max_mem: 2572M
[11/22 22:15:09] d2.utils.events INFO:  eta: 0:23:33  iter: 13199  total_loss: 0.4352  loss_ce: 0.0006572  loss_objectness: 0.3475  loss_dice: 0.06566  loss_mask: 0.01474    time: 4.0858  last_time: 0.8557  data_time: 0.0079  last_data_time: 0.0080   lr: 5e-06  max_mem: 2572M
[11/22 22:15:25] d2.utils.events INFO:  eta: 0:23:18  iter: 13219  total_loss: 0.4288  loss_ce: 0.0003949  loss_objectness: 0.3291  loss_dice: 0.05627  loss_mask: 0.01494    time: 4.0809  last_time: 0.7979  data_time: 0.0078  last_data_time: 0.0069   lr: 5e-06  max_mem: 2572M
[11/22 22:15:41] d2.utils.events INFO:  eta: 0:23:04  iter: 13239  total_loss: 0.3787  loss_ce: 0.0002734  loss_objectness: 0.2963  loss_dice: 0.04972  loss_mask: 0.01329    time: 4.0759  last_time: 0.7951  data_time: 0.0079  last_data_time: 0.0071   lr: 5e-06  max_mem: 2572M
[11/22 22:15:57] d2.utils.events INFO:  eta: 0:22:50  iter: 13259  total_loss: 0.4241  loss_ce: 0.0005102  loss_objectness: 0.3283  loss_dice: 0.06359  loss_mask: 0.01321    time: 4.0710  last_time: 0.8112  data_time: 0.0080  last_data_time: 0.0075   lr: 5e-06  max_mem: 2572M
[11/22 22:16:13] d2.utils.events INFO:  eta: 0:22:34  iter: 13279  total_loss: 0.3825  loss_ce: 0.0002369  loss_objectness: 0.312  loss_dice: 0.05938  loss_mask: 0.01408    time: 4.0660  last_time: 0.7830  data_time: 0.0073  last_data_time: 0.0073   lr: 5e-06  max_mem: 2572M
[11/22 22:16:28] d2.utils.events INFO:  eta: 0:22:18  iter: 13299  total_loss: 0.4314  loss_ce: 0.0003941  loss_objectness: 0.3326  loss_dice: 0.05808  loss_mask: 0.01294    time: 4.0611  last_time: 0.7495  data_time: 0.0078  last_data_time: 0.0069   lr: 5e-06  max_mem: 2572M
[11/22 22:16:44] d2.utils.events INFO:  eta: 0:22:01  iter: 13319  total_loss: 0.3762  loss_ce: 0.0003216  loss_objectness: 0.3099  loss_dice: 0.05471  loss_mask: 0.01497    time: 4.0561  last_time: 0.7508  data_time: 0.0076  last_data_time: 0.0080   lr: 5e-06  max_mem: 2572M
[11/22 22:16:57] d2.utils.events INFO:  eta: 0:21:45  iter: 13339  total_loss: 0.3938  loss_ce: 0.000398  loss_objectness: 0.3147  loss_dice: 0.06603  loss_mask: 0.01308    time: 4.0511  last_time: 0.6486  data_time: 0.0078  last_data_time: 0.0058   lr: 5e-06  max_mem: 2572M
[11/22 22:17:10] d2.utils.events INFO:  eta: 0:21:29  iter: 13359  total_loss: 0.4028  loss_ce: 0.0002442  loss_objectness: 0.3097  loss_dice: 0.06594  loss_mask: 0.01401    time: 4.0460  last_time: 0.6637  data_time: 0.0077  last_data_time: 0.0070   lr: 5e-06  max_mem: 2572M
[11/22 22:17:23] d2.utils.events INFO:  eta: 0:21:14  iter: 13379  total_loss: 0.4162  loss_ce: 0.0004098  loss_objectness: 0.3375  loss_dice: 0.06359  loss_mask: 0.01401    time: 4.0409  last_time: 0.6536  data_time: 0.0078  last_data_time: 0.0090   lr: 5e-06  max_mem: 2572M
[11/22 22:17:36] d2.utils.events INFO:  eta: 0:20:58  iter: 13399  total_loss: 0.4186  loss_ce: 0.0002619  loss_objectness: 0.3235  loss_dice: 0.0705  loss_mask: 0.01456    time: 4.0358  last_time: 0.6511  data_time: 0.0090  last_data_time: 0.0063   lr: 5e-06  max_mem: 2572M
[11/22 22:17:49] d2.utils.events INFO:  eta: 0:20:42  iter: 13419  total_loss: 0.4009  loss_ce: 0.000284  loss_objectness: 0.3116  loss_dice: 0.06368  loss_mask: 0.01313    time: 4.0308  last_time: 0.6507  data_time: 0.0078  last_data_time: 0.0083   lr: 5e-06  max_mem: 2572M
[11/22 22:18:02] d2.utils.events INFO:  eta: 0:20:26  iter: 13439  total_loss: 0.3982  loss_ce: 0.000144  loss_objectness: 0.3114  loss_dice: 0.04942  loss_mask: 0.0121    time: 4.0258  last_time: 0.6447  data_time: 0.0075  last_data_time: 0.0061   lr: 5e-06  max_mem: 2572M
[11/22 22:18:15] d2.utils.events INFO:  eta: 0:20:11  iter: 13459  total_loss: 0.3976  loss_ce: 0.0003673  loss_objectness: 0.3039  loss_dice: 0.05955  loss_mask: 0.01331    time: 4.0208  last_time: 0.6544  data_time: 0.0076  last_data_time: 0.0063   lr: 5e-06  max_mem: 2572M
[11/22 22:18:28] d2.utils.events INFO:  eta: 0:19:55  iter: 13479  total_loss: 0.4225  loss_ce: 0.0006451  loss_objectness: 0.3332  loss_dice: 0.06518  loss_mask: 0.01449    time: 4.0157  last_time: 0.6510  data_time: 0.0076  last_data_time: 0.0081   lr: 5e-06  max_mem: 2572M
[11/22 22:18:41] d2.utils.events INFO:  eta: 0:19:39  iter: 13499  total_loss: 0.4436  loss_ce: 0.0004077  loss_objectness: 0.3395  loss_dice: 0.06135  loss_mask: 0.01285    time: 4.0108  last_time: 0.6459  data_time: 0.0079  last_data_time: 0.0083   lr: 5e-06  max_mem: 2572M
[11/22 22:18:54] d2.utils.events INFO:  eta: 0:19:23  iter: 13519  total_loss: 0.3893  loss_ce: 0.0001508  loss_objectness: 0.3096  loss_dice: 0.05569  loss_mask: 0.0152    time: 4.0058  last_time: 0.6397  data_time: 0.0073  last_data_time: 0.0073   lr: 5e-06  max_mem: 2572M
[11/22 22:19:09] d2.utils.events INFO:  eta: 0:19:04  iter: 13539  total_loss: 0.4266  loss_ce: 0.0004197  loss_objectness: 0.332  loss_dice: 0.06409  loss_mask: 0.01443    time: 4.0009  last_time: 0.7466  data_time: 0.0072  last_data_time: 0.0078   lr: 5e-06  max_mem: 2572M
[11/22 22:19:24] d2.utils.events INFO:  eta: 0:18:47  iter: 13559  total_loss: 0.4081  loss_ce: 0.0002844  loss_objectness: 0.3213  loss_dice: 0.06783  loss_mask: 0.01308    time: 3.9961  last_time: 0.6468  data_time: 0.0079  last_data_time: 0.0074   lr: 5e-06  max_mem: 2572M
[11/22 22:19:37] d2.utils.events INFO:  eta: 0:18:29  iter: 13579  total_loss: 0.3892  loss_ce: 0.0002402  loss_objectness: 0.3133  loss_dice: 0.05085  loss_mask: 0.01251    time: 3.9912  last_time: 0.6496  data_time: 0.0078  last_data_time: 0.0086   lr: 5e-06  max_mem: 2572M
[11/22 22:19:52] d2.utils.events INFO:  eta: 0:18:09  iter: 13599  total_loss: 0.4505  loss_ce: 0.0005184  loss_objectness: 0.3261  loss_dice: 0.07076  loss_mask: 0.01431    time: 3.9864  last_time: 0.7799  data_time: 0.0079  last_data_time: 0.0072   lr: 5e-06  max_mem: 2572M
[11/22 22:20:08] d2.utils.events INFO:  eta: 0:17:51  iter: 13619  total_loss: 0.3782  loss_ce: 0.0002568  loss_objectness: 0.3135  loss_dice: 0.05441  loss_mask: 0.01377    time: 3.9817  last_time: 0.8240  data_time: 0.0080  last_data_time: 0.0068   lr: 5e-06  max_mem: 2572M
[11/22 22:20:24] d2.utils.events INFO:  eta: 0:17:35  iter: 13639  total_loss: 0.426  loss_ce: 0.0002356  loss_objectness: 0.3354  loss_dice: 0.07103  loss_mask: 0.0136    time: 3.9771  last_time: 0.8190  data_time: 0.0082  last_data_time: 0.0076   lr: 5e-06  max_mem: 2572M
[11/22 22:20:40] d2.utils.events INFO:  eta: 0:17:20  iter: 13659  total_loss: 0.4171  loss_ce: 0.0001282  loss_objectness: 0.3412  loss_dice: 0.06192  loss_mask: 0.01523    time: 3.9725  last_time: 0.7769  data_time: 0.0080  last_data_time: 0.0069   lr: 5e-06  max_mem: 2572M
[11/22 22:20:57] d2.utils.events INFO:  eta: 0:17:05  iter: 13679  total_loss: 0.4065  loss_ce: 0.0003861  loss_objectness: 0.325  loss_dice: 0.06157  loss_mask: 0.01233    time: 3.9679  last_time: 0.8105  data_time: 0.0077  last_data_time: 0.0073   lr: 5e-06  max_mem: 2572M
[11/22 22:21:13] d2.utils.events INFO:  eta: 0:16:49  iter: 13699  total_loss: 0.3865  loss_ce: 0.0005732  loss_objectness: 0.3044  loss_dice: 0.05934  loss_mask: 0.01373    time: 3.9633  last_time: 0.8148  data_time: 0.0077  last_data_time: 0.0070   lr: 5e-06  max_mem: 2572M
[11/22 22:21:29] d2.utils.events INFO:  eta: 0:16:33  iter: 13719  total_loss: 0.4038  loss_ce: 0.0002447  loss_objectness: 0.3257  loss_dice: 0.06057  loss_mask: 0.01321    time: 3.9587  last_time: 0.8605  data_time: 0.0075  last_data_time: 0.0061   lr: 5e-06  max_mem: 2572M
[11/22 22:21:46] d2.utils.events INFO:  eta: 0:16:18  iter: 13739  total_loss: 0.4261  loss_ce: 0.0002639  loss_objectness: 0.3114  loss_dice: 0.05948  loss_mask: 0.01401    time: 3.9542  last_time: 0.7980  data_time: 0.0081  last_data_time: 0.0082   lr: 5e-06  max_mem: 2572M
[11/22 22:22:04] d2.utils.events INFO:  eta: 0:16:02  iter: 13759  total_loss: 0.3782  loss_ce: 0.0002691  loss_objectness: 0.3054  loss_dice: 0.05047  loss_mask: 0.01101    time: 3.9497  last_time: 0.9249  data_time: 0.0076  last_data_time: 0.0067   lr: 5e-06  max_mem: 2572M
[11/22 22:22:21] d2.utils.events INFO:  eta: 0:15:47  iter: 13779  total_loss: 0.3938  loss_ce: 0.0006196  loss_objectness: 0.3023  loss_dice: 0.07646  loss_mask: 0.01426    time: 3.9452  last_time: 0.8750  data_time: 0.0082  last_data_time: 0.0086   lr: 5e-06  max_mem: 2572M
[11/22 22:22:38] d2.utils.events INFO:  eta: 0:15:31  iter: 13799  total_loss: 0.4358  loss_ce: 0.0002116  loss_objectness: 0.3065  loss_dice: 0.06947  loss_mask: 0.01321    time: 3.9407  last_time: 0.8593  data_time: 0.0079  last_data_time: 0.0078   lr: 5e-06  max_mem: 2572M
[11/22 22:22:55] d2.utils.events INFO:  eta: 0:15:16  iter: 13819  total_loss: 0.3673  loss_ce: 6.977e-05  loss_objectness: 0.3015  loss_dice: 0.0533  loss_mask: 0.01338    time: 3.9363  last_time: 0.8554  data_time: 0.0078  last_data_time: 0.0066   lr: 5e-06  max_mem: 2572M
[11/22 22:23:13] d2.utils.events INFO:  eta: 0:15:00  iter: 13839  total_loss: 0.3932  loss_ce: 0.0002239  loss_objectness: 0.3063  loss_dice: 0.0622  loss_mask: 0.01231    time: 3.9318  last_time: 0.8725  data_time: 0.0083  last_data_time: 0.0081   lr: 5e-06  max_mem: 2572M
[11/22 22:23:30] d2.utils.events INFO:  eta: 0:14:46  iter: 13859  total_loss: 0.3923  loss_ce: 0.0001896  loss_objectness: 0.3184  loss_dice: 0.05519  loss_mask: 0.01426    time: 3.9274  last_time: 0.9253  data_time: 0.0078  last_data_time: 0.0082   lr: 5e-06  max_mem: 2572M
[11/22 22:23:42] d2.utils.events INFO:  eta: 0:14:29  iter: 13879  total_loss: 0.4142  loss_ce: 0.0005723  loss_objectness: 0.3386  loss_dice: 0.05966  loss_mask: 0.01224    time: 3.9226  last_time: 0.4366  data_time: 0.0067  last_data_time: 0.0054   lr: 5e-06  max_mem: 2572M
[11/22 22:23:51] d2.utils.events INFO:  eta: 0:14:14  iter: 13899  total_loss: 0.3931  loss_ce: 7.959e-05  loss_objectness: 0.319  loss_dice: 0.05209  loss_mask: 0.01393    time: 3.9176  last_time: 0.5524  data_time: 0.0062  last_data_time: 0.0053   lr: 5e-06  max_mem: 2572M
[11/22 22:24:03] d2.utils.events INFO:  eta: 0:13:58  iter: 13919  total_loss: 0.4408  loss_ce: 0.0001889  loss_objectness: 0.339  loss_dice: 0.05855  loss_mask: 0.01323    time: 3.9128  last_time: 0.5644  data_time: 0.0064  last_data_time: 0.0076   lr: 5e-06  max_mem: 2572M
[11/22 22:24:14] d2.utils.events INFO:  eta: 0:13:43  iter: 13939  total_loss: 0.3854  loss_ce: 0.0003459  loss_objectness: 0.3057  loss_dice: 0.06521  loss_mask: 0.01343    time: 3.9080  last_time: 0.5623  data_time: 0.0066  last_data_time: 0.0070   lr: 5e-06  max_mem: 2572M
[11/22 22:24:27] d2.utils.events INFO:  eta: 0:13:28  iter: 13959  total_loss: 0.3907  loss_ce: 0.0003961  loss_objectness: 0.2983  loss_dice: 0.05527  loss_mask: 0.01255    time: 3.9033  last_time: 0.8039  data_time: 0.0077  last_data_time: 0.0066   lr: 5e-06  max_mem: 2572M
[11/22 22:24:43] d2.utils.events INFO:  eta: 0:13:15  iter: 13979  total_loss: 0.4479  loss_ce: 0.001091  loss_objectness: 0.3524  loss_dice: 0.06693  loss_mask: 0.01232    time: 3.8989  last_time: 0.7524  data_time: 0.0079  last_data_time: 0.0078   lr: 5e-06  max_mem: 2572M
[11/22 22:24:58] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 22:24:58] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 22:24:58] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 22:24:58] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 22:24:58] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 22:24:58] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 22:25:06] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0004 s/iter. Inference: 0.0437 s/iter. Eval: 0.0111 s/iter. Total: 0.0553 s/iter. ETA=0:00:06
[11/22 22:25:11] d2.evaluation.evaluator INFO: Inference done 83/120. Dataloading: 0.0007 s/iter. Inference: 0.0502 s/iter. Eval: 0.0180 s/iter. Total: 0.0689 s/iter. ETA=0:00:02
[11/22 22:25:15] d2.evaluation.evaluator INFO: Total inference time: 0:00:09.668812 (0.084077 s / iter per device, on 1 devices)
[11/22 22:25:15] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.050469 s / iter per device, on 1 devices)
[11/22 22:25:15] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 22:25:15] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 22:25:15] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 22:25:15] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 22:25:15] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.04 seconds.
[11/22 22:25:15] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 22:25:15] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/22 22:25:15] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.561 | 12.752 | 7.024  | 0.041 | 12.742 | 51.897 |
[11/22 22:25:15] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 22:25:15] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 22:25:15] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 22:25:15] d2.evaluation.testing INFO: copypaste: 6.5610,12.7524,7.0240,0.0411,12.7420,51.8974
[11/22 22:25:15] d2.utils.events INFO:  eta: 0:13:01  iter: 13999  total_loss: 0.3903  loss_ce: 0.0003651  loss_objectness: 0.3148  loss_dice: 0.06424  loss_mask: 0.013    time: 3.8944  last_time: 0.7902  data_time: 0.0079  last_data_time: 0.0083   lr: 5e-06  max_mem: 2572M
[11/22 22:25:31] d2.utils.events INFO:  eta: 0:12:45  iter: 14019  total_loss: 0.3983  loss_ce: 0.0003133  loss_objectness: 0.3153  loss_dice: 0.05687  loss_mask: 0.01304    time: 3.8900  last_time: 0.7886  data_time: 0.0085  last_data_time: 0.0096   lr: 5e-06  max_mem: 2572M
[11/22 22:25:47] d2.utils.events INFO:  eta: 0:12:29  iter: 14039  total_loss: 0.4035  loss_ce: 0.0004167  loss_objectness: 0.3319  loss_dice: 0.05942  loss_mask: 0.01232    time: 3.8855  last_time: 0.7078  data_time: 0.0085  last_data_time: 0.0106   lr: 5e-06  max_mem: 2572M
[11/22 22:26:01] d2.utils.events INFO:  eta: 0:12:12  iter: 14059  total_loss: 0.4219  loss_ce: 0.0002692  loss_objectness: 0.32  loss_dice: 0.0611  loss_mask: 0.01459    time: 3.8810  last_time: 0.6506  data_time: 0.0085  last_data_time: 0.0117   lr: 5e-06  max_mem: 2572M
[11/22 22:26:15] d2.utils.events INFO:  eta: 0:11:54  iter: 14079  total_loss: 0.4355  loss_ce: 0.0003531  loss_objectness: 0.3431  loss_dice: 0.05946  loss_mask: 0.01235    time: 3.8765  last_time: 0.7340  data_time: 0.0094  last_data_time: 0.0069   lr: 5e-06  max_mem: 2572M
[11/22 22:26:29] d2.utils.events INFO:  eta: 0:11:36  iter: 14099  total_loss: 0.3954  loss_ce: 0.0004081  loss_objectness: 0.3093  loss_dice: 0.06605  loss_mask: 0.01134    time: 3.8720  last_time: 0.7460  data_time: 0.0087  last_data_time: 0.0089   lr: 5e-06  max_mem: 2572M
[11/22 22:26:44] d2.utils.events INFO:  eta: 0:11:17  iter: 14119  total_loss: 0.422  loss_ce: 0.0003178  loss_objectness: 0.3371  loss_dice: 0.05881  loss_mask: 0.0121    time: 3.8676  last_time: 0.7212  data_time: 0.0078  last_data_time: 0.0072   lr: 5e-06  max_mem: 2572M
[11/22 22:26:58] d2.utils.events INFO:  eta: 0:10:57  iter: 14139  total_loss: 0.4161  loss_ce: 0.0003349  loss_objectness: 0.3278  loss_dice: 0.06571  loss_mask: 0.01656    time: 3.8631  last_time: 0.7422  data_time: 0.0080  last_data_time: 0.0056   lr: 5e-06  max_mem: 2572M
[11/22 22:27:13] d2.utils.events INFO:  eta: 0:10:38  iter: 14159  total_loss: 0.4028  loss_ce: 0.0002616  loss_objectness: 0.3286  loss_dice: 0.06255  loss_mask: 0.01326    time: 3.8587  last_time: 0.7504  data_time: 0.0080  last_data_time: 0.0071   lr: 5e-06  max_mem: 2572M
[11/22 22:27:27] d2.utils.events INFO:  eta: 0:10:20  iter: 14179  total_loss: 0.395  loss_ce: 0.0006544  loss_objectness: 0.3249  loss_dice: 0.05332  loss_mask: 0.01284    time: 3.8543  last_time: 0.7144  data_time: 0.0082  last_data_time: 0.0077   lr: 5e-06  max_mem: 2572M
[11/22 22:27:42] d2.utils.events INFO:  eta: 0:10:01  iter: 14199  total_loss: 0.4045  loss_ce: 0.0004966  loss_objectness: 0.3153  loss_dice: 0.05925  loss_mask: 0.01383    time: 3.8499  last_time: 0.7164  data_time: 0.0077  last_data_time: 0.0075   lr: 5e-06  max_mem: 2572M
[11/22 22:27:55] d2.utils.events INFO:  eta: 0:09:44  iter: 14219  total_loss: 0.3975  loss_ce: 0.0001849  loss_objectness: 0.3295  loss_dice: 0.05828  loss_mask: 0.01167    time: 3.8454  last_time: 0.6726  data_time: 0.0093  last_data_time: 0.0103   lr: 5e-06  max_mem: 2572M
[11/22 22:28:05] d2.utils.events INFO:  eta: 0:09:24  iter: 14239  total_loss: 0.3996  loss_ce: 0.0002265  loss_objectness: 0.3163  loss_dice: 0.06776  loss_mask: 0.01222    time: 3.8407  last_time: 0.5011  data_time: 0.0081  last_data_time: 0.0065   lr: 5e-06  max_mem: 2572M
[11/22 22:28:16] d2.utils.events INFO:  eta: 0:09:06  iter: 14259  total_loss: 0.3961  loss_ce: 0.000154  loss_objectness: 0.3071  loss_dice: 0.04764  loss_mask: 0.0119    time: 3.8361  last_time: 0.5337  data_time: 0.0094  last_data_time: 0.0077   lr: 5e-06  max_mem: 2572M
[11/22 22:28:28] d2.utils.events INFO:  eta: 0:08:46  iter: 14279  total_loss: 0.4077  loss_ce: 0.0003783  loss_objectness: 0.3131  loss_dice: 0.06715  loss_mask: 0.01292    time: 3.8315  last_time: 0.5811  data_time: 0.0077  last_data_time: 0.0066   lr: 5e-06  max_mem: 2572M
[11/22 22:28:40] d2.utils.events INFO:  eta: 0:08:29  iter: 14299  total_loss: 0.3735  loss_ce: 0.0003111  loss_objectness: 0.2952  loss_dice: 0.0546  loss_mask: 0.01209    time: 3.8270  last_time: 0.6086  data_time: 0.0073  last_data_time: 0.0060   lr: 5e-06  max_mem: 2572M
[11/22 22:28:52] d2.utils.events INFO:  eta: 0:08:10  iter: 14319  total_loss: 0.394  loss_ce: 0.0001788  loss_objectness: 0.3216  loss_dice: 0.06338  loss_mask: 0.0136    time: 3.8225  last_time: 0.6178  data_time: 0.0077  last_data_time: 0.0063   lr: 5e-06  max_mem: 2572M
[11/22 22:29:04] d2.utils.events INFO:  eta: 0:07:51  iter: 14339  total_loss: 0.3839  loss_ce: 0.0002426  loss_objectness: 0.3096  loss_dice: 0.05105  loss_mask: 0.01398    time: 3.8180  last_time: 0.5852  data_time: 0.0072  last_data_time: 0.0066   lr: 5e-06  max_mem: 2572M
[11/22 22:29:16] d2.utils.events INFO:  eta: 0:07:37  iter: 14359  total_loss: 0.4058  loss_ce: 0.0003527  loss_objectness: 0.3364  loss_dice: 0.05354  loss_mask: 0.0125    time: 3.8135  last_time: 0.6161  data_time: 0.0077  last_data_time: 0.0063   lr: 5e-06  max_mem: 2572M
[11/22 22:29:28] d2.utils.events INFO:  eta: 0:07:23  iter: 14379  total_loss: 0.3681  loss_ce: 0.0002419  loss_objectness: 0.3019  loss_dice: 0.04712  loss_mask: 0.01155    time: 3.8090  last_time: 0.6199  data_time: 0.0077  last_data_time: 0.0084   lr: 5e-06  max_mem: 2572M
[11/22 22:29:40] d2.utils.events INFO:  eta: 0:07:08  iter: 14399  total_loss: 0.4022  loss_ce: 0.0002056  loss_objectness: 0.3426  loss_dice: 0.05475  loss_mask: 0.01284    time: 3.8046  last_time: 0.6116  data_time: 0.0074  last_data_time: 0.0095   lr: 5e-06  max_mem: 2572M
[11/22 22:29:52] d2.utils.events INFO:  eta: 0:06:54  iter: 14419  total_loss: 0.3887  loss_ce: 0.0002291  loss_objectness: 0.3017  loss_dice: 0.06072  loss_mask: 0.01442    time: 3.8002  last_time: 0.6152  data_time: 0.0069  last_data_time: 0.0070   lr: 5e-06  max_mem: 2572M
[11/22 22:30:04] d2.utils.events INFO:  eta: 0:06:40  iter: 14439  total_loss: 0.4122  loss_ce: 0.0001601  loss_objectness: 0.3268  loss_dice: 0.06318  loss_mask: 0.01167    time: 3.7957  last_time: 0.5889  data_time: 0.0073  last_data_time: 0.0063   lr: 5e-06  max_mem: 2572M
[11/22 22:30:16] d2.utils.events INFO:  eta: 0:06:25  iter: 14459  total_loss: 0.3838  loss_ce: 0.0001963  loss_objectness: 0.3094  loss_dice: 0.05624  loss_mask: 0.01288    time: 3.7913  last_time: 0.5737  data_time: 0.0071  last_data_time: 0.0079   lr: 5e-06  max_mem: 2572M
[11/22 22:30:26] d2.utils.events INFO:  eta: 0:06:11  iter: 14479  total_loss: 0.3505  loss_ce: 0.0001314  loss_objectness: 0.2875  loss_dice: 0.04899  loss_mask: 0.01432    time: 3.7867  last_time: 0.3406  data_time: 0.0073  last_data_time: 0.0061   lr: 5e-06  max_mem: 2572M
[11/22 22:30:32] d2.utils.events INFO:  eta: 0:05:57  iter: 14499  total_loss: 0.4172  loss_ce: 0.0001582  loss_objectness: 0.3099  loss_dice: 0.04861  loss_mask: 0.01192    time: 3.7819  last_time: 0.3041  data_time: 0.0057  last_data_time: 0.0045   lr: 5e-06  max_mem: 2572M
[11/22 22:30:38] d2.utils.events INFO:  eta: 0:05:43  iter: 14519  total_loss: 0.3829  loss_ce: 0.0001569  loss_objectness: 0.302  loss_dice: 0.0586  loss_mask: 0.01311    time: 3.7771  last_time: 0.3161  data_time: 0.0059  last_data_time: 0.0061   lr: 5e-06  max_mem: 2572M
[11/22 22:30:45] d2.utils.events INFO:  eta: 0:05:25  iter: 14539  total_loss: 0.3701  loss_ce: 0.0001964  loss_objectness: 0.3055  loss_dice: 0.04645  loss_mask: 0.0111    time: 3.7724  last_time: 0.4697  data_time: 0.0106  last_data_time: 0.0307   lr: 5e-06  max_mem: 2572M
[11/22 22:30:52] d2.utils.events INFO:  eta: 0:05:07  iter: 14559  total_loss: 0.3815  loss_ce: 0.0002288  loss_objectness: 0.31  loss_dice: 0.05487  loss_mask: 0.01227    time: 3.7677  last_time: 0.3259  data_time: 0.0073  last_data_time: 0.0054   lr: 5e-06  max_mem: 2572M
[11/22 22:30:58] d2.utils.events INFO:  eta: 0:04:51  iter: 14579  total_loss: 0.3902  loss_ce: 0.0003207  loss_objectness: 0.3196  loss_dice: 0.05908  loss_mask: 0.01268    time: 3.7630  last_time: 0.3137  data_time: 0.0061  last_data_time: 0.0059   lr: 5e-06  max_mem: 2572M
[11/22 22:31:05] d2.utils.events INFO:  eta: 0:04:32  iter: 14599  total_loss: 0.3712  loss_ce: 0.0002048  loss_objectness: 0.3044  loss_dice: 0.04315  loss_mask: 0.01146    time: 3.7582  last_time: 0.3141  data_time: 0.0063  last_data_time: 0.0061   lr: 5e-06  max_mem: 2572M
[11/22 22:31:11] d2.utils.events INFO:  eta: 0:04:11  iter: 14619  total_loss: 0.4042  loss_ce: 0.0001651  loss_objectness: 0.3252  loss_dice: 0.05702  loss_mask: 0.01339    time: 3.7535  last_time: 0.3181  data_time: 0.0058  last_data_time: 0.0070   lr: 5e-06  max_mem: 2572M
[11/22 22:31:17] d2.utils.events INFO:  eta: 0:03:47  iter: 14639  total_loss: 0.3959  loss_ce: 0.0006549  loss_objectness: 0.3109  loss_dice: 0.05577  loss_mask: 0.01187    time: 3.7488  last_time: 0.3117  data_time: 0.0064  last_data_time: 0.0062   lr: 5e-06  max_mem: 2572M
[11/22 22:31:23] d2.utils.events INFO:  eta: 0:03:31  iter: 14659  total_loss: 0.4026  loss_ce: 6.711e-05  loss_objectness: 0.3063  loss_dice: 0.05177  loss_mask: 0.0123    time: 3.7441  last_time: 0.3137  data_time: 0.0064  last_data_time: 0.0067   lr: 5e-06  max_mem: 2572M
[11/22 22:31:30] d2.utils.events INFO:  eta: 0:03:17  iter: 14679  total_loss: 0.4076  loss_ce: 0.0002777  loss_objectness: 0.3127  loss_dice: 0.06697  loss_mask: 0.0114    time: 3.7395  last_time: 0.3060  data_time: 0.0060  last_data_time: 0.0058   lr: 5e-06  max_mem: 2572M
[11/22 22:31:36] d2.utils.events INFO:  eta: 0:03:03  iter: 14699  total_loss: 0.4021  loss_ce: 0.0005041  loss_objectness: 0.3128  loss_dice: 0.05857  loss_mask: 0.01201    time: 3.7348  last_time: 0.3031  data_time: 0.0057  last_data_time: 0.0051   lr: 5e-06  max_mem: 2572M
[11/22 22:31:42] d2.utils.events INFO:  eta: 0:02:50  iter: 14719  total_loss: 0.374  loss_ce: 0.0001248  loss_objectness: 0.3042  loss_dice: 0.04733  loss_mask: 0.01148    time: 3.7301  last_time: 0.3040  data_time: 0.0057  last_data_time: 0.0051   lr: 5e-06  max_mem: 2572M
[11/22 22:31:48] d2.utils.events INFO:  eta: 0:02:36  iter: 14739  total_loss: 0.3736  loss_ce: 0.0002202  loss_objectness: 0.3004  loss_dice: 0.05536  loss_mask: 0.01288    time: 3.7255  last_time: 0.3092  data_time: 0.0055  last_data_time: 0.0058   lr: 5e-06  max_mem: 2572M
[11/22 22:31:54] d2.utils.events INFO:  eta: 0:02:23  iter: 14759  total_loss: 0.411  loss_ce: 0.0002177  loss_objectness: 0.333  loss_dice: 0.0591  loss_mask: 0.01262    time: 3.7209  last_time: 0.3020  data_time: 0.0059  last_data_time: 0.0049   lr: 5e-06  max_mem: 2572M
[11/22 22:32:00] d2.utils.events INFO:  eta: 0:02:10  iter: 14779  total_loss: 0.4124  loss_ce: 0.0005051  loss_objectness: 0.3334  loss_dice: 0.06317  loss_mask: 0.01146    time: 3.7162  last_time: 0.3051  data_time: 0.0058  last_data_time: 0.0055   lr: 5e-06  max_mem: 2572M
[11/22 22:32:07] d2.utils.events INFO:  eta: 0:01:57  iter: 14799  total_loss: 0.3795  loss_ce: 0.0001431  loss_objectness: 0.3176  loss_dice: 0.04704  loss_mask: 0.01323    time: 3.7116  last_time: 0.3067  data_time: 0.0057  last_data_time: 0.0060   lr: 5e-06  max_mem: 2572M
[11/22 22:32:13] d2.utils.events INFO:  eta: 0:01:44  iter: 14819  total_loss: 0.4312  loss_ce: 0.0002345  loss_objectness: 0.3336  loss_dice: 0.0771  loss_mask: 0.01063    time: 3.7070  last_time: 0.3096  data_time: 0.0060  last_data_time: 0.0059   lr: 5e-06  max_mem: 2572M
[11/22 22:32:19] d2.utils.events INFO:  eta: 0:01:31  iter: 14839  total_loss: 0.355  loss_ce: 0.0003468  loss_objectness: 0.2962  loss_dice: 0.05031  loss_mask: 0.01153    time: 3.7025  last_time: 0.3086  data_time: 0.0058  last_data_time: 0.0053   lr: 5e-06  max_mem: 2572M
[11/22 22:32:25] d2.utils.events INFO:  eta: 0:01:19  iter: 14859  total_loss: 0.3828  loss_ce: 0.0001203  loss_objectness: 0.3161  loss_dice: 0.0466  loss_mask: 0.01215    time: 3.6979  last_time: 0.3065  data_time: 0.0055  last_data_time: 0.0054   lr: 5e-06  max_mem: 2572M
[11/22 22:32:31] d2.utils.events INFO:  eta: 0:01:07  iter: 14879  total_loss: 0.3954  loss_ce: 0.000218  loss_objectness: 0.2976  loss_dice: 0.05776  loss_mask: 0.01183    time: 3.6933  last_time: 0.3107  data_time: 0.0055  last_data_time: 0.0056   lr: 5e-06  max_mem: 2572M
[11/22 22:32:37] d2.utils.events INFO:  eta: 0:00:56  iter: 14899  total_loss: 0.3883  loss_ce: 0.0001865  loss_objectness: 0.3193  loss_dice: 0.05638  loss_mask: 0.01193    time: 3.6888  last_time: 0.3038  data_time: 0.0054  last_data_time: 0.0056   lr: 5e-06  max_mem: 2572M
[11/22 22:32:43] d2.utils.events INFO:  eta: 0:00:44  iter: 14919  total_loss: 0.4015  loss_ce: 0.0002036  loss_objectness: 0.2976  loss_dice: 0.05618  loss_mask: 0.01078    time: 3.6842  last_time: 0.3083  data_time: 0.0055  last_data_time: 0.0053   lr: 5e-06  max_mem: 2572M
[11/22 22:32:50] d2.utils.events INFO:  eta: 0:00:33  iter: 14939  total_loss: 0.4044  loss_ce: 6.71e-05  loss_objectness: 0.3008  loss_dice: 0.05322  loss_mask: 0.01221    time: 3.6797  last_time: 0.3040  data_time: 0.0057  last_data_time: 0.0052   lr: 5e-06  max_mem: 2572M
[11/22 22:32:56] d2.utils.events INFO:  eta: 0:00:20  iter: 14959  total_loss: 0.3802  loss_ce: 0.0002727  loss_objectness: 0.3082  loss_dice: 0.04863  loss_mask: 0.01107    time: 3.6752  last_time: 0.3058  data_time: 0.0055  last_data_time: 0.0062   lr: 5e-06  max_mem: 2572M
[11/22 22:33:02] d2.utils.events INFO:  eta: 0:00:06  iter: 14979  total_loss: 0.3755  loss_ce: 0.0001811  loss_objectness: 0.2894  loss_dice: 0.06242  loss_mask: 0.01166    time: 3.6707  last_time: 0.3049  data_time: 0.0054  last_data_time: 0.0054   lr: 5e-06  max_mem: 2572M
[11/22 22:33:08] fvcore.common.checkpoint INFO: Saving checkpoint to output/crack_model_turbo\model_0014999.pth
[11/22 22:33:08] fvcore.common.checkpoint INFO: Saving checkpoint to output/crack_model_turbo\model_final.pth
[11/22 22:33:09] d2.utils.events INFO:  eta: 0:00:00  iter: 14999  total_loss: 0.3927  loss_ce: 7.224e-05  loss_objectness: 0.3076  loss_dice: 0.05535  loss_mask: 0.01373    time: 3.6662  last_time: 0.3091  data_time: 0.0056  last_data_time: 0.0056   lr: 5e-06  max_mem: 2572M
[11/22 22:33:09] d2.engine.hooks INFO: Overall training speed: 14998 iterations in 15:16:26 (3.6662 s / it)
[11/22 22:33:09] d2.engine.hooks INFO: Total training time: 15:21:14 (0:04:48 on hooks)
[11/22 22:33:09] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/22 22:33:09] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/22 22:33:09] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/22 22:33:09] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/22 22:33:09] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/22 22:33:09] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/22 22:33:19] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0193 s/iter. Eval: 0.0079 s/iter. Total: 0.0275 s/iter. ETA=0:00:02
[11/22 22:33:24] d2.evaluation.evaluator INFO: Total inference time: 0:00:05.421749 (0.047146 s / iter per device, on 1 devices)
[11/22 22:33:24] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.019873 s / iter per device, on 1 devices)
[11/22 22:33:24] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/22 22:33:24] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_model_turbo\inference\coco_instances_results.json
[11/22 22:33:24] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/22 22:33:24] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/22 22:33:24] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.03 seconds.
[11/22 22:33:24] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/22 22:33:24] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[11/22 22:33:24] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.054 | 11.886 | 6.608  | 0.033 | 11.858 | 50.739 |
[11/22 22:33:24] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/22 22:33:24] d2.evaluation.testing INFO: copypaste: Task: segm
[11/22 22:33:24] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/22 22:33:24] d2.evaluation.testing INFO: copypaste: 6.0542,11.8862,6.6083,0.0330,11.8577,50.7389

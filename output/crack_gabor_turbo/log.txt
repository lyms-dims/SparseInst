[11/23 00:01:06] detectron2 INFO: Rank of current process: 0. World size: 1
[11/23 00:01:07] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]
numpy                            2.2.6
detectron2                       0.6 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\detectron2
Compiler                         MSVC 195035718
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.9.1+cu126 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  True
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4060 (arch=8.9)
Driver version                   572.42
CUDA_HOME                        None - invalid!
Pillow                           12.0.0
torchvision                      0.24.1+cu126 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torchvision
torchvision arch flags           C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 194234444
  - Intel(R) oneAPI Math Kernel Library Version 2025.3-Product Build 20251007 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.7.1 (Git Hash 8d263e693366ef8db40acc569cc7d8edf644556d)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.6
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 91.0.2  (built against CUDA 12.9)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, COMMIT_SHA=5811a8d7da873dd699ff6687092c225caffcf1bb, CUDA_VERSION=12.6, CUDNN_VERSION=9.10.2, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/pytorch/.ci/pytorch/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, USE_XCCL=OFF, USE_XPU=OFF, 

[11/23 00:01:07] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sparse_inst_r50_giam_crack_gabor.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:49153', opts=['SOLVER.STEPS', '(10000,)', 'SOLVER.IMS_PER_BATCH', '8', 'SOLVER.BASE_LR', '0.00005', 'SOLVER.AMP.ENABLED', 'True', 'INPUT.MIN_SIZE_TRAIN', '(512,)', 'INPUT.MIN_SIZE_TEST', '512', 'OUTPUT_DIR', 'output/crack_gabor_turbo'])
[11/23 00:01:07] detectron2 INFO: Contents of args.config_file=configs/sparse_inst_r50_giam_crack_gabor.yaml:
# Configuration for SparseInst with ResNet-50 backbone for crack detection with Gabor Filtering
# Based on sparse_inst_r50_giam_crack.yaml

_BASE_: "Base-SparseInst.yaml"

MODEL:
  WEIGHTS: "pretrained_models/R-50.pkl"
  SPARSE_INST:
    DECODER:
      NUM_CLASSES: 1  # Only one class: crack
      NUM_MASKS: 100  # Maximum number of instances to detect
    DATASET_MAPPER: "GaborDatasetMapper" # Use the Gabor Filter Mapper

DATASETS:
  # Update these names after registering your dataset
  # Example: ("deepcracks_train",)
  TRAIN: ("deepcracks_train",)
  TEST: ("deepcracks_val",)

SOLVER:
  IMS_PER_BATCH: 16  # Reduced from 64 for smaller datasets, adjust based on GPU memory
  BASE_LR: 0.0001  # Slightly higher learning rate for fine-tuning
  STEPS: (10000, 15000)  # Adjust based on your dataset size
  MAX_ITER: 15000  # Adjust based on your dataset size
  WEIGHT_DECAY: 0.05
  # For smaller datasets, you might want to reduce learning rate schedule
  # STEPS: (5000, 10000)
  # MAX_ITER: 15000

INPUT:
  MIN_SIZE_TRAIN: (416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 853
  MIN_SIZE_TEST: 640
  MAX_SIZE_TEST: 853
  FORMAT: "RGB"
  MASK_FORMAT: "bitmask"

TEST:
  EVAL_PERIOD: 1000  # Evaluate every 1000 iterations

DATALOADER:
  NUM_WORKERS: 4  # Adjust based on your system

OUTPUT_DIR: "output/sparse_inst_r50_giam_crack_gabor"


[11/23 00:01:07] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - deepcracks_val
  TRAIN:
  - deepcracks_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: RGB
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 853
  MAX_SIZE_TRAIN: 853
  MIN_SIZE_TEST: 512
  MIN_SIZE_TRAIN:
  - 512
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_backbone
  CSPNET:
    NAME: darknet53
    NORM: ''
    OUT_FEATURES:
    - csp1
    - csp2
    - csp3
    - csp4
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: SparseInst
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  PVT:
    LINEAR: false
    NAME: b1
    OUT_FEATURES:
    - p2
    - p3
    - p4
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SPARSE_INST:
    CLS_THRESHOLD: 0.005
    DATASET_MAPPER: GaborDatasetMapper
    DECODER:
      GROUPS: 4
      INST:
        CONVS: 4
        DIM: 256
      KERNEL_DIM: 128
      MASK:
        CONVS: 4
        DIM: 256
      NAME: GroupIAMDecoder
      NUM_CLASSES: 1
      NUM_MASKS: 100
      OUTPUT_IAM: false
      SCALE_FACTOR: 2.0
    ENCODER:
      IN_FEATURES:
      - res3
      - res4
      - res5
      NAME: InstanceContextEncoder
      NORM: ''
      NUM_CHANNELS: 256
    LOSS:
      CLASS_WEIGHT: 2.0
      ITEMS:
      - labels
      - masks
      MASK_DICE_WEIGHT: 2.0
      MASK_PIXEL_WEIGHT: 5.0
      NAME: SparseInstCriterion
      OBJECTNESS_WEIGHT: 1.0
    MASK_THRESHOLD: 0.45
    MATCHER:
      ALPHA: 0.8
      BETA: 0.2
      NAME: SparseInstMatcher
    MAX_DETECTIONS: 100
  WEIGHTS: pretrained_models/R-50.pkl
OUTPUT_DIR: output/crack_gabor_turbo
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  AMSGRAD: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 15000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 10000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/23 00:01:07] detectron2 INFO: Full config saved to output/crack_gabor_turbo\config.yaml
[11/23 00:01:07] d2.utils.env INFO: Using a generated random seed 7406622
[11/23 00:01:07] d2.engine.defaults INFO: Model:
SparseInst(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (encoder): InstanceContextEncoder(
    (fpn_laterals): ModuleList(
      (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (fpn_outputs): ModuleList(
      (0-2): 3 x Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (ppm): PyramidPoolingModule(
      (stages): ModuleList(
        (0): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(2, 2))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(3, 3))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(6, 6))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (bottleneck): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (fusion): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
  )
  (decoder): GroupIAMDecoder(
    (inst_branch): GroupInstanceBranch(
      (inst_convs): Sequential(
        (0): Conv2d(258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU(inplace=True)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU(inplace=True)
      )
      (iam_conv): Conv2d(256, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)
      (fc): Linear(in_features=1024, out_features=1024, bias=True)
      (cls_score): Linear(in_features=1024, out_features=1, bias=True)
      (mask_kernel): Linear(in_features=1024, out_features=128, bias=True)
      (objectness): Linear(in_features=1024, out_features=1, bias=True)
    )
    (mask_branch): MaskBranch(
      (mask_convs): Sequential(
        (0): Conv2d(258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU(inplace=True)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU(inplace=True)
      )
      (projection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (criterion): SparseInstCriterion(
    (matcher): SparseInstMatcher()
  )
)
[11/23 00:01:07] sparseinst.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(512,), max_size=853, sample_style='choice')]
[11/23 00:01:07] d2.data.datasets.coco INFO: Loaded 382 images in COCO format from datasets/DeepCrack/annotations/train.json
[11/23 00:01:07] d2.data.build INFO: Removed 0 images with no usable annotations. 382 images left.
[11/23 00:01:07] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   crack    | 1250         |
|            |              |[0m
[11/23 00:01:07] d2.data.build INFO: Using training sampler TrainingSampler
[11/23 00:01:07] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/23 00:01:07] d2.data.common INFO: Serializing 382 elements to byte tensors and concatenating them all ...
[11/23 00:01:07] d2.data.common INFO: Serialized dataset takes 0.66 MiB
[11/23 00:01:07] d2.data.build INFO: Making batched data loader with batch_size=8
[11/23 00:01:07] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from pretrained_models/R-50.pkl ...
[11/23 00:01:07] fvcore.common.checkpoint INFO: [Checkpointer] Loading from pretrained_models/R-50.pkl ...
[11/23 00:01:07] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[11/23 00:01:08] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone - Total num: 54
[11/23 00:01:08] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mdecoder.inst_branch.cls_score.{bias, weight}[0m
[34mdecoder.inst_branch.fc.{bias, weight}[0m
[34mdecoder.inst_branch.iam_conv.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.0.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.2.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.4.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.6.{bias, weight}[0m
[34mdecoder.inst_branch.mask_kernel.{bias, weight}[0m
[34mdecoder.inst_branch.objectness.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.0.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.2.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.4.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.6.{bias, weight}[0m
[34mdecoder.mask_branch.projection.{bias, weight}[0m
[34mencoder.fpn_laterals.0.{bias, weight}[0m
[34mencoder.fpn_laterals.1.{bias, weight}[0m
[34mencoder.fpn_laterals.2.{bias, weight}[0m
[34mencoder.fpn_outputs.0.{bias, weight}[0m
[34mencoder.fpn_outputs.1.{bias, weight}[0m
[34mencoder.fpn_outputs.2.{bias, weight}[0m
[34mencoder.fusion.{bias, weight}[0m
[34mencoder.ppm.bottleneck.{bias, weight}[0m
[34mencoder.ppm.stages.0.1.{bias, weight}[0m
[34mencoder.ppm.stages.1.1.{bias, weight}[0m
[34mencoder.ppm.stages.2.1.{bias, weight}[0m
[34mencoder.ppm.stages.3.1.{bias, weight}[0m
[11/23 00:01:08] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[11/23 00:01:08] d2.engine.train_loop INFO: Starting training from iteration 0
[11/23 00:01:31] d2.utils.events INFO:  eta: 1:15:20  iter: 19  total_loss: 6.276  loss_ce: 2.403  loss_objectness: 0.6632  loss_dice: 1.97  loss_mask: 1.204    time: 0.3294  last_time: 0.3054  data_time: 0.7227  last_data_time: 0.0055   lr: 9.9905e-07  max_mem: 2550M
[11/23 00:01:37] d2.utils.events INFO:  eta: 1:15:17  iter: 39  total_loss: 5.365  loss_ce: 2.354  loss_objectness: 0.5837  loss_dice: 1.95  loss_mask: 0.6448    time: 0.3152  last_time: 0.3026  data_time: 0.0050  last_data_time: 0.0050   lr: 1.998e-06  max_mem: 2550M
[11/23 00:01:44] d2.utils.events INFO:  eta: 1:15:13  iter: 59  total_loss: 4.797  loss_ce: 2.216  loss_objectness: 0.3953  loss_dice: 1.814  loss_mask: 0.3561    time: 0.3110  last_time: 0.3030  data_time: 0.0050  last_data_time: 0.0048   lr: 2.997e-06  max_mem: 2555M
[11/23 00:01:50] d2.utils.events INFO:  eta: 1:15:07  iter: 79  total_loss: 4.429  loss_ce: 2.032  loss_objectness: 0.3232  loss_dice: 1.769  loss_mask: 0.2695    time: 0.3090  last_time: 0.3029  data_time: 0.0050  last_data_time: 0.0049   lr: 3.9961e-06  max_mem: 2555M
[11/23 00:01:56] d2.utils.events INFO:  eta: 1:14:58  iter: 99  total_loss: 3.982  loss_ce: 1.715  loss_objectness: 0.3016  loss_dice: 1.67  loss_mask: 0.2993    time: 0.3075  last_time: 0.3106  data_time: 0.0048  last_data_time: 0.0049   lr: 4.9951e-06  max_mem: 2555M
[11/23 00:02:02] d2.utils.events INFO:  eta: 1:14:54  iter: 119  total_loss: 3.403  loss_ce: 1.109  loss_objectness: 0.3271  loss_dice: 1.642  loss_mask: 0.35    time: 0.3067  last_time: 0.2996  data_time: 0.0049  last_data_time: 0.0045   lr: 5.9941e-06  max_mem: 2555M
[11/23 00:02:08] d2.utils.events INFO:  eta: 1:14:46  iter: 139  total_loss: 3.153  loss_ce: 0.8789  loss_objectness: 0.3124  loss_dice: 1.641  loss_mask: 0.3133    time: 0.3061  last_time: 0.3000  data_time: 0.0050  last_data_time: 0.0048   lr: 6.993e-06  max_mem: 2556M
[11/23 00:02:14] d2.utils.events INFO:  eta: 1:14:39  iter: 159  total_loss: 3.024  loss_ce: 0.8487  loss_objectness: 0.3532  loss_dice: 1.556  loss_mask: 0.2549    time: 0.3055  last_time: 0.3004  data_time: 0.0049  last_data_time: 0.0041   lr: 7.9921e-06  max_mem: 2556M
[11/23 00:02:20] d2.utils.events INFO:  eta: 1:14:33  iter: 179  total_loss: 2.993  loss_ce: 0.85  loss_objectness: 0.3602  loss_dice: 1.569  loss_mask: 0.2409    time: 0.3051  last_time: 0.2984  data_time: 0.0048  last_data_time: 0.0043   lr: 8.9911e-06  max_mem: 2563M
[11/23 00:02:26] d2.utils.events INFO:  eta: 1:14:28  iter: 199  total_loss: 2.967  loss_ce: 0.8321  loss_objectness: 0.3882  loss_dice: 1.474  loss_mask: 0.2264    time: 0.3048  last_time: 0.3031  data_time: 0.0048  last_data_time: 0.0042   lr: 9.99e-06  max_mem: 2563M
[11/23 00:02:32] d2.utils.events INFO:  eta: 1:14:23  iter: 219  total_loss: 2.875  loss_ce: 0.8181  loss_objectness: 0.4079  loss_dice: 1.49  loss_mask: 0.1703    time: 0.3046  last_time: 0.3020  data_time: 0.0049  last_data_time: 0.0048   lr: 1.0989e-05  max_mem: 2563M
[11/23 00:02:38] d2.utils.events INFO:  eta: 1:14:17  iter: 239  total_loss: 2.786  loss_ce: 0.7331  loss_objectness: 0.3896  loss_dice: 1.471  loss_mask: 0.1673    time: 0.3044  last_time: 0.3046  data_time: 0.0049  last_data_time: 0.0044   lr: 1.1988e-05  max_mem: 2563M
[11/23 00:02:44] d2.utils.events INFO:  eta: 1:14:11  iter: 259  total_loss: 2.788  loss_ce: 0.6869  loss_objectness: 0.3983  loss_dice: 1.445  loss_mask: 0.2457    time: 0.3043  last_time: 0.3051  data_time: 0.0048  last_data_time: 0.0046   lr: 1.2987e-05  max_mem: 2563M
[11/23 00:02:50] d2.utils.events INFO:  eta: 1:14:06  iter: 279  total_loss: 2.639  loss_ce: 0.6083  loss_objectness: 0.4055  loss_dice: 1.43  loss_mask: 0.1747    time: 0.3041  last_time: 0.2997  data_time: 0.0051  last_data_time: 0.0043   lr: 1.3986e-05  max_mem: 2563M
[11/23 00:02:56] d2.utils.events INFO:  eta: 1:14:00  iter: 299  total_loss: 2.619  loss_ce: 0.6203  loss_objectness: 0.4152  loss_dice: 1.421  loss_mask: 0.1928    time: 0.3040  last_time: 0.3004  data_time: 0.0048  last_data_time: 0.0050   lr: 1.4985e-05  max_mem: 2563M
[11/23 00:03:02] d2.utils.events INFO:  eta: 1:13:53  iter: 319  total_loss: 2.57  loss_ce: 0.5523  loss_objectness: 0.4024  loss_dice: 1.41  loss_mask: 0.2157    time: 0.3039  last_time: 0.3005  data_time: 0.0048  last_data_time: 0.0050   lr: 1.5984e-05  max_mem: 2563M
[11/23 00:03:08] d2.utils.events INFO:  eta: 1:13:48  iter: 339  total_loss: 2.524  loss_ce: 0.536  loss_objectness: 0.4436  loss_dice: 1.34  loss_mask: 0.201    time: 0.3038  last_time: 0.3044  data_time: 0.0049  last_data_time: 0.0051   lr: 1.6983e-05  max_mem: 2563M
[11/23 00:03:13] d2.engine.hooks INFO: Overall training speed: 352 iterations in 0:01:47 (0.3046 s / it)
[11/23 00:03:13] d2.engine.hooks INFO: Total training time: 0:01:47 (0:00:00 on hooks)
[11/23 00:03:13] d2.utils.events INFO:  eta: 1:13:43  iter: 354  total_loss: 2.349  loss_ce: 0.4611  loss_objectness: 0.4704  loss_dice: 1.29  loss_mask: 0.1529    time: 0.3038  last_time: 0.3017  data_time: 0.0052  last_data_time: 0.0044   lr: 1.7682e-05  max_mem: 2563M
[11/23 00:03:30] detectron2 INFO: Rank of current process: 0. World size: 1
[11/23 00:03:31] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]
numpy                            2.2.6
detectron2                       0.6 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\detectron2
Compiler                         MSVC 195035718
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.9.1+cu126 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  True
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4060 (arch=8.9)
Driver version                   572.42
CUDA_HOME                        None - invalid!
Pillow                           12.0.0
torchvision                      0.24.1+cu126 @C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torchvision
torchvision arch flags           C:\Users\lymuel\Documents\GitHub\Thesis\venv\Lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 194234444
  - Intel(R) oneAPI Math Kernel Library Version 2025.3-Product Build 20251007 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.7.1 (Git Hash 8d263e693366ef8db40acc569cc7d8edf644556d)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.6
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 91.0.2  (built against CUDA 12.9)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, COMMIT_SHA=5811a8d7da873dd699ff6687092c225caffcf1bb, CUDA_VERSION=12.6, CUDNN_VERSION=9.10.2, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/pytorch/.ci/pytorch/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, USE_XCCL=OFF, USE_XPU=OFF, 

[11/23 00:03:31] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sparse_inst_r50_giam_crack_gabor.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:49153', opts=['SOLVER.STEPS', '(10000,)', 'SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.00005', 'SOLVER.AMP.ENABLED', 'True', 'INPUT.MIN_SIZE_TRAIN', '(512,)', 'INPUT.MIN_SIZE_TEST', '512', 'OUTPUT_DIR', 'output/crack_gabor_turbo'])
[11/23 00:03:31] detectron2 INFO: Contents of args.config_file=configs/sparse_inst_r50_giam_crack_gabor.yaml:
# Configuration for SparseInst with ResNet-50 backbone for crack detection with Gabor Filtering
# Based on sparse_inst_r50_giam_crack.yaml

_BASE_: "Base-SparseInst.yaml"

MODEL:
  WEIGHTS: "pretrained_models/R-50.pkl"
  SPARSE_INST:
    DECODER:
      NUM_CLASSES: 1  # Only one class: crack
      NUM_MASKS: 100  # Maximum number of instances to detect
    DATASET_MAPPER: "GaborDatasetMapper" # Use the Gabor Filter Mapper

DATASETS:
  # Update these names after registering your dataset
  # Example: ("deepcracks_train",)
  TRAIN: ("deepcracks_train",)
  TEST: ("deepcracks_val",)

SOLVER:
  IMS_PER_BATCH: 16  # Reduced from 64 for smaller datasets, adjust based on GPU memory
  BASE_LR: 0.0001  # Slightly higher learning rate for fine-tuning
  STEPS: (10000, 15000)  # Adjust based on your dataset size
  MAX_ITER: 15000  # Adjust based on your dataset size
  WEIGHT_DECAY: 0.05
  # For smaller datasets, you might want to reduce learning rate schedule
  # STEPS: (5000, 10000)
  # MAX_ITER: 15000

INPUT:
  MIN_SIZE_TRAIN: (416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 853
  MIN_SIZE_TEST: 640
  MAX_SIZE_TEST: 853
  FORMAT: "RGB"
  MASK_FORMAT: "bitmask"

TEST:
  EVAL_PERIOD: 1000  # Evaluate every 1000 iterations

DATALOADER:
  NUM_WORKERS: 4  # Adjust based on your system

OUTPUT_DIR: "output/sparse_inst_r50_giam_crack_gabor"


[11/23 00:03:31] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - deepcracks_val
  TRAIN:
  - deepcracks_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: RGB
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 853
  MAX_SIZE_TRAIN: 853
  MIN_SIZE_TEST: 512
  MIN_SIZE_TRAIN:
  - 512
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_backbone
  CSPNET:
    NAME: darknet53
    NORM: ''
    OUT_FEATURES:
    - csp1
    - csp2
    - csp3
    - csp4
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: SparseInst
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  PVT:
    LINEAR: false
    NAME: b1
    OUT_FEATURES:
    - p2
    - p3
    - p4
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SPARSE_INST:
    CLS_THRESHOLD: 0.005
    DATASET_MAPPER: GaborDatasetMapper
    DECODER:
      GROUPS: 4
      INST:
        CONVS: 4
        DIM: 256
      KERNEL_DIM: 128
      MASK:
        CONVS: 4
        DIM: 256
      NAME: GroupIAMDecoder
      NUM_CLASSES: 1
      NUM_MASKS: 100
      OUTPUT_IAM: false
      SCALE_FACTOR: 2.0
    ENCODER:
      IN_FEATURES:
      - res3
      - res4
      - res5
      NAME: InstanceContextEncoder
      NORM: ''
      NUM_CHANNELS: 256
    LOSS:
      CLASS_WEIGHT: 2.0
      ITEMS:
      - labels
      - masks
      MASK_DICE_WEIGHT: 2.0
      MASK_PIXEL_WEIGHT: 5.0
      NAME: SparseInstCriterion
      OBJECTNESS_WEIGHT: 1.0
    MASK_THRESHOLD: 0.45
    MATCHER:
      ALPHA: 0.8
      BETA: 0.2
      NAME: SparseInstMatcher
    MAX_DETECTIONS: 100
  WEIGHTS: pretrained_models/R-50.pkl
OUTPUT_DIR: output/crack_gabor_turbo
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  AMSGRAD: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 15000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 10000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/23 00:03:31] detectron2 INFO: Full config saved to output/crack_gabor_turbo\config.yaml
[11/23 00:03:31] d2.utils.env INFO: Using a generated random seed 31330418
[11/23 00:03:31] d2.engine.defaults INFO: Model:
SparseInst(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (encoder): InstanceContextEncoder(
    (fpn_laterals): ModuleList(
      (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (fpn_outputs): ModuleList(
      (0-2): 3 x Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (ppm): PyramidPoolingModule(
      (stages): ModuleList(
        (0): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(2, 2))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(3, 3))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(6, 6))
          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (bottleneck): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (fusion): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
  )
  (decoder): GroupIAMDecoder(
    (inst_branch): GroupInstanceBranch(
      (inst_convs): Sequential(
        (0): Conv2d(258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU(inplace=True)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU(inplace=True)
      )
      (iam_conv): Conv2d(256, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)
      (fc): Linear(in_features=1024, out_features=1024, bias=True)
      (cls_score): Linear(in_features=1024, out_features=1, bias=True)
      (mask_kernel): Linear(in_features=1024, out_features=128, bias=True)
      (objectness): Linear(in_features=1024, out_features=1, bias=True)
    )
    (mask_branch): MaskBranch(
      (mask_convs): Sequential(
        (0): Conv2d(258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU(inplace=True)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU(inplace=True)
      )
      (projection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (criterion): SparseInstCriterion(
    (matcher): SparseInstMatcher()
  )
)
[11/23 00:03:31] sparseinst.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(512,), max_size=853, sample_style='choice')]
[11/23 00:03:31] d2.data.datasets.coco INFO: Loaded 382 images in COCO format from datasets/DeepCrack/annotations/train.json
[11/23 00:03:31] d2.data.build INFO: Removed 0 images with no usable annotations. 382 images left.
[11/23 00:03:31] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   crack    | 1250         |
|            |              |[0m
[11/23 00:03:31] d2.data.build INFO: Using training sampler TrainingSampler
[11/23 00:03:31] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/23 00:03:31] d2.data.common INFO: Serializing 382 elements to byte tensors and concatenating them all ...
[11/23 00:03:31] d2.data.common INFO: Serialized dataset takes 0.66 MiB
[11/23 00:03:31] d2.data.build INFO: Making batched data loader with batch_size=4
[11/23 00:03:31] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from pretrained_models/R-50.pkl ...
[11/23 00:03:31] fvcore.common.checkpoint INFO: [Checkpointer] Loading from pretrained_models/R-50.pkl ...
[11/23 00:03:31] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[11/23 00:03:31] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone - Total num: 54
[11/23 00:03:31] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mdecoder.inst_branch.cls_score.{bias, weight}[0m
[34mdecoder.inst_branch.fc.{bias, weight}[0m
[34mdecoder.inst_branch.iam_conv.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.0.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.2.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.4.{bias, weight}[0m
[34mdecoder.inst_branch.inst_convs.6.{bias, weight}[0m
[34mdecoder.inst_branch.mask_kernel.{bias, weight}[0m
[34mdecoder.inst_branch.objectness.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.0.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.2.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.4.{bias, weight}[0m
[34mdecoder.mask_branch.mask_convs.6.{bias, weight}[0m
[34mdecoder.mask_branch.projection.{bias, weight}[0m
[34mencoder.fpn_laterals.0.{bias, weight}[0m
[34mencoder.fpn_laterals.1.{bias, weight}[0m
[34mencoder.fpn_laterals.2.{bias, weight}[0m
[34mencoder.fpn_outputs.0.{bias, weight}[0m
[34mencoder.fpn_outputs.1.{bias, weight}[0m
[34mencoder.fpn_outputs.2.{bias, weight}[0m
[34mencoder.fusion.{bias, weight}[0m
[34mencoder.ppm.bottleneck.{bias, weight}[0m
[34mencoder.ppm.stages.0.1.{bias, weight}[0m
[34mencoder.ppm.stages.1.1.{bias, weight}[0m
[34mencoder.ppm.stages.2.1.{bias, weight}[0m
[34mencoder.ppm.stages.3.1.{bias, weight}[0m
[11/23 00:03:31] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[11/23 00:03:31] d2.engine.train_loop INFO: Starting training from iteration 0
[11/23 00:03:50] d2.utils.events INFO:  eta: 0:40:34  iter: 19  total_loss: 7.547  loss_ce: 2.129  loss_objectness: 1.52  loss_dice: 1.99  loss_mask: 1.902    time: 0.1735  last_time: 0.1656  data_time: 0.6909  last_data_time: 0.0023   lr: 9.9905e-07  max_mem: 1579M
[11/23 00:03:53] d2.utils.events INFO:  eta: 0:40:33  iter: 39  total_loss: 5.72  loss_ce: 2.112  loss_objectness: 0.9283  loss_dice: 1.967  loss_mask: 0.8702    time: 0.1682  last_time: 0.1613  data_time: 0.0028  last_data_time: 0.0023   lr: 1.998e-06  max_mem: 1582M
[11/23 00:03:56] d2.utils.events INFO:  eta: 0:40:35  iter: 59  total_loss: 4.912  loss_ce: 2.041  loss_objectness: 0.4872  loss_dice: 1.824  loss_mask: 0.5911    time: 0.1668  last_time: 0.1632  data_time: 0.0026  last_data_time: 0.0024   lr: 2.997e-06  max_mem: 1582M
[11/23 00:04:00] d2.utils.events INFO:  eta: 0:40:38  iter: 79  total_loss: 4.355  loss_ce: 1.846  loss_objectness: 0.3373  loss_dice: 1.775  loss_mask: 0.3147    time: 0.1663  last_time: 0.1703  data_time: 0.0028  last_data_time: 0.0030   lr: 3.9961e-06  max_mem: 1583M
[11/23 00:04:03] d2.utils.events INFO:  eta: 0:40:38  iter: 99  total_loss: 3.8  loss_ce: 1.456  loss_objectness: 0.2851  loss_dice: 1.751  loss_mask: 0.2891    time: 0.1663  last_time: 0.1660  data_time: 0.0030  last_data_time: 0.0022   lr: 4.9951e-06  max_mem: 1592M
[11/23 00:04:06] d2.utils.events INFO:  eta: 0:40:41  iter: 119  total_loss: 3.318  loss_ce: 0.9399  loss_objectness: 0.2479  loss_dice: 1.759  loss_mask: 0.4349    time: 0.1661  last_time: 0.1666  data_time: 0.0028  last_data_time: 0.0022   lr: 5.9941e-06  max_mem: 1592M
[11/23 00:04:10] d2.utils.events INFO:  eta: 0:40:40  iter: 139  total_loss: 3.213  loss_ce: 0.9073  loss_objectness: 0.3118  loss_dice: 1.633  loss_mask: 0.3194    time: 0.1665  last_time: 0.1690  data_time: 0.0029  last_data_time: 0.0024   lr: 6.993e-06  max_mem: 1592M
[11/23 00:04:13] d2.utils.events INFO:  eta: 0:40:48  iter: 159  total_loss: 3.048  loss_ce: 0.8065  loss_objectness: 0.2772  loss_dice: 1.696  loss_mask: 0.2365    time: 0.1671  last_time: 0.1713  data_time: 0.0031  last_data_time: 0.0029   lr: 7.9921e-06  max_mem: 1594M
[11/23 00:04:17] d2.utils.events INFO:  eta: 0:40:52  iter: 179  total_loss: 3.071  loss_ce: 0.8697  loss_objectness: 0.4045  loss_dice: 1.517  loss_mask: 0.2702    time: 0.1674  last_time: 0.1700  data_time: 0.0028  last_data_time: 0.0033   lr: 8.9911e-06  max_mem: 1594M
[11/23 00:04:20] d2.utils.events INFO:  eta: 0:41:01  iter: 199  total_loss: 2.897  loss_ce: 0.768  loss_objectness: 0.3945  loss_dice: 1.507  loss_mask: 0.2291    time: 0.1678  last_time: 0.1704  data_time: 0.0029  last_data_time: 0.0025   lr: 9.99e-06  max_mem: 1594M
[11/23 00:04:23] d2.utils.events INFO:  eta: 0:41:12  iter: 219  total_loss: 2.831  loss_ce: 0.5989  loss_objectness: 0.3074  loss_dice: 1.667  loss_mask: 0.2621    time: 0.1682  last_time: 0.1736  data_time: 0.0031  last_data_time: 0.0045   lr: 1.0989e-05  max_mem: 1596M
[11/23 00:04:27] d2.utils.events INFO:  eta: 0:41:29  iter: 239  total_loss: 3.653  loss_ce: 0.8623  loss_objectness: 0.2288  loss_dice: 1.805  loss_mask: 0.7104    time: 0.1683  last_time: 0.1700  data_time: 0.0027  last_data_time: 0.0026   lr: 1.1988e-05  max_mem: 1596M
[11/23 00:04:30] d2.utils.events INFO:  eta: 0:41:33  iter: 259  total_loss: 2.996  loss_ce: 0.8135  loss_objectness: 0.3569  loss_dice: 1.579  loss_mask: 0.2384    time: 0.1686  last_time: 0.1752  data_time: 0.0031  last_data_time: 0.0037   lr: 1.2987e-05  max_mem: 1596M
[11/23 00:04:34] d2.utils.events INFO:  eta: 0:41:33  iter: 279  total_loss: 2.911  loss_ce: 0.7411  loss_objectness: 0.3912  loss_dice: 1.509  loss_mask: 0.2513    time: 0.1689  last_time: 0.1926  data_time: 0.0034  last_data_time: 0.0132   lr: 1.3986e-05  max_mem: 1596M
[11/23 00:04:37] d2.utils.events INFO:  eta: 0:41:33  iter: 299  total_loss: 2.711  loss_ce: 0.6234  loss_objectness: 0.3875  loss_dice: 1.44  loss_mask: 0.2592    time: 0.1691  last_time: 0.1694  data_time: 0.0030  last_data_time: 0.0022   lr: 1.4985e-05  max_mem: 1598M
[11/23 00:04:41] d2.utils.events INFO:  eta: 0:41:32  iter: 319  total_loss: 2.549  loss_ce: 0.5722  loss_objectness: 0.4165  loss_dice: 1.345  loss_mask: 0.2122    time: 0.1692  last_time: 0.1724  data_time: 0.0029  last_data_time: 0.0029   lr: 1.5984e-05  max_mem: 1598M
[11/23 00:04:44] d2.utils.events INFO:  eta: 0:41:32  iter: 339  total_loss: 2.594  loss_ce: 0.5248  loss_objectness: 0.3714  loss_dice: 1.497  loss_mask: 0.1686    time: 0.1694  last_time: 0.1742  data_time: 0.0032  last_data_time: 0.0031   lr: 1.6983e-05  max_mem: 1598M
[11/23 00:04:48] d2.utils.events INFO:  eta: 0:41:29  iter: 359  total_loss: 2.577  loss_ce: 0.6177  loss_objectness: 0.4193  loss_dice: 1.314  loss_mask: 0.2005    time: 0.1695  last_time: 0.1767  data_time: 0.0030  last_data_time: 0.0039   lr: 1.7982e-05  max_mem: 1598M
[11/23 00:04:51] d2.utils.events INFO:  eta: 0:41:27  iter: 379  total_loss: 2.761  loss_ce: 0.6264  loss_objectness: 0.4043  loss_dice: 1.437  loss_mask: 0.2064    time: 0.1696  last_time: 0.1723  data_time: 0.0030  last_data_time: 0.0027   lr: 1.8981e-05  max_mem: 1598M
[11/23 00:04:54] d2.utils.events INFO:  eta: 0:41:25  iter: 399  total_loss: 2.42  loss_ce: 0.5239  loss_objectness: 0.4627  loss_dice: 1.28  loss_mask: 0.2017    time: 0.1697  last_time: 0.1695  data_time: 0.0029  last_data_time: 0.0025   lr: 1.998e-05  max_mem: 1598M
[11/23 00:04:58] d2.utils.events INFO:  eta: 0:41:22  iter: 419  total_loss: 2.41  loss_ce: 0.4675  loss_objectness: 0.4817  loss_dice: 1.257  loss_mask: 0.1799    time: 0.1698  last_time: 0.1696  data_time: 0.0028  last_data_time: 0.0032   lr: 2.0979e-05  max_mem: 1616M
[11/23 00:05:01] d2.utils.events INFO:  eta: 0:41:20  iter: 439  total_loss: 2.449  loss_ce: 0.578  loss_objectness: 0.3904  loss_dice: 1.391  loss_mask: 0.1138    time: 0.1699  last_time: 0.1699  data_time: 0.0029  last_data_time: 0.0028   lr: 2.1978e-05  max_mem: 1616M
[11/23 00:05:05] d2.utils.events INFO:  eta: 0:41:17  iter: 459  total_loss: 2.535  loss_ce: 0.6249  loss_objectness: 0.4348  loss_dice: 1.356  loss_mask: 0.1093    time: 0.1699  last_time: 0.1723  data_time: 0.0029  last_data_time: 0.0025   lr: 2.2977e-05  max_mem: 1616M
[11/23 00:05:08] d2.utils.events INFO:  eta: 0:41:14  iter: 479  total_loss: 2.401  loss_ce: 0.5185  loss_objectness: 0.4819  loss_dice: 1.27  loss_mask: 0.1579    time: 0.1700  last_time: 0.1691  data_time: 0.0031  last_data_time: 0.0026   lr: 2.3976e-05  max_mem: 1616M
[11/23 00:05:12] d2.utils.events INFO:  eta: 0:41:11  iter: 499  total_loss: 2.446  loss_ce: 0.5374  loss_objectness: 0.4692  loss_dice: 1.213  loss_mask: 0.1661    time: 0.1700  last_time: 0.1704  data_time: 0.0033  last_data_time: 0.0030   lr: 2.4975e-05  max_mem: 1616M
[11/23 00:05:15] d2.utils.events INFO:  eta: 0:41:08  iter: 519  total_loss: 2.429  loss_ce: 0.5847  loss_objectness: 0.4198  loss_dice: 1.302  loss_mask: 0.105    time: 0.1701  last_time: 0.1693  data_time: 0.0031  last_data_time: 0.0022   lr: 2.5974e-05  max_mem: 1616M
[11/23 00:05:18] d2.utils.events INFO:  eta: 0:41:05  iter: 539  total_loss: 2.446  loss_ce: 0.541  loss_objectness: 0.4656  loss_dice: 1.297  loss_mask: 0.1507    time: 0.1701  last_time: 0.1710  data_time: 0.0030  last_data_time: 0.0028   lr: 2.6973e-05  max_mem: 1616M
[11/23 00:05:22] d2.utils.events INFO:  eta: 0:41:01  iter: 559  total_loss: 2.281  loss_ce: 0.5185  loss_objectness: 0.508  loss_dice: 1.136  loss_mask: 0.1013    time: 0.1701  last_time: 0.1605  data_time: 0.0029  last_data_time: 0.0032   lr: 2.7972e-05  max_mem: 1616M
[11/23 00:05:25] d2.utils.events INFO:  eta: 0:40:57  iter: 579  total_loss: 2.389  loss_ce: 0.572  loss_objectness: 0.5135  loss_dice: 1.114  loss_mask: 0.1396    time: 0.1699  last_time: 0.1637  data_time: 0.0028  last_data_time: 0.0028   lr: 2.8971e-05  max_mem: 1616M
[11/23 00:05:29] d2.utils.events INFO:  eta: 0:40:53  iter: 599  total_loss: 2.362  loss_ce: 0.5434  loss_objectness: 0.4951  loss_dice: 1.2  loss_mask: 0.103    time: 0.1699  last_time: 0.1729  data_time: 0.0031  last_data_time: 0.0041   lr: 2.997e-05  max_mem: 1616M
[11/23 00:05:32] d2.utils.events INFO:  eta: 0:40:50  iter: 619  total_loss: 2.367  loss_ce: 0.5514  loss_objectness: 0.5274  loss_dice: 1.143  loss_mask: 0.09896    time: 0.1700  last_time: 0.1713  data_time: 0.0029  last_data_time: 0.0028   lr: 3.0969e-05  max_mem: 1616M
[11/23 00:05:35] d2.utils.events INFO:  eta: 0:40:48  iter: 639  total_loss: 2.357  loss_ce: 0.5609  loss_objectness: 0.5001  loss_dice: 1.177  loss_mask: 0.1259    time: 0.1701  last_time: 0.1741  data_time: 0.0029  last_data_time: 0.0028   lr: 3.1968e-05  max_mem: 1616M
[11/23 00:05:39] d2.utils.events INFO:  eta: 0:40:45  iter: 659  total_loss: 2.573  loss_ce: 0.6086  loss_objectness: 0.4719  loss_dice: 1.293  loss_mask: 0.1579    time: 0.1701  last_time: 0.1693  data_time: 0.0031  last_data_time: 0.0023   lr: 3.2967e-05  max_mem: 1616M
[11/23 00:05:42] d2.utils.events INFO:  eta: 0:40:41  iter: 679  total_loss: 2.523  loss_ce: 0.6459  loss_objectness: 0.4603  loss_dice: 1.245  loss_mask: 0.1734    time: 0.1702  last_time: 0.1749  data_time: 0.0029  last_data_time: 0.0028   lr: 3.3966e-05  max_mem: 1616M
[11/23 00:05:46] d2.utils.events INFO:  eta: 0:40:38  iter: 699  total_loss: 2.507  loss_ce: 0.6083  loss_objectness: 0.4984  loss_dice: 1.206  loss_mask: 0.1238    time: 0.1702  last_time: 0.1701  data_time: 0.0029  last_data_time: 0.0027   lr: 3.4965e-05  max_mem: 1616M
[11/23 00:05:49] d2.utils.events INFO:  eta: 0:40:35  iter: 719  total_loss: 2.583  loss_ce: 0.6554  loss_objectness: 0.5364  loss_dice: 1.211  loss_mask: 0.1631    time: 0.1702  last_time: 0.1756  data_time: 0.0029  last_data_time: 0.0032   lr: 3.5964e-05  max_mem: 1616M
[11/23 00:05:53] d2.utils.events INFO:  eta: 0:40:31  iter: 739  total_loss: 2.52  loss_ce: 0.747  loss_objectness: 0.4762  loss_dice: 1.297  loss_mask: 0.1137    time: 0.1703  last_time: 0.1691  data_time: 0.0029  last_data_time: 0.0025   lr: 3.6963e-05  max_mem: 1616M
[11/23 00:05:56] d2.utils.events INFO:  eta: 0:40:28  iter: 759  total_loss: 2.376  loss_ce: 0.5756  loss_objectness: 0.4761  loss_dice: 1.251  loss_mask: 0.114    time: 0.1703  last_time: 0.1728  data_time: 0.0029  last_data_time: 0.0027   lr: 3.7962e-05  max_mem: 1616M
[11/23 00:06:00] d2.utils.events INFO:  eta: 0:40:25  iter: 779  total_loss: 2.486  loss_ce: 0.6323  loss_objectness: 0.4985  loss_dice: 1.194  loss_mask: 0.1176    time: 0.1703  last_time: 0.1754  data_time: 0.0029  last_data_time: 0.0037   lr: 3.8961e-05  max_mem: 1616M
[11/23 00:06:03] d2.utils.events INFO:  eta: 0:40:22  iter: 799  total_loss: 2.377  loss_ce: 0.584  loss_objectness: 0.5112  loss_dice: 1.219  loss_mask: 0.088    time: 0.1704  last_time: 0.1769  data_time: 0.0030  last_data_time: 0.0039   lr: 3.996e-05  max_mem: 1616M
[11/23 00:06:06] d2.utils.events INFO:  eta: 0:40:19  iter: 819  total_loss: 2.209  loss_ce: 0.4929  loss_objectness: 0.5954  loss_dice: 0.9235  loss_mask: 0.1254    time: 0.1704  last_time: 0.1714  data_time: 0.0028  last_data_time: 0.0029   lr: 4.0959e-05  max_mem: 1616M
[11/23 00:06:10] d2.utils.events INFO:  eta: 0:40:15  iter: 839  total_loss: 2.331  loss_ce: 0.5517  loss_objectness: 0.5332  loss_dice: 1.118  loss_mask: 0.08646    time: 0.1704  last_time: 0.1710  data_time: 0.0029  last_data_time: 0.0024   lr: 4.1958e-05  max_mem: 1616M
[11/23 00:06:13] d2.utils.events INFO:  eta: 0:40:12  iter: 859  total_loss: 2.329  loss_ce: 0.6647  loss_objectness: 0.5286  loss_dice: 1.106  loss_mask: 0.1271    time: 0.1704  last_time: 0.1722  data_time: 0.0030  last_data_time: 0.0033   lr: 4.2957e-05  max_mem: 1616M
[11/23 00:06:17] d2.utils.events INFO:  eta: 0:40:09  iter: 879  total_loss: 2.336  loss_ce: 0.5607  loss_objectness: 0.5559  loss_dice: 1.026  loss_mask: 0.1101    time: 0.1704  last_time: 0.1718  data_time: 0.0029  last_data_time: 0.0025   lr: 4.3956e-05  max_mem: 1616M
[11/23 00:06:20] d2.utils.events INFO:  eta: 0:40:06  iter: 899  total_loss: 2.379  loss_ce: 0.5555  loss_objectness: 0.56  loss_dice: 1.073  loss_mask: 0.1062    time: 0.1704  last_time: 0.1707  data_time: 0.0029  last_data_time: 0.0034   lr: 4.4955e-05  max_mem: 1616M
[11/23 00:06:24] d2.utils.events INFO:  eta: 0:40:02  iter: 919  total_loss: 2.342  loss_ce: 0.6085  loss_objectness: 0.5196  loss_dice: 1.077  loss_mask: 0.09005    time: 0.1704  last_time: 0.1702  data_time: 0.0029  last_data_time: 0.0030   lr: 4.5954e-05  max_mem: 1616M
[11/23 00:06:27] d2.utils.events INFO:  eta: 0:39:59  iter: 939  total_loss: 2.291  loss_ce: 0.6231  loss_objectness: 0.6059  loss_dice: 0.9646  loss_mask: 0.09359    time: 0.1704  last_time: 0.1703  data_time: 0.0029  last_data_time: 0.0029   lr: 4.6953e-05  max_mem: 1616M
[11/23 00:06:30] d2.utils.events INFO:  eta: 0:39:56  iter: 959  total_loss: 2.215  loss_ce: 0.5183  loss_objectness: 0.5602  loss_dice: 0.9914  loss_mask: 0.09643    time: 0.1705  last_time: 0.1709  data_time: 0.0032  last_data_time: 0.0024   lr: 4.7952e-05  max_mem: 1616M
[11/23 00:06:34] d2.utils.events INFO:  eta: 0:39:52  iter: 979  total_loss: 2.276  loss_ce: 0.5946  loss_objectness: 0.5645  loss_dice: 0.9703  loss_mask: 0.1209    time: 0.1705  last_time: 0.1692  data_time: 0.0029  last_data_time: 0.0027   lr: 4.8951e-05  max_mem: 1616M
[11/23 00:06:37] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/23 00:06:37] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   crack    | 376          |
|            |              |[0m
[11/23 00:06:37] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/23 00:06:37] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/23 00:06:37] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/23 00:06:37] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/23 00:06:37] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/23 00:06:45] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0004 s/iter. Inference: 0.0358 s/iter. Eval: 0.0512 s/iter. Total: 0.0874 s/iter. ETA=0:00:09
[11/23 00:06:50] d2.evaluation.evaluator INFO: Inference done 78/120. Dataloading: 0.0005 s/iter. Inference: 0.0256 s/iter. Eval: 0.0501 s/iter. Total: 0.0763 s/iter. ETA=0:00:03
[11/23 00:06:54] d2.evaluation.evaluator INFO: Total inference time: 0:00:09.728377 (0.084595 s / iter per device, on 1 devices)
[11/23 00:06:54] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.025874 s / iter per device, on 1 devices)
[11/23 00:06:55] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/23 00:06:55] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_gabor_turbo\inference\coco_instances_results.json
[11/23 00:06:55] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/23 00:06:55] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/23 00:06:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.08 seconds.
[11/23 00:06:55] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/23 00:06:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/23 00:06:55] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 3.935 | 10.653 | 2.609  | 0.021 | 8.317 | 31.388 |
[11/23 00:06:55] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/23 00:06:55] d2.evaluation.testing INFO: copypaste: Task: segm
[11/23 00:06:55] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/23 00:06:55] d2.evaluation.testing INFO: copypaste: 3.9350,10.6533,2.6086,0.0205,8.3168,31.3882
[11/23 00:06:55] d2.utils.events INFO:  eta: 0:39:49  iter: 999  total_loss: 2.353  loss_ce: 0.6406  loss_objectness: 0.5478  loss_dice: 1.081  loss_mask: 0.08285    time: 0.1705  last_time: 0.1699  data_time: 0.0031  last_data_time: 0.0026   lr: 4.995e-05  max_mem: 1616M
[11/23 00:06:59] d2.utils.events INFO:  eta: 0:39:47  iter: 1019  total_loss: 2.394  loss_ce: 0.6247  loss_objectness: 0.5466  loss_dice: 1.076  loss_mask: 0.09969    time: 0.1709  last_time: 0.1777  data_time: 0.0033  last_data_time: 0.0028   lr: 5e-05  max_mem: 1616M
[11/23 00:07:02] d2.utils.events INFO:  eta: 0:39:45  iter: 1039  total_loss: 2.221  loss_ce: 0.5314  loss_objectness: 0.5455  loss_dice: 1.017  loss_mask: 0.09586    time: 0.1709  last_time: 0.1767  data_time: 0.0031  last_data_time: 0.0030   lr: 5e-05  max_mem: 1616M
[11/23 00:07:06] d2.utils.events INFO:  eta: 0:39:42  iter: 1059  total_loss: 2.229  loss_ce: 0.5651  loss_objectness: 0.5818  loss_dice: 0.9993  loss_mask: 0.1024    time: 0.1709  last_time: 0.1696  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1616M
[11/23 00:07:09] d2.utils.events INFO:  eta: 0:39:40  iter: 1079  total_loss: 2.285  loss_ce: 0.5586  loss_objectness: 0.5568  loss_dice: 0.997  loss_mask: 0.0938    time: 0.1709  last_time: 0.1685  data_time: 0.0030  last_data_time: 0.0030   lr: 5e-05  max_mem: 1616M
[11/23 00:07:13] d2.utils.events INFO:  eta: 0:39:36  iter: 1099  total_loss: 2.266  loss_ce: 0.6236  loss_objectness: 0.5958  loss_dice: 0.9742  loss_mask: 0.08852    time: 0.1709  last_time: 0.1705  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-05  max_mem: 1616M
[11/23 00:07:16] d2.utils.events INFO:  eta: 0:39:33  iter: 1119  total_loss: 2.27  loss_ce: 0.5485  loss_objectness: 0.5526  loss_dice: 1.061  loss_mask: 0.0899    time: 0.1709  last_time: 0.1714  data_time: 0.0030  last_data_time: 0.0031   lr: 5e-05  max_mem: 1616M
[11/23 00:07:19] d2.utils.events INFO:  eta: 0:39:30  iter: 1139  total_loss: 2.157  loss_ce: 0.5126  loss_objectness: 0.5929  loss_dice: 0.9435  loss_mask: 0.09068    time: 0.1710  last_time: 0.1705  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-05  max_mem: 1616M
[11/23 00:07:23] d2.utils.events INFO:  eta: 0:39:27  iter: 1159  total_loss: 2.156  loss_ce: 0.5357  loss_objectness: 0.6085  loss_dice: 0.9384  loss_mask: 0.07076    time: 0.1710  last_time: 0.1681  data_time: 0.0030  last_data_time: 0.0024   lr: 5e-05  max_mem: 1616M
[11/23 00:07:26] d2.utils.events INFO:  eta: 0:39:24  iter: 1179  total_loss: 2.3  loss_ce: 0.5826  loss_objectness: 0.5358  loss_dice: 1.082  loss_mask: 0.0756    time: 0.1710  last_time: 0.1728  data_time: 0.0030  last_data_time: 0.0025   lr: 5e-05  max_mem: 1616M
[11/23 00:07:30] d2.utils.events INFO:  eta: 0:39:21  iter: 1199  total_loss: 2.195  loss_ce: 0.5854  loss_objectness: 0.5988  loss_dice: 0.8557  loss_mask: 0.0868    time: 0.1710  last_time: 0.1719  data_time: 0.0031  last_data_time: 0.0033   lr: 5e-05  max_mem: 1616M
[11/23 00:07:33] d2.utils.events INFO:  eta: 0:39:17  iter: 1219  total_loss: 2.246  loss_ce: 0.5934  loss_objectness: 0.6191  loss_dice: 0.9172  loss_mask: 0.1162    time: 0.1710  last_time: 0.1706  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-05  max_mem: 1616M
[11/23 00:07:37] d2.utils.events INFO:  eta: 0:39:14  iter: 1239  total_loss: 2.103  loss_ce: 0.5346  loss_objectness: 0.6322  loss_dice: 0.8409  loss_mask: 0.09367    time: 0.1711  last_time: 0.1701  data_time: 0.0037  last_data_time: 0.0025   lr: 5e-05  max_mem: 1616M
[11/23 00:07:40] d2.utils.events INFO:  eta: 0:39:11  iter: 1259  total_loss: 2.207  loss_ce: 0.5709  loss_objectness: 0.5945  loss_dice: 0.9432  loss_mask: 0.09477    time: 0.1711  last_time: 0.1701  data_time: 0.0030  last_data_time: 0.0033   lr: 5e-05  max_mem: 1616M
[11/23 00:07:44] d2.utils.events INFO:  eta: 0:39:07  iter: 1279  total_loss: 2.231  loss_ce: 0.5722  loss_objectness: 0.5951  loss_dice: 0.9634  loss_mask: 0.0725    time: 0.1711  last_time: 0.1695  data_time: 0.0032  last_data_time: 0.0030   lr: 5e-05  max_mem: 1616M
[11/23 00:07:47] d2.utils.events INFO:  eta: 0:39:03  iter: 1299  total_loss: 2.088  loss_ce: 0.5582  loss_objectness: 0.6329  loss_dice: 0.7854  loss_mask: 0.08393    time: 0.1711  last_time: 0.1690  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1616M
[11/23 00:07:50] d2.utils.events INFO:  eta: 0:39:00  iter: 1319  total_loss: 2.157  loss_ce: 0.5088  loss_objectness: 0.6399  loss_dice: 0.8601  loss_mask: 0.0924    time: 0.1711  last_time: 0.1702  data_time: 0.0030  last_data_time: 0.0023   lr: 5e-05  max_mem: 1616M
[11/23 00:07:54] d2.utils.events INFO:  eta: 0:38:56  iter: 1339  total_loss: 2.142  loss_ce: 0.5818  loss_objectness: 0.6223  loss_dice: 0.8752  loss_mask: 0.06792    time: 0.1711  last_time: 0.1713  data_time: 0.0030  last_data_time: 0.0022   lr: 5e-05  max_mem: 1616M
[11/23 00:07:57] d2.utils.events INFO:  eta: 0:38:53  iter: 1359  total_loss: 2.035  loss_ce: 0.4687  loss_objectness: 0.6436  loss_dice: 0.816  loss_mask: 0.07817    time: 0.1711  last_time: 0.1706  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1616M
[11/23 00:08:01] d2.utils.events INFO:  eta: 0:38:49  iter: 1379  total_loss: 2.196  loss_ce: 0.5849  loss_objectness: 0.6225  loss_dice: 0.8868  loss_mask: 0.09707    time: 0.1711  last_time: 0.1730  data_time: 0.0030  last_data_time: 0.0024   lr: 5e-05  max_mem: 1616M
[11/23 00:08:04] d2.utils.events INFO:  eta: 0:38:46  iter: 1399  total_loss: 2.133  loss_ce: 0.5738  loss_objectness: 0.6189  loss_dice: 0.817  loss_mask: 0.09114    time: 0.1711  last_time: 0.1692  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-05  max_mem: 1616M
[11/23 00:08:08] d2.utils.events INFO:  eta: 0:38:43  iter: 1419  total_loss: 2.115  loss_ce: 0.5795  loss_objectness: 0.6258  loss_dice: 0.8677  loss_mask: 0.06902    time: 0.1711  last_time: 0.1768  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-05  max_mem: 1616M
[11/23 00:08:11] d2.utils.events INFO:  eta: 0:38:39  iter: 1439  total_loss: 2.189  loss_ce: 0.5414  loss_objectness: 0.6101  loss_dice: 0.8946  loss_mask: 0.07489    time: 0.1711  last_time: 0.1754  data_time: 0.0031  last_data_time: 0.0040   lr: 5e-05  max_mem: 1616M
[11/23 00:08:14] d2.utils.events INFO:  eta: 0:38:36  iter: 1459  total_loss: 2.06  loss_ce: 0.5564  loss_objectness: 0.6169  loss_dice: 0.7746  loss_mask: 0.07299    time: 0.1711  last_time: 0.1728  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-05  max_mem: 1616M
[11/23 00:08:18] d2.utils.events INFO:  eta: 0:38:32  iter: 1479  total_loss: 2.173  loss_ce: 0.5948  loss_objectness: 0.626  loss_dice: 0.8618  loss_mask: 0.09281    time: 0.1711  last_time: 0.1685  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1616M
[11/23 00:08:21] d2.utils.events INFO:  eta: 0:38:29  iter: 1499  total_loss: 2.156  loss_ce: 0.523  loss_objectness: 0.5855  loss_dice: 0.8633  loss_mask: 0.08613    time: 0.1711  last_time: 0.1700  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1616M
[11/23 00:08:25] d2.utils.events INFO:  eta: 0:38:25  iter: 1519  total_loss: 2.1  loss_ce: 0.523  loss_objectness: 0.613  loss_dice: 0.8573  loss_mask: 0.06469    time: 0.1711  last_time: 0.1720  data_time: 0.0030  last_data_time: 0.0029   lr: 5e-05  max_mem: 1616M
[11/23 00:08:28] d2.utils.events INFO:  eta: 0:38:22  iter: 1539  total_loss: 2.141  loss_ce: 0.5064  loss_objectness: 0.6498  loss_dice: 0.8153  loss_mask: 0.1077    time: 0.1711  last_time: 0.1728  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1616M
[11/23 00:08:32] d2.utils.events INFO:  eta: 0:38:18  iter: 1559  total_loss: 2.131  loss_ce: 0.5603  loss_objectness: 0.6155  loss_dice: 0.8535  loss_mask: 0.0846    time: 0.1711  last_time: 0.1717  data_time: 0.0029  last_data_time: 0.0022   lr: 5e-05  max_mem: 1616M
[11/23 00:08:35] d2.utils.events INFO:  eta: 0:38:15  iter: 1579  total_loss: 2.149  loss_ce: 0.5574  loss_objectness: 0.6291  loss_dice: 0.853  loss_mask: 0.0954    time: 0.1711  last_time: 0.1693  data_time: 0.0034  last_data_time: 0.0029   lr: 5e-05  max_mem: 1616M
[11/23 00:08:39] d2.utils.events INFO:  eta: 0:38:12  iter: 1599  total_loss: 2.144  loss_ce: 0.5829  loss_objectness: 0.6122  loss_dice: 0.8239  loss_mask: 0.08519    time: 0.1711  last_time: 0.1765  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1616M
[11/23 00:08:42] d2.utils.events INFO:  eta: 0:38:08  iter: 1619  total_loss: 2.022  loss_ce: 0.5529  loss_objectness: 0.658  loss_dice: 0.7946  loss_mask: 0.05702    time: 0.1712  last_time: 0.1701  data_time: 0.0030  last_data_time: 0.0030   lr: 5e-05  max_mem: 1616M
[11/23 00:08:45] d2.utils.events INFO:  eta: 0:38:05  iter: 1639  total_loss: 2.024  loss_ce: 0.4748  loss_objectness: 0.638  loss_dice: 0.7581  loss_mask: 0.08975    time: 0.1711  last_time: 0.1715  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1616M
[11/23 00:08:49] d2.utils.events INFO:  eta: 0:38:01  iter: 1659  total_loss: 2.068  loss_ce: 0.5454  loss_objectness: 0.6435  loss_dice: 0.81  loss_mask: 0.06615    time: 0.1711  last_time: 0.1692  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1616M
[11/23 00:08:52] d2.utils.events INFO:  eta: 0:37:58  iter: 1679  total_loss: 2.069  loss_ce: 0.5731  loss_objectness: 0.6257  loss_dice: 0.7803  loss_mask: 0.08082    time: 0.1711  last_time: 0.1696  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1616M
[11/23 00:08:56] d2.utils.events INFO:  eta: 0:37:54  iter: 1699  total_loss: 2.138  loss_ce: 0.5313  loss_objectness: 0.6248  loss_dice: 0.8825  loss_mask: 0.07619    time: 0.1711  last_time: 0.1690  data_time: 0.0031  last_data_time: 0.0036   lr: 5e-05  max_mem: 1616M
[11/23 00:08:59] d2.utils.events INFO:  eta: 0:37:51  iter: 1719  total_loss: 2.064  loss_ce: 0.5162  loss_objectness: 0.6395  loss_dice: 0.8387  loss_mask: 0.08926    time: 0.1711  last_time: 0.1747  data_time: 0.0030  last_data_time: 0.0043   lr: 5e-05  max_mem: 1616M
[11/23 00:09:03] d2.utils.events INFO:  eta: 0:37:48  iter: 1739  total_loss: 2.037  loss_ce: 0.5321  loss_objectness: 0.6306  loss_dice: 0.7869  loss_mask: 0.0669    time: 0.1711  last_time: 0.1723  data_time: 0.0029  last_data_time: 0.0037   lr: 5e-05  max_mem: 1616M
[11/23 00:09:06] d2.utils.events INFO:  eta: 0:37:44  iter: 1759  total_loss: 2.07  loss_ce: 0.5341  loss_objectness: 0.6535  loss_dice: 0.7865  loss_mask: 0.06557    time: 0.1712  last_time: 0.1697  data_time: 0.0030  last_data_time: 0.0029   lr: 5e-05  max_mem: 1616M
[11/23 00:09:09] d2.utils.events INFO:  eta: 0:37:41  iter: 1779  total_loss: 2.015  loss_ce: 0.5317  loss_objectness: 0.6375  loss_dice: 0.7079  loss_mask: 0.07763    time: 0.1712  last_time: 0.1712  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1616M
[11/23 00:09:13] d2.utils.events INFO:  eta: 0:37:37  iter: 1799  total_loss: 2.021  loss_ce: 0.495  loss_objectness: 0.653  loss_dice: 0.7821  loss_mask: 0.08214    time: 0.1711  last_time: 0.1749  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1616M
[11/23 00:09:16] d2.utils.events INFO:  eta: 0:37:34  iter: 1819  total_loss: 2.144  loss_ce: 0.5117  loss_objectness: 0.6261  loss_dice: 0.8851  loss_mask: 0.06838    time: 0.1711  last_time: 0.1700  data_time: 0.0031  last_data_time: 0.0036   lr: 5e-05  max_mem: 1616M
[11/23 00:09:20] d2.utils.events INFO:  eta: 0:37:31  iter: 1839  total_loss: 2.02  loss_ce: 0.5324  loss_objectness: 0.6391  loss_dice: 0.7789  loss_mask: 0.06805    time: 0.1711  last_time: 0.1713  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-05  max_mem: 1616M
[11/23 00:09:23] d2.utils.events INFO:  eta: 0:37:27  iter: 1859  total_loss: 2.044  loss_ce: 0.53  loss_objectness: 0.6416  loss_dice: 0.7315  loss_mask: 0.06462    time: 0.1711  last_time: 0.1716  data_time: 0.0030  last_data_time: 0.0024   lr: 5e-05  max_mem: 1616M
[11/23 00:09:27] d2.utils.events INFO:  eta: 0:37:24  iter: 1879  total_loss: 2.099  loss_ce: 0.5854  loss_objectness: 0.6411  loss_dice: 0.7993  loss_mask: 0.06349    time: 0.1711  last_time: 0.1759  data_time: 0.0031  last_data_time: 0.0025   lr: 5e-05  max_mem: 1616M
[11/23 00:09:30] d2.utils.events INFO:  eta: 0:37:20  iter: 1899  total_loss: 2.02  loss_ce: 0.5455  loss_objectness: 0.6488  loss_dice: 0.6982  loss_mask: 0.08093    time: 0.1712  last_time: 0.1737  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1616M
[11/23 00:09:34] d2.utils.events INFO:  eta: 0:37:17  iter: 1919  total_loss: 1.934  loss_ce: 0.4725  loss_objectness: 0.6401  loss_dice: 0.7362  loss_mask: 0.0766    time: 0.1712  last_time: 0.1720  data_time: 0.0031  last_data_time: 0.0025   lr: 5e-05  max_mem: 1616M
[11/23 00:09:37] d2.utils.events INFO:  eta: 0:37:14  iter: 1939  total_loss: 2.037  loss_ce: 0.5166  loss_objectness: 0.6421  loss_dice: 0.7847  loss_mask: 0.06051    time: 0.1712  last_time: 0.1691  data_time: 0.0031  last_data_time: 0.0030   lr: 5e-05  max_mem: 1616M
[11/23 00:09:40] d2.utils.events INFO:  eta: 0:37:10  iter: 1959  total_loss: 1.953  loss_ce: 0.5291  loss_objectness: 0.6527  loss_dice: 0.6482  loss_mask: 0.07234    time: 0.1712  last_time: 0.1754  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-05  max_mem: 1616M
[11/23 00:09:44] d2.utils.events INFO:  eta: 0:37:07  iter: 1979  total_loss: 2.066  loss_ce: 0.6081  loss_objectness: 0.6658  loss_dice: 0.7338  loss_mask: 0.06435    time: 0.1712  last_time: 0.1725  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1616M
[11/23 00:09:47] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/23 00:09:47] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/23 00:09:47] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/23 00:09:47] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/23 00:09:47] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/23 00:09:47] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/23 00:09:53] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0235 s/iter. Eval: 0.0535 s/iter. Total: 0.0774 s/iter. ETA=0:00:08
[11/23 00:09:58] d2.evaluation.evaluator INFO: Inference done 79/120. Dataloading: 0.0005 s/iter. Inference: 0.0238 s/iter. Eval: 0.0497 s/iter. Total: 0.0740 s/iter. ETA=0:00:03
[11/23 00:10:02] d2.evaluation.evaluator INFO: Total inference time: 0:00:09.478664 (0.082423 s / iter per device, on 1 devices)
[11/23 00:10:02] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.024302 s / iter per device, on 1 devices)
[11/23 00:10:03] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/23 00:10:03] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_gabor_turbo\inference\coco_instances_results.json
[11/23 00:10:03] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/23 00:10:03] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/23 00:10:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.11 seconds.
[11/23 00:10:03] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/23 00:10:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/23 00:10:03] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 5.624 | 14.722 | 3.757  | 0.063 | 12.361 | 34.280 |
[11/23 00:10:03] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/23 00:10:03] d2.evaluation.testing INFO: copypaste: Task: segm
[11/23 00:10:03] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/23 00:10:03] d2.evaluation.testing INFO: copypaste: 5.6239,14.7217,3.7574,0.0627,12.3612,34.2805
[11/23 00:10:03] d2.utils.events INFO:  eta: 0:37:03  iter: 1999  total_loss: 2.05  loss_ce: 0.527  loss_objectness: 0.6367  loss_dice: 0.6673  loss_mask: 0.0845    time: 0.1712  last_time: 0.1699  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-05  max_mem: 1616M
[11/23 00:10:06] d2.utils.events INFO:  eta: 0:36:59  iter: 2019  total_loss: 2.119  loss_ce: 0.5755  loss_objectness: 0.6215  loss_dice: 0.811  loss_mask: 0.06941    time: 0.1712  last_time: 0.1725  data_time: 0.0033  last_data_time: 0.0027   lr: 5e-05  max_mem: 1616M
[11/23 00:10:10] d2.utils.events INFO:  eta: 0:36:55  iter: 2039  total_loss: 1.995  loss_ce: 0.572  loss_objectness: 0.6382  loss_dice: 0.7481  loss_mask: 0.06574    time: 0.1712  last_time: 0.1703  data_time: 0.0030  last_data_time: 0.0032   lr: 5e-05  max_mem: 1616M
[11/23 00:10:13] d2.utils.events INFO:  eta: 0:36:52  iter: 2059  total_loss: 1.881  loss_ce: 0.5129  loss_objectness: 0.681  loss_dice: 0.6203  loss_mask: 0.07222    time: 0.1712  last_time: 0.1699  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1616M
[11/23 00:10:17] d2.utils.events INFO:  eta: 0:36:48  iter: 2079  total_loss: 1.992  loss_ce: 0.5502  loss_objectness: 0.6488  loss_dice: 0.6615  loss_mask: 0.07873    time: 0.1712  last_time: 0.1695  data_time: 0.0028  last_data_time: 0.0022   lr: 5e-05  max_mem: 1616M
[11/23 00:10:20] d2.utils.events INFO:  eta: 0:36:45  iter: 2099  total_loss: 1.994  loss_ce: 0.5213  loss_objectness: 0.6026  loss_dice: 0.7713  loss_mask: 0.06831    time: 0.1712  last_time: 0.1732  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-05  max_mem: 1616M
[11/23 00:10:24] d2.utils.events INFO:  eta: 0:36:41  iter: 2119  total_loss: 1.945  loss_ce: 0.4427  loss_objectness: 0.6605  loss_dice: 0.7194  loss_mask: 0.09208    time: 0.1712  last_time: 0.1730  data_time: 0.0030  last_data_time: 0.0039   lr: 5e-05  max_mem: 1616M
[11/23 00:10:27] d2.utils.events INFO:  eta: 0:36:38  iter: 2139  total_loss: 2.048  loss_ce: 0.5432  loss_objectness: 0.6363  loss_dice: 0.7709  loss_mask: 0.06656    time: 0.1712  last_time: 0.1715  data_time: 0.0035  last_data_time: 0.0044   lr: 5e-05  max_mem: 1616M
[11/23 00:10:30] d2.utils.events INFO:  eta: 0:36:35  iter: 2159  total_loss: 1.951  loss_ce: 0.5732  loss_objectness: 0.6476  loss_dice: 0.6636  loss_mask: 0.05339    time: 0.1712  last_time: 0.1708  data_time: 0.0030  last_data_time: 0.0028   lr: 5e-05  max_mem: 1616M
[11/23 00:10:34] d2.utils.events INFO:  eta: 0:36:31  iter: 2179  total_loss: 2.015  loss_ce: 0.4775  loss_objectness: 0.6414  loss_dice: 0.7451  loss_mask: 0.0937    time: 0.1712  last_time: 0.1705  data_time: 0.0029  last_data_time: 0.0033   lr: 5e-05  max_mem: 1616M
[11/23 00:10:37] d2.utils.events INFO:  eta: 0:36:28  iter: 2199  total_loss: 1.965  loss_ce: 0.5211  loss_objectness: 0.6558  loss_dice: 0.6081  loss_mask: 0.08311    time: 0.1712  last_time: 0.1700  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1616M
[11/23 00:10:41] d2.utils.events INFO:  eta: 0:36:24  iter: 2219  total_loss: 2.012  loss_ce: 0.5594  loss_objectness: 0.6442  loss_dice: 0.6959  loss_mask: 0.06153    time: 0.1712  last_time: 0.1741  data_time: 0.0031  last_data_time: 0.0031   lr: 5e-05  max_mem: 1616M
[11/23 00:10:44] d2.utils.events INFO:  eta: 0:36:21  iter: 2239  total_loss: 2.247  loss_ce: 0.5863  loss_objectness: 0.5974  loss_dice: 0.8761  loss_mask: 0.08303    time: 0.1712  last_time: 0.1694  data_time: 0.0030  last_data_time: 0.0031   lr: 5e-05  max_mem: 1616M
[11/23 00:10:48] d2.utils.events INFO:  eta: 0:36:17  iter: 2259  total_loss: 2.076  loss_ce: 0.5552  loss_objectness: 0.6365  loss_dice: 0.7972  loss_mask: 0.06593    time: 0.1712  last_time: 0.1696  data_time: 0.0030  last_data_time: 0.0027   lr: 5e-05  max_mem: 1616M
[11/23 00:10:51] d2.utils.events INFO:  eta: 0:36:14  iter: 2279  total_loss: 2.106  loss_ce: 0.5936  loss_objectness: 0.6436  loss_dice: 0.7704  loss_mask: 0.07379    time: 0.1712  last_time: 0.1719  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-05  max_mem: 1616M
[11/23 00:10:55] d2.utils.events INFO:  eta: 0:36:10  iter: 2299  total_loss: 2.083  loss_ce: 0.5134  loss_objectness: 0.6545  loss_dice: 0.7712  loss_mask: 0.06279    time: 0.1712  last_time: 0.1725  data_time: 0.0030  last_data_time: 0.0034   lr: 5e-05  max_mem: 1616M
[11/23 00:10:58] d2.utils.events INFO:  eta: 0:36:07  iter: 2319  total_loss: 1.958  loss_ce: 0.5059  loss_objectness: 0.6243  loss_dice: 0.715  loss_mask: 0.06785    time: 0.1712  last_time: 0.1667  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1616M
[11/23 00:11:01] d2.utils.events INFO:  eta: 0:36:04  iter: 2339  total_loss: 1.915  loss_ce: 0.4677  loss_objectness: 0.6354  loss_dice: 0.6999  loss_mask: 0.05446    time: 0.1712  last_time: 0.1707  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1616M
[11/23 00:11:05] d2.utils.events INFO:  eta: 0:36:00  iter: 2359  total_loss: 1.987  loss_ce: 0.4885  loss_objectness: 0.6375  loss_dice: 0.767  loss_mask: 0.0771    time: 0.1712  last_time: 0.1717  data_time: 0.0030  last_data_time: 0.0028   lr: 5e-05  max_mem: 1616M
[11/23 00:11:08] d2.utils.events INFO:  eta: 0:35:57  iter: 2379  total_loss: 1.937  loss_ce: 0.5484  loss_objectness: 0.6735  loss_dice: 0.6089  loss_mask: 0.07224    time: 0.1712  last_time: 0.1700  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1616M
[11/23 00:11:12] d2.utils.events INFO:  eta: 0:35:53  iter: 2399  total_loss: 1.984  loss_ce: 0.5174  loss_objectness: 0.6471  loss_dice: 0.736  loss_mask: 0.07368    time: 0.1712  last_time: 0.1706  data_time: 0.0030  last_data_time: 0.0032   lr: 5e-05  max_mem: 1616M
[11/23 00:11:15] d2.utils.events INFO:  eta: 0:35:49  iter: 2419  total_loss: 1.906  loss_ce: 0.5148  loss_objectness: 0.6534  loss_dice: 0.6861  loss_mask: 0.06656    time: 0.1712  last_time: 0.1702  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-05  max_mem: 1616M
[11/23 00:11:18] d2.utils.events INFO:  eta: 0:35:46  iter: 2439  total_loss: 1.962  loss_ce: 0.5311  loss_objectness: 0.6542  loss_dice: 0.6707  loss_mask: 0.09274    time: 0.1712  last_time: 0.1700  data_time: 0.0030  last_data_time: 0.0027   lr: 5e-05  max_mem: 1616M
[11/23 00:11:22] d2.utils.events INFO:  eta: 0:35:42  iter: 2459  total_loss: 1.855  loss_ce: 0.4969  loss_objectness: 0.6611  loss_dice: 0.6745  loss_mask: 0.06389    time: 0.1712  last_time: 0.1767  data_time: 0.0034  last_data_time: 0.0050   lr: 5e-05  max_mem: 1616M
[11/23 00:11:25] d2.utils.events INFO:  eta: 0:35:39  iter: 2479  total_loss: 1.982  loss_ce: 0.5363  loss_objectness: 0.6604  loss_dice: 0.6879  loss_mask: 0.05432    time: 0.1712  last_time: 0.1705  data_time: 0.0031  last_data_time: 0.0030   lr: 5e-05  max_mem: 1616M
[11/23 00:11:29] d2.utils.events INFO:  eta: 0:35:36  iter: 2499  total_loss: 1.815  loss_ce: 0.4786  loss_objectness: 0.6691  loss_dice: 0.53  loss_mask: 0.05553    time: 0.1712  last_time: 0.1696  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1616M
[11/23 00:11:32] d2.utils.events INFO:  eta: 0:35:32  iter: 2519  total_loss: 1.883  loss_ce: 0.5107  loss_objectness: 0.6645  loss_dice: 0.5905  loss_mask: 0.06199    time: 0.1712  last_time: 0.1705  data_time: 0.0030  last_data_time: 0.0033   lr: 5e-05  max_mem: 1616M
[11/23 00:11:36] d2.utils.events INFO:  eta: 0:35:29  iter: 2539  total_loss: 1.935  loss_ce: 0.501  loss_objectness: 0.6537  loss_dice: 0.7216  loss_mask: 0.04912    time: 0.1712  last_time: 0.1734  data_time: 0.0030  last_data_time: 0.0024   lr: 5e-05  max_mem: 1616M
[11/23 00:11:39] d2.utils.events INFO:  eta: 0:35:26  iter: 2559  total_loss: 2.008  loss_ce: 0.5586  loss_objectness: 0.649  loss_dice: 0.7284  loss_mask: 0.06232    time: 0.1712  last_time: 0.1701  data_time: 0.0035  last_data_time: 0.0035   lr: 5e-05  max_mem: 1616M
[11/23 00:11:43] d2.utils.events INFO:  eta: 0:35:22  iter: 2579  total_loss: 1.887  loss_ce: 0.5589  loss_objectness: 0.6747  loss_dice: 0.576  loss_mask: 0.07273    time: 0.1712  last_time: 0.1705  data_time: 0.0027  last_data_time: 0.0032   lr: 5e-05  max_mem: 1616M
[11/23 00:11:46] d2.utils.events INFO:  eta: 0:35:19  iter: 2599  total_loss: 2.017  loss_ce: 0.5363  loss_objectness: 0.6668  loss_dice: 0.7015  loss_mask: 0.05354    time: 0.1712  last_time: 0.1721  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-05  max_mem: 1616M
[11/23 00:11:49] d2.utils.events INFO:  eta: 0:35:15  iter: 2619  total_loss: 1.864  loss_ce: 0.4744  loss_objectness: 0.6548  loss_dice: 0.5921  loss_mask: 0.09515    time: 0.1712  last_time: 0.1717  data_time: 0.0027  last_data_time: 0.0029   lr: 5e-05  max_mem: 1616M
[11/23 00:11:53] d2.utils.events INFO:  eta: 0:35:12  iter: 2639  total_loss: 1.903  loss_ce: 0.4821  loss_objectness: 0.6641  loss_dice: 0.6489  loss_mask: 0.06414    time: 0.1712  last_time: 0.1700  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1616M
[11/23 00:11:56] d2.utils.events INFO:  eta: 0:35:08  iter: 2659  total_loss: 1.997  loss_ce: 0.5372  loss_objectness: 0.6623  loss_dice: 0.7329  loss_mask: 0.06069    time: 0.1712  last_time: 0.1717  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-05  max_mem: 1616M
[11/23 00:12:00] d2.utils.events INFO:  eta: 0:35:05  iter: 2679  total_loss: 1.859  loss_ce: 0.4859  loss_objectness: 0.6645  loss_dice: 0.6154  loss_mask: 0.07303    time: 0.1712  last_time: 0.1721  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-05  max_mem: 1616M
[11/23 00:12:03] d2.utils.events INFO:  eta: 0:35:02  iter: 2699  total_loss: 1.783  loss_ce: 0.5091  loss_objectness: 0.6732  loss_dice: 0.5027  loss_mask: 0.06073    time: 0.1712  last_time: 0.1691  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1616M
[11/23 00:12:07] d2.utils.events INFO:  eta: 0:34:58  iter: 2719  total_loss: 1.738  loss_ce: 0.512  loss_objectness: 0.6675  loss_dice: 0.5195  loss_mask: 0.05571    time: 0.1712  last_time: 0.1745  data_time: 0.0029  last_data_time: 0.0035   lr: 5e-05  max_mem: 1616M
[11/23 00:12:10] d2.utils.events INFO:  eta: 0:34:55  iter: 2739  total_loss: 1.932  loss_ce: 0.516  loss_objectness: 0.658  loss_dice: 0.6897  loss_mask: 0.05705    time: 0.1712  last_time: 0.1717  data_time: 0.0030  last_data_time: 0.0032   lr: 5e-05  max_mem: 1616M
[11/23 00:12:14] d2.utils.events INFO:  eta: 0:34:51  iter: 2759  total_loss: 2.046  loss_ce: 0.5657  loss_objectness: 0.6356  loss_dice: 0.6972  loss_mask: 0.07394    time: 0.1712  last_time: 0.1697  data_time: 0.0030  last_data_time: 0.0031   lr: 5e-05  max_mem: 1616M
[11/23 00:12:17] d2.utils.events INFO:  eta: 0:34:48  iter: 2779  total_loss: 1.908  loss_ce: 0.4652  loss_objectness: 0.6641  loss_dice: 0.6729  loss_mask: 0.07669    time: 0.1712  last_time: 0.1687  data_time: 0.0031  last_data_time: 0.0027   lr: 5e-05  max_mem: 1616M
[11/23 00:12:20] d2.utils.events INFO:  eta: 0:34:45  iter: 2799  total_loss: 1.97  loss_ce: 0.5457  loss_objectness: 0.6361  loss_dice: 0.6786  loss_mask: 0.06077    time: 0.1712  last_time: 0.1690  data_time: 0.0032  last_data_time: 0.0031   lr: 5e-05  max_mem: 1616M
[11/23 00:12:24] d2.utils.events INFO:  eta: 0:34:41  iter: 2819  total_loss: 1.802  loss_ce: 0.5149  loss_objectness: 0.669  loss_dice: 0.5442  loss_mask: 0.05402    time: 0.1712  last_time: 0.1707  data_time: 0.0030  last_data_time: 0.0030   lr: 5e-05  max_mem: 1617M
[11/23 00:12:27] d2.utils.events INFO:  eta: 0:34:38  iter: 2839  total_loss: 1.817  loss_ce: 0.5154  loss_objectness: 0.6681  loss_dice: 0.5884  loss_mask: 0.05226    time: 0.1712  last_time: 0.1709  data_time: 0.0030  last_data_time: 0.0031   lr: 5e-05  max_mem: 1617M
[11/23 00:12:31] d2.utils.events INFO:  eta: 0:34:34  iter: 2859  total_loss: 1.826  loss_ce: 0.5182  loss_objectness: 0.6574  loss_dice: 0.5411  loss_mask: 0.06281    time: 0.1712  last_time: 0.1729  data_time: 0.0030  last_data_time: 0.0031   lr: 5e-05  max_mem: 1617M
[11/23 00:12:34] d2.utils.events INFO:  eta: 0:34:31  iter: 2879  total_loss: 1.967  loss_ce: 0.5659  loss_objectness: 0.6479  loss_dice: 0.6592  loss_mask: 0.07357    time: 0.1712  last_time: 0.1721  data_time: 0.0031  last_data_time: 0.0037   lr: 5e-05  max_mem: 1617M
[11/23 00:12:38] d2.utils.events INFO:  eta: 0:34:28  iter: 2899  total_loss: 1.915  loss_ce: 0.5344  loss_objectness: 0.66  loss_dice: 0.6398  loss_mask: 0.06539    time: 0.1713  last_time: 0.1705  data_time: 0.0031  last_data_time: 0.0029   lr: 5e-05  max_mem: 1617M
[11/23 00:12:41] d2.utils.events INFO:  eta: 0:34:24  iter: 2919  total_loss: 1.906  loss_ce: 0.5409  loss_objectness: 0.678  loss_dice: 0.6182  loss_mask: 0.07691    time: 0.1713  last_time: 0.1711  data_time: 0.0032  last_data_time: 0.0030   lr: 5e-05  max_mem: 1617M
[11/23 00:12:45] d2.utils.events INFO:  eta: 0:34:20  iter: 2939  total_loss: 1.894  loss_ce: 0.5156  loss_objectness: 0.6309  loss_dice: 0.6061  loss_mask: 0.06822    time: 0.1712  last_time: 0.1715  data_time: 0.0029  last_data_time: 0.0039   lr: 5e-05  max_mem: 1617M
[11/23 00:12:48] d2.utils.events INFO:  eta: 0:34:17  iter: 2959  total_loss: 1.883  loss_ce: 0.5178  loss_objectness: 0.6575  loss_dice: 0.6363  loss_mask: 0.05945    time: 0.1712  last_time: 0.1718  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-05  max_mem: 1617M
[11/23 00:12:51] d2.utils.events INFO:  eta: 0:34:13  iter: 2979  total_loss: 1.886  loss_ce: 0.5248  loss_objectness: 0.6435  loss_dice: 0.7164  loss_mask: 0.06011    time: 0.1712  last_time: 0.1731  data_time: 0.0030  last_data_time: 0.0029   lr: 5e-05  max_mem: 1617M
[11/23 00:12:55] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/23 00:12:55] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/23 00:12:55] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/23 00:12:55] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/23 00:12:55] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/23 00:12:55] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/23 00:13:01] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0236 s/iter. Eval: 0.0461 s/iter. Total: 0.0701 s/iter. ETA=0:00:07
[11/23 00:13:06] d2.evaluation.evaluator INFO: Inference done 77/120. Dataloading: 0.0005 s/iter. Inference: 0.0254 s/iter. Eval: 0.0504 s/iter. Total: 0.0763 s/iter. ETA=0:00:03
[11/23 00:13:10] d2.evaluation.evaluator INFO: Total inference time: 0:00:09.684650 (0.084214 s / iter per device, on 1 devices)
[11/23 00:13:10] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.025786 s / iter per device, on 1 devices)
[11/23 00:13:10] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/23 00:13:10] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_gabor_turbo\inference\coco_instances_results.json
[11/23 00:13:10] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/23 00:13:10] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/23 00:13:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.07 seconds.
[11/23 00:13:10] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/23 00:13:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/23 00:13:10] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.845 | 15.856 | 5.429  | 0.132 | 15.058 | 44.764 |
[11/23 00:13:10] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/23 00:13:10] d2.evaluation.testing INFO: copypaste: Task: segm
[11/23 00:13:10] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/23 00:13:10] d2.evaluation.testing INFO: copypaste: 6.8454,15.8560,5.4293,0.1323,15.0580,44.7640
[11/23 00:13:10] d2.utils.events INFO:  eta: 0:34:10  iter: 2999  total_loss: 1.713  loss_ce: 0.4442  loss_objectness: 0.6666  loss_dice: 0.5121  loss_mask: 0.07423    time: 0.1712  last_time: 0.1708  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1617M
[11/23 00:13:14] d2.utils.events INFO:  eta: 0:34:06  iter: 3019  total_loss: 1.846  loss_ce: 0.4403  loss_objectness: 0.6727  loss_dice: 0.6089  loss_mask: 0.06423    time: 0.1712  last_time: 0.1696  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-05  max_mem: 1617M
[11/23 00:13:17] d2.utils.events INFO:  eta: 0:34:03  iter: 3039  total_loss: 1.822  loss_ce: 0.4902  loss_objectness: 0.6415  loss_dice: 0.6048  loss_mask: 0.05712    time: 0.1712  last_time: 0.1715  data_time: 0.0030  last_data_time: 0.0032   lr: 5e-05  max_mem: 1617M
[11/23 00:13:21] d2.utils.events INFO:  eta: 0:34:00  iter: 3059  total_loss: 1.834  loss_ce: 0.5079  loss_objectness: 0.6522  loss_dice: 0.5758  loss_mask: 0.0598    time: 0.1712  last_time: 0.1711  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1617M
[11/23 00:13:24] d2.utils.events INFO:  eta: 0:33:56  iter: 3079  total_loss: 1.669  loss_ce: 0.4418  loss_objectness: 0.6401  loss_dice: 0.5269  loss_mask: 0.05228    time: 0.1712  last_time: 0.1713  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1617M
[11/23 00:13:28] d2.utils.events INFO:  eta: 0:33:53  iter: 3099  total_loss: 1.752  loss_ce: 0.4291  loss_objectness: 0.6676  loss_dice: 0.5711  loss_mask: 0.07089    time: 0.1712  last_time: 0.1688  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-05  max_mem: 1617M
[11/23 00:13:31] d2.utils.events INFO:  eta: 0:33:49  iter: 3119  total_loss: 1.848  loss_ce: 0.5151  loss_objectness: 0.6683  loss_dice: 0.5139  loss_mask: 0.06345    time: 0.1712  last_time: 0.1736  data_time: 0.0032  last_data_time: 0.0057   lr: 5e-05  max_mem: 1617M
[11/23 00:13:34] d2.utils.events INFO:  eta: 0:33:45  iter: 3139  total_loss: 1.825  loss_ce: 0.5159  loss_objectness: 0.6544  loss_dice: 0.5361  loss_mask: 0.04791    time: 0.1712  last_time: 0.1715  data_time: 0.0031  last_data_time: 0.0032   lr: 5e-05  max_mem: 1617M
[11/23 00:13:38] d2.utils.events INFO:  eta: 0:33:42  iter: 3159  total_loss: 1.872  loss_ce: 0.4705  loss_objectness: 0.6333  loss_dice: 0.6574  loss_mask: 0.06041    time: 0.1712  last_time: 0.1766  data_time: 0.0031  last_data_time: 0.0027   lr: 5e-05  max_mem: 1617M
[11/23 00:13:41] d2.utils.events INFO:  eta: 0:33:39  iter: 3179  total_loss: 1.835  loss_ce: 0.5222  loss_objectness: 0.6708  loss_dice: 0.5741  loss_mask: 0.06105    time: 0.1713  last_time: 0.1706  data_time: 0.0031  last_data_time: 0.0026   lr: 5e-05  max_mem: 1617M
[11/23 00:13:45] d2.utils.events INFO:  eta: 0:33:36  iter: 3199  total_loss: 1.802  loss_ce: 0.4944  loss_objectness: 0.6547  loss_dice: 0.5647  loss_mask: 0.05683    time: 0.1713  last_time: 0.1717  data_time: 0.0030  last_data_time: 0.0030   lr: 5e-05  max_mem: 1617M
[11/23 00:13:48] d2.utils.events INFO:  eta: 0:33:32  iter: 3219  total_loss: 1.758  loss_ce: 0.4838  loss_objectness: 0.6589  loss_dice: 0.5654  loss_mask: 0.05994    time: 0.1713  last_time: 0.1704  data_time: 0.0031  last_data_time: 0.0034   lr: 5e-05  max_mem: 1617M
[11/23 00:13:52] d2.utils.events INFO:  eta: 0:33:29  iter: 3239  total_loss: 1.845  loss_ce: 0.5017  loss_objectness: 0.6311  loss_dice: 0.5759  loss_mask: 0.0616    time: 0.1713  last_time: 0.1700  data_time: 0.0030  last_data_time: 0.0031   lr: 5e-05  max_mem: 1617M
[11/23 00:13:55] d2.utils.events INFO:  eta: 0:33:25  iter: 3259  total_loss: 1.815  loss_ce: 0.5101  loss_objectness: 0.6755  loss_dice: 0.5242  loss_mask: 0.05958    time: 0.1713  last_time: 0.1713  data_time: 0.0030  last_data_time: 0.0029   lr: 5e-05  max_mem: 1617M
[11/23 00:13:58] d2.utils.events INFO:  eta: 0:33:22  iter: 3279  total_loss: 1.762  loss_ce: 0.4871  loss_objectness: 0.6587  loss_dice: 0.568  loss_mask: 0.05384    time: 0.1713  last_time: 0.1700  data_time: 0.0030  last_data_time: 0.0040   lr: 5e-05  max_mem: 1617M
[11/23 00:14:02] d2.utils.events INFO:  eta: 0:33:18  iter: 3299  total_loss: 1.805  loss_ce: 0.5006  loss_objectness: 0.6478  loss_dice: 0.6003  loss_mask: 0.05843    time: 0.1713  last_time: 0.1739  data_time: 0.0030  last_data_time: 0.0051   lr: 5e-05  max_mem: 1617M
[11/23 00:14:05] d2.utils.events INFO:  eta: 0:33:15  iter: 3319  total_loss: 1.925  loss_ce: 0.5144  loss_objectness: 0.6557  loss_dice: 0.6196  loss_mask: 0.07321    time: 0.1712  last_time: 0.1715  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-05  max_mem: 1617M
[11/23 00:14:09] d2.utils.events INFO:  eta: 0:33:12  iter: 3339  total_loss: 1.811  loss_ce: 0.4934  loss_objectness: 0.6511  loss_dice: 0.5801  loss_mask: 0.05565    time: 0.1712  last_time: 0.1694  data_time: 0.0030  last_data_time: 0.0029   lr: 5e-05  max_mem: 1617M
[11/23 00:14:12] d2.utils.events INFO:  eta: 0:33:08  iter: 3359  total_loss: 1.882  loss_ce: 0.5016  loss_objectness: 0.6582  loss_dice: 0.5916  loss_mask: 0.07849    time: 0.1712  last_time: 0.1718  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1617M
[11/23 00:14:16] d2.utils.events INFO:  eta: 0:33:05  iter: 3379  total_loss: 1.774  loss_ce: 0.4377  loss_objectness: 0.6564  loss_dice: 0.5688  loss_mask: 0.06333    time: 0.1712  last_time: 0.1728  data_time: 0.0031  last_data_time: 0.0046   lr: 5e-05  max_mem: 1617M
[11/23 00:14:19] d2.utils.events INFO:  eta: 0:33:01  iter: 3399  total_loss: 1.726  loss_ce: 0.4461  loss_objectness: 0.6611  loss_dice: 0.5268  loss_mask: 0.0476    time: 0.1712  last_time: 0.1709  data_time: 0.0031  last_data_time: 0.0030   lr: 5e-05  max_mem: 1617M
[11/23 00:14:22] d2.utils.events INFO:  eta: 0:32:58  iter: 3419  total_loss: 1.779  loss_ce: 0.461  loss_objectness: 0.6519  loss_dice: 0.5713  loss_mask: 0.06152    time: 0.1712  last_time: 0.1712  data_time: 0.0028  last_data_time: 0.0035   lr: 5e-05  max_mem: 1617M
[11/23 00:14:26] d2.utils.events INFO:  eta: 0:32:54  iter: 3439  total_loss: 1.625  loss_ce: 0.4641  loss_objectness: 0.6547  loss_dice: 0.4622  loss_mask: 0.04868    time: 0.1712  last_time: 0.1709  data_time: 0.0027  last_data_time: 0.0022   lr: 5e-05  max_mem: 1617M
[11/23 00:14:29] d2.utils.events INFO:  eta: 0:32:51  iter: 3459  total_loss: 1.778  loss_ce: 0.4244  loss_objectness: 0.6712  loss_dice: 0.5578  loss_mask: 0.06826    time: 0.1712  last_time: 0.1713  data_time: 0.0030  last_data_time: 0.0028   lr: 5e-05  max_mem: 1617M
[11/23 00:14:33] d2.utils.events INFO:  eta: 0:32:48  iter: 3479  total_loss: 1.858  loss_ce: 0.5348  loss_objectness: 0.6743  loss_dice: 0.5855  loss_mask: 0.06733    time: 0.1712  last_time: 0.1714  data_time: 0.0030  last_data_time: 0.0027   lr: 5e-05  max_mem: 1617M
[11/23 00:14:36] d2.utils.events INFO:  eta: 0:32:45  iter: 3499  total_loss: 1.727  loss_ce: 0.4596  loss_objectness: 0.6655  loss_dice: 0.492  loss_mask: 0.06792    time: 0.1712  last_time: 0.1697  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-05  max_mem: 1617M
[11/23 00:14:40] d2.utils.events INFO:  eta: 0:32:41  iter: 3519  total_loss: 1.681  loss_ce: 0.4707  loss_objectness: 0.6491  loss_dice: 0.5003  loss_mask: 0.04094    time: 0.1712  last_time: 0.1750  data_time: 0.0029  last_data_time: 0.0044   lr: 5e-05  max_mem: 1617M
[11/23 00:14:43] d2.utils.events INFO:  eta: 0:32:37  iter: 3539  total_loss: 1.775  loss_ce: 0.4657  loss_objectness: 0.6386  loss_dice: 0.5325  loss_mask: 0.04549    time: 0.1712  last_time: 0.1691  data_time: 0.0030  last_data_time: 0.0023   lr: 5e-05  max_mem: 1617M
[11/23 00:14:46] d2.utils.events INFO:  eta: 0:32:34  iter: 3559  total_loss: 1.787  loss_ce: 0.4343  loss_objectness: 0.6605  loss_dice: 0.6109  loss_mask: 0.04216    time: 0.1712  last_time: 0.1722  data_time: 0.0030  last_data_time: 0.0027   lr: 5e-05  max_mem: 1617M
[11/23 00:14:50] d2.utils.events INFO:  eta: 0:32:31  iter: 3579  total_loss: 1.764  loss_ce: 0.4662  loss_objectness: 0.6699  loss_dice: 0.5736  loss_mask: 0.04107    time: 0.1712  last_time: 0.1702  data_time: 0.0030  last_data_time: 0.0027   lr: 5e-05  max_mem: 1617M
[11/23 00:14:53] d2.utils.events INFO:  eta: 0:32:27  iter: 3599  total_loss: 1.69  loss_ce: 0.4608  loss_objectness: 0.6569  loss_dice: 0.4691  loss_mask: 0.06638    time: 0.1712  last_time: 0.1682  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1617M
[11/23 00:14:57] d2.utils.events INFO:  eta: 0:32:24  iter: 3619  total_loss: 1.799  loss_ce: 0.4328  loss_objectness: 0.6469  loss_dice: 0.5363  loss_mask: 0.06506    time: 0.1712  last_time: 0.1706  data_time: 0.0030  last_data_time: 0.0032   lr: 5e-05  max_mem: 1617M
[11/23 00:15:00] d2.utils.events INFO:  eta: 0:32:20  iter: 3639  total_loss: 1.705  loss_ce: 0.4118  loss_objectness: 0.68  loss_dice: 0.4614  loss_mask: 0.06715    time: 0.1712  last_time: 0.1702  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1617M
[11/23 00:15:04] d2.utils.events INFO:  eta: 0:32:17  iter: 3659  total_loss: 1.75  loss_ce: 0.4505  loss_objectness: 0.6549  loss_dice: 0.5187  loss_mask: 0.04977    time: 0.1712  last_time: 0.1727  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1617M
[11/23 00:15:07] d2.utils.events INFO:  eta: 0:32:13  iter: 3679  total_loss: 1.848  loss_ce: 0.5296  loss_objectness: 0.6454  loss_dice: 0.5788  loss_mask: 0.04958    time: 0.1712  last_time: 0.1743  data_time: 0.0030  last_data_time: 0.0030   lr: 5e-05  max_mem: 1617M
[11/23 00:15:10] d2.utils.events INFO:  eta: 0:32:10  iter: 3699  total_loss: 1.626  loss_ce: 0.4542  loss_objectness: 0.6656  loss_dice: 0.4931  loss_mask: 0.0575    time: 0.1712  last_time: 0.1689  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1617M
[11/23 00:15:14] d2.utils.events INFO:  eta: 0:32:06  iter: 3719  total_loss: 1.603  loss_ce: 0.4491  loss_objectness: 0.6175  loss_dice: 0.438  loss_mask: 0.05892    time: 0.1712  last_time: 0.1718  data_time: 0.0029  last_data_time: 0.0044   lr: 5e-05  max_mem: 1617M
[11/23 00:15:17] d2.utils.events INFO:  eta: 0:32:03  iter: 3739  total_loss: 1.738  loss_ce: 0.4452  loss_objectness: 0.6548  loss_dice: 0.5683  loss_mask: 0.05342    time: 0.1712  last_time: 0.1743  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-05  max_mem: 1617M
[11/23 00:15:21] d2.utils.events INFO:  eta: 0:31:59  iter: 3759  total_loss: 1.742  loss_ce: 0.5007  loss_objectness: 0.6639  loss_dice: 0.491  loss_mask: 0.04822    time: 0.1712  last_time: 0.1708  data_time: 0.0030  last_data_time: 0.0033   lr: 5e-05  max_mem: 1617M
[11/23 00:15:24] d2.utils.events INFO:  eta: 0:31:56  iter: 3779  total_loss: 1.704  loss_ce: 0.4748  loss_objectness: 0.6625  loss_dice: 0.4922  loss_mask: 0.05265    time: 0.1712  last_time: 0.1772  data_time: 0.0030  last_data_time: 0.0037   lr: 5e-05  max_mem: 1617M
[11/23 00:15:28] d2.utils.events INFO:  eta: 0:31:52  iter: 3799  total_loss: 1.602  loss_ce: 0.3996  loss_objectness: 0.6544  loss_dice: 0.4354  loss_mask: 0.06929    time: 0.1712  last_time: 0.1711  data_time: 0.0028  last_data_time: 0.0034   lr: 5e-05  max_mem: 1617M
[11/23 00:15:31] d2.utils.events INFO:  eta: 0:31:49  iter: 3819  total_loss: 1.785  loss_ce: 0.4976  loss_objectness: 0.6552  loss_dice: 0.521  loss_mask: 0.06185    time: 0.1712  last_time: 0.1645  data_time: 0.0033  last_data_time: 0.0024   lr: 5e-05  max_mem: 1617M
[11/23 00:15:34] d2.utils.events INFO:  eta: 0:31:45  iter: 3839  total_loss: 1.752  loss_ce: 0.5014  loss_objectness: 0.6732  loss_dice: 0.4953  loss_mask: 0.04774    time: 0.1712  last_time: 0.1735  data_time: 0.0031  last_data_time: 0.0022   lr: 5e-05  max_mem: 1617M
[11/23 00:15:38] d2.utils.events INFO:  eta: 0:31:41  iter: 3859  total_loss: 1.61  loss_ce: 0.4337  loss_objectness: 0.6511  loss_dice: 0.4693  loss_mask: 0.05945    time: 0.1712  last_time: 0.1633  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1617M
[11/23 00:15:41] d2.utils.events INFO:  eta: 0:31:37  iter: 3879  total_loss: 1.756  loss_ce: 0.4282  loss_objectness: 0.6546  loss_dice: 0.5439  loss_mask: 0.04776    time: 0.1711  last_time: 0.1635  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1617M
[11/23 00:15:44] d2.utils.events INFO:  eta: 0:31:33  iter: 3899  total_loss: 1.611  loss_ce: 0.4305  loss_objectness: 0.6312  loss_dice: 0.4466  loss_mask: 0.0547    time: 0.1711  last_time: 0.1609  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-05  max_mem: 1617M
[11/23 00:15:48] d2.utils.events INFO:  eta: 0:31:29  iter: 3919  total_loss: 1.729  loss_ce: 0.4621  loss_objectness: 0.66  loss_dice: 0.5619  loss_mask: 0.05717    time: 0.1711  last_time: 0.1598  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-05  max_mem: 1617M
[11/23 00:15:51] d2.utils.events INFO:  eta: 0:31:26  iter: 3939  total_loss: 1.717  loss_ce: 0.4276  loss_objectness: 0.6668  loss_dice: 0.4911  loss_mask: 0.06463    time: 0.1710  last_time: 0.1649  data_time: 0.0028  last_data_time: 0.0034   lr: 5e-05  max_mem: 1617M
[11/23 00:15:54] d2.utils.events INFO:  eta: 0:31:22  iter: 3959  total_loss: 1.537  loss_ce: 0.4156  loss_objectness: 0.6548  loss_dice: 0.4362  loss_mask: 0.04658    time: 0.1710  last_time: 0.1619  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1617M
[11/23 00:15:58] d2.utils.events INFO:  eta: 0:31:18  iter: 3979  total_loss: 1.723  loss_ce: 0.4745  loss_objectness: 0.655  loss_dice: 0.482  loss_mask: 0.05313    time: 0.1710  last_time: 0.1605  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-05  max_mem: 1617M
[11/23 00:16:01] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/23 00:16:01] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/23 00:16:01] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/23 00:16:01] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/23 00:16:01] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/23 00:16:01] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/23 00:16:06] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0226 s/iter. Eval: 0.0416 s/iter. Total: 0.0646 s/iter. ETA=0:00:07
[11/23 00:16:11] d2.evaluation.evaluator INFO: Inference done 85/120. Dataloading: 0.0004 s/iter. Inference: 0.0236 s/iter. Eval: 0.0435 s/iter. Total: 0.0675 s/iter. ETA=0:00:02
[11/23 00:16:14] d2.evaluation.evaluator INFO: Total inference time: 0:00:08.478852 (0.073729 s / iter per device, on 1 devices)
[11/23 00:16:14] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.023305 s / iter per device, on 1 devices)
[11/23 00:16:14] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/23 00:16:14] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_gabor_turbo\inference\coco_instances_results.json
[11/23 00:16:14] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/23 00:16:14] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/23 00:16:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.06 seconds.
[11/23 00:16:14] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/23 00:16:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/23 00:16:14] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 7.028 | 16.913 | 4.994  | 0.066 | 15.400 | 46.797 |
[11/23 00:16:14] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/23 00:16:14] d2.evaluation.testing INFO: copypaste: Task: segm
[11/23 00:16:14] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/23 00:16:14] d2.evaluation.testing INFO: copypaste: 7.0280,16.9127,4.9941,0.0663,15.3997,46.7975
[11/23 00:16:14] d2.utils.events INFO:  eta: 0:31:14  iter: 3999  total_loss: 1.605  loss_ce: 0.4262  loss_objectness: 0.6607  loss_dice: 0.4258  loss_mask: 0.03807    time: 0.1709  last_time: 0.1633  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1617M
[11/23 00:16:17] d2.utils.events INFO:  eta: 0:31:10  iter: 4019  total_loss: 1.701  loss_ce: 0.5591  loss_objectness: 0.6574  loss_dice: 0.4556  loss_mask: 0.05355    time: 0.1709  last_time: 0.1630  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1617M
[11/23 00:16:21] d2.utils.events INFO:  eta: 0:31:06  iter: 4039  total_loss: 1.624  loss_ce: 0.4259  loss_objectness: 0.6612  loss_dice: 0.468  loss_mask: 0.04487    time: 0.1709  last_time: 0.1624  data_time: 0.0027  last_data_time: 0.0031   lr: 5e-05  max_mem: 1617M
[11/23 00:16:24] d2.utils.events INFO:  eta: 0:31:02  iter: 4059  total_loss: 1.592  loss_ce: 0.424  loss_objectness: 0.6667  loss_dice: 0.4382  loss_mask: 0.04419    time: 0.1709  last_time: 0.1653  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:16:27] d2.utils.events INFO:  eta: 0:30:58  iter: 4079  total_loss: 1.642  loss_ce: 0.4145  loss_objectness: 0.6505  loss_dice: 0.458  loss_mask: 0.05243    time: 0.1708  last_time: 0.1647  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:16:31] d2.utils.events INFO:  eta: 0:30:54  iter: 4099  total_loss: 1.636  loss_ce: 0.4385  loss_objectness: 0.6477  loss_dice: 0.4989  loss_mask: 0.04813    time: 0.1708  last_time: 0.1644  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:16:34] d2.utils.events INFO:  eta: 0:30:49  iter: 4119  total_loss: 1.606  loss_ce: 0.3996  loss_objectness: 0.6582  loss_dice: 0.5041  loss_mask: 0.04364    time: 0.1708  last_time: 0.1659  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:16:37] d2.utils.events INFO:  eta: 0:30:46  iter: 4139  total_loss: 1.607  loss_ce: 0.4264  loss_objectness: 0.6426  loss_dice: 0.4681  loss_mask: 0.04319    time: 0.1707  last_time: 0.1630  data_time: 0.0030  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:16:41] d2.utils.events INFO:  eta: 0:30:41  iter: 4159  total_loss: 1.636  loss_ce: 0.4347  loss_objectness: 0.6423  loss_dice: 0.4896  loss_mask: 0.04302    time: 0.1707  last_time: 0.1657  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:16:44] d2.utils.events INFO:  eta: 0:30:36  iter: 4179  total_loss: 1.801  loss_ce: 0.4894  loss_objectness: 0.6519  loss_dice: 0.5437  loss_mask: 0.0652    time: 0.1707  last_time: 0.1640  data_time: 0.0027  last_data_time: 0.0022   lr: 5e-05  max_mem: 1637M
[11/23 00:16:47] d2.utils.events INFO:  eta: 0:30:32  iter: 4199  total_loss: 1.646  loss_ce: 0.4143  loss_objectness: 0.6697  loss_dice: 0.4239  loss_mask: 0.0522    time: 0.1707  last_time: 0.1645  data_time: 0.0027  last_data_time: 0.0021   lr: 5e-05  max_mem: 1637M
[11/23 00:16:50] d2.utils.events INFO:  eta: 0:30:27  iter: 4219  total_loss: 1.474  loss_ce: 0.3956  loss_objectness: 0.6297  loss_dice: 0.3723  loss_mask: 0.04616    time: 0.1706  last_time: 0.1736  data_time: 0.0027  last_data_time: 0.0033   lr: 5e-05  max_mem: 1637M
[11/23 00:16:54] d2.utils.events INFO:  eta: 0:30:23  iter: 4239  total_loss: 1.63  loss_ce: 0.4156  loss_objectness: 0.6413  loss_dice: 0.4574  loss_mask: 0.04316    time: 0.1706  last_time: 0.1629  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:16:57] d2.utils.events INFO:  eta: 0:30:18  iter: 4259  total_loss: 1.71  loss_ce: 0.458  loss_objectness: 0.6693  loss_dice: 0.494  loss_mask: 0.04884    time: 0.1706  last_time: 0.1607  data_time: 0.0028  last_data_time: 0.0037   lr: 5e-05  max_mem: 1637M
[11/23 00:17:00] d2.utils.events INFO:  eta: 0:30:13  iter: 4279  total_loss: 1.574  loss_ce: 0.3952  loss_objectness: 0.643  loss_dice: 0.4402  loss_mask: 0.04453    time: 0.1705  last_time: 0.1620  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:17:04] d2.utils.events INFO:  eta: 0:30:07  iter: 4299  total_loss: 1.644  loss_ce: 0.4141  loss_objectness: 0.6575  loss_dice: 0.4982  loss_mask: 0.06169    time: 0.1705  last_time: 0.1642  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:17:07] d2.utils.events INFO:  eta: 0:30:01  iter: 4319  total_loss: 1.57  loss_ce: 0.446  loss_objectness: 0.6463  loss_dice: 0.4448  loss_mask: 0.04636    time: 0.1705  last_time: 0.1717  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1637M
[11/23 00:17:10] d2.utils.events INFO:  eta: 0:29:57  iter: 4339  total_loss: 1.572  loss_ce: 0.3892  loss_objectness: 0.6483  loss_dice: 0.4185  loss_mask: 0.06337    time: 0.1705  last_time: 0.1647  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:17:14] d2.utils.events INFO:  eta: 0:29:51  iter: 4359  total_loss: 1.68  loss_ce: 0.4285  loss_objectness: 0.6528  loss_dice: 0.5138  loss_mask: 0.04269    time: 0.1704  last_time: 0.1714  data_time: 0.0029  last_data_time: 0.0039   lr: 5e-05  max_mem: 1637M
[11/23 00:17:17] d2.utils.events INFO:  eta: 0:29:43  iter: 4379  total_loss: 1.592  loss_ce: 0.4048  loss_objectness: 0.6663  loss_dice: 0.4429  loss_mask: 0.0451    time: 0.1704  last_time: 0.1642  data_time: 0.0028  last_data_time: 0.0022   lr: 5e-05  max_mem: 1637M
[11/23 00:17:20] d2.utils.events INFO:  eta: 0:29:37  iter: 4399  total_loss: 1.64  loss_ce: 0.419  loss_objectness: 0.6363  loss_dice: 0.5147  loss_mask: 0.04285    time: 0.1704  last_time: 0.1701  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:17:24] d2.utils.events INFO:  eta: 0:29:27  iter: 4419  total_loss: 1.649  loss_ce: 0.4119  loss_objectness: 0.6445  loss_dice: 0.4704  loss_mask: 0.04792    time: 0.1704  last_time: 0.1627  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:17:27] d2.utils.events INFO:  eta: 0:29:19  iter: 4439  total_loss: 1.547  loss_ce: 0.4262  loss_objectness: 0.6532  loss_dice: 0.3857  loss_mask: 0.03792    time: 0.1703  last_time: 0.1620  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:17:30] d2.utils.events INFO:  eta: 0:29:13  iter: 4459  total_loss: 1.598  loss_ce: 0.434  loss_objectness: 0.6503  loss_dice: 0.4601  loss_mask: 0.05257    time: 0.1703  last_time: 0.1661  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:17:34] d2.utils.events INFO:  eta: 0:29:07  iter: 4479  total_loss: 1.734  loss_ce: 0.4077  loss_objectness: 0.6428  loss_dice: 0.5604  loss_mask: 0.05309    time: 0.1703  last_time: 0.1631  data_time: 0.0027  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:17:37] d2.utils.events INFO:  eta: 0:29:01  iter: 4499  total_loss: 1.46  loss_ce: 0.3482  loss_objectness: 0.6466  loss_dice: 0.3923  loss_mask: 0.05695    time: 0.1703  last_time: 0.1651  data_time: 0.0028  last_data_time: 0.0032   lr: 5e-05  max_mem: 1637M
[11/23 00:17:40] d2.utils.events INFO:  eta: 0:28:56  iter: 4519  total_loss: 1.618  loss_ce: 0.4016  loss_objectness: 0.6491  loss_dice: 0.492  loss_mask: 0.04693    time: 0.1702  last_time: 0.1662  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:17:43] d2.utils.events INFO:  eta: 0:28:50  iter: 4539  total_loss: 1.486  loss_ce: 0.3746  loss_objectness: 0.6443  loss_dice: 0.3759  loss_mask: 0.05497    time: 0.1702  last_time: 0.1647  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:17:47] d2.utils.events INFO:  eta: 0:28:45  iter: 4559  total_loss: 1.51  loss_ce: 0.3466  loss_objectness: 0.6423  loss_dice: 0.4311  loss_mask: 0.05027    time: 0.1702  last_time: 0.1637  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:17:50] d2.utils.events INFO:  eta: 0:28:40  iter: 4579  total_loss: 1.636  loss_ce: 0.4083  loss_objectness: 0.6634  loss_dice: 0.501  loss_mask: 0.04373    time: 0.1702  last_time: 0.1666  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:17:53] d2.utils.events INFO:  eta: 0:28:35  iter: 4599  total_loss: 1.572  loss_ce: 0.3952  loss_objectness: 0.6433  loss_dice: 0.4948  loss_mask: 0.03729    time: 0.1701  last_time: 0.1612  data_time: 0.0030  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:17:57] d2.utils.events INFO:  eta: 0:28:31  iter: 4619  total_loss: 1.615  loss_ce: 0.4536  loss_objectness: 0.6623  loss_dice: 0.4336  loss_mask: 0.05137    time: 0.1701  last_time: 0.1646  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:18:00] d2.utils.events INFO:  eta: 0:28:27  iter: 4639  total_loss: 1.75  loss_ce: 0.4962  loss_objectness: 0.6661  loss_dice: 0.5101  loss_mask: 0.0491    time: 0.1701  last_time: 0.1637  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:18:03] d2.utils.events INFO:  eta: 0:28:22  iter: 4659  total_loss: 1.464  loss_ce: 0.3994  loss_objectness: 0.6436  loss_dice: 0.3713  loss_mask: 0.0492    time: 0.1701  last_time: 0.1709  data_time: 0.0026  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:18:07] d2.utils.events INFO:  eta: 0:28:18  iter: 4679  total_loss: 1.519  loss_ce: 0.4044  loss_objectness: 0.6422  loss_dice: 0.4395  loss_mask: 0.0559    time: 0.1700  last_time: 0.1643  data_time: 0.0028  last_data_time: 0.0022   lr: 5e-05  max_mem: 1637M
[11/23 00:18:10] d2.utils.events INFO:  eta: 0:28:15  iter: 4699  total_loss: 1.682  loss_ce: 0.4368  loss_objectness: 0.6594  loss_dice: 0.5235  loss_mask: 0.0571    time: 0.1700  last_time: 0.1671  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:18:13] d2.utils.events INFO:  eta: 0:28:11  iter: 4719  total_loss: 1.513  loss_ce: 0.4262  loss_objectness: 0.6418  loss_dice: 0.3977  loss_mask: 0.04029    time: 0.1700  last_time: 0.1703  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:18:16] d2.utils.events INFO:  eta: 0:28:07  iter: 4739  total_loss: 1.478  loss_ce: 0.3954  loss_objectness: 0.6374  loss_dice: 0.3622  loss_mask: 0.05729    time: 0.1700  last_time: 0.1638  data_time: 0.0027  last_data_time: 0.0022   lr: 5e-05  max_mem: 1637M
[11/23 00:18:20] d2.utils.events INFO:  eta: 0:28:02  iter: 4759  total_loss: 1.414  loss_ce: 0.3612  loss_objectness: 0.6346  loss_dice: 0.3888  loss_mask: 0.05779    time: 0.1699  last_time: 0.1629  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:18:23] d2.utils.events INFO:  eta: 0:27:58  iter: 4779  total_loss: 1.571  loss_ce: 0.3902  loss_objectness: 0.6512  loss_dice: 0.4271  loss_mask: 0.04169    time: 0.1699  last_time: 0.1669  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:18:26] d2.utils.events INFO:  eta: 0:27:55  iter: 4799  total_loss: 1.506  loss_ce: 0.3636  loss_objectness: 0.6529  loss_dice: 0.4411  loss_mask: 0.03976    time: 0.1699  last_time: 0.1625  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:18:30] d2.utils.events INFO:  eta: 0:27:51  iter: 4819  total_loss: 1.521  loss_ce: 0.3974  loss_objectness: 0.6526  loss_dice: 0.4036  loss_mask: 0.03708    time: 0.1699  last_time: 0.1720  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:18:33] d2.utils.events INFO:  eta: 0:27:48  iter: 4839  total_loss: 1.52  loss_ce: 0.365  loss_objectness: 0.6441  loss_dice: 0.4055  loss_mask: 0.053    time: 0.1699  last_time: 0.1651  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:18:36] d2.utils.events INFO:  eta: 0:27:44  iter: 4859  total_loss: 1.613  loss_ce: 0.408  loss_objectness: 0.6655  loss_dice: 0.4423  loss_mask: 0.04454    time: 0.1698  last_time: 0.1643  data_time: 0.0028  last_data_time: 0.0032   lr: 5e-05  max_mem: 1637M
[11/23 00:18:40] d2.utils.events INFO:  eta: 0:27:41  iter: 4879  total_loss: 1.457  loss_ce: 0.3832  loss_objectness: 0.6404  loss_dice: 0.3688  loss_mask: 0.04027    time: 0.1698  last_time: 0.1633  data_time: 0.0030  last_data_time: 0.0034   lr: 5e-05  max_mem: 1637M
[11/23 00:18:43] d2.utils.events INFO:  eta: 0:27:37  iter: 4899  total_loss: 1.55  loss_ce: 0.4046  loss_objectness: 0.6648  loss_dice: 0.4122  loss_mask: 0.05294    time: 0.1698  last_time: 0.1620  data_time: 0.0027  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:18:46] d2.utils.events INFO:  eta: 0:27:34  iter: 4919  total_loss: 1.479  loss_ce: 0.3791  loss_objectness: 0.633  loss_dice: 0.411  loss_mask: 0.046    time: 0.1698  last_time: 0.1744  data_time: 0.0028  last_data_time: 0.0037   lr: 5e-05  max_mem: 1637M
[11/23 00:18:49] d2.utils.events INFO:  eta: 0:27:31  iter: 4939  total_loss: 1.549  loss_ce: 0.4175  loss_objectness: 0.6349  loss_dice: 0.4189  loss_mask: 0.04987    time: 0.1697  last_time: 0.1617  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:18:53] d2.utils.events INFO:  eta: 0:27:28  iter: 4959  total_loss: 1.512  loss_ce: 0.4061  loss_objectness: 0.6393  loss_dice: 0.3853  loss_mask: 0.04391    time: 0.1697  last_time: 0.1615  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:18:56] d2.utils.events INFO:  eta: 0:27:24  iter: 4979  total_loss: 1.564  loss_ce: 0.3786  loss_objectness: 0.6402  loss_dice: 0.4237  loss_mask: 0.03862    time: 0.1697  last_time: 0.1620  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:18:59] fvcore.common.checkpoint INFO: Saving checkpoint to output/crack_gabor_turbo\model_0004999.pth
[11/23 00:19:00] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/23 00:19:00] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/23 00:19:00] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/23 00:19:00] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/23 00:19:00] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/23 00:19:00] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/23 00:19:04] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0225 s/iter. Eval: 0.0403 s/iter. Total: 0.0631 s/iter. ETA=0:00:06
[11/23 00:19:09] d2.evaluation.evaluator INFO: Inference done 88/120. Dataloading: 0.0004 s/iter. Inference: 0.0222 s/iter. Eval: 0.0424 s/iter. Total: 0.0650 s/iter. ETA=0:00:02
[11/23 00:19:12] d2.evaluation.evaluator INFO: Total inference time: 0:00:08.369333 (0.072777 s / iter per device, on 1 devices)
[11/23 00:19:12] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.022745 s / iter per device, on 1 devices)
[11/23 00:19:12] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/23 00:19:12] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_gabor_turbo\inference\coco_instances_results.json
[11/23 00:19:12] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/23 00:19:12] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/23 00:19:13] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.06 seconds.
[11/23 00:19:13] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/23 00:19:13] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/23 00:19:13] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.522 | 13.933 | 6.060  | 0.123 | 13.374 | 42.614 |
[11/23 00:19:13] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/23 00:19:13] d2.evaluation.testing INFO: copypaste: Task: segm
[11/23 00:19:13] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/23 00:19:13] d2.evaluation.testing INFO: copypaste: 6.5222,13.9333,6.0596,0.1230,13.3735,42.6138
[11/23 00:19:13] d2.utils.events INFO:  eta: 0:27:20  iter: 4999  total_loss: 1.482  loss_ce: 0.3704  loss_objectness: 0.6371  loss_dice: 0.4167  loss_mask: 0.04723    time: 0.1697  last_time: 0.1633  data_time: 0.0027  last_data_time: 0.0028   lr: 5e-05  max_mem: 1637M
[11/23 00:19:16] d2.utils.events INFO:  eta: 0:27:17  iter: 5019  total_loss: 1.506  loss_ce: 0.3952  loss_objectness: 0.6361  loss_dice: 0.453  loss_mask: 0.03451    time: 0.1697  last_time: 0.1697  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:19:19] d2.utils.events INFO:  eta: 0:27:14  iter: 5039  total_loss: 1.555  loss_ce: 0.4288  loss_objectness: 0.6345  loss_dice: 0.4466  loss_mask: 0.04447    time: 0.1697  last_time: 0.1620  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:19:23] d2.utils.events INFO:  eta: 0:27:10  iter: 5059  total_loss: 1.51  loss_ce: 0.4096  loss_objectness: 0.6572  loss_dice: 0.4033  loss_mask: 0.03775    time: 0.1696  last_time: 0.1652  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:19:26] d2.utils.events INFO:  eta: 0:27:07  iter: 5079  total_loss: 1.502  loss_ce: 0.3687  loss_objectness: 0.6361  loss_dice: 0.4125  loss_mask: 0.03472    time: 0.1696  last_time: 0.1651  data_time: 0.0038  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:19:29] d2.utils.events INFO:  eta: 0:27:04  iter: 5099  total_loss: 1.464  loss_ce: 0.3818  loss_objectness: 0.6312  loss_dice: 0.3584  loss_mask: 0.03966    time: 0.1696  last_time: 0.1631  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:19:32] d2.utils.events INFO:  eta: 0:27:01  iter: 5119  total_loss: 1.514  loss_ce: 0.3799  loss_objectness: 0.6471  loss_dice: 0.4052  loss_mask: 0.03989    time: 0.1696  last_time: 0.1665  data_time: 0.0030  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:19:36] d2.utils.events INFO:  eta: 0:26:58  iter: 5139  total_loss: 1.539  loss_ce: 0.375  loss_objectness: 0.658  loss_dice: 0.3983  loss_mask: 0.04898    time: 0.1696  last_time: 0.1641  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:19:39] d2.utils.events INFO:  eta: 0:26:55  iter: 5159  total_loss: 1.521  loss_ce: 0.3585  loss_objectness: 0.6377  loss_dice: 0.4192  loss_mask: 0.05718    time: 0.1696  last_time: 0.1685  data_time: 0.0036  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:19:42] d2.utils.events INFO:  eta: 0:26:52  iter: 5179  total_loss: 1.423  loss_ce: 0.3513  loss_objectness: 0.653  loss_dice: 0.3766  loss_mask: 0.04133    time: 0.1695  last_time: 0.1659  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1637M
[11/23 00:19:46] d2.utils.events INFO:  eta: 0:26:49  iter: 5199  total_loss: 1.537  loss_ce: 0.3599  loss_objectness: 0.64  loss_dice: 0.4266  loss_mask: 0.0471    time: 0.1695  last_time: 0.1648  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:19:49] d2.utils.events INFO:  eta: 0:26:46  iter: 5219  total_loss: 1.656  loss_ce: 0.4189  loss_objectness: 0.6402  loss_dice: 0.5084  loss_mask: 0.04481    time: 0.1695  last_time: 0.1724  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:19:52] d2.utils.events INFO:  eta: 0:26:43  iter: 5239  total_loss: 1.523  loss_ce: 0.407  loss_objectness: 0.6561  loss_dice: 0.3986  loss_mask: 0.03763    time: 0.1695  last_time: 0.1640  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:19:56] d2.utils.events INFO:  eta: 0:26:40  iter: 5259  total_loss: 1.458  loss_ce: 0.3563  loss_objectness: 0.6258  loss_dice: 0.3238  loss_mask: 0.04201    time: 0.1695  last_time: 0.1661  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:19:59] d2.utils.events INFO:  eta: 0:26:38  iter: 5279  total_loss: 1.446  loss_ce: 0.3879  loss_objectness: 0.6317  loss_dice: 0.3443  loss_mask: 0.04963    time: 0.1695  last_time: 0.1664  data_time: 0.0028  last_data_time: 0.0033   lr: 5e-05  max_mem: 1637M
[11/23 00:20:02] d2.utils.events INFO:  eta: 0:26:35  iter: 5299  total_loss: 1.396  loss_ce: 0.3444  loss_objectness: 0.6392  loss_dice: 0.3555  loss_mask: 0.0404    time: 0.1695  last_time: 0.1651  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:20:06] d2.utils.events INFO:  eta: 0:26:31  iter: 5319  total_loss: 1.396  loss_ce: 0.359  loss_objectness: 0.6391  loss_dice: 0.3629  loss_mask: 0.04195    time: 0.1695  last_time: 0.1684  data_time: 0.0029  last_data_time: 0.0039   lr: 5e-05  max_mem: 1637M
[11/23 00:20:09] d2.utils.events INFO:  eta: 0:26:28  iter: 5339  total_loss: 1.365  loss_ce: 0.3517  loss_objectness: 0.6182  loss_dice: 0.3381  loss_mask: 0.04456    time: 0.1694  last_time: 0.1672  data_time: 0.0027  last_data_time: 0.0033   lr: 5e-05  max_mem: 1637M
[11/23 00:20:12] d2.utils.events INFO:  eta: 0:26:25  iter: 5359  total_loss: 1.53  loss_ce: 0.4424  loss_objectness: 0.6433  loss_dice: 0.3969  loss_mask: 0.03145    time: 0.1694  last_time: 0.1668  data_time: 0.0030  last_data_time: 0.0035   lr: 5e-05  max_mem: 1637M
[11/23 00:20:16] d2.utils.events INFO:  eta: 0:26:22  iter: 5379  total_loss: 1.393  loss_ce: 0.3483  loss_objectness: 0.6452  loss_dice: 0.3747  loss_mask: 0.04538    time: 0.1694  last_time: 0.1657  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:20:19] d2.utils.events INFO:  eta: 0:26:19  iter: 5399  total_loss: 1.476  loss_ce: 0.3844  loss_objectness: 0.6405  loss_dice: 0.4211  loss_mask: 0.04129    time: 0.1694  last_time: 0.1663  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:20:22] d2.utils.events INFO:  eta: 0:26:16  iter: 5419  total_loss: 1.498  loss_ce: 0.3707  loss_objectness: 0.6436  loss_dice: 0.4197  loss_mask: 0.04425    time: 0.1694  last_time: 0.1664  data_time: 0.0029  last_data_time: 0.0033   lr: 5e-05  max_mem: 1637M
[11/23 00:20:26] d2.utils.events INFO:  eta: 0:26:13  iter: 5439  total_loss: 1.427  loss_ce: 0.3385  loss_objectness: 0.6348  loss_dice: 0.3628  loss_mask: 0.03921    time: 0.1694  last_time: 0.1634  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:20:29] d2.utils.events INFO:  eta: 0:26:10  iter: 5459  total_loss: 1.428  loss_ce: 0.3756  loss_objectness: 0.6137  loss_dice: 0.3144  loss_mask: 0.03767    time: 0.1694  last_time: 0.1646  data_time: 0.0029  last_data_time: 0.0038   lr: 5e-05  max_mem: 1637M
[11/23 00:20:32] d2.utils.events INFO:  eta: 0:26:07  iter: 5479  total_loss: 1.472  loss_ce: 0.3871  loss_objectness: 0.6259  loss_dice: 0.3529  loss_mask: 0.03569    time: 0.1693  last_time: 0.1658  data_time: 0.0027  last_data_time: 0.0021   lr: 5e-05  max_mem: 1637M
[11/23 00:20:36] d2.utils.events INFO:  eta: 0:26:04  iter: 5499  total_loss: 1.373  loss_ce: 0.3362  loss_objectness: 0.6344  loss_dice: 0.3601  loss_mask: 0.04237    time: 0.1693  last_time: 0.1647  data_time: 0.0035  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:20:39] d2.utils.events INFO:  eta: 0:26:01  iter: 5519  total_loss: 1.432  loss_ce: 0.3553  loss_objectness: 0.6466  loss_dice: 0.4137  loss_mask: 0.04002    time: 0.1693  last_time: 0.1636  data_time: 0.0037  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:20:42] d2.utils.events INFO:  eta: 0:25:58  iter: 5539  total_loss: 1.315  loss_ce: 0.3615  loss_objectness: 0.6419  loss_dice: 0.2973  loss_mask: 0.04234    time: 0.1693  last_time: 0.1636  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:20:46] d2.utils.events INFO:  eta: 0:25:55  iter: 5559  total_loss: 1.442  loss_ce: 0.3817  loss_objectness: 0.6233  loss_dice: 0.3856  loss_mask: 0.03642    time: 0.1693  last_time: 0.1642  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:20:49] d2.utils.events INFO:  eta: 0:25:51  iter: 5579  total_loss: 1.469  loss_ce: 0.3706  loss_objectness: 0.6465  loss_dice: 0.351  loss_mask: 0.04979    time: 0.1693  last_time: 0.1673  data_time: 0.0027  last_data_time: 0.0035   lr: 5e-05  max_mem: 1637M
[11/23 00:20:52] d2.utils.events INFO:  eta: 0:25:48  iter: 5599  total_loss: 1.398  loss_ce: 0.3462  loss_objectness: 0.6164  loss_dice: 0.3662  loss_mask: 0.04276    time: 0.1693  last_time: 0.1688  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:20:56] d2.utils.events INFO:  eta: 0:25:45  iter: 5619  total_loss: 1.407  loss_ce: 0.3469  loss_objectness: 0.6266  loss_dice: 0.385  loss_mask: 0.04841    time: 0.1692  last_time: 0.1666  data_time: 0.0028  last_data_time: 0.0033   lr: 5e-05  max_mem: 1637M
[11/23 00:20:59] d2.utils.events INFO:  eta: 0:25:42  iter: 5639  total_loss: 1.382  loss_ce: 0.3479  loss_objectness: 0.624  loss_dice: 0.373  loss_mask: 0.0412    time: 0.1692  last_time: 0.1642  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:21:02] d2.utils.events INFO:  eta: 0:25:39  iter: 5659  total_loss: 1.403  loss_ce: 0.33  loss_objectness: 0.6409  loss_dice: 0.3693  loss_mask: 0.03521    time: 0.1692  last_time: 0.1629  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:21:06] d2.utils.events INFO:  eta: 0:25:36  iter: 5679  total_loss: 1.417  loss_ce: 0.3372  loss_objectness: 0.6461  loss_dice: 0.3797  loss_mask: 0.05253    time: 0.1692  last_time: 0.1668  data_time: 0.0028  last_data_time: 0.0043   lr: 5e-05  max_mem: 1637M
[11/23 00:21:09] d2.utils.events INFO:  eta: 0:25:32  iter: 5699  total_loss: 1.407  loss_ce: 0.3691  loss_objectness: 0.6255  loss_dice: 0.393  loss_mask: 0.03359    time: 0.1692  last_time: 0.1657  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:21:12] d2.utils.events INFO:  eta: 0:25:29  iter: 5719  total_loss: 1.4  loss_ce: 0.2984  loss_objectness: 0.641  loss_dice: 0.3845  loss_mask: 0.0423    time: 0.1692  last_time: 0.1628  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:21:16] d2.utils.events INFO:  eta: 0:25:26  iter: 5739  total_loss: 1.369  loss_ce: 0.3003  loss_objectness: 0.6212  loss_dice: 0.3334  loss_mask: 0.03908    time: 0.1692  last_time: 0.1652  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:21:19] d2.utils.events INFO:  eta: 0:25:23  iter: 5759  total_loss: 1.387  loss_ce: 0.3513  loss_objectness: 0.6287  loss_dice: 0.4037  loss_mask: 0.04106    time: 0.1691  last_time: 0.1635  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:21:22] d2.utils.events INFO:  eta: 0:25:20  iter: 5779  total_loss: 1.393  loss_ce: 0.3285  loss_objectness: 0.6114  loss_dice: 0.3661  loss_mask: 0.04418    time: 0.1691  last_time: 0.1626  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:21:25] d2.utils.events INFO:  eta: 0:25:17  iter: 5799  total_loss: 1.444  loss_ce: 0.3343  loss_objectness: 0.6109  loss_dice: 0.3591  loss_mask: 0.04612    time: 0.1691  last_time: 0.1650  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:21:29] d2.utils.events INFO:  eta: 0:25:13  iter: 5819  total_loss: 1.339  loss_ce: 0.3141  loss_objectness: 0.6248  loss_dice: 0.3909  loss_mask: 0.04239    time: 0.1691  last_time: 0.1670  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:21:32] d2.utils.events INFO:  eta: 0:25:10  iter: 5839  total_loss: 1.467  loss_ce: 0.3337  loss_objectness: 0.6483  loss_dice: 0.4068  loss_mask: 0.03813    time: 0.1691  last_time: 0.1650  data_time: 0.0028  last_data_time: 0.0021   lr: 5e-05  max_mem: 1637M
[11/23 00:21:35] d2.utils.events INFO:  eta: 0:25:07  iter: 5859  total_loss: 1.486  loss_ce: 0.3206  loss_objectness: 0.6349  loss_dice: 0.4564  loss_mask: 0.03898    time: 0.1691  last_time: 0.1654  data_time: 0.0030  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:21:39] d2.utils.events INFO:  eta: 0:25:04  iter: 5879  total_loss: 1.375  loss_ce: 0.3177  loss_objectness: 0.6261  loss_dice: 0.3715  loss_mask: 0.03223    time: 0.1691  last_time: 0.1654  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:21:42] d2.utils.events INFO:  eta: 0:25:01  iter: 5899  total_loss: 1.352  loss_ce: 0.2933  loss_objectness: 0.6413  loss_dice: 0.339  loss_mask: 0.034    time: 0.1691  last_time: 0.1639  data_time: 0.0031  last_data_time: 0.0028   lr: 5e-05  max_mem: 1637M
[11/23 00:21:45] d2.utils.events INFO:  eta: 0:24:58  iter: 5919  total_loss: 1.357  loss_ce: 0.3254  loss_objectness: 0.6254  loss_dice: 0.3653  loss_mask: 0.0399    time: 0.1691  last_time: 0.1724  data_time: 0.0031  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:21:49] d2.utils.events INFO:  eta: 0:24:55  iter: 5939  total_loss: 1.413  loss_ce: 0.3277  loss_objectness: 0.634  loss_dice: 0.396  loss_mask: 0.0389    time: 0.1691  last_time: 0.1649  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:21:52] d2.utils.events INFO:  eta: 0:24:51  iter: 5959  total_loss: 1.295  loss_ce: 0.3048  loss_objectness: 0.6247  loss_dice: 0.3113  loss_mask: 0.03617    time: 0.1690  last_time: 0.1620  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:21:55] d2.utils.events INFO:  eta: 0:24:48  iter: 5979  total_loss: 1.377  loss_ce: 0.3128  loss_objectness: 0.6375  loss_dice: 0.3645  loss_mask: 0.03794    time: 0.1690  last_time: 0.1666  data_time: 0.0030  last_data_time: 0.0033   lr: 5e-05  max_mem: 1637M
[11/23 00:21:59] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/23 00:21:59] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/23 00:21:59] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/23 00:21:59] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/23 00:21:59] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/23 00:21:59] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/23 00:22:05] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0426 s/iter. Eval: 0.0728 s/iter. Total: 0.1157 s/iter. ETA=0:00:12
[11/23 00:22:10] d2.evaluation.evaluator INFO: Inference done 77/120. Dataloading: 0.0004 s/iter. Inference: 0.0300 s/iter. Eval: 0.0492 s/iter. Total: 0.0797 s/iter. ETA=0:00:03
[11/23 00:22:14] d2.evaluation.evaluator INFO: Total inference time: 0:00:09.462664 (0.082284 s / iter per device, on 1 devices)
[11/23 00:22:14] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:03 (0.027589 s / iter per device, on 1 devices)
[11/23 00:22:14] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/23 00:22:14] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_gabor_turbo\inference\coco_instances_results.json
[11/23 00:22:14] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/23 00:22:14] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/23 00:22:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.06 seconds.
[11/23 00:22:14] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/23 00:22:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/23 00:22:14] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.586 | 14.444 | 6.231  | 0.025 | 13.555 | 48.448 |
[11/23 00:22:14] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/23 00:22:14] d2.evaluation.testing INFO: copypaste: Task: segm
[11/23 00:22:14] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/23 00:22:14] d2.evaluation.testing INFO: copypaste: 6.5859,14.4443,6.2314,0.0247,13.5549,48.4484
[11/23 00:22:14] d2.utils.events INFO:  eta: 0:24:45  iter: 5999  total_loss: 1.267  loss_ce: 0.2784  loss_objectness: 0.6258  loss_dice: 0.3229  loss_mask: 0.03857    time: 0.1690  last_time: 0.1654  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:22:18] d2.utils.events INFO:  eta: 0:24:42  iter: 6019  total_loss: 1.356  loss_ce: 0.301  loss_objectness: 0.6245  loss_dice: 0.3305  loss_mask: 0.03528    time: 0.1690  last_time: 0.1619  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:22:21] d2.utils.events INFO:  eta: 0:24:38  iter: 6039  total_loss: 1.371  loss_ce: 0.3694  loss_objectness: 0.6244  loss_dice: 0.3555  loss_mask: 0.03584    time: 0.1690  last_time: 0.1647  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-05  max_mem: 1637M
[11/23 00:22:24] d2.utils.events INFO:  eta: 0:24:35  iter: 6059  total_loss: 1.228  loss_ce: 0.2841  loss_objectness: 0.6019  loss_dice: 0.3059  loss_mask: 0.03596    time: 0.1690  last_time: 0.1645  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:22:27] d2.utils.events INFO:  eta: 0:24:32  iter: 6079  total_loss: 1.34  loss_ce: 0.3358  loss_objectness: 0.6184  loss_dice: 0.3435  loss_mask: 0.0404    time: 0.1690  last_time: 0.1651  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:22:31] d2.utils.events INFO:  eta: 0:24:28  iter: 6099  total_loss: 1.404  loss_ce: 0.34  loss_objectness: 0.6333  loss_dice: 0.3455  loss_mask: 0.03878    time: 0.1690  last_time: 0.1641  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:22:34] d2.utils.events INFO:  eta: 0:24:25  iter: 6119  total_loss: 1.42  loss_ce: 0.3409  loss_objectness: 0.6276  loss_dice: 0.3943  loss_mask: 0.03664    time: 0.1689  last_time: 0.1641  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:22:37] d2.utils.events INFO:  eta: 0:24:21  iter: 6139  total_loss: 1.399  loss_ce: 0.3786  loss_objectness: 0.6293  loss_dice: 0.3389  loss_mask: 0.0411    time: 0.1689  last_time: 0.1692  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:22:41] d2.utils.events INFO:  eta: 0:24:18  iter: 6159  total_loss: 1.351  loss_ce: 0.3497  loss_objectness: 0.6152  loss_dice: 0.3305  loss_mask: 0.04364    time: 0.1689  last_time: 0.1641  data_time: 0.0031  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:22:44] d2.utils.events INFO:  eta: 0:24:15  iter: 6179  total_loss: 1.229  loss_ce: 0.2524  loss_objectness: 0.6139  loss_dice: 0.3126  loss_mask: 0.04322    time: 0.1689  last_time: 0.1713  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:22:48] d2.utils.events INFO:  eta: 0:24:12  iter: 6199  total_loss: 1.337  loss_ce: 0.3119  loss_objectness: 0.6216  loss_dice: 0.3288  loss_mask: 0.03284    time: 0.1690  last_time: 0.1875  data_time: 0.0046  last_data_time: 0.0090   lr: 5e-05  max_mem: 1637M
[11/23 00:22:51] d2.utils.events INFO:  eta: 0:24:09  iter: 6219  total_loss: 1.446  loss_ce: 0.3327  loss_objectness: 0.6281  loss_dice: 0.3729  loss_mask: 0.03337    time: 0.1690  last_time: 0.1726  data_time: 0.0030  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:22:55] d2.utils.events INFO:  eta: 0:24:06  iter: 6239  total_loss: 1.464  loss_ce: 0.3803  loss_objectness: 0.6239  loss_dice: 0.3449  loss_mask: 0.0315    time: 0.1690  last_time: 0.1766  data_time: 0.0031  last_data_time: 0.0043   lr: 5e-05  max_mem: 1637M
[11/23 00:22:58] d2.utils.events INFO:  eta: 0:24:04  iter: 6259  total_loss: 1.463  loss_ce: 0.3354  loss_objectness: 0.6379  loss_dice: 0.3985  loss_mask: 0.03719    time: 0.1690  last_time: 0.1689  data_time: 0.0035  last_data_time: 0.0028   lr: 5e-05  max_mem: 1637M
[11/23 00:23:02] d2.utils.events INFO:  eta: 0:24:00  iter: 6279  total_loss: 1.347  loss_ce: 0.3159  loss_objectness: 0.6376  loss_dice: 0.3227  loss_mask: 0.05416    time: 0.1690  last_time: 0.1640  data_time: 0.0032  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:23:05] d2.utils.events INFO:  eta: 0:23:57  iter: 6299  total_loss: 1.349  loss_ce: 0.3262  loss_objectness: 0.6491  loss_dice: 0.3739  loss_mask: 0.04694    time: 0.1690  last_time: 0.1679  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:23:08] d2.utils.events INFO:  eta: 0:23:53  iter: 6319  total_loss: 1.35  loss_ce: 0.2919  loss_objectness: 0.6516  loss_dice: 0.3601  loss_mask: 0.04533    time: 0.1690  last_time: 0.1640  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:23:12] d2.utils.events INFO:  eta: 0:23:50  iter: 6339  total_loss: 1.392  loss_ce: 0.3187  loss_objectness: 0.6194  loss_dice: 0.344  loss_mask: 0.03452    time: 0.1690  last_time: 0.1638  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:23:15] d2.utils.events INFO:  eta: 0:23:46  iter: 6359  total_loss: 1.301  loss_ce: 0.339  loss_objectness: 0.62  loss_dice: 0.2825  loss_mask: 0.0409    time: 0.1690  last_time: 0.1627  data_time: 0.0040  last_data_time: 0.0037   lr: 5e-05  max_mem: 1637M
[11/23 00:23:18] d2.utils.events INFO:  eta: 0:23:43  iter: 6379  total_loss: 1.334  loss_ce: 0.3262  loss_objectness: 0.6226  loss_dice: 0.336  loss_mask: 0.04079    time: 0.1690  last_time: 0.1642  data_time: 0.0027  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:23:22] d2.utils.events INFO:  eta: 0:23:39  iter: 6399  total_loss: 1.413  loss_ce: 0.342  loss_objectness: 0.6302  loss_dice: 0.4194  loss_mask: 0.03911    time: 0.1689  last_time: 0.1614  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:23:25] d2.utils.events INFO:  eta: 0:23:36  iter: 6419  total_loss: 1.301  loss_ce: 0.2709  loss_objectness: 0.6324  loss_dice: 0.3443  loss_mask: 0.03876    time: 0.1689  last_time: 0.1634  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:23:28] d2.utils.events INFO:  eta: 0:23:32  iter: 6439  total_loss: 1.4  loss_ce: 0.3371  loss_objectness: 0.6251  loss_dice: 0.3444  loss_mask: 0.03451    time: 0.1689  last_time: 0.1620  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:23:31] d2.utils.events INFO:  eta: 0:23:29  iter: 6459  total_loss: 1.355  loss_ce: 0.3241  loss_objectness: 0.6384  loss_dice: 0.3584  loss_mask: 0.03397    time: 0.1689  last_time: 0.1639  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:23:35] d2.utils.events INFO:  eta: 0:23:25  iter: 6479  total_loss: 1.337  loss_ce: 0.3003  loss_objectness: 0.5965  loss_dice: 0.3336  loss_mask: 0.03952    time: 0.1689  last_time: 0.1697  data_time: 0.0026  last_data_time: 0.0022   lr: 5e-05  max_mem: 1637M
[11/23 00:23:38] d2.utils.events INFO:  eta: 0:23:22  iter: 6499  total_loss: 1.39  loss_ce: 0.3226  loss_objectness: 0.6528  loss_dice: 0.3683  loss_mask: 0.03716    time: 0.1689  last_time: 0.1624  data_time: 0.0031  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:23:41] d2.utils.events INFO:  eta: 0:23:19  iter: 6519  total_loss: 1.213  loss_ce: 0.2821  loss_objectness: 0.6307  loss_dice: 0.2817  loss_mask: 0.03861    time: 0.1689  last_time: 0.1636  data_time: 0.0029  last_data_time: 0.0021   lr: 5e-05  max_mem: 1637M
[11/23 00:23:45] d2.utils.events INFO:  eta: 0:23:15  iter: 6539  total_loss: 1.318  loss_ce: 0.2644  loss_objectness: 0.6313  loss_dice: 0.3127  loss_mask: 0.03395    time: 0.1689  last_time: 0.1661  data_time: 0.0028  last_data_time: 0.0033   lr: 5e-05  max_mem: 1637M
[11/23 00:23:48] d2.utils.events INFO:  eta: 0:23:12  iter: 6559  total_loss: 1.223  loss_ce: 0.2468  loss_objectness: 0.6231  loss_dice: 0.3089  loss_mask: 0.03277    time: 0.1688  last_time: 0.1633  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:23:51] d2.utils.events INFO:  eta: 0:23:09  iter: 6579  total_loss: 1.252  loss_ce: 0.2503  loss_objectness: 0.6239  loss_dice: 0.3325  loss_mask: 0.03284    time: 0.1688  last_time: 0.1668  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:23:55] d2.utils.events INFO:  eta: 0:23:05  iter: 6599  total_loss: 1.264  loss_ce: 0.243  loss_objectness: 0.624  loss_dice: 0.2974  loss_mask: 0.03905    time: 0.1688  last_time: 0.1651  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:23:58] d2.utils.events INFO:  eta: 0:23:02  iter: 6619  total_loss: 1.24  loss_ce: 0.2846  loss_objectness: 0.6158  loss_dice: 0.3173  loss_mask: 0.03637    time: 0.1688  last_time: 0.1649  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:24:01] d2.utils.events INFO:  eta: 0:22:59  iter: 6639  total_loss: 1.436  loss_ce: 0.3395  loss_objectness: 0.632  loss_dice: 0.4022  loss_mask: 0.03723    time: 0.1688  last_time: 0.1610  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:24:05] d2.utils.events INFO:  eta: 0:22:55  iter: 6659  total_loss: 1.278  loss_ce: 0.2998  loss_objectness: 0.6265  loss_dice: 0.3088  loss_mask: 0.03692    time: 0.1688  last_time: 0.1657  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:24:08] d2.utils.events INFO:  eta: 0:22:52  iter: 6679  total_loss: 1.231  loss_ce: 0.2014  loss_objectness: 0.6105  loss_dice: 0.2962  loss_mask: 0.04049    time: 0.1688  last_time: 0.1634  data_time: 0.0028  last_data_time: 0.0040   lr: 5e-05  max_mem: 1637M
[11/23 00:24:11] d2.utils.events INFO:  eta: 0:22:48  iter: 6699  total_loss: 1.232  loss_ce: 0.2561  loss_objectness: 0.6242  loss_dice: 0.3074  loss_mask: 0.03045    time: 0.1688  last_time: 0.1690  data_time: 0.0027  last_data_time: 0.0028   lr: 5e-05  max_mem: 1637M
[11/23 00:24:14] d2.utils.events INFO:  eta: 0:22:45  iter: 6719  total_loss: 1.2  loss_ce: 0.2372  loss_objectness: 0.6244  loss_dice: 0.3092  loss_mask: 0.04223    time: 0.1687  last_time: 0.1628  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:24:18] d2.utils.events INFO:  eta: 0:22:42  iter: 6739  total_loss: 1.517  loss_ce: 0.3553  loss_objectness: 0.6351  loss_dice: 0.4043  loss_mask: 0.03731    time: 0.1687  last_time: 0.1679  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:24:21] d2.utils.events INFO:  eta: 0:22:38  iter: 6759  total_loss: 1.361  loss_ce: 0.3073  loss_objectness: 0.6435  loss_dice: 0.3787  loss_mask: 0.03977    time: 0.1687  last_time: 0.1614  data_time: 0.0029  last_data_time: 0.0034   lr: 5e-05  max_mem: 1637M
[11/23 00:24:24] d2.utils.events INFO:  eta: 0:22:35  iter: 6779  total_loss: 1.231  loss_ce: 0.2517  loss_objectness: 0.6254  loss_dice: 0.3113  loss_mask: 0.03791    time: 0.1687  last_time: 0.1705  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:24:28] d2.utils.events INFO:  eta: 0:22:31  iter: 6799  total_loss: 1.216  loss_ce: 0.2537  loss_objectness: 0.6017  loss_dice: 0.3009  loss_mask: 0.03976    time: 0.1687  last_time: 0.1649  data_time: 0.0028  last_data_time: 0.0035   lr: 5e-05  max_mem: 1637M
[11/23 00:24:31] d2.utils.events INFO:  eta: 0:22:28  iter: 6819  total_loss: 1.22  loss_ce: 0.2441  loss_objectness: 0.6134  loss_dice: 0.3042  loss_mask: 0.03598    time: 0.1687  last_time: 0.1706  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:24:34] d2.utils.events INFO:  eta: 0:22:25  iter: 6839  total_loss: 1.251  loss_ce: 0.3197  loss_objectness: 0.6156  loss_dice: 0.3375  loss_mask: 0.02992    time: 0.1687  last_time: 0.1637  data_time: 0.0031  last_data_time: 0.0034   lr: 5e-05  max_mem: 1637M
[11/23 00:24:38] d2.utils.events INFO:  eta: 0:22:21  iter: 6859  total_loss: 1.116  loss_ce: 0.2203  loss_objectness: 0.6087  loss_dice: 0.2827  loss_mask: 0.03175    time: 0.1687  last_time: 0.1632  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:24:41] d2.utils.events INFO:  eta: 0:22:18  iter: 6879  total_loss: 1.321  loss_ce: 0.2973  loss_objectness: 0.6172  loss_dice: 0.3202  loss_mask: 0.03429    time: 0.1687  last_time: 0.1623  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:24:44] d2.utils.events INFO:  eta: 0:22:14  iter: 6899  total_loss: 1.154  loss_ce: 0.2638  loss_objectness: 0.6038  loss_dice: 0.252  loss_mask: 0.02989    time: 0.1687  last_time: 0.1676  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:24:48] d2.utils.events INFO:  eta: 0:22:11  iter: 6919  total_loss: 1.184  loss_ce: 0.2373  loss_objectness: 0.5888  loss_dice: 0.2849  loss_mask: 0.0348    time: 0.1686  last_time: 0.1620  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:24:51] d2.utils.events INFO:  eta: 0:22:08  iter: 6939  total_loss: 1.34  loss_ce: 0.2844  loss_objectness: 0.6031  loss_dice: 0.3261  loss_mask: 0.02939    time: 0.1686  last_time: 0.1701  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:24:54] d2.utils.events INFO:  eta: 0:22:04  iter: 6959  total_loss: 1.211  loss_ce: 0.2534  loss_objectness: 0.6122  loss_dice: 0.2955  loss_mask: 0.03275    time: 0.1686  last_time: 0.1687  data_time: 0.0030  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:24:57] d2.utils.events INFO:  eta: 0:22:01  iter: 6979  total_loss: 1.115  loss_ce: 0.202  loss_objectness: 0.5753  loss_dice: 0.2647  loss_mask: 0.03326    time: 0.1686  last_time: 0.1624  data_time: 0.0028  last_data_time: 0.0041   lr: 5e-05  max_mem: 1637M
[11/23 00:25:01] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/23 00:25:01] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/23 00:25:01] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/23 00:25:01] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/23 00:25:01] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/23 00:25:01] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/23 00:25:05] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0226 s/iter. Eval: 0.0445 s/iter. Total: 0.0673 s/iter. ETA=0:00:07
[11/23 00:25:10] d2.evaluation.evaluator INFO: Inference done 88/120. Dataloading: 0.0004 s/iter. Inference: 0.0224 s/iter. Eval: 0.0428 s/iter. Total: 0.0657 s/iter. ETA=0:00:02
[11/23 00:25:14] d2.evaluation.evaluator INFO: Total inference time: 0:00:08.511880 (0.074016 s / iter per device, on 1 devices)
[11/23 00:25:14] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.022948 s / iter per device, on 1 devices)
[11/23 00:25:14] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/23 00:25:14] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_gabor_turbo\inference\coco_instances_results.json
[11/23 00:25:14] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/23 00:25:14] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/23 00:25:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.05 seconds.
[11/23 00:25:14] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/23 00:25:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/23 00:25:14] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 5.841 | 13.781 | 5.238  | 0.014 | 12.501 | 38.595 |
[11/23 00:25:14] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/23 00:25:14] d2.evaluation.testing INFO: copypaste: Task: segm
[11/23 00:25:14] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/23 00:25:14] d2.evaluation.testing INFO: copypaste: 5.8410,13.7806,5.2384,0.0142,12.5007,38.5946
[11/23 00:25:14] d2.utils.events INFO:  eta: 0:21:57  iter: 6999  total_loss: 1.152  loss_ce: 0.2261  loss_objectness: 0.5968  loss_dice: 0.2739  loss_mask: 0.02834    time: 0.1686  last_time: 0.1635  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:25:17] d2.utils.events INFO:  eta: 0:21:54  iter: 7019  total_loss: 1.098  loss_ce: 0.2121  loss_objectness: 0.5967  loss_dice: 0.2548  loss_mask: 0.02894    time: 0.1686  last_time: 0.1735  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:25:20] d2.utils.events INFO:  eta: 0:21:51  iter: 7039  total_loss: 1.134  loss_ce: 0.1955  loss_objectness: 0.5982  loss_dice: 0.2524  loss_mask: 0.03931    time: 0.1686  last_time: 0.1640  data_time: 0.0027  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:25:24] d2.utils.events INFO:  eta: 0:21:47  iter: 7059  total_loss: 1.161  loss_ce: 0.2334  loss_objectness: 0.6094  loss_dice: 0.2982  loss_mask: 0.03119    time: 0.1686  last_time: 0.1617  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:25:27] d2.utils.events INFO:  eta: 0:21:44  iter: 7079  total_loss: 1.227  loss_ce: 0.255  loss_objectness: 0.6017  loss_dice: 0.3147  loss_mask: 0.03369    time: 0.1685  last_time: 0.1653  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:25:30] d2.utils.events INFO:  eta: 0:21:41  iter: 7099  total_loss: 1.091  loss_ce: 0.1864  loss_objectness: 0.5808  loss_dice: 0.2623  loss_mask: 0.03869    time: 0.1685  last_time: 0.1656  data_time: 0.0029  last_data_time: 0.0037   lr: 5e-05  max_mem: 1637M
[11/23 00:25:34] d2.utils.events INFO:  eta: 0:21:38  iter: 7119  total_loss: 1.199  loss_ce: 0.2379  loss_objectness: 0.5879  loss_dice: 0.2686  loss_mask: 0.03161    time: 0.1685  last_time: 0.1641  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:25:37] d2.utils.events INFO:  eta: 0:21:35  iter: 7139  total_loss: 1.129  loss_ce: 0.2651  loss_objectness: 0.5901  loss_dice: 0.2581  loss_mask: 0.03193    time: 0.1685  last_time: 0.1634  data_time: 0.0035  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:25:40] d2.utils.events INFO:  eta: 0:21:31  iter: 7159  total_loss: 1.08  loss_ce: 0.1983  loss_objectness: 0.5934  loss_dice: 0.2889  loss_mask: 0.03346    time: 0.1685  last_time: 0.1658  data_time: 0.0028  last_data_time: 0.0034   lr: 5e-05  max_mem: 1637M
[11/23 00:25:44] d2.utils.events INFO:  eta: 0:21:27  iter: 7179  total_loss: 1.228  loss_ce: 0.2392  loss_objectness: 0.5991  loss_dice: 0.3151  loss_mask: 0.02999    time: 0.1685  last_time: 0.1633  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:25:47] d2.utils.events INFO:  eta: 0:21:23  iter: 7199  total_loss: 0.9851  loss_ce: 0.1868  loss_objectness: 0.5667  loss_dice: 0.2312  loss_mask: 0.03419    time: 0.1685  last_time: 0.1661  data_time: 0.0030  last_data_time: 0.0034   lr: 5e-05  max_mem: 1637M
[11/23 00:25:50] d2.utils.events INFO:  eta: 0:21:19  iter: 7219  total_loss: 1.169  loss_ce: 0.207  loss_objectness: 0.5886  loss_dice: 0.2709  loss_mask: 0.03056    time: 0.1685  last_time: 0.1661  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:25:54] d2.utils.events INFO:  eta: 0:21:15  iter: 7239  total_loss: 1.154  loss_ce: 0.1992  loss_objectness: 0.6156  loss_dice: 0.309  loss_mask: 0.03105    time: 0.1685  last_time: 0.1632  data_time: 0.0028  last_data_time: 0.0034   lr: 5e-05  max_mem: 1637M
[11/23 00:25:57] d2.utils.events INFO:  eta: 0:21:11  iter: 7259  total_loss: 1.094  loss_ce: 0.1952  loss_objectness: 0.5942  loss_dice: 0.2615  loss_mask: 0.03352    time: 0.1685  last_time: 0.1648  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:26:00] d2.utils.events INFO:  eta: 0:21:08  iter: 7279  total_loss: 1.029  loss_ce: 0.1784  loss_objectness: 0.5763  loss_dice: 0.2346  loss_mask: 0.03871    time: 0.1684  last_time: 0.1618  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:26:03] d2.utils.events INFO:  eta: 0:21:04  iter: 7299  total_loss: 1.178  loss_ce: 0.2149  loss_objectness: 0.6187  loss_dice: 0.3191  loss_mask: 0.03444    time: 0.1684  last_time: 0.1676  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:26:07] d2.utils.events INFO:  eta: 0:21:01  iter: 7319  total_loss: 1.176  loss_ce: 0.2243  loss_objectness: 0.588  loss_dice: 0.295  loss_mask: 0.03392    time: 0.1684  last_time: 0.1616  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:26:10] d2.utils.events INFO:  eta: 0:20:57  iter: 7339  total_loss: 1.187  loss_ce: 0.2403  loss_objectness: 0.6023  loss_dice: 0.2779  loss_mask: 0.0285    time: 0.1684  last_time: 0.1649  data_time: 0.0028  last_data_time: 0.0033   lr: 5e-05  max_mem: 1637M
[11/23 00:26:13] d2.utils.events INFO:  eta: 0:20:54  iter: 7359  total_loss: 1.131  loss_ce: 0.1891  loss_objectness: 0.6014  loss_dice: 0.2617  loss_mask: 0.03323    time: 0.1684  last_time: 0.1639  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:26:17] d2.utils.events INFO:  eta: 0:20:51  iter: 7379  total_loss: 1.124  loss_ce: 0.2303  loss_objectness: 0.6009  loss_dice: 0.2678  loss_mask: 0.03177    time: 0.1684  last_time: 0.1625  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:26:20] d2.utils.events INFO:  eta: 0:20:48  iter: 7399  total_loss: 1.135  loss_ce: 0.2005  loss_objectness: 0.6167  loss_dice: 0.3059  loss_mask: 0.04012    time: 0.1684  last_time: 0.1660  data_time: 0.0030  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:26:23] d2.utils.events INFO:  eta: 0:20:44  iter: 7419  total_loss: 1.019  loss_ce: 0.1546  loss_objectness: 0.5657  loss_dice: 0.2337  loss_mask: 0.03727    time: 0.1684  last_time: 0.1676  data_time: 0.0025  last_data_time: 0.0028   lr: 5e-05  max_mem: 1637M
[11/23 00:26:26] d2.utils.events INFO:  eta: 0:20:41  iter: 7439  total_loss: 1.099  loss_ce: 0.1442  loss_objectness: 0.5938  loss_dice: 0.2729  loss_mask: 0.03293    time: 0.1684  last_time: 0.1655  data_time: 0.0027  last_data_time: 0.0033   lr: 5e-05  max_mem: 1637M
[11/23 00:26:30] d2.utils.events INFO:  eta: 0:20:37  iter: 7459  total_loss: 1.191  loss_ce: 0.2173  loss_objectness: 0.6112  loss_dice: 0.3094  loss_mask: 0.03512    time: 0.1684  last_time: 0.1666  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:26:33] d2.utils.events INFO:  eta: 0:20:34  iter: 7479  total_loss: 1.104  loss_ce: 0.1852  loss_objectness: 0.6079  loss_dice: 0.2693  loss_mask: 0.03301    time: 0.1683  last_time: 0.1618  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:26:36] d2.utils.events INFO:  eta: 0:20:31  iter: 7499  total_loss: 1.155  loss_ce: 0.204  loss_objectness: 0.6193  loss_dice: 0.2811  loss_mask: 0.02826    time: 0.1683  last_time: 0.1637  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:26:40] d2.utils.events INFO:  eta: 0:20:28  iter: 7519  total_loss: 1.184  loss_ce: 0.249  loss_objectness: 0.6145  loss_dice: 0.2798  loss_mask: 0.0269    time: 0.1683  last_time: 0.1678  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:26:43] d2.utils.events INFO:  eta: 0:20:25  iter: 7539  total_loss: 1.117  loss_ce: 0.2224  loss_objectness: 0.5855  loss_dice: 0.2858  loss_mask: 0.03374    time: 0.1683  last_time: 0.1696  data_time: 0.0032  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:26:46] d2.utils.events INFO:  eta: 0:20:21  iter: 7559  total_loss: 1.075  loss_ce: 0.1829  loss_objectness: 0.577  loss_dice: 0.2626  loss_mask: 0.03647    time: 0.1683  last_time: 0.1615  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:26:50] d2.utils.events INFO:  eta: 0:20:18  iter: 7579  total_loss: 1.111  loss_ce: 0.2015  loss_objectness: 0.6129  loss_dice: 0.2796  loss_mask: 0.0355    time: 0.1683  last_time: 0.1653  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:26:53] d2.utils.events INFO:  eta: 0:20:14  iter: 7599  total_loss: 1.148  loss_ce: 0.1907  loss_objectness: 0.6092  loss_dice: 0.2855  loss_mask: 0.03139    time: 0.1683  last_time: 0.1633  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:26:56] d2.utils.events INFO:  eta: 0:20:11  iter: 7619  total_loss: 1.084  loss_ce: 0.1828  loss_objectness: 0.6072  loss_dice: 0.2821  loss_mask: 0.03189    time: 0.1683  last_time: 0.1684  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:27:00] d2.utils.events INFO:  eta: 0:20:08  iter: 7639  total_loss: 1.222  loss_ce: 0.232  loss_objectness: 0.6078  loss_dice: 0.3148  loss_mask: 0.03427    time: 0.1683  last_time: 0.1692  data_time: 0.0030  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:27:03] d2.utils.events INFO:  eta: 0:20:05  iter: 7659  total_loss: 1.201  loss_ce: 0.1951  loss_objectness: 0.6218  loss_dice: 0.3224  loss_mask: 0.0323    time: 0.1683  last_time: 0.1712  data_time: 0.0030  last_data_time: 0.0039   lr: 5e-05  max_mem: 1637M
[11/23 00:27:06] d2.utils.events INFO:  eta: 0:20:02  iter: 7679  total_loss: 1.136  loss_ce: 0.2226  loss_objectness: 0.5965  loss_dice: 0.2374  loss_mask: 0.02639    time: 0.1683  last_time: 0.1660  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:27:10] d2.utils.events INFO:  eta: 0:19:59  iter: 7699  total_loss: 1.112  loss_ce: 0.1974  loss_objectness: 0.5883  loss_dice: 0.2919  loss_mask: 0.02965    time: 0.1683  last_time: 0.1672  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-05  max_mem: 1637M
[11/23 00:27:13] d2.utils.events INFO:  eta: 0:19:56  iter: 7719  total_loss: 1.18  loss_ce: 0.1718  loss_objectness: 0.6254  loss_dice: 0.3039  loss_mask: 0.03766    time: 0.1683  last_time: 0.1648  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:27:16] d2.utils.events INFO:  eta: 0:19:53  iter: 7739  total_loss: 1.103  loss_ce: 0.1995  loss_objectness: 0.5912  loss_dice: 0.2526  loss_mask: 0.02901    time: 0.1683  last_time: 0.1674  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:27:20] d2.utils.events INFO:  eta: 0:19:50  iter: 7759  total_loss: 1.002  loss_ce: 0.1646  loss_objectness: 0.5609  loss_dice: 0.2106  loss_mask: 0.03471    time: 0.1682  last_time: 0.1630  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:27:23] d2.utils.events INFO:  eta: 0:19:47  iter: 7779  total_loss: 1.111  loss_ce: 0.1883  loss_objectness: 0.5816  loss_dice: 0.2739  loss_mask: 0.02399    time: 0.1682  last_time: 0.1645  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1637M
[11/23 00:27:26] d2.utils.events INFO:  eta: 0:19:44  iter: 7799  total_loss: 1.079  loss_ce: 0.1831  loss_objectness: 0.6094  loss_dice: 0.2742  loss_mask: 0.0318    time: 0.1682  last_time: 0.1657  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:27:30] d2.utils.events INFO:  eta: 0:19:41  iter: 7819  total_loss: 1.081  loss_ce: 0.1888  loss_objectness: 0.5925  loss_dice: 0.2768  loss_mask: 0.03328    time: 0.1682  last_time: 0.1774  data_time: 0.0030  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:27:33] d2.utils.events INFO:  eta: 0:19:38  iter: 7839  total_loss: 1.141  loss_ce: 0.1964  loss_objectness: 0.5974  loss_dice: 0.3062  loss_mask: 0.03042    time: 0.1682  last_time: 0.1673  data_time: 0.0031  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:27:36] d2.utils.events INFO:  eta: 0:19:35  iter: 7859  total_loss: 1.037  loss_ce: 0.1566  loss_objectness: 0.5765  loss_dice: 0.285  loss_mask: 0.03331    time: 0.1682  last_time: 0.1652  data_time: 0.0030  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:27:40] d2.utils.events INFO:  eta: 0:19:32  iter: 7879  total_loss: 1.048  loss_ce: 0.1667  loss_objectness: 0.5708  loss_dice: 0.2524  loss_mask: 0.03077    time: 0.1682  last_time: 0.1659  data_time: 0.0030  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:27:43] d2.utils.events INFO:  eta: 0:19:29  iter: 7899  total_loss: 0.957  loss_ce: 0.1523  loss_objectness: 0.5738  loss_dice: 0.2163  loss_mask: 0.03322    time: 0.1682  last_time: 0.1662  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:27:46] d2.utils.events INFO:  eta: 0:19:25  iter: 7919  total_loss: 1.033  loss_ce: 0.1748  loss_objectness: 0.5576  loss_dice: 0.2376  loss_mask: 0.02157    time: 0.1682  last_time: 0.1637  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:27:50] d2.utils.events INFO:  eta: 0:19:22  iter: 7939  total_loss: 0.986  loss_ce: 0.1088  loss_objectness: 0.5426  loss_dice: 0.2539  loss_mask: 0.03189    time: 0.1682  last_time: 0.1641  data_time: 0.0027  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:27:53] d2.utils.events INFO:  eta: 0:19:19  iter: 7959  total_loss: 1.047  loss_ce: 0.1475  loss_objectness: 0.6104  loss_dice: 0.2673  loss_mask: 0.03057    time: 0.1682  last_time: 0.1659  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:27:56] d2.utils.events INFO:  eta: 0:19:16  iter: 7979  total_loss: 0.9921  loss_ce: 0.1587  loss_objectness: 0.568  loss_dice: 0.2284  loss_mask: 0.03213    time: 0.1682  last_time: 0.1649  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1637M
[11/23 00:28:00] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/23 00:28:00] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/23 00:28:00] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/23 00:28:00] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/23 00:28:00] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/23 00:28:00] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/23 00:28:06] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0360 s/iter. Eval: 0.0555 s/iter. Total: 0.0919 s/iter. ETA=0:00:10
[11/23 00:28:11] d2.evaluation.evaluator INFO: Inference done 69/120. Dataloading: 0.0004 s/iter. Inference: 0.0318 s/iter. Eval: 0.0557 s/iter. Total: 0.0879 s/iter. ETA=0:00:04
[11/23 00:28:16] d2.evaluation.evaluator INFO: Total inference time: 0:00:10.576100 (0.091966 s / iter per device, on 1 devices)
[11/23 00:28:16] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:03 (0.029425 s / iter per device, on 1 devices)
[11/23 00:28:16] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/23 00:28:16] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_gabor_turbo\inference\coco_instances_results.json
[11/23 00:28:16] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/23 00:28:16] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/23 00:28:16] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.05 seconds.
[11/23 00:28:16] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/23 00:28:16] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/23 00:28:16] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.695 | 14.745 | 6.071  | 0.054 | 14.421 | 45.128 |
[11/23 00:28:16] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/23 00:28:16] d2.evaluation.testing INFO: copypaste: Task: segm
[11/23 00:28:16] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/23 00:28:16] d2.evaluation.testing INFO: copypaste: 6.6948,14.7453,6.0712,0.0538,14.4211,45.1276
[11/23 00:28:16] d2.utils.events INFO:  eta: 0:19:13  iter: 7999  total_loss: 1.061  loss_ce: 0.1753  loss_objectness: 0.6027  loss_dice: 0.294  loss_mask: 0.0298    time: 0.1682  last_time: 0.1647  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:28:20] d2.utils.events INFO:  eta: 0:19:09  iter: 8019  total_loss: 1.139  loss_ce: 0.2357  loss_objectness: 0.6053  loss_dice: 0.3123  loss_mask: 0.0274    time: 0.1682  last_time: 0.1641  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-05  max_mem: 1637M
[11/23 00:28:23] d2.utils.events INFO:  eta: 0:19:06  iter: 8039  total_loss: 1.076  loss_ce: 0.1552  loss_objectness: 0.5858  loss_dice: 0.2601  loss_mask: 0.033    time: 0.1682  last_time: 0.1641  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:28:26] d2.utils.events INFO:  eta: 0:19:03  iter: 8059  total_loss: 0.9565  loss_ce: 0.09024  loss_objectness: 0.5838  loss_dice: 0.2257  loss_mask: 0.03413    time: 0.1682  last_time: 0.1671  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:28:29] d2.utils.events INFO:  eta: 0:19:00  iter: 8079  total_loss: 1.089  loss_ce: 0.1565  loss_objectness: 0.6051  loss_dice: 0.285  loss_mask: 0.02592    time: 0.1682  last_time: 0.1651  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:28:33] d2.utils.events INFO:  eta: 0:18:57  iter: 8099  total_loss: 1.084  loss_ce: 0.1939  loss_objectness: 0.601  loss_dice: 0.2837  loss_mask: 0.02568    time: 0.1682  last_time: 0.1703  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1637M
[11/23 00:28:36] d2.utils.events INFO:  eta: 0:18:54  iter: 8119  total_loss: 0.9551  loss_ce: 0.1337  loss_objectness: 0.5437  loss_dice: 0.2167  loss_mask: 0.02718    time: 0.1682  last_time: 0.1649  data_time: 0.0030  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:28:39] d2.utils.events INFO:  eta: 0:18:51  iter: 8139  total_loss: 0.8751  loss_ce: 0.1201  loss_objectness: 0.5251  loss_dice: 0.1862  loss_mask: 0.02798    time: 0.1682  last_time: 0.1642  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:28:43] d2.utils.events INFO:  eta: 0:18:48  iter: 8159  total_loss: 1.035  loss_ce: 0.1365  loss_objectness: 0.5781  loss_dice: 0.2525  loss_mask: 0.0343    time: 0.1681  last_time: 0.1657  data_time: 0.0028  last_data_time: 0.0040   lr: 5e-05  max_mem: 1637M
[11/23 00:28:46] d2.utils.events INFO:  eta: 0:18:44  iter: 8179  total_loss: 1.018  loss_ce: 0.1823  loss_objectness: 0.5729  loss_dice: 0.2476  loss_mask: 0.02478    time: 0.1681  last_time: 0.1638  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:28:49] d2.utils.events INFO:  eta: 0:18:41  iter: 8199  total_loss: 1.144  loss_ce: 0.1969  loss_objectness: 0.599  loss_dice: 0.3001  loss_mask: 0.02728    time: 0.1681  last_time: 0.1646  data_time: 0.0030  last_data_time: 0.0034   lr: 5e-05  max_mem: 1637M
[11/23 00:28:53] d2.utils.events INFO:  eta: 0:18:38  iter: 8219  total_loss: 0.904  loss_ce: 0.1499  loss_objectness: 0.5453  loss_dice: 0.2363  loss_mask: 0.03091    time: 0.1681  last_time: 0.1655  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:28:56] d2.utils.events INFO:  eta: 0:18:35  iter: 8239  total_loss: 1.055  loss_ce: 0.1661  loss_objectness: 0.5992  loss_dice: 0.26  loss_mask: 0.0277    time: 0.1681  last_time: 0.1680  data_time: 0.0031  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:28:59] d2.utils.events INFO:  eta: 0:18:32  iter: 8259  total_loss: 1.105  loss_ce: 0.1659  loss_objectness: 0.594  loss_dice: 0.2808  loss_mask: 0.02927    time: 0.1681  last_time: 0.1668  data_time: 0.0029  last_data_time: 0.0033   lr: 5e-05  max_mem: 1637M
[11/23 00:29:03] d2.utils.events INFO:  eta: 0:18:28  iter: 8279  total_loss: 0.9695  loss_ce: 0.133  loss_objectness: 0.5415  loss_dice: 0.2151  loss_mask: 0.02804    time: 0.1681  last_time: 0.1680  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:29:06] d2.utils.events INFO:  eta: 0:18:25  iter: 8299  total_loss: 0.8956  loss_ce: 0.07887  loss_objectness: 0.5622  loss_dice: 0.2284  loss_mask: 0.03629    time: 0.1681  last_time: 0.1723  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:29:09] d2.utils.events INFO:  eta: 0:18:22  iter: 8319  total_loss: 0.9909  loss_ce: 0.1757  loss_objectness: 0.5714  loss_dice: 0.2368  loss_mask: 0.0297    time: 0.1681  last_time: 0.1662  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:29:13] d2.utils.events INFO:  eta: 0:18:19  iter: 8339  total_loss: 0.9431  loss_ce: 0.156  loss_objectness: 0.5636  loss_dice: 0.2195  loss_mask: 0.03155    time: 0.1681  last_time: 0.1622  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:29:16] d2.utils.events INFO:  eta: 0:18:16  iter: 8359  total_loss: 1.125  loss_ce: 0.1891  loss_objectness: 0.578  loss_dice: 0.2769  loss_mask: 0.03358    time: 0.1681  last_time: 0.1670  data_time: 0.0030  last_data_time: 0.0036   lr: 5e-05  max_mem: 1637M
[11/23 00:29:19] d2.utils.events INFO:  eta: 0:18:13  iter: 8379  total_loss: 1.094  loss_ce: 0.1733  loss_objectness: 0.6109  loss_dice: 0.2489  loss_mask: 0.02965    time: 0.1681  last_time: 0.1676  data_time: 0.0032  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:29:23] d2.utils.events INFO:  eta: 0:18:10  iter: 8399  total_loss: 0.9099  loss_ce: 0.1031  loss_objectness: 0.5352  loss_dice: 0.2189  loss_mask: 0.0354    time: 0.1681  last_time: 0.1653  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:29:26] d2.utils.events INFO:  eta: 0:18:07  iter: 8419  total_loss: 0.812  loss_ce: 0.08372  loss_objectness: 0.5277  loss_dice: 0.1763  loss_mask: 0.03509    time: 0.1681  last_time: 0.1666  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:29:29] d2.utils.events INFO:  eta: 0:18:04  iter: 8439  total_loss: 0.9392  loss_ce: 0.159  loss_objectness: 0.5538  loss_dice: 0.2023  loss_mask: 0.02961    time: 0.1681  last_time: 0.1637  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:29:33] d2.utils.events INFO:  eta: 0:18:00  iter: 8459  total_loss: 0.9577  loss_ce: 0.09205  loss_objectness: 0.5678  loss_dice: 0.2561  loss_mask: 0.03406    time: 0.1681  last_time: 0.1637  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:29:36] d2.utils.events INFO:  eta: 0:17:57  iter: 8479  total_loss: 1.003  loss_ce: 0.1792  loss_objectness: 0.5858  loss_dice: 0.225  loss_mask: 0.02258    time: 0.1681  last_time: 0.1644  data_time: 0.0032  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:29:39] d2.utils.events INFO:  eta: 0:17:54  iter: 8499  total_loss: 1.028  loss_ce: 0.172  loss_objectness: 0.582  loss_dice: 0.217  loss_mask: 0.02794    time: 0.1680  last_time: 0.1656  data_time: 0.0028  last_data_time: 0.0032   lr: 5e-05  max_mem: 1637M
[11/23 00:29:43] d2.utils.events INFO:  eta: 0:17:50  iter: 8519  total_loss: 0.7988  loss_ce: 0.08482  loss_objectness: 0.5381  loss_dice: 0.1647  loss_mask: 0.02314    time: 0.1680  last_time: 0.1638  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:29:46] d2.utils.events INFO:  eta: 0:17:47  iter: 8539  total_loss: 0.8436  loss_ce: 0.07245  loss_objectness: 0.5397  loss_dice: 0.197  loss_mask: 0.02757    time: 0.1680  last_time: 0.1636  data_time: 0.0027  last_data_time: 0.0033   lr: 5e-05  max_mem: 1637M
[11/23 00:29:49] d2.utils.events INFO:  eta: 0:17:43  iter: 8559  total_loss: 1.089  loss_ce: 0.1694  loss_objectness: 0.5876  loss_dice: 0.2662  loss_mask: 0.02614    time: 0.1680  last_time: 0.1657  data_time: 0.0030  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:29:52] d2.utils.events INFO:  eta: 0:17:40  iter: 8579  total_loss: 1.048  loss_ce: 0.1381  loss_objectness: 0.602  loss_dice: 0.2519  loss_mask: 0.0333    time: 0.1680  last_time: 0.1628  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:29:56] d2.utils.events INFO:  eta: 0:17:37  iter: 8599  total_loss: 1.025  loss_ce: 0.107  loss_objectness: 0.5874  loss_dice: 0.2607  loss_mask: 0.03243    time: 0.1680  last_time: 0.1626  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:29:59] d2.utils.events INFO:  eta: 0:17:34  iter: 8619  total_loss: 0.9737  loss_ce: 0.1258  loss_objectness: 0.5712  loss_dice: 0.2272  loss_mask: 0.02916    time: 0.1680  last_time: 0.1629  data_time: 0.0030  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:30:02] d2.utils.events INFO:  eta: 0:17:30  iter: 8639  total_loss: 1.011  loss_ce: 0.2156  loss_objectness: 0.5601  loss_dice: 0.2208  loss_mask: 0.03307    time: 0.1680  last_time: 0.1669  data_time: 0.0029  last_data_time: 0.0034   lr: 5e-05  max_mem: 1637M
[11/23 00:30:06] d2.utils.events INFO:  eta: 0:17:27  iter: 8659  total_loss: 1.048  loss_ce: 0.1382  loss_objectness: 0.5962  loss_dice: 0.279  loss_mask: 0.02817    time: 0.1680  last_time: 0.1633  data_time: 0.0029  last_data_time: 0.0022   lr: 5e-05  max_mem: 1637M
[11/23 00:30:09] d2.utils.events INFO:  eta: 0:17:23  iter: 8679  total_loss: 0.9626  loss_ce: 0.1233  loss_objectness: 0.5827  loss_dice: 0.2226  loss_mask: 0.02627    time: 0.1680  last_time: 0.1613  data_time: 0.0027  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:30:12] d2.utils.events INFO:  eta: 0:17:20  iter: 8699  total_loss: 1.219  loss_ce: 0.219  loss_objectness: 0.6232  loss_dice: 0.33  loss_mask: 0.02521    time: 0.1680  last_time: 0.1638  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:30:16] d2.utils.events INFO:  eta: 0:17:16  iter: 8719  total_loss: 1.122  loss_ce: 0.1838  loss_objectness: 0.6096  loss_dice: 0.287  loss_mask: 0.0339    time: 0.1680  last_time: 0.1633  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-05  max_mem: 1637M
[11/23 00:30:19] d2.utils.events INFO:  eta: 0:17:13  iter: 8739  total_loss: 1.13  loss_ce: 0.1377  loss_objectness: 0.607  loss_dice: 0.2787  loss_mask: 0.03367    time: 0.1679  last_time: 0.1626  data_time: 0.0028  last_data_time: 0.0032   lr: 5e-05  max_mem: 1637M
[11/23 00:30:22] d2.utils.events INFO:  eta: 0:17:09  iter: 8759  total_loss: 0.9633  loss_ce: 0.09609  loss_objectness: 0.5804  loss_dice: 0.241  loss_mask: 0.03558    time: 0.1679  last_time: 0.1652  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:30:25] d2.utils.events INFO:  eta: 0:17:06  iter: 8779  total_loss: 0.9158  loss_ce: 0.08182  loss_objectness: 0.5717  loss_dice: 0.2175  loss_mask: 0.0338    time: 0.1679  last_time: 0.1640  data_time: 0.0027  last_data_time: 0.0022   lr: 5e-05  max_mem: 1637M
[11/23 00:30:29] d2.utils.events INFO:  eta: 0:17:02  iter: 8799  total_loss: 1.133  loss_ce: 0.1654  loss_objectness: 0.6076  loss_dice: 0.291  loss_mask: 0.03393    time: 0.1679  last_time: 0.1644  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:30:32] d2.utils.events INFO:  eta: 0:16:59  iter: 8819  total_loss: 0.9208  loss_ce: 0.114  loss_objectness: 0.5731  loss_dice: 0.2142  loss_mask: 0.03204    time: 0.1679  last_time: 0.1624  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:30:35] d2.utils.events INFO:  eta: 0:16:55  iter: 8839  total_loss: 0.8557  loss_ce: 0.09408  loss_objectness: 0.5413  loss_dice: 0.188  loss_mask: 0.03291    time: 0.1679  last_time: 0.1643  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:30:39] d2.utils.events INFO:  eta: 0:16:52  iter: 8859  total_loss: 1.077  loss_ce: 0.1496  loss_objectness: 0.6268  loss_dice: 0.2732  loss_mask: 0.02887    time: 0.1679  last_time: 0.1648  data_time: 0.0031  last_data_time: 0.0028   lr: 5e-05  max_mem: 1637M
[11/23 00:30:42] d2.utils.events INFO:  eta: 0:16:48  iter: 8879  total_loss: 0.9724  loss_ce: 0.1126  loss_objectness: 0.576  loss_dice: 0.2222  loss_mask: 0.02994    time: 0.1679  last_time: 0.1629  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:30:45] d2.utils.events INFO:  eta: 0:16:45  iter: 8899  total_loss: 0.9166  loss_ce: 0.0794  loss_objectness: 0.5708  loss_dice: 0.2169  loss_mask: 0.02708    time: 0.1679  last_time: 0.1649  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-05  max_mem: 1637M
[11/23 00:30:49] d2.utils.events INFO:  eta: 0:16:42  iter: 8919  total_loss: 0.9251  loss_ce: 0.1338  loss_objectness: 0.5694  loss_dice: 0.2223  loss_mask: 0.0229    time: 0.1679  last_time: 0.1736  data_time: 0.0031  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:30:52] d2.utils.events INFO:  eta: 0:16:38  iter: 8939  total_loss: 0.94  loss_ce: 0.1178  loss_objectness: 0.5762  loss_dice: 0.1834  loss_mask: 0.02998    time: 0.1679  last_time: 0.1617  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:30:55] d2.utils.events INFO:  eta: 0:16:35  iter: 8959  total_loss: 0.8488  loss_ce: 0.06055  loss_objectness: 0.5314  loss_dice: 0.1961  loss_mask: 0.02737    time: 0.1679  last_time: 0.1655  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:30:58] d2.utils.events INFO:  eta: 0:16:31  iter: 8979  total_loss: 0.9664  loss_ce: 0.1291  loss_objectness: 0.5848  loss_dice: 0.2352  loss_mask: 0.02415    time: 0.1679  last_time: 0.1669  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:31:02] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/23 00:31:02] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/23 00:31:02] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/23 00:31:02] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/23 00:31:02] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/23 00:31:02] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/23 00:31:08] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0225 s/iter. Eval: 0.0411 s/iter. Total: 0.0640 s/iter. ETA=0:00:06
[11/23 00:31:13] d2.evaluation.evaluator INFO: Inference done 80/120. Dataloading: 0.0004 s/iter. Inference: 0.0245 s/iter. Eval: 0.0471 s/iter. Total: 0.0721 s/iter. ETA=0:00:02
[11/23 00:31:16] d2.evaluation.evaluator INFO: Total inference time: 0:00:09.179369 (0.079821 s / iter per device, on 1 devices)
[11/23 00:31:16] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.025247 s / iter per device, on 1 devices)
[11/23 00:31:16] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/23 00:31:16] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_gabor_turbo\inference\coco_instances_results.json
[11/23 00:31:16] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/23 00:31:17] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/23 00:31:17] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.08 seconds.
[11/23 00:31:17] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/23 00:31:17] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/23 00:31:17] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 7.682 | 15.602 | 7.132  | 0.205 | 16.749 | 50.264 |
[11/23 00:31:17] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/23 00:31:17] d2.evaluation.testing INFO: copypaste: Task: segm
[11/23 00:31:17] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/23 00:31:17] d2.evaluation.testing INFO: copypaste: 7.6815,15.6018,7.1320,0.2055,16.7487,50.2640
[11/23 00:31:17] d2.utils.events INFO:  eta: 0:16:28  iter: 8999  total_loss: 0.8565  loss_ce: 0.1116  loss_objectness: 0.546  loss_dice: 0.1989  loss_mask: 0.02289    time: 0.1679  last_time: 0.1622  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:31:20] d2.utils.events INFO:  eta: 0:16:25  iter: 9019  total_loss: 1.083  loss_ce: 0.1942  loss_objectness: 0.5875  loss_dice: 0.2692  loss_mask: 0.02881    time: 0.1679  last_time: 0.1669  data_time: 0.0030  last_data_time: 0.0028   lr: 5e-05  max_mem: 1637M
[11/23 00:31:23] d2.utils.events INFO:  eta: 0:16:21  iter: 9039  total_loss: 1.015  loss_ce: 0.1794  loss_objectness: 0.5853  loss_dice: 0.239  loss_mask: 0.04147    time: 0.1679  last_time: 0.1639  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:31:27] d2.utils.events INFO:  eta: 0:16:18  iter: 9059  total_loss: 1.021  loss_ce: 0.1358  loss_objectness: 0.5963  loss_dice: 0.2637  loss_mask: 0.03858    time: 0.1678  last_time: 0.1646  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:31:30] d2.utils.events INFO:  eta: 0:16:14  iter: 9079  total_loss: 1.039  loss_ce: 0.1452  loss_objectness: 0.6171  loss_dice: 0.2954  loss_mask: 0.03274    time: 0.1678  last_time: 0.1657  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:31:33] d2.utils.events INFO:  eta: 0:16:11  iter: 9099  total_loss: 0.9605  loss_ce: 0.1079  loss_objectness: 0.5873  loss_dice: 0.2452  loss_mask: 0.02899    time: 0.1678  last_time: 0.1635  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:31:37] d2.utils.events INFO:  eta: 0:16:07  iter: 9119  total_loss: 1.002  loss_ce: 0.123  loss_objectness: 0.5889  loss_dice: 0.2521  loss_mask: 0.02477    time: 0.1678  last_time: 0.1654  data_time: 0.0030  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:31:40] d2.utils.events INFO:  eta: 0:16:04  iter: 9139  total_loss: 0.9456  loss_ce: 0.1209  loss_objectness: 0.5605  loss_dice: 0.2198  loss_mask: 0.03027    time: 0.1678  last_time: 0.1650  data_time: 0.0031  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:31:43] d2.utils.events INFO:  eta: 0:16:01  iter: 9159  total_loss: 0.9011  loss_ce: 0.08097  loss_objectness: 0.5609  loss_dice: 0.2151  loss_mask: 0.02661    time: 0.1678  last_time: 0.1641  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:31:47] d2.utils.events INFO:  eta: 0:15:57  iter: 9179  total_loss: 0.9111  loss_ce: 0.0963  loss_objectness: 0.5522  loss_dice: 0.1984  loss_mask: 0.0229    time: 0.1678  last_time: 0.1636  data_time: 0.0031  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:31:50] d2.utils.events INFO:  eta: 0:15:54  iter: 9199  total_loss: 0.852  loss_ce: 0.05831  loss_objectness: 0.5403  loss_dice: 0.1965  loss_mask: 0.03209    time: 0.1678  last_time: 0.1634  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:31:53] d2.utils.events INFO:  eta: 0:15:50  iter: 9219  total_loss: 1.035  loss_ce: 0.1662  loss_objectness: 0.584  loss_dice: 0.2323  loss_mask: 0.0234    time: 0.1678  last_time: 0.1642  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:31:57] d2.utils.events INFO:  eta: 0:15:47  iter: 9239  total_loss: 0.845  loss_ce: 0.06072  loss_objectness: 0.5459  loss_dice: 0.1908  loss_mask: 0.02611    time: 0.1678  last_time: 0.1636  data_time: 0.0029  last_data_time: 0.0035   lr: 5e-05  max_mem: 1637M
[11/23 00:32:00] d2.utils.events INFO:  eta: 0:15:43  iter: 9259  total_loss: 0.8179  loss_ce: 0.06212  loss_objectness: 0.5328  loss_dice: 0.1943  loss_mask: 0.02951    time: 0.1678  last_time: 0.1645  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:32:03] d2.utils.events INFO:  eta: 0:15:40  iter: 9279  total_loss: 0.8123  loss_ce: 0.02317  loss_objectness: 0.5246  loss_dice: 0.1903  loss_mask: 0.03126    time: 0.1678  last_time: 0.1628  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:32:06] d2.utils.events INFO:  eta: 0:15:37  iter: 9299  total_loss: 0.9114  loss_ce: 0.08691  loss_objectness: 0.5536  loss_dice: 0.2228  loss_mask: 0.02456    time: 0.1678  last_time: 0.1631  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:32:10] d2.utils.events INFO:  eta: 0:15:33  iter: 9319  total_loss: 0.9449  loss_ce: 0.1157  loss_objectness: 0.5654  loss_dice: 0.2481  loss_mask: 0.0232    time: 0.1678  last_time: 0.1636  data_time: 0.0030  last_data_time: 0.0041   lr: 5e-05  max_mem: 1637M
[11/23 00:32:13] d2.utils.events INFO:  eta: 0:15:30  iter: 9339  total_loss: 0.768  loss_ce: 0.04356  loss_objectness: 0.5161  loss_dice: 0.1737  loss_mask: 0.02607    time: 0.1678  last_time: 0.1638  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:32:16] d2.utils.events INFO:  eta: 0:15:26  iter: 9359  total_loss: 0.775  loss_ce: 0.038  loss_objectness: 0.5075  loss_dice: 0.1718  loss_mask: 0.02562    time: 0.1677  last_time: 0.1629  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:32:20] d2.utils.events INFO:  eta: 0:15:23  iter: 9379  total_loss: 0.8975  loss_ce: 0.07964  loss_objectness: 0.5839  loss_dice: 0.2371  loss_mask: 0.02288    time: 0.1677  last_time: 0.1646  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:32:23] d2.utils.events INFO:  eta: 0:15:20  iter: 9399  total_loss: 0.8677  loss_ce: 0.1003  loss_objectness: 0.5302  loss_dice: 0.1839  loss_mask: 0.02757    time: 0.1677  last_time: 0.1653  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:32:26] d2.utils.events INFO:  eta: 0:15:16  iter: 9419  total_loss: 0.8886  loss_ce: 0.07304  loss_objectness: 0.5667  loss_dice: 0.1931  loss_mask: 0.03089    time: 0.1677  last_time: 0.1632  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:32:29] d2.utils.events INFO:  eta: 0:15:13  iter: 9439  total_loss: 0.8751  loss_ce: 0.1086  loss_objectness: 0.5467  loss_dice: 0.209  loss_mask: 0.02343    time: 0.1677  last_time: 0.1638  data_time: 0.0030  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:32:33] d2.utils.events INFO:  eta: 0:15:10  iter: 9459  total_loss: 0.8913  loss_ce: 0.1099  loss_objectness: 0.5391  loss_dice: 0.2031  loss_mask: 0.03118    time: 0.1677  last_time: 0.1655  data_time: 0.0029  last_data_time: 0.0039   lr: 5e-05  max_mem: 1637M
[11/23 00:32:36] d2.utils.events INFO:  eta: 0:15:06  iter: 9479  total_loss: 0.8935  loss_ce: 0.07924  loss_objectness: 0.5319  loss_dice: 0.2115  loss_mask: 0.02397    time: 0.1677  last_time: 0.1634  data_time: 0.0028  last_data_time: 0.0033   lr: 5e-05  max_mem: 1637M
[11/23 00:32:39] d2.utils.events INFO:  eta: 0:15:03  iter: 9499  total_loss: 0.964  loss_ce: 0.1142  loss_objectness: 0.5532  loss_dice: 0.2211  loss_mask: 0.02346    time: 0.1677  last_time: 0.1635  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-05  max_mem: 1637M
[11/23 00:32:43] d2.utils.events INFO:  eta: 0:15:00  iter: 9519  total_loss: 0.8571  loss_ce: 0.07313  loss_objectness: 0.5225  loss_dice: 0.1889  loss_mask: 0.023    time: 0.1677  last_time: 0.1622  data_time: 0.0029  last_data_time: 0.0022   lr: 5e-05  max_mem: 1637M
[11/23 00:32:46] d2.utils.events INFO:  eta: 0:14:57  iter: 9539  total_loss: 0.8245  loss_ce: 0.05927  loss_objectness: 0.5587  loss_dice: 0.1941  loss_mask: 0.02374    time: 0.1677  last_time: 0.1646  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-05  max_mem: 1637M
[11/23 00:32:49] d2.utils.events INFO:  eta: 0:14:53  iter: 9559  total_loss: 0.8041  loss_ce: 0.06069  loss_objectness: 0.5159  loss_dice: 0.1802  loss_mask: 0.02379    time: 0.1677  last_time: 0.1651  data_time: 0.0029  last_data_time: 0.0034   lr: 5e-05  max_mem: 1637M
[11/23 00:32:53] d2.utils.events INFO:  eta: 0:14:50  iter: 9579  total_loss: 0.6864  loss_ce: 0.02214  loss_objectness: 0.5059  loss_dice: 0.1381  loss_mask: 0.02902    time: 0.1677  last_time: 0.1641  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:32:56] d2.utils.events INFO:  eta: 0:14:47  iter: 9599  total_loss: 0.7716  loss_ce: 0.06629  loss_objectness: 0.5177  loss_dice: 0.1769  loss_mask: 0.02365    time: 0.1677  last_time: 0.1661  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:32:59] d2.utils.events INFO:  eta: 0:14:44  iter: 9619  total_loss: 0.8637  loss_ce: 0.08147  loss_objectness: 0.5379  loss_dice: 0.2064  loss_mask: 0.02406    time: 0.1677  last_time: 0.1639  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-05  max_mem: 1637M
[11/23 00:33:03] d2.utils.events INFO:  eta: 0:14:40  iter: 9639  total_loss: 0.8656  loss_ce: 0.1061  loss_objectness: 0.5484  loss_dice: 0.2037  loss_mask: 0.02907    time: 0.1677  last_time: 0.1634  data_time: 0.0030  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:33:06] d2.utils.events INFO:  eta: 0:14:37  iter: 9659  total_loss: 1.057  loss_ce: 0.1589  loss_objectness: 0.6019  loss_dice: 0.2892  loss_mask: 0.03016    time: 0.1677  last_time: 0.1662  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:33:09] d2.utils.events INFO:  eta: 0:14:34  iter: 9679  total_loss: 1.011  loss_ce: 0.1284  loss_objectness: 0.6005  loss_dice: 0.2501  loss_mask: 0.03237    time: 0.1676  last_time: 0.1642  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:33:12] d2.utils.events INFO:  eta: 0:14:30  iter: 9699  total_loss: 1.023  loss_ce: 0.09046  loss_objectness: 0.5851  loss_dice: 0.2479  loss_mask: 0.02856    time: 0.1676  last_time: 0.1645  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-05  max_mem: 1637M
[11/23 00:33:16] d2.utils.events INFO:  eta: 0:14:27  iter: 9719  total_loss: 0.9112  loss_ce: 0.06798  loss_objectness: 0.5468  loss_dice: 0.231  loss_mask: 0.02846    time: 0.1676  last_time: 0.1648  data_time: 0.0027  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:33:19] d2.utils.events INFO:  eta: 0:14:24  iter: 9739  total_loss: 0.8012  loss_ce: 0.05921  loss_objectness: 0.5178  loss_dice: 0.1607  loss_mask: 0.02026    time: 0.1676  last_time: 0.1625  data_time: 0.0027  last_data_time: 0.0029   lr: 5e-05  max_mem: 1637M
[11/23 00:33:22] d2.utils.events INFO:  eta: 0:14:21  iter: 9759  total_loss: 0.7639  loss_ce: 0.05604  loss_objectness: 0.5231  loss_dice: 0.1665  loss_mask: 0.02569    time: 0.1676  last_time: 0.1645  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:33:26] d2.utils.events INFO:  eta: 0:14:17  iter: 9779  total_loss: 0.8363  loss_ce: 0.04416  loss_objectness: 0.547  loss_dice: 0.1989  loss_mask: 0.02643    time: 0.1676  last_time: 0.1615  data_time: 0.0030  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:33:29] d2.utils.events INFO:  eta: 0:14:14  iter: 9799  total_loss: 0.8087  loss_ce: 0.07324  loss_objectness: 0.5331  loss_dice: 0.1869  loss_mask: 0.02351    time: 0.1676  last_time: 0.1650  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:33:32] d2.utils.events INFO:  eta: 0:14:11  iter: 9819  total_loss: 0.9463  loss_ce: 0.116  loss_objectness: 0.564  loss_dice: 0.2146  loss_mask: 0.02248    time: 0.1676  last_time: 0.1661  data_time: 0.0031  last_data_time: 0.0040   lr: 5e-05  max_mem: 1637M
[11/23 00:33:36] d2.utils.events INFO:  eta: 0:14:08  iter: 9839  total_loss: 0.7861  loss_ce: 0.06802  loss_objectness: 0.5137  loss_dice: 0.17  loss_mask: 0.02671    time: 0.1676  last_time: 0.1641  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:33:39] d2.utils.events INFO:  eta: 0:14:05  iter: 9859  total_loss: 0.8255  loss_ce: 0.06034  loss_objectness: 0.5668  loss_dice: 0.1879  loss_mask: 0.02317    time: 0.1676  last_time: 0.1655  data_time: 0.0030  last_data_time: 0.0024   lr: 5e-05  max_mem: 1637M
[11/23 00:33:42] d2.utils.events INFO:  eta: 0:14:01  iter: 9879  total_loss: 0.7964  loss_ce: 0.03889  loss_objectness: 0.5369  loss_dice: 0.1683  loss_mask: 0.02745    time: 0.1676  last_time: 0.1629  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-05  max_mem: 1637M
[11/23 00:33:46] d2.utils.events INFO:  eta: 0:13:58  iter: 9899  total_loss: 0.8708  loss_ce: 0.1036  loss_objectness: 0.5509  loss_dice: 0.2063  loss_mask: 0.02633    time: 0.1676  last_time: 0.1601  data_time: 0.0030  last_data_time: 0.0028   lr: 5e-05  max_mem: 1637M
[11/23 00:33:49] d2.utils.events INFO:  eta: 0:13:54  iter: 9919  total_loss: 0.8331  loss_ce: 0.07812  loss_objectness: 0.5418  loss_dice: 0.1812  loss_mask: 0.02868    time: 0.1676  last_time: 0.1600  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:33:52] d2.utils.events INFO:  eta: 0:13:51  iter: 9939  total_loss: 0.8424  loss_ce: 0.065  loss_objectness: 0.5568  loss_dice: 0.1975  loss_mask: 0.02006    time: 0.1676  last_time: 0.1669  data_time: 0.0029  last_data_time: 0.0033   lr: 5e-05  max_mem: 1637M
[11/23 00:33:55] d2.utils.events INFO:  eta: 0:13:48  iter: 9959  total_loss: 0.741  loss_ce: 0.02949  loss_objectness: 0.5129  loss_dice: 0.1659  loss_mask: 0.02423    time: 0.1676  last_time: 0.1648  data_time: 0.0026  last_data_time: 0.0025   lr: 5e-05  max_mem: 1637M
[11/23 00:33:59] d2.utils.events INFO:  eta: 0:13:45  iter: 9979  total_loss: 0.8393  loss_ce: 0.04497  loss_objectness: 0.5608  loss_dice: 0.2035  loss_mask: 0.02464    time: 0.1676  last_time: 0.1660  data_time: 0.0029  last_data_time: 0.0035   lr: 5e-05  max_mem: 1637M
[11/23 00:34:02] fvcore.common.checkpoint INFO: Saving checkpoint to output/crack_gabor_turbo\model_0009999.pth
[11/23 00:34:02] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/23 00:34:02] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/23 00:34:02] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/23 00:34:02] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/23 00:34:02] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/23 00:34:02] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/23 00:34:08] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0224 s/iter. Eval: 0.0455 s/iter. Total: 0.0682 s/iter. ETA=0:00:07
[11/23 00:34:13] d2.evaluation.evaluator INFO: Inference done 82/120. Dataloading: 0.0004 s/iter. Inference: 0.0245 s/iter. Eval: 0.0455 s/iter. Total: 0.0705 s/iter. ETA=0:00:02
[11/23 00:34:17] d2.evaluation.evaluator INFO: Total inference time: 0:00:09.280261 (0.080698 s / iter per device, on 1 devices)
[11/23 00:34:17] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.025033 s / iter per device, on 1 devices)
[11/23 00:34:17] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/23 00:34:17] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_gabor_turbo\inference\coco_instances_results.json
[11/23 00:34:17] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/23 00:34:17] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/23 00:34:17] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.08 seconds.
[11/23 00:34:17] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/23 00:34:17] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/23 00:34:17] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 7.042 | 13.573 | 6.397  | 0.033 | 14.869 | 50.917 |
[11/23 00:34:17] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/23 00:34:17] d2.evaluation.testing INFO: copypaste: Task: segm
[11/23 00:34:17] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/23 00:34:17] d2.evaluation.testing INFO: copypaste: 7.0416,13.5728,6.3974,0.0330,14.8687,50.9170
[11/23 00:34:17] d2.utils.events INFO:  eta: 0:13:41  iter: 9999  total_loss: 0.9038  loss_ce: 0.09855  loss_objectness: 0.5719  loss_dice: 0.2124  loss_mask: 0.03092    time: 0.1676  last_time: 0.1628  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-05  max_mem: 1637M
[11/23 00:34:21] d2.utils.events INFO:  eta: 0:13:38  iter: 10019  total_loss: 0.8223  loss_ce: 0.06498  loss_objectness: 0.498  loss_dice: 0.1958  loss_mask: 0.02379    time: 0.1676  last_time: 0.1644  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-06  max_mem: 1637M
[11/23 00:34:24] d2.utils.events INFO:  eta: 0:13:35  iter: 10039  total_loss: 0.7953  loss_ce: 0.07826  loss_objectness: 0.5039  loss_dice: 0.1536  loss_mask: 0.02241    time: 0.1676  last_time: 0.1624  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:34:28] d2.utils.events INFO:  eta: 0:13:31  iter: 10059  total_loss: 0.6941  loss_ce: 0.02529  loss_objectness: 0.4895  loss_dice: 0.1492  loss_mask: 0.02534    time: 0.1676  last_time: 0.1657  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-06  max_mem: 1637M
[11/23 00:34:31] d2.utils.events INFO:  eta: 0:13:28  iter: 10079  total_loss: 0.7368  loss_ce: 0.04745  loss_objectness: 0.4995  loss_dice: 0.1596  loss_mask: 0.02288    time: 0.1675  last_time: 0.1626  data_time: 0.0029  last_data_time: 0.0036   lr: 5e-06  max_mem: 1637M
[11/23 00:34:34] d2.utils.events INFO:  eta: 0:13:25  iter: 10099  total_loss: 0.7126  loss_ce: 0.03467  loss_objectness: 0.4963  loss_dice: 0.1339  loss_mask: 0.02331    time: 0.1675  last_time: 0.1657  data_time: 0.0027  last_data_time: 0.0030   lr: 5e-06  max_mem: 1637M
[11/23 00:34:37] d2.utils.events INFO:  eta: 0:13:22  iter: 10119  total_loss: 0.6524  loss_ce: 0.04282  loss_objectness: 0.4825  loss_dice: 0.1171  loss_mask: 0.01978    time: 0.1675  last_time: 0.1626  data_time: 0.0029  last_data_time: 0.0030   lr: 5e-06  max_mem: 1637M
[11/23 00:34:41] d2.utils.events INFO:  eta: 0:13:18  iter: 10139  total_loss: 0.6688  loss_ce: 0.02565  loss_objectness: 0.4775  loss_dice: 0.1404  loss_mask: 0.01919    time: 0.1675  last_time: 0.1663  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:34:44] d2.utils.events INFO:  eta: 0:13:15  iter: 10159  total_loss: 0.6482  loss_ce: 0.02393  loss_objectness: 0.4652  loss_dice: 0.1143  loss_mask: 0.02    time: 0.1675  last_time: 0.1666  data_time: 0.0027  last_data_time: 0.0032   lr: 5e-06  max_mem: 1637M
[11/23 00:34:47] d2.utils.events INFO:  eta: 0:13:12  iter: 10179  total_loss: 0.7368  loss_ce: 0.06  loss_objectness: 0.5016  loss_dice: 0.1502  loss_mask: 0.02054    time: 0.1675  last_time: 0.1656  data_time: 0.0033  last_data_time: 0.0029   lr: 5e-06  max_mem: 1637M
[11/23 00:34:51] d2.utils.events INFO:  eta: 0:13:08  iter: 10199  total_loss: 0.6094  loss_ce: 0.0257  loss_objectness: 0.4292  loss_dice: 0.1053  loss_mask: 0.02423    time: 0.1675  last_time: 0.1640  data_time: 0.0028  last_data_time: 0.0038   lr: 5e-06  max_mem: 1637M
[11/23 00:34:54] d2.utils.events INFO:  eta: 0:13:05  iter: 10219  total_loss: 0.7456  loss_ce: 0.05329  loss_objectness: 0.501  loss_dice: 0.157  loss_mask: 0.0219    time: 0.1675  last_time: 0.1635  data_time: 0.0030  last_data_time: 0.0028   lr: 5e-06  max_mem: 1637M
[11/23 00:34:57] d2.utils.events INFO:  eta: 0:13:02  iter: 10239  total_loss: 0.6826  loss_ce: 0.02582  loss_objectness: 0.4831  loss_dice: 0.1351  loss_mask: 0.02251    time: 0.1675  last_time: 0.1635  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:35:01] d2.utils.events INFO:  eta: 0:12:59  iter: 10259  total_loss: 0.5898  loss_ce: 0.01353  loss_objectness: 0.4471  loss_dice: 0.1159  loss_mask: 0.01918    time: 0.1675  last_time: 0.1633  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-06  max_mem: 1637M
[11/23 00:35:04] d2.utils.events INFO:  eta: 0:12:55  iter: 10279  total_loss: 0.6648  loss_ce: 0.03271  loss_objectness: 0.4598  loss_dice: 0.1302  loss_mask: 0.02629    time: 0.1675  last_time: 0.1657  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-06  max_mem: 1637M
[11/23 00:35:07] d2.utils.events INFO:  eta: 0:12:52  iter: 10299  total_loss: 0.6586  loss_ce: 0.02168  loss_objectness: 0.4489  loss_dice: 0.1243  loss_mask: 0.01926    time: 0.1675  last_time: 0.1627  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:35:11] d2.utils.events INFO:  eta: 0:12:49  iter: 10319  total_loss: 0.6122  loss_ce: 0.02645  loss_objectness: 0.4566  loss_dice: 0.1097  loss_mask: 0.02147    time: 0.1675  last_time: 0.1614  data_time: 0.0030  last_data_time: 0.0031   lr: 5e-06  max_mem: 1637M
[11/23 00:35:14] d2.utils.events INFO:  eta: 0:12:45  iter: 10339  total_loss: 0.6746  loss_ce: 0.02772  loss_objectness: 0.48  loss_dice: 0.1266  loss_mask: 0.02217    time: 0.1675  last_time: 0.1639  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-06  max_mem: 1637M
[11/23 00:35:17] d2.utils.events INFO:  eta: 0:12:42  iter: 10359  total_loss: 0.6645  loss_ce: 0.03414  loss_objectness: 0.4667  loss_dice: 0.1306  loss_mask: 0.01989    time: 0.1675  last_time: 0.1624  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:35:20] d2.utils.events INFO:  eta: 0:12:39  iter: 10379  total_loss: 0.5784  loss_ce: 0.01995  loss_objectness: 0.4136  loss_dice: 0.1085  loss_mask: 0.02188    time: 0.1675  last_time: 0.1650  data_time: 0.0027  last_data_time: 0.0033   lr: 5e-06  max_mem: 1637M
[11/23 00:35:24] d2.utils.events INFO:  eta: 0:12:36  iter: 10399  total_loss: 0.6628  loss_ce: 0.03529  loss_objectness: 0.4628  loss_dice: 0.1314  loss_mask: 0.0207    time: 0.1675  last_time: 0.1645  data_time: 0.0030  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:35:27] d2.utils.events INFO:  eta: 0:12:33  iter: 10419  total_loss: 0.6175  loss_ce: 0.02792  loss_objectness: 0.4338  loss_dice: 0.1178  loss_mask: 0.01952    time: 0.1675  last_time: 0.1723  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:35:30] d2.utils.events INFO:  eta: 0:12:29  iter: 10439  total_loss: 0.6203  loss_ce: 0.01417  loss_objectness: 0.4553  loss_dice: 0.1087  loss_mask: 0.0175    time: 0.1675  last_time: 0.1662  data_time: 0.0031  last_data_time: 0.0032   lr: 5e-06  max_mem: 1637M
[11/23 00:35:34] d2.utils.events INFO:  eta: 0:12:26  iter: 10459  total_loss: 0.62  loss_ce: 0.008937  loss_objectness: 0.4526  loss_dice: 0.1079  loss_mask: 0.0244    time: 0.1674  last_time: 0.1635  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-06  max_mem: 1637M
[11/23 00:35:37] d2.utils.events INFO:  eta: 0:12:23  iter: 10479  total_loss: 0.5827  loss_ce: 0.01705  loss_objectness: 0.4439  loss_dice: 0.09277  loss_mask: 0.02056    time: 0.1674  last_time: 0.1655  data_time: 0.0028  last_data_time: 0.0033   lr: 5e-06  max_mem: 1637M
[11/23 00:35:40] d2.utils.events INFO:  eta: 0:12:19  iter: 10499  total_loss: 0.7131  loss_ce: 0.03855  loss_objectness: 0.4778  loss_dice: 0.1536  loss_mask: 0.01747    time: 0.1674  last_time: 0.1633  data_time: 0.0030  last_data_time: 0.0029   lr: 5e-06  max_mem: 1637M
[11/23 00:35:44] d2.utils.events INFO:  eta: 0:12:16  iter: 10519  total_loss: 0.5885  loss_ce: 0.01109  loss_objectness: 0.4409  loss_dice: 0.1052  loss_mask: 0.01875    time: 0.1674  last_time: 0.1616  data_time: 0.0028  last_data_time: 0.0031   lr: 5e-06  max_mem: 1637M
[11/23 00:35:47] d2.utils.events INFO:  eta: 0:12:13  iter: 10539  total_loss: 0.5678  loss_ce: 0.01965  loss_objectness: 0.4195  loss_dice: 0.1039  loss_mask: 0.02092    time: 0.1674  last_time: 0.1695  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:35:50] d2.utils.events INFO:  eta: 0:12:09  iter: 10559  total_loss: 0.6483  loss_ce: 0.01224  loss_objectness: 0.4421  loss_dice: 0.1148  loss_mask: 0.02109    time: 0.1674  last_time: 0.1629  data_time: 0.0028  last_data_time: 0.0032   lr: 5e-06  max_mem: 1637M
[11/23 00:35:53] d2.utils.events INFO:  eta: 0:12:06  iter: 10579  total_loss: 0.6235  loss_ce: 0.02278  loss_objectness: 0.4455  loss_dice: 0.1143  loss_mask: 0.01811    time: 0.1674  last_time: 0.1642  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:35:57] d2.utils.events INFO:  eta: 0:12:03  iter: 10599  total_loss: 0.6729  loss_ce: 0.03368  loss_objectness: 0.4649  loss_dice: 0.1198  loss_mask: 0.01978    time: 0.1674  last_time: 0.1633  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:36:00] d2.utils.events INFO:  eta: 0:11:59  iter: 10619  total_loss: 0.6353  loss_ce: 0.02388  loss_objectness: 0.4649  loss_dice: 0.1118  loss_mask: 0.01992    time: 0.1674  last_time: 0.1634  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-06  max_mem: 1637M
[11/23 00:36:03] d2.utils.events INFO:  eta: 0:11:56  iter: 10639  total_loss: 0.5934  loss_ce: 0.02151  loss_objectness: 0.4355  loss_dice: 0.1073  loss_mask: 0.0172    time: 0.1674  last_time: 0.1652  data_time: 0.0031  last_data_time: 0.0042   lr: 5e-06  max_mem: 1637M
[11/23 00:36:07] d2.utils.events INFO:  eta: 0:11:53  iter: 10659  total_loss: 0.5931  loss_ce: 0.01487  loss_objectness: 0.4425  loss_dice: 0.1121  loss_mask: 0.02182    time: 0.1674  last_time: 0.1647  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:36:10] d2.utils.events INFO:  eta: 0:11:49  iter: 10679  total_loss: 0.6154  loss_ce: 0.009258  loss_objectness: 0.4398  loss_dice: 0.1107  loss_mask: 0.02306    time: 0.1674  last_time: 0.1656  data_time: 0.0027  last_data_time: 0.0029   lr: 5e-06  max_mem: 1637M
[11/23 00:36:13] d2.utils.events INFO:  eta: 0:11:46  iter: 10699  total_loss: 0.6606  loss_ce: 0.0371  loss_objectness: 0.4362  loss_dice: 0.1155  loss_mask: 0.01882    time: 0.1674  last_time: 0.1685  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-06  max_mem: 1637M
[11/23 00:36:17] d2.utils.events INFO:  eta: 0:11:43  iter: 10719  total_loss: 0.611  loss_ce: 0.02668  loss_objectness: 0.4346  loss_dice: 0.1154  loss_mask: 0.02013    time: 0.1674  last_time: 0.1662  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-06  max_mem: 1637M
[11/23 00:36:20] d2.utils.events INFO:  eta: 0:11:40  iter: 10739  total_loss: 0.5719  loss_ce: 0.01222  loss_objectness: 0.4251  loss_dice: 0.1125  loss_mask: 0.02299    time: 0.1674  last_time: 0.1609  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:36:23] d2.utils.events INFO:  eta: 0:11:36  iter: 10759  total_loss: 0.5801  loss_ce: 0.02344  loss_objectness: 0.4514  loss_dice: 0.09996  loss_mask: 0.02189    time: 0.1674  last_time: 0.1636  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:36:26] d2.utils.events INFO:  eta: 0:11:33  iter: 10779  total_loss: 0.6011  loss_ce: 0.01367  loss_objectness: 0.4271  loss_dice: 0.1098  loss_mask: 0.02279    time: 0.1674  last_time: 0.1656  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:36:30] d2.utils.events INFO:  eta: 0:11:30  iter: 10799  total_loss: 0.6247  loss_ce: 0.01874  loss_objectness: 0.4496  loss_dice: 0.1163  loss_mask: 0.01959    time: 0.1674  last_time: 0.1683  data_time: 0.0030  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:36:33] d2.utils.events INFO:  eta: 0:11:26  iter: 10819  total_loss: 0.6189  loss_ce: 0.0289  loss_objectness: 0.4407  loss_dice: 0.1132  loss_mask: 0.0189    time: 0.1673  last_time: 0.1656  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-06  max_mem: 1637M
[11/23 00:36:36] d2.utils.events INFO:  eta: 0:11:23  iter: 10839  total_loss: 0.5716  loss_ce: 0.01214  loss_objectness: 0.4329  loss_dice: 0.09322  loss_mask: 0.01685    time: 0.1673  last_time: 0.1642  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-06  max_mem: 1637M
[11/23 00:36:40] d2.utils.events INFO:  eta: 0:11:20  iter: 10859  total_loss: 0.5227  loss_ce: 0.006051  loss_objectness: 0.3905  loss_dice: 0.09479  loss_mask: 0.01725    time: 0.1673  last_time: 0.1651  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-06  max_mem: 1637M
[11/23 00:36:43] d2.utils.events INFO:  eta: 0:11:16  iter: 10879  total_loss: 0.6322  loss_ce: 0.03058  loss_objectness: 0.4387  loss_dice: 0.1229  loss_mask: 0.02405    time: 0.1673  last_time: 0.1626  data_time: 0.0030  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:36:46] d2.utils.events INFO:  eta: 0:11:13  iter: 10899  total_loss: 0.5813  loss_ce: 0.01654  loss_objectness: 0.4156  loss_dice: 0.1061  loss_mask: 0.02165    time: 0.1673  last_time: 0.1608  data_time: 0.0032  last_data_time: 0.0023   lr: 5e-06  max_mem: 1637M
[11/23 00:36:50] d2.utils.events INFO:  eta: 0:11:10  iter: 10919  total_loss: 0.6042  loss_ce: 0.03381  loss_objectness: 0.4102  loss_dice: 0.1034  loss_mask: 0.01736    time: 0.1673  last_time: 0.1641  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-06  max_mem: 1637M
[11/23 00:36:53] d2.utils.events INFO:  eta: 0:11:07  iter: 10939  total_loss: 0.6174  loss_ce: 0.0223  loss_objectness: 0.4392  loss_dice: 0.1182  loss_mask: 0.01784    time: 0.1673  last_time: 0.1618  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-06  max_mem: 1637M
[11/23 00:36:56] d2.utils.events INFO:  eta: 0:11:03  iter: 10959  total_loss: 0.5717  loss_ce: 0.01469  loss_objectness: 0.4081  loss_dice: 0.1105  loss_mask: 0.01793    time: 0.1673  last_time: 0.1644  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:36:59] d2.utils.events INFO:  eta: 0:11:00  iter: 10979  total_loss: 0.5541  loss_ce: 0.00328  loss_objectness: 0.4186  loss_dice: 0.1105  loss_mask: 0.01921    time: 0.1673  last_time: 0.1619  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:37:03] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/23 00:37:03] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/23 00:37:03] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/23 00:37:03] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/23 00:37:03] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/23 00:37:03] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/23 00:37:09] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0222 s/iter. Eval: 0.0380 s/iter. Total: 0.0605 s/iter. ETA=0:00:06
[11/23 00:37:14] d2.evaluation.evaluator INFO: Inference done 94/120. Dataloading: 0.0004 s/iter. Inference: 0.0212 s/iter. Eval: 0.0387 s/iter. Total: 0.0603 s/iter. ETA=0:00:01
[11/23 00:37:16] d2.evaluation.evaluator INFO: Total inference time: 0:00:08.165685 (0.071006 s / iter per device, on 1 devices)
[11/23 00:37:16] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.021475 s / iter per device, on 1 devices)
[11/23 00:37:16] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/23 00:37:16] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_gabor_turbo\inference\coco_instances_results.json
[11/23 00:37:16] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/23 00:37:17] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/23 00:37:17] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.05 seconds.
[11/23 00:37:17] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/23 00:37:17] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/23 00:37:17] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 7.227 | 13.977 | 7.192  | 0.105 | 15.481 | 51.558 |
[11/23 00:37:17] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/23 00:37:17] d2.evaluation.testing INFO: copypaste: Task: segm
[11/23 00:37:17] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/23 00:37:17] d2.evaluation.testing INFO: copypaste: 7.2268,13.9770,7.1924,0.1047,15.4806,51.5581
[11/23 00:37:17] d2.utils.events INFO:  eta: 0:10:57  iter: 10999  total_loss: 0.5659  loss_ce: 0.007776  loss_objectness: 0.4249  loss_dice: 0.09678  loss_mask: 0.01888    time: 0.1673  last_time: 0.1686  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:37:20] d2.utils.events INFO:  eta: 0:10:53  iter: 11019  total_loss: 0.6218  loss_ce: 0.02967  loss_objectness: 0.448  loss_dice: 0.09966  loss_mask: 0.02272    time: 0.1673  last_time: 0.1637  data_time: 0.0028  last_data_time: 0.0020   lr: 5e-06  max_mem: 1637M
[11/23 00:37:23] d2.utils.events INFO:  eta: 0:10:50  iter: 11039  total_loss: 0.5683  loss_ce: 0.00663  loss_objectness: 0.4306  loss_dice: 0.104  loss_mask: 0.0236    time: 0.1673  last_time: 0.1684  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:37:27] d2.utils.events INFO:  eta: 0:10:47  iter: 11059  total_loss: 0.5308  loss_ce: 0.02017  loss_objectness: 0.4115  loss_dice: 0.0931  loss_mask: 0.01515    time: 0.1673  last_time: 0.1650  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:37:30] d2.utils.events INFO:  eta: 0:10:43  iter: 11079  total_loss: 0.6766  loss_ce: 0.05159  loss_objectness: 0.4955  loss_dice: 0.121  loss_mask: 0.01852    time: 0.1673  last_time: 0.1668  data_time: 0.0030  last_data_time: 0.0030   lr: 5e-06  max_mem: 1637M
[11/23 00:37:33] d2.utils.events INFO:  eta: 0:10:40  iter: 11099  total_loss: 0.5358  loss_ce: 0.01201  loss_objectness: 0.4086  loss_dice: 0.08815  loss_mask: 0.02089    time: 0.1673  last_time: 0.1638  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:37:37] d2.utils.events INFO:  eta: 0:10:37  iter: 11119  total_loss: 0.5632  loss_ce: 0.009934  loss_objectness: 0.4378  loss_dice: 0.09483  loss_mask: 0.02128    time: 0.1673  last_time: 0.1671  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:37:40] d2.utils.events INFO:  eta: 0:10:34  iter: 11139  total_loss: 0.646  loss_ce: 0.02326  loss_objectness: 0.4335  loss_dice: 0.129  loss_mask: 0.01787    time: 0.1673  last_time: 0.1652  data_time: 0.0031  last_data_time: 0.0044   lr: 5e-06  max_mem: 1637M
[11/23 00:37:43] d2.utils.events INFO:  eta: 0:10:30  iter: 11159  total_loss: 0.5411  loss_ce: 0.008536  loss_objectness: 0.4094  loss_dice: 0.09479  loss_mask: 0.01845    time: 0.1673  last_time: 0.1660  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:37:47] d2.utils.events INFO:  eta: 0:10:27  iter: 11179  total_loss: 0.5664  loss_ce: 0.01785  loss_objectness: 0.4447  loss_dice: 0.09822  loss_mask: 0.01994    time: 0.1673  last_time: 0.1634  data_time: 0.0030  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:37:50] d2.utils.events INFO:  eta: 0:10:24  iter: 11199  total_loss: 0.5973  loss_ce: 0.01754  loss_objectness: 0.4494  loss_dice: 0.1048  loss_mask: 0.01731    time: 0.1673  last_time: 0.1626  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:37:53] d2.utils.events INFO:  eta: 0:10:20  iter: 11219  total_loss: 0.6148  loss_ce: 0.01609  loss_objectness: 0.4409  loss_dice: 0.1191  loss_mask: 0.01904    time: 0.1673  last_time: 0.1633  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:37:57] d2.utils.events INFO:  eta: 0:10:17  iter: 11239  total_loss: 0.5554  loss_ce: 0.01925  loss_objectness: 0.4079  loss_dice: 0.09799  loss_mask: 0.02077    time: 0.1673  last_time: 0.1647  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:38:00] d2.utils.events INFO:  eta: 0:10:14  iter: 11259  total_loss: 0.5537  loss_ce: 0.008901  loss_objectness: 0.4108  loss_dice: 0.09984  loss_mask: 0.02113    time: 0.1673  last_time: 0.1638  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-06  max_mem: 1637M
[11/23 00:38:03] d2.utils.events INFO:  eta: 0:10:11  iter: 11279  total_loss: 0.5538  loss_ce: 0.01681  loss_objectness: 0.4084  loss_dice: 0.1105  loss_mask: 0.01567    time: 0.1673  last_time: 0.1645  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:38:07] d2.utils.events INFO:  eta: 0:10:07  iter: 11299  total_loss: 0.6026  loss_ce: 0.01965  loss_objectness: 0.4668  loss_dice: 0.09824  loss_mask: 0.01788    time: 0.1672  last_time: 0.1656  data_time: 0.0030  last_data_time: 0.0036   lr: 5e-06  max_mem: 1637M
[11/23 00:38:10] d2.utils.events INFO:  eta: 0:10:04  iter: 11319  total_loss: 0.5267  loss_ce: 0.004724  loss_objectness: 0.386  loss_dice: 0.09102  loss_mask: 0.02071    time: 0.1672  last_time: 0.1629  data_time: 0.0027  last_data_time: 0.0029   lr: 5e-06  max_mem: 1637M
[11/23 00:38:13] d2.utils.events INFO:  eta: 0:10:01  iter: 11339  total_loss: 0.56  loss_ce: 0.01523  loss_objectness: 0.4229  loss_dice: 0.1047  loss_mask: 0.0168    time: 0.1672  last_time: 0.1621  data_time: 0.0030  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:38:16] d2.utils.events INFO:  eta: 0:09:58  iter: 11359  total_loss: 0.5371  loss_ce: 0.01214  loss_objectness: 0.404  loss_dice: 0.09182  loss_mask: 0.01975    time: 0.1672  last_time: 0.1659  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-06  max_mem: 1637M
[11/23 00:38:20] d2.utils.events INFO:  eta: 0:09:54  iter: 11379  total_loss: 0.54  loss_ce: 0.004655  loss_objectness: 0.4195  loss_dice: 0.08911  loss_mask: 0.01669    time: 0.1672  last_time: 0.1625  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:38:23] d2.utils.events INFO:  eta: 0:09:51  iter: 11399  total_loss: 0.565  loss_ce: 0.01695  loss_objectness: 0.3968  loss_dice: 0.1016  loss_mask: 0.01819    time: 0.1672  last_time: 0.1633  data_time: 0.0029  last_data_time: 0.0038   lr: 5e-06  max_mem: 1637M
[11/23 00:38:26] d2.utils.events INFO:  eta: 0:09:48  iter: 11419  total_loss: 0.542  loss_ce: 0.02414  loss_objectness: 0.4036  loss_dice: 0.08263  loss_mask: 0.02085    time: 0.1672  last_time: 0.1628  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:38:30] d2.utils.events INFO:  eta: 0:09:44  iter: 11439  total_loss: 0.5847  loss_ce: 0.01448  loss_objectness: 0.458  loss_dice: 0.0939  loss_mask: 0.02231    time: 0.1672  last_time: 0.1673  data_time: 0.0028  last_data_time: 0.0038   lr: 5e-06  max_mem: 1637M
[11/23 00:38:33] d2.utils.events INFO:  eta: 0:09:41  iter: 11459  total_loss: 0.5421  loss_ce: 0.007026  loss_objectness: 0.4085  loss_dice: 0.1026  loss_mask: 0.01987    time: 0.1672  last_time: 0.1668  data_time: 0.0027  last_data_time: 0.0021   lr: 5e-06  max_mem: 1637M
[11/23 00:38:36] d2.utils.events INFO:  eta: 0:09:38  iter: 11479  total_loss: 0.5321  loss_ce: 0.01115  loss_objectness: 0.3986  loss_dice: 0.0955  loss_mask: 0.02207    time: 0.1672  last_time: 0.1632  data_time: 0.0034  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:38:40] d2.utils.events INFO:  eta: 0:09:34  iter: 11499  total_loss: 0.5565  loss_ce: 0.01923  loss_objectness: 0.4049  loss_dice: 0.08355  loss_mask: 0.0202    time: 0.1672  last_time: 0.1644  data_time: 0.0032  last_data_time: 0.0038   lr: 5e-06  max_mem: 1637M
[11/23 00:38:43] d2.utils.events INFO:  eta: 0:09:31  iter: 11519  total_loss: 0.5536  loss_ce: 0.01372  loss_objectness: 0.4324  loss_dice: 0.09547  loss_mask: 0.01673    time: 0.1672  last_time: 0.1647  data_time: 0.0030  last_data_time: 0.0032   lr: 5e-06  max_mem: 1637M
[11/23 00:38:46] d2.utils.events INFO:  eta: 0:09:28  iter: 11539  total_loss: 0.5652  loss_ce: 0.01004  loss_objectness: 0.4244  loss_dice: 0.09499  loss_mask: 0.0204    time: 0.1672  last_time: 0.1668  data_time: 0.0028  last_data_time: 0.0021   lr: 5e-06  max_mem: 1637M
[11/23 00:38:50] d2.utils.events INFO:  eta: 0:09:25  iter: 11559  total_loss: 0.5539  loss_ce: 0.003206  loss_objectness: 0.4146  loss_dice: 0.09478  loss_mask: 0.01888    time: 0.1672  last_time: 0.1666  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-06  max_mem: 1637M
[11/23 00:38:53] d2.utils.events INFO:  eta: 0:09:21  iter: 11579  total_loss: 0.5561  loss_ce: 0.01862  loss_objectness: 0.4321  loss_dice: 0.102  loss_mask: 0.01647    time: 0.1672  last_time: 0.1637  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-06  max_mem: 1637M
[11/23 00:38:56] d2.utils.events INFO:  eta: 0:09:18  iter: 11599  total_loss: 0.5574  loss_ce: 0.01147  loss_objectness: 0.4039  loss_dice: 0.1  loss_mask: 0.01761    time: 0.1672  last_time: 0.1626  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-06  max_mem: 1637M
[11/23 00:38:59] d2.utils.events INFO:  eta: 0:09:15  iter: 11619  total_loss: 0.5774  loss_ce: 0.01493  loss_objectness: 0.403  loss_dice: 0.09723  loss_mask: 0.01956    time: 0.1672  last_time: 0.1638  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:39:03] d2.utils.events INFO:  eta: 0:09:11  iter: 11639  total_loss: 0.5249  loss_ce: 0.01205  loss_objectness: 0.415  loss_dice: 0.08872  loss_mask: 0.01871    time: 0.1672  last_time: 0.1657  data_time: 0.0029  last_data_time: 0.0021   lr: 5e-06  max_mem: 1637M
[11/23 00:39:06] d2.utils.events INFO:  eta: 0:09:08  iter: 11659  total_loss: 0.5069  loss_ce: 0.007545  loss_objectness: 0.3774  loss_dice: 0.08261  loss_mask: 0.02173    time: 0.1672  last_time: 0.1620  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:39:09] d2.utils.events INFO:  eta: 0:09:05  iter: 11679  total_loss: 0.6027  loss_ce: 0.01642  loss_objectness: 0.4315  loss_dice: 0.1098  loss_mask: 0.01566    time: 0.1672  last_time: 0.1649  data_time: 0.0030  last_data_time: 0.0038   lr: 5e-06  max_mem: 1637M
[11/23 00:39:13] d2.utils.events INFO:  eta: 0:09:02  iter: 11699  total_loss: 0.5704  loss_ce: 0.005095  loss_objectness: 0.4274  loss_dice: 0.105  loss_mask: 0.02193    time: 0.1672  last_time: 0.1623  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-06  max_mem: 1637M
[11/23 00:39:16] d2.utils.events INFO:  eta: 0:08:58  iter: 11719  total_loss: 0.5438  loss_ce: 0.01369  loss_objectness: 0.4137  loss_dice: 0.0897  loss_mask: 0.01742    time: 0.1672  last_time: 0.1634  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:39:19] d2.utils.events INFO:  eta: 0:08:55  iter: 11739  total_loss: 0.501  loss_ce: 0.002903  loss_objectness: 0.381  loss_dice: 0.09371  loss_mask: 0.02118    time: 0.1672  last_time: 0.1653  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:39:23] d2.utils.events INFO:  eta: 0:08:52  iter: 11759  total_loss: 0.5352  loss_ce: 0.002516  loss_objectness: 0.4035  loss_dice: 0.08508  loss_mask: 0.01872    time: 0.1671  last_time: 0.1630  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:39:26] d2.utils.events INFO:  eta: 0:08:49  iter: 11779  total_loss: 0.5654  loss_ce: 0.01946  loss_objectness: 0.4231  loss_dice: 0.1  loss_mask: 0.01646    time: 0.1671  last_time: 0.1647  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-06  max_mem: 1637M
[11/23 00:39:29] d2.utils.events INFO:  eta: 0:08:45  iter: 11799  total_loss: 0.5157  loss_ce: 0.005775  loss_objectness: 0.3857  loss_dice: 0.08556  loss_mask: 0.01909    time: 0.1671  last_time: 0.1658  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:39:32] d2.utils.events INFO:  eta: 0:08:42  iter: 11819  total_loss: 0.5501  loss_ce: 0.01309  loss_objectness: 0.4096  loss_dice: 0.1123  loss_mask: 0.01724    time: 0.1671  last_time: 0.1656  data_time: 0.0031  last_data_time: 0.0032   lr: 5e-06  max_mem: 1637M
[11/23 00:39:36] d2.utils.events INFO:  eta: 0:08:39  iter: 11839  total_loss: 0.5173  loss_ce: 0.003155  loss_objectness: 0.3885  loss_dice: 0.09171  loss_mask: 0.02407    time: 0.1671  last_time: 0.1635  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:39:39] d2.utils.events INFO:  eta: 0:08:35  iter: 11859  total_loss: 0.5189  loss_ce: 0.008674  loss_objectness: 0.3832  loss_dice: 0.09219  loss_mask: 0.01701    time: 0.1671  last_time: 0.1629  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-06  max_mem: 1637M
[11/23 00:39:42] d2.utils.events INFO:  eta: 0:08:32  iter: 11879  total_loss: 0.5272  loss_ce: 0.003727  loss_objectness: 0.3969  loss_dice: 0.08898  loss_mask: 0.01885    time: 0.1671  last_time: 0.1650  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:39:46] d2.utils.events INFO:  eta: 0:08:29  iter: 11899  total_loss: 0.5006  loss_ce: 0.006044  loss_objectness: 0.3965  loss_dice: 0.08216  loss_mask: 0.01813    time: 0.1671  last_time: 0.1615  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:39:49] d2.utils.events INFO:  eta: 0:08:25  iter: 11919  total_loss: 0.5934  loss_ce: 0.02742  loss_objectness: 0.4368  loss_dice: 0.1124  loss_mask: 0.02373    time: 0.1671  last_time: 0.1656  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:39:52] d2.utils.events INFO:  eta: 0:08:22  iter: 11939  total_loss: 0.4632  loss_ce: 0.008729  loss_objectness: 0.3641  loss_dice: 0.07536  loss_mask: 0.01728    time: 0.1671  last_time: 0.1631  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:39:56] d2.utils.events INFO:  eta: 0:08:19  iter: 11959  total_loss: 0.545  loss_ce: 0.009858  loss_objectness: 0.4  loss_dice: 0.08787  loss_mask: 0.01901    time: 0.1671  last_time: 0.1647  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:39:59] d2.utils.events INFO:  eta: 0:08:16  iter: 11979  total_loss: 0.4739  loss_ce: 0.002618  loss_objectness: 0.3532  loss_dice: 0.08325  loss_mask: 0.01566    time: 0.1671  last_time: 0.1703  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-06  max_mem: 1637M
[11/23 00:40:02] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/23 00:40:02] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/23 00:40:02] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/23 00:40:02] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/23 00:40:02] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/23 00:40:02] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/23 00:40:07] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0211 s/iter. Eval: 0.0273 s/iter. Total: 0.0487 s/iter. ETA=0:00:05
[11/23 00:40:12] d2.evaluation.evaluator INFO: Inference done 114/120. Dataloading: 0.0004 s/iter. Inference: 0.0206 s/iter. Eval: 0.0278 s/iter. Total: 0.0488 s/iter. ETA=0:00:00
[11/23 00:40:14] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.515358 (0.056655 s / iter per device, on 1 devices)
[11/23 00:40:14] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.020623 s / iter per device, on 1 devices)
[11/23 00:40:14] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/23 00:40:14] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_gabor_turbo\inference\coco_instances_results.json
[11/23 00:40:14] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/23 00:40:14] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/23 00:40:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.04 seconds.
[11/23 00:40:14] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/23 00:40:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/23 00:40:14] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 7.101 | 13.668 | 7.146  | 0.070 | 14.754 | 52.797 |
[11/23 00:40:14] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/23 00:40:14] d2.evaluation.testing INFO: copypaste: Task: segm
[11/23 00:40:14] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/23 00:40:14] d2.evaluation.testing INFO: copypaste: 7.1010,13.6676,7.1465,0.0699,14.7542,52.7968
[11/23 00:40:14] d2.utils.events INFO:  eta: 0:08:12  iter: 11999  total_loss: 0.5339  loss_ce: 0.01256  loss_objectness: 0.4304  loss_dice: 0.08796  loss_mask: 0.01911    time: 0.1671  last_time: 0.1629  data_time: 0.0030  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:40:17] d2.utils.events INFO:  eta: 0:08:09  iter: 12019  total_loss: 0.5901  loss_ce: 0.01186  loss_objectness: 0.4363  loss_dice: 0.09883  loss_mask: 0.02108    time: 0.1671  last_time: 0.1636  data_time: 0.0030  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:40:21] d2.utils.events INFO:  eta: 0:08:06  iter: 12039  total_loss: 0.4847  loss_ce: 0.001798  loss_objectness: 0.3692  loss_dice: 0.08466  loss_mask: 0.01637    time: 0.1671  last_time: 0.1618  data_time: 0.0027  last_data_time: 0.0033   lr: 5e-06  max_mem: 1637M
[11/23 00:40:24] d2.utils.events INFO:  eta: 0:08:03  iter: 12059  total_loss: 0.489  loss_ce: 0.005046  loss_objectness: 0.3948  loss_dice: 0.07971  loss_mask: 0.01814    time: 0.1671  last_time: 0.1593  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:40:27] d2.utils.events INFO:  eta: 0:07:59  iter: 12079  total_loss: 0.5578  loss_ce: 0.01526  loss_objectness: 0.4266  loss_dice: 0.09555  loss_mask: 0.01815    time: 0.1671  last_time: 0.1642  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:40:30] d2.utils.events INFO:  eta: 0:07:56  iter: 12099  total_loss: 0.5283  loss_ce: 0.005034  loss_objectness: 0.3909  loss_dice: 0.08269  loss_mask: 0.02163    time: 0.1671  last_time: 0.1673  data_time: 0.0030  last_data_time: 0.0040   lr: 5e-06  max_mem: 1637M
[11/23 00:40:34] d2.utils.events INFO:  eta: 0:07:53  iter: 12119  total_loss: 0.5282  loss_ce: 0.01054  loss_objectness: 0.3941  loss_dice: 0.09448  loss_mask: 0.01695    time: 0.1671  last_time: 0.1637  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:40:37] d2.utils.events INFO:  eta: 0:07:49  iter: 12139  total_loss: 0.5003  loss_ce: 0.002382  loss_objectness: 0.3963  loss_dice: 0.08007  loss_mask: 0.01777    time: 0.1671  last_time: 0.1695  data_time: 0.0029  last_data_time: 0.0069   lr: 5e-06  max_mem: 1637M
[11/23 00:40:40] d2.utils.events INFO:  eta: 0:07:46  iter: 12159  total_loss: 0.5175  loss_ce: 0.004118  loss_objectness: 0.3943  loss_dice: 0.09229  loss_mask: 0.02137    time: 0.1671  last_time: 0.1656  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:40:44] d2.utils.events INFO:  eta: 0:07:43  iter: 12179  total_loss: 0.5046  loss_ce: 0.004659  loss_objectness: 0.3686  loss_dice: 0.08342  loss_mask: 0.01864    time: 0.1671  last_time: 0.1677  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:40:47] d2.utils.events INFO:  eta: 0:07:40  iter: 12199  total_loss: 0.5296  loss_ce: 0.007322  loss_objectness: 0.4066  loss_dice: 0.0851  loss_mask: 0.01846    time: 0.1671  last_time: 0.1642  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:40:50] d2.utils.events INFO:  eta: 0:07:36  iter: 12219  total_loss: 0.5598  loss_ce: 0.01357  loss_objectness: 0.4113  loss_dice: 0.09097  loss_mask: 0.01653    time: 0.1671  last_time: 0.1625  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:40:54] d2.utils.events INFO:  eta: 0:07:33  iter: 12239  total_loss: 0.5336  loss_ce: 0.01017  loss_objectness: 0.3983  loss_dice: 0.09197  loss_mask: 0.01516    time: 0.1671  last_time: 0.1648  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-06  max_mem: 1637M
[11/23 00:40:57] d2.utils.events INFO:  eta: 0:07:30  iter: 12259  total_loss: 0.4622  loss_ce: 0.007956  loss_objectness: 0.3659  loss_dice: 0.07755  loss_mask: 0.01922    time: 0.1671  last_time: 0.1661  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:41:00] d2.utils.events INFO:  eta: 0:07:26  iter: 12279  total_loss: 0.5128  loss_ce: 0.00681  loss_objectness: 0.4017  loss_dice: 0.08738  loss_mask: 0.0172    time: 0.1671  last_time: 0.1702  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:41:04] d2.utils.events INFO:  eta: 0:07:23  iter: 12299  total_loss: 0.4775  loss_ce: 0.006682  loss_objectness: 0.3823  loss_dice: 0.08231  loss_mask: 0.02237    time: 0.1671  last_time: 0.1634  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-06  max_mem: 1637M
[11/23 00:41:07] d2.utils.events INFO:  eta: 0:07:20  iter: 12319  total_loss: 0.4949  loss_ce: 0.005445  loss_objectness: 0.3706  loss_dice: 0.08038  loss_mask: 0.01544    time: 0.1671  last_time: 0.1636  data_time: 0.0026  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:41:10] d2.utils.events INFO:  eta: 0:07:17  iter: 12339  total_loss: 0.5029  loss_ce: 0.004622  loss_objectness: 0.3931  loss_dice: 0.07972  loss_mask: 0.02068    time: 0.1670  last_time: 0.1666  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:41:13] d2.utils.events INFO:  eta: 0:07:13  iter: 12359  total_loss: 0.5349  loss_ce: 0.006171  loss_objectness: 0.395  loss_dice: 0.08815  loss_mask: 0.016    time: 0.1670  last_time: 0.1693  data_time: 0.0029  last_data_time: 0.0034   lr: 5e-06  max_mem: 1637M
[11/23 00:41:17] d2.utils.events INFO:  eta: 0:07:10  iter: 12379  total_loss: 0.5231  loss_ce: 0.001581  loss_objectness: 0.4076  loss_dice: 0.08125  loss_mask: 0.01877    time: 0.1670  last_time: 0.1619  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-06  max_mem: 1637M
[11/23 00:41:20] d2.utils.events INFO:  eta: 0:07:07  iter: 12399  total_loss: 0.4754  loss_ce: 0.002826  loss_objectness: 0.3748  loss_dice: 0.08203  loss_mask: 0.0182    time: 0.1670  last_time: 0.1629  data_time: 0.0027  last_data_time: 0.0032   lr: 5e-06  max_mem: 1637M
[11/23 00:41:23] d2.utils.events INFO:  eta: 0:07:04  iter: 12419  total_loss: 0.4806  loss_ce: 0.006378  loss_objectness: 0.3486  loss_dice: 0.07617  loss_mask: 0.01673    time: 0.1670  last_time: 0.1645  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:41:27] d2.utils.events INFO:  eta: 0:07:00  iter: 12439  total_loss: 0.5179  loss_ce: 0.004861  loss_objectness: 0.4086  loss_dice: 0.08225  loss_mask: 0.01916    time: 0.1670  last_time: 0.1637  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:41:30] d2.utils.events INFO:  eta: 0:06:57  iter: 12459  total_loss: 0.5075  loss_ce: 0.003952  loss_objectness: 0.3887  loss_dice: 0.08466  loss_mask: 0.0165    time: 0.1670  last_time: 0.1673  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-06  max_mem: 1637M
[11/23 00:41:33] d2.utils.events INFO:  eta: 0:06:54  iter: 12479  total_loss: 0.5193  loss_ce: 0.003384  loss_objectness: 0.3843  loss_dice: 0.09064  loss_mask: 0.01825    time: 0.1670  last_time: 0.1643  data_time: 0.0028  last_data_time: 0.0029   lr: 5e-06  max_mem: 1637M
[11/23 00:41:37] d2.utils.events INFO:  eta: 0:06:50  iter: 12499  total_loss: 0.5246  loss_ce: 0.00944  loss_objectness: 0.4084  loss_dice: 0.09693  loss_mask: 0.01732    time: 0.1670  last_time: 0.1642  data_time: 0.0031  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:41:40] d2.utils.events INFO:  eta: 0:06:47  iter: 12519  total_loss: 0.5784  loss_ce: 0.007501  loss_objectness: 0.4328  loss_dice: 0.08789  loss_mask: 0.02137    time: 0.1670  last_time: 0.1617  data_time: 0.0029  last_data_time: 0.0034   lr: 5e-06  max_mem: 1637M
[11/23 00:41:43] d2.utils.events INFO:  eta: 0:06:44  iter: 12539  total_loss: 0.494  loss_ce: 0.00677  loss_objectness: 0.4013  loss_dice: 0.07519  loss_mask: 0.01598    time: 0.1670  last_time: 0.1671  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:41:47] d2.utils.events INFO:  eta: 0:06:40  iter: 12559  total_loss: 0.4931  loss_ce: 0.00293  loss_objectness: 0.3699  loss_dice: 0.07633  loss_mask: 0.02372    time: 0.1670  last_time: 0.1620  data_time: 0.0027  last_data_time: 0.0031   lr: 5e-06  max_mem: 1637M
[11/23 00:41:50] d2.utils.events INFO:  eta: 0:06:37  iter: 12579  total_loss: 0.5027  loss_ce: 0.002669  loss_objectness: 0.381  loss_dice: 0.09398  loss_mask: 0.01939    time: 0.1670  last_time: 0.1678  data_time: 0.0026  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:41:53] d2.utils.events INFO:  eta: 0:06:34  iter: 12599  total_loss: 0.5336  loss_ce: 0.008806  loss_objectness: 0.3978  loss_dice: 0.0971  loss_mask: 0.0181    time: 0.1670  last_time: 0.1625  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-06  max_mem: 1637M
[11/23 00:41:56] d2.utils.events INFO:  eta: 0:06:31  iter: 12619  total_loss: 0.4432  loss_ce: 0.002189  loss_objectness: 0.3519  loss_dice: 0.07102  loss_mask: 0.01246    time: 0.1670  last_time: 0.1613  data_time: 0.0026  last_data_time: 0.0029   lr: 5e-06  max_mem: 1637M
[11/23 00:42:00] d2.utils.events INFO:  eta: 0:06:27  iter: 12639  total_loss: 0.5136  loss_ce: 0.00308  loss_objectness: 0.3707  loss_dice: 0.08841  loss_mask: 0.0235    time: 0.1670  last_time: 0.1620  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:42:03] d2.utils.events INFO:  eta: 0:06:24  iter: 12659  total_loss: 0.5157  loss_ce: 0.01006  loss_objectness: 0.3985  loss_dice: 0.08506  loss_mask: 0.01845    time: 0.1670  last_time: 0.1629  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:42:06] d2.utils.events INFO:  eta: 0:06:21  iter: 12679  total_loss: 0.4811  loss_ce: 0.003248  loss_objectness: 0.3571  loss_dice: 0.08191  loss_mask: 0.01652    time: 0.1670  last_time: 0.1650  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-06  max_mem: 1637M
[11/23 00:42:10] d2.utils.events INFO:  eta: 0:06:18  iter: 12699  total_loss: 0.4784  loss_ce: 0.00345  loss_objectness: 0.3752  loss_dice: 0.06963  loss_mask: 0.01995    time: 0.1670  last_time: 0.1650  data_time: 0.0028  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:42:13] d2.utils.events INFO:  eta: 0:06:14  iter: 12719  total_loss: 0.4398  loss_ce: 0.0006672  loss_objectness: 0.3509  loss_dice: 0.06352  loss_mask: 0.01419    time: 0.1670  last_time: 0.1636  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-06  max_mem: 1637M
[11/23 00:42:16] d2.utils.events INFO:  eta: 0:06:11  iter: 12739  total_loss: 0.4954  loss_ce: 0.008555  loss_objectness: 0.388  loss_dice: 0.08243  loss_mask: 0.01479    time: 0.1670  last_time: 0.1630  data_time: 0.0029  last_data_time: 0.0022   lr: 5e-06  max_mem: 1637M
[11/23 00:42:20] d2.utils.events INFO:  eta: 0:06:08  iter: 12759  total_loss: 0.5292  loss_ce: 0.00492  loss_objectness: 0.3972  loss_dice: 0.08797  loss_mask: 0.02033    time: 0.1670  last_time: 0.1614  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:42:23] d2.utils.events INFO:  eta: 0:06:05  iter: 12779  total_loss: 0.5864  loss_ce: 0.008309  loss_objectness: 0.4246  loss_dice: 0.0994  loss_mask: 0.02062    time: 0.1670  last_time: 0.1619  data_time: 0.0029  last_data_time: 0.0037   lr: 5e-06  max_mem: 1637M
[11/23 00:42:26] d2.utils.events INFO:  eta: 0:06:01  iter: 12799  total_loss: 0.5367  loss_ce: 0.008534  loss_objectness: 0.4214  loss_dice: 0.09074  loss_mask: 0.01826    time: 0.1670  last_time: 0.1660  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:42:30] d2.utils.events INFO:  eta: 0:05:58  iter: 12819  total_loss: 0.4563  loss_ce: 0.006679  loss_objectness: 0.3532  loss_dice: 0.07404  loss_mask: 0.01426    time: 0.1670  last_time: 0.1676  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-06  max_mem: 1637M
[11/23 00:42:33] d2.utils.events INFO:  eta: 0:05:55  iter: 12839  total_loss: 0.59  loss_ce: 0.007011  loss_objectness: 0.3956  loss_dice: 0.08858  loss_mask: 0.01891    time: 0.1670  last_time: 0.1630  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:42:36] d2.utils.events INFO:  eta: 0:05:51  iter: 12859  total_loss: 0.5209  loss_ce: 0.007711  loss_objectness: 0.3867  loss_dice: 0.09326  loss_mask: 0.01883    time: 0.1670  last_time: 0.1687  data_time: 0.0030  last_data_time: 0.0036   lr: 5e-06  max_mem: 1637M
[11/23 00:42:40] d2.utils.events INFO:  eta: 0:05:48  iter: 12879  total_loss: 0.4534  loss_ce: 0.007532  loss_objectness: 0.3703  loss_dice: 0.07593  loss_mask: 0.01618    time: 0.1670  last_time: 0.1631  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:42:43] d2.utils.events INFO:  eta: 0:05:45  iter: 12899  total_loss: 0.465  loss_ce: 0.002145  loss_objectness: 0.3624  loss_dice: 0.07458  loss_mask: 0.01919    time: 0.1670  last_time: 0.1632  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:42:46] d2.utils.events INFO:  eta: 0:05:42  iter: 12919  total_loss: 0.4973  loss_ce: 0.00486  loss_objectness: 0.3719  loss_dice: 0.08326  loss_mask: 0.01461    time: 0.1670  last_time: 0.1627  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:42:50] d2.utils.events INFO:  eta: 0:05:38  iter: 12939  total_loss: 0.5192  loss_ce: 0.0008775  loss_objectness: 0.3882  loss_dice: 0.08174  loss_mask: 0.01783    time: 0.1670  last_time: 0.1615  data_time: 0.0035  last_data_time: 0.0028   lr: 5e-06  max_mem: 1637M
[11/23 00:42:53] d2.utils.events INFO:  eta: 0:05:35  iter: 12959  total_loss: 0.5054  loss_ce: 0.003179  loss_objectness: 0.3845  loss_dice: 0.08925  loss_mask: 0.01891    time: 0.1670  last_time: 0.1632  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:42:56] d2.utils.events INFO:  eta: 0:05:32  iter: 12979  total_loss: 0.4754  loss_ce: 0.003981  loss_objectness: 0.3575  loss_dice: 0.07645  loss_mask: 0.01753    time: 0.1670  last_time: 0.1659  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:43:00] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/23 00:43:00] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/23 00:43:00] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/23 00:43:00] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/23 00:43:00] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/23 00:43:00] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/23 00:43:04] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0206 s/iter. Eval: 0.0194 s/iter. Total: 0.0403 s/iter. ETA=0:00:04
[11/23 00:43:10] d2.evaluation.evaluator INFO: Total inference time: 0:00:05.850958 (0.050878 s / iter per device, on 1 devices)
[11/23 00:43:10] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.020261 s / iter per device, on 1 devices)
[11/23 00:43:10] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/23 00:43:10] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_gabor_turbo\inference\coco_instances_results.json
[11/23 00:43:10] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/23 00:43:10] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/23 00:43:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.03 seconds.
[11/23 00:43:10] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/23 00:43:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/23 00:43:10] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.921 | 13.270 | 7.122  | 0.053 | 14.462 | 54.131 |
[11/23 00:43:10] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/23 00:43:10] d2.evaluation.testing INFO: copypaste: Task: segm
[11/23 00:43:10] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/23 00:43:10] d2.evaluation.testing INFO: copypaste: 6.9212,13.2696,7.1222,0.0531,14.4618,54.1312
[11/23 00:43:10] d2.utils.events INFO:  eta: 0:05:29  iter: 12999  total_loss: 0.5311  loss_ce: 0.00814  loss_objectness: 0.4103  loss_dice: 0.08528  loss_mask: 0.01649    time: 0.1670  last_time: 0.1615  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-06  max_mem: 1637M
[11/23 00:43:13] d2.utils.events INFO:  eta: 0:05:25  iter: 13019  total_loss: 0.4642  loss_ce: 0.001765  loss_objectness: 0.3537  loss_dice: 0.07698  loss_mask: 0.01786    time: 0.1670  last_time: 0.1652  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-06  max_mem: 1637M
[11/23 00:43:17] d2.utils.events INFO:  eta: 0:05:22  iter: 13039  total_loss: 0.5034  loss_ce: 0.002074  loss_objectness: 0.402  loss_dice: 0.07903  loss_mask: 0.01424    time: 0.1670  last_time: 0.1673  data_time: 0.0028  last_data_time: 0.0022   lr: 5e-06  max_mem: 1637M
[11/23 00:43:20] d2.utils.events INFO:  eta: 0:05:19  iter: 13059  total_loss: 0.4967  loss_ce: 0.004094  loss_objectness: 0.3807  loss_dice: 0.08551  loss_mask: 0.01926    time: 0.1670  last_time: 0.1620  data_time: 0.0029  last_data_time: 0.0022   lr: 5e-06  max_mem: 1637M
[11/23 00:43:23] d2.utils.events INFO:  eta: 0:05:15  iter: 13079  total_loss: 0.4695  loss_ce: 0.001808  loss_objectness: 0.3802  loss_dice: 0.07939  loss_mask: 0.01595    time: 0.1669  last_time: 0.1608  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:43:27] d2.utils.events INFO:  eta: 0:05:12  iter: 13099  total_loss: 0.5417  loss_ce: 0.003012  loss_objectness: 0.4209  loss_dice: 0.1019  loss_mask: 0.02192    time: 0.1669  last_time: 0.1644  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:43:30] d2.utils.events INFO:  eta: 0:05:09  iter: 13119  total_loss: 0.5496  loss_ce: 0.002078  loss_objectness: 0.4287  loss_dice: 0.09603  loss_mask: 0.01521    time: 0.1669  last_time: 0.1670  data_time: 0.0030  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:43:33] d2.utils.events INFO:  eta: 0:05:05  iter: 13139  total_loss: 0.4263  loss_ce: 0.002539  loss_objectness: 0.3497  loss_dice: 0.0747  loss_mask: 0.0192    time: 0.1669  last_time: 0.1641  data_time: 0.0028  last_data_time: 0.0023   lr: 5e-06  max_mem: 1637M
[11/23 00:43:36] d2.utils.events INFO:  eta: 0:05:02  iter: 13159  total_loss: 0.4884  loss_ce: 0.006317  loss_objectness: 0.3688  loss_dice: 0.0808  loss_mask: 0.01528    time: 0.1669  last_time: 0.1658  data_time: 0.0031  last_data_time: 0.0036   lr: 5e-06  max_mem: 1637M
[11/23 00:43:40] d2.utils.events INFO:  eta: 0:04:59  iter: 13179  total_loss: 0.4791  loss_ce: 0.002172  loss_objectness: 0.3678  loss_dice: 0.07003  loss_mask: 0.01668    time: 0.1669  last_time: 0.1699  data_time: 0.0031  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:43:43] d2.utils.events INFO:  eta: 0:04:56  iter: 13199  total_loss: 0.5144  loss_ce: 0.003178  loss_objectness: 0.3948  loss_dice: 0.07689  loss_mask: 0.01768    time: 0.1669  last_time: 0.1660  data_time: 0.0030  last_data_time: 0.0033   lr: 5e-06  max_mem: 1637M
[11/23 00:43:46] d2.utils.events INFO:  eta: 0:04:52  iter: 13219  total_loss: 0.4615  loss_ce: 0.004139  loss_objectness: 0.3701  loss_dice: 0.07565  loss_mask: 0.01692    time: 0.1669  last_time: 0.1653  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-06  max_mem: 1637M
[11/23 00:43:50] d2.utils.events INFO:  eta: 0:04:49  iter: 13239  total_loss: 0.4555  loss_ce: 0.004277  loss_objectness: 0.3709  loss_dice: 0.08178  loss_mask: 0.01895    time: 0.1669  last_time: 0.1685  data_time: 0.0028  last_data_time: 0.0043   lr: 5e-06  max_mem: 1637M
[11/23 00:43:53] d2.utils.events INFO:  eta: 0:04:46  iter: 13259  total_loss: 0.4558  loss_ce: 0.003006  loss_objectness: 0.3549  loss_dice: 0.08261  loss_mask: 0.01767    time: 0.1669  last_time: 0.1642  data_time: 0.0028  last_data_time: 0.0032   lr: 5e-06  max_mem: 1637M
[11/23 00:43:56] d2.utils.events INFO:  eta: 0:04:42  iter: 13279  total_loss: 0.4514  loss_ce: 0.0008015  loss_objectness: 0.3621  loss_dice: 0.07213  loss_mask: 0.01608    time: 0.1669  last_time: 0.1649  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:44:00] d2.utils.events INFO:  eta: 0:04:39  iter: 13299  total_loss: 0.4733  loss_ce: 0.001558  loss_objectness: 0.3593  loss_dice: 0.07749  loss_mask: 0.0181    time: 0.1669  last_time: 0.1753  data_time: 0.0029  last_data_time: 0.0044   lr: 5e-06  max_mem: 1637M
[11/23 00:44:03] d2.utils.events INFO:  eta: 0:04:36  iter: 13319  total_loss: 0.524  loss_ce: 0.001642  loss_objectness: 0.3898  loss_dice: 0.08916  loss_mask: 0.01969    time: 0.1669  last_time: 0.1653  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-06  max_mem: 1637M
[11/23 00:44:06] d2.utils.events INFO:  eta: 0:04:33  iter: 13339  total_loss: 0.4081  loss_ce: 0.0007445  loss_objectness: 0.3182  loss_dice: 0.06659  loss_mask: 0.01707    time: 0.1669  last_time: 0.1636  data_time: 0.0028  last_data_time: 0.0022   lr: 5e-06  max_mem: 1637M
[11/23 00:44:10] d2.utils.events INFO:  eta: 0:04:29  iter: 13359  total_loss: 0.426  loss_ce: 0.001208  loss_objectness: 0.3338  loss_dice: 0.0663  loss_mask: 0.01659    time: 0.1669  last_time: 0.1665  data_time: 0.0028  last_data_time: 0.0044   lr: 5e-06  max_mem: 1637M
[11/23 00:44:13] d2.utils.events INFO:  eta: 0:04:26  iter: 13379  total_loss: 0.494  loss_ce: 0.004465  loss_objectness: 0.4037  loss_dice: 0.07643  loss_mask: 0.01511    time: 0.1669  last_time: 0.1656  data_time: 0.0030  last_data_time: 0.0029   lr: 5e-06  max_mem: 1637M
[11/23 00:44:16] d2.utils.events INFO:  eta: 0:04:23  iter: 13399  total_loss: 0.4387  loss_ce: 0.002047  loss_objectness: 0.3643  loss_dice: 0.06643  loss_mask: 0.01753    time: 0.1669  last_time: 0.1600  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:44:20] d2.utils.events INFO:  eta: 0:04:20  iter: 13419  total_loss: 0.5035  loss_ce: 0.001092  loss_objectness: 0.3795  loss_dice: 0.07791  loss_mask: 0.01794    time: 0.1669  last_time: 0.1647  data_time: 0.0027  last_data_time: 0.0028   lr: 5e-06  max_mem: 1637M
[11/23 00:44:23] d2.utils.events INFO:  eta: 0:04:16  iter: 13439  total_loss: 0.5495  loss_ce: 0.005951  loss_objectness: 0.4052  loss_dice: 0.09974  loss_mask: 0.01769    time: 0.1669  last_time: 0.1650  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-06  max_mem: 1637M
[11/23 00:44:26] d2.utils.events INFO:  eta: 0:04:13  iter: 13459  total_loss: 0.442  loss_ce: 0.001424  loss_objectness: 0.3403  loss_dice: 0.07025  loss_mask: 0.01542    time: 0.1669  last_time: 0.1633  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-06  max_mem: 1637M
[11/23 00:44:30] d2.utils.events INFO:  eta: 0:04:10  iter: 13479  total_loss: 0.5335  loss_ce: 0.005287  loss_objectness: 0.4047  loss_dice: 0.08876  loss_mask: 0.01382    time: 0.1669  last_time: 0.1643  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-06  max_mem: 1637M
[11/23 00:44:33] d2.utils.events INFO:  eta: 0:04:06  iter: 13499  total_loss: 0.5034  loss_ce: 0.004006  loss_objectness: 0.363  loss_dice: 0.09578  loss_mask: 0.01582    time: 0.1669  last_time: 0.1658  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-06  max_mem: 1637M
[11/23 00:44:36] d2.utils.events INFO:  eta: 0:04:03  iter: 13519  total_loss: 0.3864  loss_ce: 9.704e-05  loss_objectness: 0.3006  loss_dice: 0.06505  loss_mask: 0.01902    time: 0.1669  last_time: 0.1702  data_time: 0.0043  last_data_time: 0.0030   lr: 5e-06  max_mem: 1637M
[11/23 00:44:40] d2.utils.events INFO:  eta: 0:04:00  iter: 13539  total_loss: 0.4834  loss_ce: 0.002878  loss_objectness: 0.3726  loss_dice: 0.07438  loss_mask: 0.01584    time: 0.1669  last_time: 0.1639  data_time: 0.0028  last_data_time: 0.0028   lr: 5e-06  max_mem: 1637M
[11/23 00:44:43] d2.utils.events INFO:  eta: 0:03:57  iter: 13559  total_loss: 0.4435  loss_ce: 0.003976  loss_objectness: 0.347  loss_dice: 0.0845  loss_mask: 0.0159    time: 0.1669  last_time: 0.1652  data_time: 0.0029  last_data_time: 0.0034   lr: 5e-06  max_mem: 1637M
[11/23 00:44:46] d2.utils.events INFO:  eta: 0:03:53  iter: 13579  total_loss: 0.4798  loss_ce: 0.002366  loss_objectness: 0.3886  loss_dice: 0.07537  loss_mask: 0.01533    time: 0.1669  last_time: 0.1618  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:44:50] d2.utils.events INFO:  eta: 0:03:50  iter: 13599  total_loss: 0.4612  loss_ce: 0.002164  loss_objectness: 0.3568  loss_dice: 0.07854  loss_mask: 0.01975    time: 0.1669  last_time: 0.1652  data_time: 0.0027  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:44:53] d2.utils.events INFO:  eta: 0:03:47  iter: 13619  total_loss: 0.4991  loss_ce: 0.002513  loss_objectness: 0.4074  loss_dice: 0.07973  loss_mask: 0.01563    time: 0.1669  last_time: 0.1615  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-06  max_mem: 1637M
[11/23 00:44:56] d2.utils.events INFO:  eta: 0:03:43  iter: 13639  total_loss: 0.5096  loss_ce: 0.005353  loss_objectness: 0.3664  loss_dice: 0.1017  loss_mask: 0.01459    time: 0.1669  last_time: 0.1626  data_time: 0.0030  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:45:00] d2.utils.events INFO:  eta: 0:03:40  iter: 13659  total_loss: 0.4612  loss_ce: 0.001103  loss_objectness: 0.3752  loss_dice: 0.06977  loss_mask: 0.01694    time: 0.1669  last_time: 0.1667  data_time: 0.0029  last_data_time: 0.0035   lr: 5e-06  max_mem: 1637M
[11/23 00:45:03] d2.utils.events INFO:  eta: 0:03:37  iter: 13679  total_loss: 0.5163  loss_ce: 0.002166  loss_objectness: 0.3968  loss_dice: 0.08391  loss_mask: 0.01564    time: 0.1669  last_time: 0.1649  data_time: 0.0028  last_data_time: 0.0032   lr: 5e-06  max_mem: 1637M
[11/23 00:45:06] d2.utils.events INFO:  eta: 0:03:34  iter: 13699  total_loss: 0.4621  loss_ce: 0.001237  loss_objectness: 0.3552  loss_dice: 0.07146  loss_mask: 0.01638    time: 0.1669  last_time: 0.1646  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:45:09] d2.utils.events INFO:  eta: 0:03:30  iter: 13719  total_loss: 0.4286  loss_ce: 0.0002962  loss_objectness: 0.3336  loss_dice: 0.06197  loss_mask: 0.01929    time: 0.1669  last_time: 0.1648  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:45:13] d2.utils.events INFO:  eta: 0:03:27  iter: 13739  total_loss: 0.5073  loss_ce: 0.00414  loss_objectness: 0.3921  loss_dice: 0.09855  loss_mask: 0.01675    time: 0.1669  last_time: 0.1654  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:45:16] d2.utils.events INFO:  eta: 0:03:24  iter: 13759  total_loss: 0.453  loss_ce: 0.0006113  loss_objectness: 0.3593  loss_dice: 0.08379  loss_mask: 0.01649    time: 0.1669  last_time: 0.1655  data_time: 0.0037  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:45:19] d2.utils.events INFO:  eta: 0:03:20  iter: 13779  total_loss: 0.4511  loss_ce: 0.001736  loss_objectness: 0.3717  loss_dice: 0.06712  loss_mask: 0.01867    time: 0.1669  last_time: 0.1657  data_time: 0.0028  last_data_time: 0.0035   lr: 5e-06  max_mem: 1637M
[11/23 00:45:23] d2.utils.events INFO:  eta: 0:03:17  iter: 13799  total_loss: 0.494  loss_ce: 0.003019  loss_objectness: 0.383  loss_dice: 0.07289  loss_mask: 0.01525    time: 0.1669  last_time: 0.1645  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:45:26] d2.utils.events INFO:  eta: 0:03:14  iter: 13819  total_loss: 0.445  loss_ce: 0.0008886  loss_objectness: 0.3591  loss_dice: 0.0728  loss_mask: 0.01518    time: 0.1669  last_time: 0.1670  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:45:29] d2.utils.events INFO:  eta: 0:03:11  iter: 13839  total_loss: 0.463  loss_ce: 0.001657  loss_objectness: 0.3713  loss_dice: 0.07168  loss_mask: 0.01566    time: 0.1669  last_time: 0.1616  data_time: 0.0028  last_data_time: 0.0034   lr: 5e-06  max_mem: 1637M
[11/23 00:45:33] d2.utils.events INFO:  eta: 0:03:07  iter: 13859  total_loss: 0.471  loss_ce: 0.0001692  loss_objectness: 0.3795  loss_dice: 0.07041  loss_mask: 0.01522    time: 0.1668  last_time: 0.1618  data_time: 0.0028  last_data_time: 0.0022   lr: 5e-06  max_mem: 1637M
[11/23 00:45:36] d2.utils.events INFO:  eta: 0:03:04  iter: 13879  total_loss: 0.4368  loss_ce: 0.004504  loss_objectness: 0.3403  loss_dice: 0.0698  loss_mask: 0.0161    time: 0.1668  last_time: 0.1632  data_time: 0.0029  last_data_time: 0.0032   lr: 5e-06  max_mem: 1637M
[11/23 00:45:39] d2.utils.events INFO:  eta: 0:03:01  iter: 13899  total_loss: 0.4347  loss_ce: 0.002659  loss_objectness: 0.302  loss_dice: 0.06497  loss_mask: 0.01628    time: 0.1668  last_time: 0.1678  data_time: 0.0028  last_data_time: 0.0032   lr: 5e-06  max_mem: 1637M
[11/23 00:45:43] d2.utils.events INFO:  eta: 0:02:57  iter: 13919  total_loss: 0.4503  loss_ce: 0.001469  loss_objectness: 0.3586  loss_dice: 0.07138  loss_mask: 0.01656    time: 0.1668  last_time: 0.1629  data_time: 0.0027  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:45:46] d2.utils.events INFO:  eta: 0:02:54  iter: 13939  total_loss: 0.4712  loss_ce: 0.001237  loss_objectness: 0.3682  loss_dice: 0.0717  loss_mask: 0.01756    time: 0.1668  last_time: 0.1658  data_time: 0.0030  last_data_time: 0.0030   lr: 5e-06  max_mem: 1637M
[11/23 00:45:49] d2.utils.events INFO:  eta: 0:02:51  iter: 13959  total_loss: 0.3904  loss_ce: 0.0001801  loss_objectness: 0.3079  loss_dice: 0.06146  loss_mask: 0.01903    time: 0.1668  last_time: 0.1636  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:45:53] d2.utils.events INFO:  eta: 0:02:47  iter: 13979  total_loss: 0.457  loss_ce: 0.001577  loss_objectness: 0.3641  loss_dice: 0.06377  loss_mask: 0.01952    time: 0.1668  last_time: 0.1653  data_time: 0.0027  last_data_time: 0.0028   lr: 5e-06  max_mem: 1637M
[11/23 00:45:56] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/23 00:45:56] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/23 00:45:56] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/23 00:45:56] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/23 00:45:56] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/23 00:45:56] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/23 00:46:02] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0210 s/iter. Eval: 0.0188 s/iter. Total: 0.0401 s/iter. ETA=0:00:04
[11/23 00:46:07] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.082151 (0.052888 s / iter per device, on 1 devices)
[11/23 00:46:07] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.020039 s / iter per device, on 1 devices)
[11/23 00:46:07] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/23 00:46:07] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_gabor_turbo\inference\coco_instances_results.json
[11/23 00:46:07] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/23 00:46:08] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/23 00:46:08] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.03 seconds.
[11/23 00:46:08] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/23 00:46:08] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[11/23 00:46:08] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 7.014 | 14.098 | 7.232  | 0.119 | 13.955 | 53.949 |
[11/23 00:46:08] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/23 00:46:08] d2.evaluation.testing INFO: copypaste: Task: segm
[11/23 00:46:08] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/23 00:46:08] d2.evaluation.testing INFO: copypaste: 7.0145,14.0983,7.2324,0.1186,13.9546,53.9491
[11/23 00:46:08] d2.utils.events INFO:  eta: 0:02:44  iter: 13999  total_loss: 0.5247  loss_ce: 0.003558  loss_objectness: 0.4226  loss_dice: 0.07833  loss_mask: 0.01452    time: 0.1668  last_time: 0.1655  data_time: 0.0030  last_data_time: 0.0030   lr: 5e-06  max_mem: 1637M
[11/23 00:46:11] d2.utils.events INFO:  eta: 0:02:41  iter: 14019  total_loss: 0.5168  loss_ce: 0.001436  loss_objectness: 0.3846  loss_dice: 0.07914  loss_mask: 0.01345    time: 0.1668  last_time: 0.1662  data_time: 0.0031  last_data_time: 0.0032   lr: 5e-06  max_mem: 1637M
[11/23 00:46:14] d2.utils.events INFO:  eta: 0:02:38  iter: 14039  total_loss: 0.4478  loss_ce: 0.001622  loss_objectness: 0.3533  loss_dice: 0.07796  loss_mask: 0.01809    time: 0.1668  last_time: 0.1655  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:46:18] d2.utils.events INFO:  eta: 0:02:34  iter: 14059  total_loss: 0.4662  loss_ce: 0.001005  loss_objectness: 0.3688  loss_dice: 0.07212  loss_mask: 0.01649    time: 0.1668  last_time: 0.1659  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:46:21] d2.utils.events INFO:  eta: 0:02:31  iter: 14079  total_loss: 0.4469  loss_ce: 0.00102  loss_objectness: 0.3481  loss_dice: 0.05681  loss_mask: 0.01539    time: 0.1668  last_time: 0.1636  data_time: 0.0029  last_data_time: 0.0023   lr: 5e-06  max_mem: 1637M
[11/23 00:46:24] d2.utils.events INFO:  eta: 0:02:28  iter: 14099  total_loss: 0.4881  loss_ce: 0.001686  loss_objectness: 0.3694  loss_dice: 0.089  loss_mask: 0.01675    time: 0.1668  last_time: 0.1669  data_time: 0.0027  last_data_time: 0.0030   lr: 5e-06  max_mem: 1637M
[11/23 00:46:28] d2.utils.events INFO:  eta: 0:02:25  iter: 14119  total_loss: 0.49  loss_ce: 0.001708  loss_objectness: 0.4001  loss_dice: 0.06287  loss_mask: 0.01664    time: 0.1668  last_time: 0.1634  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:46:31] d2.utils.events INFO:  eta: 0:02:21  iter: 14139  total_loss: 0.444  loss_ce: 0.00218  loss_objectness: 0.3565  loss_dice: 0.06958  loss_mask: 0.01895    time: 0.1668  last_time: 0.1651  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:46:34] d2.utils.events INFO:  eta: 0:02:18  iter: 14159  total_loss: 0.4077  loss_ce: 0.0006598  loss_objectness: 0.3227  loss_dice: 0.06652  loss_mask: 0.01675    time: 0.1668  last_time: 0.1735  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-06  max_mem: 1637M
[11/23 00:46:38] d2.utils.events INFO:  eta: 0:02:15  iter: 14179  total_loss: 0.4853  loss_ce: 0.006563  loss_objectness: 0.3677  loss_dice: 0.07023  loss_mask: 0.01409    time: 0.1668  last_time: 0.1656  data_time: 0.0031  last_data_time: 0.0033   lr: 5e-06  max_mem: 1637M
[11/23 00:46:41] d2.utils.events INFO:  eta: 0:02:11  iter: 14199  total_loss: 0.4701  loss_ce: 0.002194  loss_objectness: 0.3623  loss_dice: 0.0733  loss_mask: 0.0197    time: 0.1668  last_time: 0.1681  data_time: 0.0030  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:46:44] d2.utils.events INFO:  eta: 0:02:08  iter: 14219  total_loss: 0.4417  loss_ce: 0.002275  loss_objectness: 0.3333  loss_dice: 0.08499  loss_mask: 0.016    time: 0.1668  last_time: 0.1657  data_time: 0.0029  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:46:48] d2.utils.events INFO:  eta: 0:02:05  iter: 14239  total_loss: 0.5051  loss_ce: 0.002613  loss_objectness: 0.3915  loss_dice: 0.08476  loss_mask: 0.01631    time: 0.1668  last_time: 0.1642  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:46:51] d2.utils.events INFO:  eta: 0:02:02  iter: 14259  total_loss: 0.4164  loss_ce: 0.0007171  loss_objectness: 0.3361  loss_dice: 0.06653  loss_mask: 0.01913    time: 0.1668  last_time: 0.1642  data_time: 0.0027  last_data_time: 0.0022   lr: 5e-06  max_mem: 1637M
[11/23 00:46:54] d2.utils.events INFO:  eta: 0:01:58  iter: 14279  total_loss: 0.4876  loss_ce: 0.00461  loss_objectness: 0.3916  loss_dice: 0.08084  loss_mask: 0.01719    time: 0.1668  last_time: 0.1665  data_time: 0.0030  last_data_time: 0.0032   lr: 5e-06  max_mem: 1637M
[11/23 00:46:58] d2.utils.events INFO:  eta: 0:01:55  iter: 14299  total_loss: 0.494  loss_ce: 0.003656  loss_objectness: 0.3439  loss_dice: 0.07476  loss_mask: 0.01545    time: 0.1668  last_time: 0.1644  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:47:01] d2.utils.events INFO:  eta: 0:01:52  iter: 14319  total_loss: 0.4268  loss_ce: 0.001403  loss_objectness: 0.3334  loss_dice: 0.06591  loss_mask: 0.01527    time: 0.1668  last_time: 0.1647  data_time: 0.0029  last_data_time: 0.0029   lr: 5e-06  max_mem: 1637M
[11/23 00:47:04] d2.utils.events INFO:  eta: 0:01:48  iter: 14339  total_loss: 0.5133  loss_ce: 0.003289  loss_objectness: 0.3881  loss_dice: 0.0927  loss_mask: 0.01696    time: 0.1668  last_time: 0.1664  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-06  max_mem: 1637M
[11/23 00:47:08] d2.utils.events INFO:  eta: 0:01:45  iter: 14359  total_loss: 0.4062  loss_ce: 0.0006442  loss_objectness: 0.3297  loss_dice: 0.06985  loss_mask: 0.01434    time: 0.1668  last_time: 0.1649  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:47:11] d2.utils.events INFO:  eta: 0:01:42  iter: 14379  total_loss: 0.4203  loss_ce: 0.0001511  loss_objectness: 0.3371  loss_dice: 0.06743  loss_mask: 0.01726    time: 0.1668  last_time: 0.1657  data_time: 0.0029  last_data_time: 0.0031   lr: 5e-06  max_mem: 1637M
[11/23 00:47:14] d2.utils.events INFO:  eta: 0:01:39  iter: 14399  total_loss: 0.4539  loss_ce: 0.0008898  loss_objectness: 0.3675  loss_dice: 0.06865  loss_mask: 0.01827    time: 0.1668  last_time: 0.1636  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:47:18] d2.utils.events INFO:  eta: 0:01:35  iter: 14419  total_loss: 0.4921  loss_ce: 0.000612  loss_objectness: 0.3815  loss_dice: 0.07796  loss_mask: 0.01532    time: 0.1668  last_time: 0.1652  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-06  max_mem: 1637M
[11/23 00:47:21] d2.utils.events INFO:  eta: 0:01:32  iter: 14439  total_loss: 0.4923  loss_ce: 0.0005276  loss_objectness: 0.394  loss_dice: 0.06859  loss_mask: 0.01462    time: 0.1668  last_time: 0.1632  data_time: 0.0030  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:47:24] d2.utils.events INFO:  eta: 0:01:29  iter: 14459  total_loss: 0.4461  loss_ce: 0.001087  loss_objectness: 0.3552  loss_dice: 0.07446  loss_mask: 0.01433    time: 0.1668  last_time: 0.1643  data_time: 0.0028  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:47:28] d2.utils.events INFO:  eta: 0:01:25  iter: 14479  total_loss: 0.4351  loss_ce: 0.001611  loss_objectness: 0.3467  loss_dice: 0.06969  loss_mask: 0.01557    time: 0.1668  last_time: 0.1646  data_time: 0.0028  last_data_time: 0.0030   lr: 5e-06  max_mem: 1637M
[11/23 00:47:31] d2.utils.events INFO:  eta: 0:01:22  iter: 14499  total_loss: 0.4699  loss_ce: 0.0007083  loss_objectness: 0.3601  loss_dice: 0.07868  loss_mask: 0.01584    time: 0.1668  last_time: 0.1651  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:47:34] d2.utils.events INFO:  eta: 0:01:19  iter: 14519  total_loss: 0.464  loss_ce: 0.002407  loss_objectness: 0.3789  loss_dice: 0.06618  loss_mask: 0.01517    time: 0.1668  last_time: 0.1674  data_time: 0.0027  last_data_time: 0.0023   lr: 5e-06  max_mem: 1637M
[11/23 00:47:38] d2.utils.events INFO:  eta: 0:01:15  iter: 14539  total_loss: 0.4967  loss_ce: 0.002174  loss_objectness: 0.3852  loss_dice: 0.07132  loss_mask: 0.01868    time: 0.1668  last_time: 0.1674  data_time: 0.0029  last_data_time: 0.0027   lr: 5e-06  max_mem: 1637M
[11/23 00:47:41] d2.utils.events INFO:  eta: 0:01:12  iter: 14559  total_loss: 0.4378  loss_ce: 0.001709  loss_objectness: 0.3487  loss_dice: 0.06304  loss_mask: 0.01411    time: 0.1668  last_time: 0.1635  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:47:44] d2.utils.events INFO:  eta: 0:01:09  iter: 14579  total_loss: 0.4545  loss_ce: 0.00169  loss_objectness: 0.3476  loss_dice: 0.06903  loss_mask: 0.01368    time: 0.1668  last_time: 0.1669  data_time: 0.0034  last_data_time: 0.0029   lr: 5e-06  max_mem: 1637M
[11/23 00:47:48] d2.utils.events INFO:  eta: 0:01:06  iter: 14599  total_loss: 0.4153  loss_ce: 0.0007232  loss_objectness: 0.3293  loss_dice: 0.06667  loss_mask: 0.01685    time: 0.1668  last_time: 0.1650  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:47:51] d2.utils.events INFO:  eta: 0:01:02  iter: 14619  total_loss: 0.4422  loss_ce: 0.0005357  loss_objectness: 0.3439  loss_dice: 0.08062  loss_mask: 0.01589    time: 0.1668  last_time: 0.1652  data_time: 0.0030  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:47:54] d2.utils.events INFO:  eta: 0:00:59  iter: 14639  total_loss: 0.4144  loss_ce: 0.0003668  loss_objectness: 0.3321  loss_dice: 0.07296  loss_mask: 0.01507    time: 0.1668  last_time: 0.1673  data_time: 0.0027  last_data_time: 0.0031   lr: 5e-06  max_mem: 1637M
[11/23 00:47:58] d2.utils.events INFO:  eta: 0:00:56  iter: 14659  total_loss: 0.4302  loss_ce: 0.0003045  loss_objectness: 0.3412  loss_dice: 0.06556  loss_mask: 0.01511    time: 0.1668  last_time: 0.1660  data_time: 0.0028  last_data_time: 0.0032   lr: 5e-06  max_mem: 1637M
[11/23 00:48:01] d2.utils.events INFO:  eta: 0:00:52  iter: 14679  total_loss: 0.4989  loss_ce: 0.0008354  loss_objectness: 0.3837  loss_dice: 0.06967  loss_mask: 0.01741    time: 0.1668  last_time: 0.1675  data_time: 0.0029  last_data_time: 0.0036   lr: 5e-06  max_mem: 1637M
[11/23 00:48:04] d2.utils.events INFO:  eta: 0:00:49  iter: 14699  total_loss: 0.4386  loss_ce: 0.0003815  loss_objectness: 0.3521  loss_dice: 0.06548  loss_mask: 0.01817    time: 0.1668  last_time: 0.1668  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:48:08] d2.utils.events INFO:  eta: 0:00:46  iter: 14719  total_loss: 0.4658  loss_ce: 0.002124  loss_objectness: 0.37  loss_dice: 0.06564  loss_mask: 0.0135    time: 0.1668  last_time: 0.1734  data_time: 0.0029  last_data_time: 0.0035   lr: 5e-06  max_mem: 1637M
[11/23 00:48:11] d2.utils.events INFO:  eta: 0:00:42  iter: 14739  total_loss: 0.4096  loss_ce: 0.001504  loss_objectness: 0.3347  loss_dice: 0.06394  loss_mask: 0.01597    time: 0.1668  last_time: 0.1654  data_time: 0.0029  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:48:14] d2.utils.events INFO:  eta: 0:00:39  iter: 14759  total_loss: 0.49  loss_ce: 0.002873  loss_objectness: 0.3664  loss_dice: 0.1025  loss_mask: 0.01532    time: 0.1668  last_time: 0.1649  data_time: 0.0030  last_data_time: 0.0023   lr: 5e-06  max_mem: 1637M
[11/23 00:48:18] d2.utils.events INFO:  eta: 0:00:36  iter: 14779  total_loss: 0.4373  loss_ce: 0.0001485  loss_objectness: 0.3232  loss_dice: 0.05799  loss_mask: 0.01755    time: 0.1668  last_time: 0.1666  data_time: 0.0027  last_data_time: 0.0028   lr: 5e-06  max_mem: 1637M
[11/23 00:48:21] d2.utils.events INFO:  eta: 0:00:33  iter: 14799  total_loss: 0.4138  loss_ce: 0.0006329  loss_objectness: 0.3432  loss_dice: 0.06595  loss_mask: 0.01471    time: 0.1668  last_time: 0.1649  data_time: 0.0029  last_data_time: 0.0028   lr: 5e-06  max_mem: 1637M
[11/23 00:48:24] d2.utils.events INFO:  eta: 0:00:29  iter: 14819  total_loss: 0.4277  loss_ce: 0.0005067  loss_objectness: 0.3352  loss_dice: 0.06187  loss_mask: 0.0151    time: 0.1668  last_time: 0.1640  data_time: 0.0028  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:48:28] d2.utils.events INFO:  eta: 0:00:26  iter: 14839  total_loss: 0.4781  loss_ce: 0.002718  loss_objectness: 0.3537  loss_dice: 0.07146  loss_mask: 0.01503    time: 0.1668  last_time: 0.1638  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:48:31] d2.utils.events INFO:  eta: 0:00:23  iter: 14859  total_loss: 0.4974  loss_ce: 0.000851  loss_objectness: 0.3868  loss_dice: 0.08152  loss_mask: 0.01781    time: 0.1668  last_time: 0.1657  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:48:34] d2.utils.events INFO:  eta: 0:00:19  iter: 14879  total_loss: 0.3958  loss_ce: 0.0006006  loss_objectness: 0.3049  loss_dice: 0.05668  loss_mask: 0.01863    time: 0.1668  last_time: 0.1635  data_time: 0.0027  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:48:38] d2.utils.events INFO:  eta: 0:00:16  iter: 14899  total_loss: 0.4083  loss_ce: 0.0007133  loss_objectness: 0.3346  loss_dice: 0.05718  loss_mask: 0.01508    time: 0.1668  last_time: 0.1669  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:48:41] d2.utils.events INFO:  eta: 0:00:13  iter: 14919  total_loss: 0.4525  loss_ce: 0.0005657  loss_objectness: 0.3667  loss_dice: 0.07419  loss_mask: 0.01458    time: 0.1668  last_time: 0.1676  data_time: 0.0030  last_data_time: 0.0043   lr: 5e-06  max_mem: 1637M
[11/23 00:48:44] d2.utils.events INFO:  eta: 0:00:09  iter: 14939  total_loss: 0.4232  loss_ce: 0.0009211  loss_objectness: 0.3547  loss_dice: 0.05973  loss_mask: 0.01842    time: 0.1668  last_time: 0.1637  data_time: 0.0029  last_data_time: 0.0026   lr: 5e-06  max_mem: 1637M
[11/23 00:48:48] d2.utils.events INFO:  eta: 0:00:06  iter: 14959  total_loss: 0.3813  loss_ce: 0.0006159  loss_objectness: 0.3056  loss_dice: 0.05828  loss_mask: 0.01633    time: 0.1668  last_time: 0.1639  data_time: 0.0027  last_data_time: 0.0025   lr: 5e-06  max_mem: 1637M
[11/23 00:48:51] d2.utils.events INFO:  eta: 0:00:03  iter: 14979  total_loss: 0.453  loss_ce: 0.001764  loss_objectness: 0.3731  loss_dice: 0.06355  loss_mask: 0.01251    time: 0.1668  last_time: 0.1657  data_time: 0.0029  last_data_time: 0.0033   lr: 5e-06  max_mem: 1637M
[11/23 00:48:54] fvcore.common.checkpoint INFO: Saving checkpoint to output/crack_gabor_turbo\model_0014999.pth
[11/23 00:48:55] fvcore.common.checkpoint INFO: Saving checkpoint to output/crack_gabor_turbo\model_final.pth
[11/23 00:48:55] d2.utils.events INFO:  eta: 0:00:00  iter: 14999  total_loss: 0.4496  loss_ce: 0.0004507  loss_objectness: 0.3493  loss_dice: 0.06301  loss_mask: 0.01753    time: 0.1668  last_time: 0.1705  data_time: 0.0028  last_data_time: 0.0024   lr: 5e-06  max_mem: 1637M
[11/23 00:48:55] d2.engine.hooks INFO: Overall training speed: 14998 iterations in 0:41:41 (0.1668 s / it)
[11/23 00:48:55] d2.engine.hooks INFO: Total training time: 0:45:08 (0:03:27 on hooks)
[11/23 00:48:55] d2.data.datasets.coco INFO: Loaded 120 images in COCO format from datasets/DeepCrack/annotations/val.json
[11/23 00:48:55] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=853, sample_style='choice')]
[11/23 00:48:55] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/23 00:48:55] d2.data.common INFO: Serializing 120 elements to byte tensors and concatenating them all ...
[11/23 00:48:55] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[11/23 00:48:55] d2.evaluation.evaluator INFO: Start inference on 120 batches
[11/23 00:49:01] d2.evaluation.evaluator INFO: Inference done 11/120. Dataloading: 0.0003 s/iter. Inference: 0.0196 s/iter. Eval: 0.0176 s/iter. Total: 0.0375 s/iter. ETA=0:00:04
[11/23 00:49:06] d2.evaluation.evaluator INFO: Total inference time: 0:00:05.501652 (0.047840 s / iter per device, on 1 devices)
[11/23 00:49:06] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:02 (0.019691 s / iter per device, on 1 devices)
[11/23 00:49:06] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/23 00:49:06] d2.evaluation.coco_evaluation INFO: Saving results to output/crack_gabor_turbo\inference\coco_instances_results.json
[11/23 00:49:06] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/23 00:49:07] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/23 00:49:07] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.03 seconds.
[11/23 00:49:07] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/23 00:49:07] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[11/23 00:49:07] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 6.864 | 13.540 | 7.269  | 0.151 | 13.871 | 53.303 |
[11/23 00:49:07] d2.engine.defaults INFO: Evaluation results for deepcracks_val in csv format:
[11/23 00:49:07] d2.evaluation.testing INFO: copypaste: Task: segm
[11/23 00:49:07] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/23 00:49:07] d2.evaluation.testing INFO: copypaste: 6.8642,13.5401,7.2685,0.1506,13.8714,53.3034
